[{"id": "acronym_identification", "sha": "c3c245a18bbd57b1682b099e14460eebf154cbdf", "lastModified": "2023-01-25T14:18:28.000Z", "tags": ["task_categories:token-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "acronym-identification", "arxiv:2010.14678", "region:us"], "private": false, "author": null, "description": "Acronym identification training and development sets for the acronym identification task at SDU@AAAI-21.", "citation": "@inproceedings{veyseh-et-al-2020-what,\n   title={{What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation}},\n   author={Amir Pouran Ben Veyseh and Franck Dernoncourt and Quan Hung Tran and Thien Huu Nguyen},\n   year={2020},\n   booktitle={Proceedings of COLING},\n   link={https://arxiv.org/pdf/2010.14678v1.pdf}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d58", "disabled": false, "gated": false, "likes": 17, "downloads": 1873, "paperswithcode_id": "acronym-identification", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ade_corpus_v2", "sha": "080cf99e1483008322d612c7262c04c8902fdbee", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_ids:coreference-resolution", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": " ADE-Corpus-V2  Dataset: Adverse Drug Reaction Data.\n This is a dataset for Classification if a sentence is ADE-related (True) or not (False) and Relation Extraction between Adverse Drug Event and Drug.\n DRUG-AE.rel provides relations between drugs and adverse effects.\n DRUG-DOSE.rel provides relations between drugs and dosages.\n ADE-NEG.txt provides all sentences in the ADE corpus that DO NOT contain any drug-related adverse effects.", "citation": "@article{GURULINGAPPA2012885,\ntitle = \"Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports\",\njournal = \"Journal of Biomedical Informatics\",\nvolume = \"45\",\nnumber = \"5\",\npages = \"885 - 892\",\nyear = \"2012\",\nnote = \"Text Mining and Natural Language Processing in Pharmacogenomics\",\nissn = \"1532-0464\",\ndoi = \"https://doi.org/10.1016/j.jbi.2012.04.008\",\nurl = \"http://www.sciencedirect.com/science/article/pii/S1532046412000615\",\nauthor = \"Harsha Gurulingappa and Abdul Mateen Rajput and Angus Roberts and Juliane Fluck and Martin Hofmann-Apitius and Luca Toldo\",\nkeywords = \"Adverse drug effect, Benchmark corpus, Annotation, Harmonization, Sentence classification\",\nabstract = \"A significant amount of information about drug-related safety issues such as adverse effects are published in medical case reports that can only be explored by human readers due to their unstructured nature. The work presented here aims at generating a systematically annotated corpus that can support the development and validation of methods for the automatic extraction of drug-related adverse effects from medical case reports. The documents are systematically double annotated in various rounds to ensure consistent annotations. The annotated documents are finally harmonized to generate representative consensus annotations. In order to demonstrate an example use case scenario, the corpus was employed to train and validate models for the classification of informative against the non-informative sentences. A Maximum Entropy classifier trained with simple features and evaluated by 10-fold cross-validation resulted in the F1 score of 0.70 indicating a potential useful application of the corpus.\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d59", "disabled": false, "gated": false, "likes": 20, "downloads": 2423, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "adversarial_qa", "sha": "2101a4597c2b5517902e2eef903c47b2caedacd8", "lastModified": "2022-11-18T17:31:37.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:2002.00293", "arxiv:1606.05250", "region:us"], "private": false, "author": null, "description": "AdversarialQA is a Reading Comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles using an adversarial model-in-the-loop.\nWe use three different models; BiDAF (Seo et al., 2016), BERT-Large (Devlin et al., 2018), and RoBERTa-Large (Liu et al., 2019) in the annotation loop and construct three datasets; D(BiDAF), D(BERT), and D(RoBERTa), each with 10,000 training examples, 1,000 validation, and 1,000 test examples.\nThe adversarial human annotation paradigm ensures that these datasets consist of questions that current state-of-the-art models (at least the ones used as adversaries in the annotation loop) find challenging.", "citation": "@article{bartolo2020beat,\n    author = {Bartolo, Max and Roberts, Alastair and Welbl, Johannes and Riedel, Sebastian and Stenetorp, Pontus},\n    title = {Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension},\n    journal = {Transactions of the Association for Computational Linguistics},\n    volume = {8},\n    number = {},\n    pages = {662-678},\n    year = {2020},\n    doi = {10.1162/tacl_a_00338},\n    URL = { https://doi.org/10.1162/tacl_a_00338 },\n    eprint = { https://doi.org/10.1162/tacl_a_00338 },\n    abstract = { Innovations in annotation methodology have been a catalyst for Reading Comprehension (RC) datasets and models. One recent trend to challenge current RC models is to involve a model in the annotation process: Humans create questions adversarially, such that the model fails to answer them correctly. In this work we investigate this annotation methodology and apply it in three different settings, collecting a total of 36,000 samples with progressively stronger models in the annotation loop. This allows us to explore questions such as the reproducibility of the adversarial effect, transfer from data collected with varying model-in-the-loop strengths, and generalization to data collected without a model. We find that training on adversarially collected samples leads to strong generalization to non-adversarially collected datasets, yet with progressive performance deterioration with increasingly stronger models-in-the-loop. Furthermore, we find that stronger models can still learn from datasets collected with substantially weaker models-in-the-loop. When trained on data collected with a BiDAF model in the loop, RoBERTa achieves 39.9F1 on questions that it cannot answer when trained on SQuAD\u2014only marginally lower than when trained on data collected using RoBERTa itself (41.0F1). }\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5a", "disabled": false, "gated": false, "likes": 30, "downloads": 5708, "paperswithcode_id": "adversarialqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "aeslc", "sha": "28d4d3a046750bf18995a77dfb9f5f082fe837f6", "lastModified": "2023-04-05T08:32:58.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "aspect-based-summarization", "conversations-summarization", "multi-document-summarization", "email-headline-generation", "arxiv:1906.03497", "region:us"], "private": false, "author": null, "description": "A collection of email messages of employees in the Enron Corporation.\n\nThere are two features:\n  - email_body: email body text.\n  - subject_line: email subject text.", "citation": "@misc{zhang2019email,\n    title={This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation},\n    author={Rui Zhang and Joel Tetreault},\n    year={2019},\n    eprint={1906.03497},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5b", "disabled": false, "gated": false, "likes": 6, "downloads": 1738, "paperswithcode_id": "aeslc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "afrikaans_ner_corpus", "sha": "58eb3b7ec689e17d42ffd858b8e514cbd0ffbc7f", "lastModified": "2023-01-25T14:20:30.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:af", "license:other", "region:us"], "private": false, "author": null, "description": "Named entity annotated data from the NCHLT Text Resource Development: Phase II Project, annotated with PERSON, LOCATION, ORGANISATION and MISCELLANEOUS tags.", "citation": "@inproceedings{afrikaans_ner_corpus,\n  author    = {\tGerhard van Huyssteen and\n                Martin Puttkammer and\n                E.B. Trollip and\n                J.C. Liversage and\n              Roald Eiselen},\n  title     = {NCHLT Afrikaans Named Entity Annotated Corpus},\n  booktitle = {Eiselen, R. 2016. Government domain named entity recognition for South African languages. Proceedings of the 10th      Language Resource and Evaluation Conference, Portoro\u017e, Slovenia.},\n  year      = {2016},\n  url       = {https://repo.sadilar.org/handle/20.500.12185/299},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5c", "disabled": false, "gated": false, "likes": 3, "downloads": 505, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ag_news", "sha": "3dcafdc56638659831698aaa2348334a5ab44513", "lastModified": "2023-04-05T08:34:57.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "AG is a collection of more than 1 million news articles. News articles have been\ngathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\nactivity. ComeToMyHead is an academic news search engine which has been running\nsince July, 2004. The dataset is provided by the academic comunity for research\npurposes in data mining (clustering, classification, etc), information retrieval\n(ranking, search, etc), xml, data compression, data streaming, and any other\nnon-commercial activity. For more information, please refer to the link\nhttp://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n\nThe AG's news topic classification dataset is constructed by Xiang Zhang\n(xiang.zhang@nyu.edu) from the dataset above. It is used as a text\nclassification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\nLeCun. Character-level Convolutional Networks for Text Classification. Advances\nin Neural Information Processing Systems 28 (NIPS 2015).", "citation": "@inproceedings{Zhang2015CharacterlevelCN,\n  title={Character-level Convolutional Networks for Text Classification},\n  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},\n  booktitle={NIPS},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5d", "disabled": false, "gated": false, "likes": 78, "downloads": 29760, "paperswithcode_id": "ag-news", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ai2_arc", "sha": "870fda1dc455fb8aec468816fb61c29c602c21ba", "lastModified": "2023-04-05T09:11:00.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:multiple-choice-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "A new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14 million science sentences relevant to the task, and an implementation of three neural baseline models for this dataset. We pose ARC as a challenge to the community.", "citation": "@article{allenai:arc,\n      author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and\n                    Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},\n      title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},\n      journal   = {arXiv:1803.05457v1},\n      year      = {2018},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5e", "disabled": false, "gated": false, "likes": 34, "downloads": 272398, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "air_dialogue", "sha": "3ef284c2b1ca63cebd46335641fa31b09763f4e5", "lastModified": "2022-11-03T16:31:11.000Z", "tags": ["task_categories:conversational", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-generation", "task_ids:dialogue-modeling", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "AirDialogue, is a large dataset that contains 402,038 goal-oriented conversations. To collect this dataset, we create a contextgenerator which provides travel and flight restrictions. Then the human annotators are asked to play the role of a customer or an agent and interact with the goal of successfully booking a trip given the restrictions.", "citation": "@inproceedings{wei-etal-2018-airdialogue,\n    title = \"{A}ir{D}ialogue: An Environment for Goal-Oriented Dialogue Research\",\n    author = \"Wei, Wei  and\n      Le, Quoc  and\n      Dai, Andrew  and\n      Li, Jia\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D18-1419\",\n    doi = \"10.18653/v1/D18-1419\",\n    pages = \"3844--3854\",\n    abstract = \"Recent progress in dialogue generation has inspired a number of studies on dialogue systems that are capable of accomplishing tasks through natural language interactions. A promising direction among these studies is the use of reinforcement learning techniques, such as self-play, for training dialogue agents. However, current datasets are limited in size, and the environment for training agents and evaluating progress is relatively unsophisticated. We present AirDialogue, a large dataset that contains 301,427 goal-oriented conversations. To collect this dataset, we create a context-generator which provides travel and flight restrictions. We then ask human annotators to play the role of a customer or an agent and interact with the goal of successfully booking a trip given the restrictions. Key to our environment is the ease of evaluating the success of the dialogue, which is achieved by using ground-truth states (e.g., the flight being booked) generated by the restrictions. Any dialogue agent that does not generate the correct states is considered to fail. Our experimental results indicate that state-of-the-art dialogue models can only achieve a score of 0.17 while humans can reach a score of 0.91, which suggests significant opportunities for future improvement.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d5f", "disabled": false, "gated": false, "likes": 6, "downloads": 615, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ajgt_twitter_ar", "sha": "8016dcbb32739004bd1fc36dd0bcc97381dcb7f1", "lastModified": "2023-01-25T14:26:05.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "Arabic Jordanian General Tweets (AJGT) Corpus consisted of 1,800 tweets annotated as positive and negative. Modern Standard Arabic (MSA) or Jordanian dialect.", "citation": "@inproceedings{alomari2017arabic,\n  title={Arabic tweets sentimental analysis using machine learning},\n  author={Alomari, Khaled Mohammad and ElSherif, Hatem M and Shaalan, Khaled},\n  booktitle={International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},\n  pages={602--610},\n  year={2017},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d60", "disabled": false, "gated": false, "likes": 3, "downloads": 541, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allegro_reviews", "sha": "640d5c0c0cf44fba49bfa7fd4d29e7feb51bde21", "lastModified": "2022-11-18T17:41:41.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-scoring", "task_ids:text-scoring", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "Allegro Reviews is a sentiment analysis dataset, consisting of 11,588 product reviews written in Polish and extracted\nfrom Allegro.pl - a popular e-commerce marketplace. Each review contains at least 50 words and has a rating on a scale\nfrom one (negative review) to five (positive review).\n\nWe recommend using the provided train/dev/test split. The ratings for the test set reviews are kept hidden.\nYou can evaluate your model using the online evaluation tool available on klejbenchmark.com.", "citation": "@inproceedings{rybak-etal-2020-klej,\n    title = \"{KLEJ}: Comprehensive Benchmark for Polish Language Understanding\",\n    author = \"Rybak, Piotr and Mroczkowski, Robert and Tracz, Janusz and Gawlik, Ireneusz\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.111\",\n    pages = \"1191--1201\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d61", "disabled": false, "gated": false, "likes": 1, "downloads": 461, "paperswithcode_id": "allegro-reviews", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allocine", "sha": "c090a3d204bed7b4a51adaaa6c1fe638cf9246c1", "lastModified": "2023-01-25T14:26:09.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:fr", "license:mit", "region:us"], "private": false, "author": null, "description": " Allocine Dataset: A Large-Scale French Movie Reviews Dataset.\n This is a dataset for binary sentiment classification, made of user reviews scraped from Allocine.fr.\n It contains 100k positive and 100k negative reviews divided into 3 balanced splits: train (160k reviews), val (20k) and test (20k).", "citation": "@misc{blard2019allocine,\n  author = {Blard, Theophile},\n  title = {french-sentiment-analysis-with-bert},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished={\\\\url{https://github.com/TheophileBlard/french-sentiment-analysis-with-bert}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d62", "disabled": false, "gated": false, "likes": 6, "downloads": 648, "paperswithcode_id": "allocine", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "alt", "sha": "1e036053e9a853af165ad831f6797a1247307f5a", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "task_categories:token-classification", "task_ids:parsing", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "multilinguality:translation", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:bn", "language:en", "language:fil", "language:hi", "language:id", "language:ja", "language:km", "language:lo", "language:ms", "language:my", "language:th", "language:vi", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. The process of building ALT began with sampling about 20,000 sentences from English Wikinews, and then these sentences were translated into the other languages. ALT now has 13 languages: Bengali, English, Filipino, Hindi, Bahasa Indonesia, Japanese, Khmer, Lao, Malay, Myanmar (Burmese), Thai, Vietnamese, Chinese (Simplified Chinese).", "citation": "@inproceedings{riza2016introduction,\n  title={Introduction of the asian language treebank},\n  author={Riza, Hammam and Purwoadi, Michael and Uliniansyah, Teduh and Ti, Aw Ai and Aljunied, Sharifah Mahani and Mai, Luong Chi and Thang, Vu Tat and Thai, Nguyen Phuong and Chea, Vichet and Sam, Sethserey and others},\n  booktitle={2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)},\n  pages={1--6},\n  year={2016},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d63", "disabled": false, "gated": false, "likes": 7, "downloads": 1681, "paperswithcode_id": "alt", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "amazon_polarity", "sha": "b19c47c74e5660014c166f3e0978b5c449718d5a", "lastModified": "2023-01-25T14:26:12.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1509.01626", "region:us"], "private": false, "author": null, "description": "The Amazon reviews dataset consists of reviews from amazon.\nThe data span a period of 18 years, including ~35 million reviews up to March 2013.\nReviews include product and user information, ratings, and a plaintext review.", "citation": "@inproceedings{mcauley2013hidden,\n  title={Hidden factors and hidden topics: understanding rating dimensions with review text},\n  author={McAuley, Julian and Leskovec, Jure},\n  booktitle={Proceedings of the 7th ACM conference on Recommender systems},\n  pages={165--172},\n  year={2013}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d64", "disabled": false, "gated": false, "likes": 30, "downloads": 11831, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "amazon_reviews_multi", "sha": "b6115b04af1d02b3c30849bdd4c55899bff0ae63", "lastModified": "2023-11-02T14:52:21.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:text-scoring", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:ja", "language:zh", "license:other", "arxiv:2010.02573", "region:us"], "private": false, "author": null, "description": "We provide an Amazon product reviews dataset for multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. \u2018books\u2019, \u2018appliances\u2019, etc.) The corpus is balanced across stars, so each star rating constitutes 20% of the reviews in each language.\n\nFor each language, there are 200,000, 5,000 and 5,000 reviews in the training, development and test sets respectively. The maximum number of reviews per reviewer is 20 and the maximum number of reviews per product is 20. All reviews are truncated after 2,000 characters, and all reviews are at least 20 characters long.\n\nNote that the language of a review does not necessarily match the language of its marketplace (e.g. reviews from amazon.de are primarily written in German, but could also be written in English, etc.). For this reason, we applied a language detection algorithm based on the work in Bojanowski et al. (2017) to determine the language of the review text and we removed reviews that were not written in the expected language.", "citation": "@inproceedings{marc_reviews,\n    title={The Multilingual Amazon Reviews Corpus},\n    author={Keung, Phillip and Lu, Yichao and Szarvas, Gy\u00f6rgy and Smith, Noah A.},\n    booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d65", "disabled": false, "gated": false, "likes": 81, "downloads": 2729, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "amazon_us_reviews", "sha": "e1bfd57e2da5dc7dc4c748eb4a4a112c71e85162", "lastModified": "2023-11-02T14:57:03.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:text-scoring", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:topic-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100M<n<1B", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Amazon Customer Reviews (a.k.a. Product Reviews) is one of Amazons iconic products. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed over a hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Accordingly, we are releasing this data to further research in multiple disciplines related to understanding customer product experiences. Specifically, this dataset was constructed to represent a sample of customer evaluations and opinions, variation in the perception of a product across geographical regions, and promotional intent or bias in reviews.\n\nOver 130+ million customer reviews are available to researchers as part of this release. The data is available in TSV files in the amazon-reviews-pds S3 bucket in AWS US East Region. Each line in the data files corresponds to an individual review (tab delimited, with no quote and escape characters).\n\nEach Dataset contains the following columns:\n\n- marketplace: 2 letter country code of the marketplace where the review was written.\n- customer_id: Random identifier that can be used to aggregate reviews written by a single author.\n- review_id: The unique ID of the review.\n- product_id: The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same product_id.\n- product_parent: Random identifier that can be used to aggregate reviews for the same product.\n- product_title: Title of the product.\n- product_category: Broad product category that can be used to group reviews (also used to group the dataset into coherent parts).\n- star_rating: The 1-5 star rating of the review.\n- helpful_votes: Number of helpful votes.\n- total_votes: Number of total votes the review received.\n- vine: Review was written as part of the Vine program.\n- verified_purchase: The review is on a verified purchase.\n- review_headline: The title of the review.\n- review_body: The review text.\n- review_date: The date the review was written.", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d66", "disabled": false, "gated": false, "likes": 56, "downloads": 8264, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ambig_qa", "sha": "4b3c61e4acf755a804e74bc7186e2599ecec36ad", "lastModified": "2022-11-03T16:31:34.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|natural_questions", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "arxiv:2004.10645", "region:us"], "private": false, "author": null, "description": "AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark. We find that over half of the questions in NQ-open are ambiguous. The types of ambiguity are diverse and sometimes subtle, many of which are only apparent after examining evidence provided by a very large text corpus.  AMBIGNQ, a dataset with\n14,042 annotations on NQ-OPEN questions containing diverse types of ambiguity.\nWe provide two distributions of our new dataset AmbigNQ: a full version with all annotation metadata and a light version with only inputs and outputs.", "citation": "@inproceedings{ min2020ambigqa,\n    title={ {A}mbig{QA}: Answering Ambiguous Open-domain Questions },\n    author={ Min, Sewon and Michael, Julian and Hajishirzi, Hannaneh and Zettlemoyer, Luke },\n    booktitle={ EMNLP },\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d67", "disabled": false, "gated": false, "likes": 2, "downloads": 832, "paperswithcode_id": "ambigqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "americas_nli", "sha": "e0b2b54a22e1987d4df45035bd0d354ac0d16d2b", "lastModified": "2023-01-25T14:26:20.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|xnli", "language:ay", "language:bzd", "language:cni", "language:gn", "language:hch", "language:nah", "language:oto", "language:qu", "language:shp", "language:tar", "license:unknown", "arxiv:2104.08726", "region:us"], "private": false, "author": null, "description": "AmericasNLI is an extension of XNLI (Conneau et al., 2018) \u2013 a natural language inference (NLI) dataset covering 15 high-resource languages \u2013 to 10 low-resource indigenous languages spoken in the Americas: Ashaninka, Aymara, Bribri, Guarani, Nahuatl, Otomi, Quechua, Raramuri, Shipibo-Konibo, and Wixarika. As with MNLI, the goal is to predict textual entailment (does sentence A imply/contradict/neither sentence B) and is a classification task (given two sentences, predict one of three labels).", "citation": "@article{DBLP:journals/corr/abs-2104-08726,\n  author    = {Abteen Ebrahimi and\n               Manuel Mager and\n               Arturo Oncevay and\n               Vishrav Chaudhary and\n               Luis Chiruzzo and\n               Angela Fan and\n               John Ortega and\n               Ricardo Ramos and\n               Annette Rios and\n               Ivan Vladimir and\n               Gustavo A. Gim{\\'{e}}nez{-}Lugo and\n               Elisabeth Mager and\n               Graham Neubig and\n               Alexis Palmer and\n               Rolando A. Coto Solano and\n               Ngoc Thang Vu and\n               Katharina Kann},\n  title     = {AmericasNLI: Evaluating Zero-shot Natural Language Understanding of\n               Pretrained Multilingual Models in Truly Low-resource Languages},\n  journal   = {CoRR},\n  volume    = {abs/2104.08726},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2104.08726},\n  eprinttype = {arXiv},\n  eprint    = {2104.08726},\n  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08726.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d68", "disabled": false, "gated": false, "likes": 1, "downloads": 2865, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ami", "sha": "0774a5e0099ba9696b9ba00bc3be025d4bb31ccd", "lastModified": "2023-01-17T13:44:21.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The AMI Meeting Corpus consists of 100 hours of meeting recordings. The recordings use a range of signals\nsynchronized to a common timeline. These include close-talking and far-field microphones, individual and\nroom-view video cameras, and output from a slide projector and an electronic whiteboard. During the meetings,\nthe participants also have unsynchronized pens available to them that record what is written. The meetings\nwere recorded in English using three different rooms with different acoustic properties, and include mostly\nnon-native speakers. \\n", "citation": "@inproceedings{10.1007/11677482_3,\nauthor = {Carletta, Jean and Ashby, Simone and Bourban, Sebastien and Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec, Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and Kronenthal, Melissa and Lathoud, Guillaume and Lincoln, Mike and Lisowska, Agnes and McCowan, Iain and Post, Wilfried and Reidsma, Dennis and Wellner, Pierre},\ntitle = {The AMI Meeting Corpus: A Pre-Announcement},\nyear = {2005},\nisbn = {3540325492},\npublisher = {Springer-Verlag},\naddress = {Berlin, Heidelberg},\nurl = {https://doi.org/10.1007/11677482_3},\ndoi = {10.1007/11677482_3},\nabstract = {The AMI Meeting Corpus is a multi-modal data set consisting of 100 hours of meeting\nrecordings. It is being created in the context of a project that is developing meeting\nbrowsing technology and will eventually be released publicly. Some of the meetings\nit contains are naturally occurring, and some are elicited, particularly using a scenario\nin which the participants play different roles in a design team, taking a design project\nfrom kick-off to completion over the course of a day. The corpus is being recorded\nusing a wide range of devices including close-talking and far-field microphones, individual\nand room-view video cameras, projection, a whiteboard, and individual pens, all of\nwhich produce output signals that are synchronized with each other. It is also being\nhand-annotated for many different phenomena, including orthographic transcription,\ndiscourse properties such as named entities and dialogue acts, summaries, emotions,\nand some head and hand gestures. We describe the data set, including the rationale\nbehind using elicited material, and explain how the material is being recorded, transcribed\nand annotated.},\nbooktitle = {Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction},\npages = {28\u201339},\nnumpages = {12},\nlocation = {Edinburgh, UK},\nseries = {MLMI'05}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d69", "disabled": false, "gated": false, "likes": 9, "downloads": 966, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "amttl", "sha": "2c63d54ff21178fe036fb45ed7f2dcb6c0872b15", "lastModified": "2023-01-25T14:26:23.000Z", "tags": ["task_categories:token-classification", "task_ids:parsing", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:mit", "region:us"], "private": false, "author": null, "description": "Chinese word segmentation (CWS) trained from open source corpus faces dramatic performance drop\nwhen dealing with domain text, especially for a domain with lots of special terms and diverse\nwriting styles, such as the biomedical domain. However, building domain-specific CWS requires\nextremely high annotation cost. In this paper, we propose an approach by exploiting domain-invariant\nknowledge from high resource to low resource domains. Extensive experiments show that our mode\nachieves consistently higher accuracy than the single-task CWS and other transfer learning\nbaselines, especially when there is a large disparity between source and target domains.\n\nThis dataset is the accompanied medical Chinese word segmentation (CWS) dataset.\nThe tags are in BIES scheme.\n\nFor more details see https://www.aclweb.org/anthology/C18-1307/", "citation": "@inproceedings{xing2018adaptive,\n  title={Adaptive multi-task transfer learning for Chinese word segmentation in medical text},\n  author={Xing, Junjie and Zhu, Kenny and Zhang, Shaodian},\n  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},\n  pages={3619--3630},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6a", "disabled": false, "gated": false, "likes": 1, "downloads": 358, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "anli", "sha": "bf206833154d4fcaf5e3b01b8bf17d4d15213cb1", "lastModified": "2023-04-05T09:33:23.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "source_datasets:extended|hotpot_qa", "language:en", "license:cc-by-nc-4.0", "arxiv:1910.14599", "region:us"], "private": false, "author": null, "description": "The Adversarial Natural Language Inference (ANLI) is a new large-scale NLI benchmark dataset,\nThe dataset is collected via an iterative, adversarial human-and-model-in-the-loop procedure.\nANLI is much more difficult than its predecessors including SNLI and MNLI.\nIt contains three rounds. Each round has train/dev/test splits.", "citation": "@InProceedings{nie2019adversarial,\n    title={Adversarial NLI: A New Benchmark for Natural Language Understanding},\n    author={Nie, Yixin\n                and Williams, Adina\n                and Dinan, Emily\n                and Bansal, Mohit\n                and Weston, Jason\n                and Kiela, Douwe},\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6b", "disabled": false, "gated": false, "likes": 23, "downloads": 27553, "paperswithcode_id": "anli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "app_reviews", "sha": "0ca262730c1edb7abe4c500005216da26d9b7374", "lastModified": "2022-11-03T16:47:21.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:sentiment-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "It is a large dataset of Android applications belonging to 23 differentapps categories, which provides an overview of the types of feedback users report on the apps and documents the evolution of the related code metrics. The dataset contains about 395 applications of the F-Droid repository, including around 600 versions, 280,000 user reviews (extracted with specific text mining approaches)", "citation": "@InProceedings{Zurich Open Repository and\nArchive:dataset,\ntitle = {Software Applications User Reviews},\nauthors={Grano, Giovanni; Di Sorbo, Andrea; Mercaldo, Francesco; Visaggio, Corrado A; Canfora, Gerardo;\nPanichella, Sebastiano},\nyear={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6c", "disabled": false, "gated": false, "likes": 18, "downloads": 3350, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "aqua_rat", "sha": "a5c302cb30cd42c0cd0d5f60a89e81ae65bb13d5", "lastModified": "2022-11-18T18:20:44.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1705.04146", "region:us"], "private": false, "author": null, "description": "A large-scale dataset consisting of approximately 100,000 algebraic word problems.\nThe solution to each question is explained step-by-step using natural language.\nThis data is used to train a program generation model that learns to generate the explanation,\nwhile generating the program that solves the question.", "citation": "@InProceedings{ACL,\ntitle = {Program induction by rationale generation: Learning to solve and explain algebraic word problems},\nauthors={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},\nyear={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6d", "disabled": false, "gated": false, "likes": 9, "downloads": 1515, "paperswithcode_id": "aqua-rat", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "aquamuse", "sha": "df0c4edce17524955ffcbdc7efb2a2aa7cafa0a1", "lastModified": "2022-11-18T18:21:11.000Z", "tags": ["task_categories:other", "task_categories:question-answering", "task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|natural_questions", "source_datasets:extended|other-Common-Crawl", "source_datasets:original", "language:en", "license:unknown", "query-based-multi-document-summarization", "arxiv:2010.12694", "region:us"], "private": false, "author": null, "description": "AQuaMuSe is a novel scalable approach to automatically mine dual query based multi-document summarization datasets for extractive and abstractive summaries using question answering dataset (Google Natural Questions) and large document corpora (Common Crawl)", "citation": "@misc{kulkarni2020aquamuse,\n      title={AQuaMuSe: Automatically Generating Datasets for Query-Based Multi-Document Summarization},\n      author={Sayali Kulkarni and Sheide Chammas and Wan Zhu and Fei Sha and Eugene Ie},\n      year={2020},\n      eprint={2010.12694},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6e", "disabled": false, "gated": false, "likes": 8, "downloads": 229, "paperswithcode_id": "aquamuse", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bigIR/ar_cov19", "sha": "447b2a5a20c9e8ffaee0f14b31697be7b0dec403", "lastModified": "2023-09-19T06:52:17.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:ar", "data-mining", "arxiv:2004.05861", "region:us"], "private": false, "author": "bigIR", "description": "ArCOV-19 is an Arabic COVID-19 Twitter dataset that covers the period from 27th of January till 30th of April 2020. ArCOV-19 is designed to enable research under several domains including natural language processing, information retrieval, and social computing, among others", "citation": "@article{haouari2020arcov19,\n  title={ArCOV-19: The First Arabic COVID-19 Twitter Dataset with Propagation Networks},\n  author={Fatima Haouari and Maram Hasanain and Reem Suwaileh and Tamer Elsayed},\n  journal={arXiv preprint arXiv:2004.05861},\n  year={2020}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d6f", "disabled": false, "gated": false, "likes": 1, "downloads": 345, "paperswithcode_id": "arcov-19", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ar_res_reviews", "sha": "c00a78aca90ab394a6dad315f331b1bb8875b08c", "lastModified": "2023-01-25T14:26:30.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "Dataset of 8364 restaurant reviews scrapped from qaym.com in Arabic for sentiment analysis", "citation": "@InProceedings{10.1007/978-3-319-18117-2_2,\nauthor=\"ElSahar, Hady\nand El-Beltagy, Samhaa R.\",\neditor=\"Gelbukh, Alexander\",\ntitle=\"Building Large Arabic Multi-domain Resources for Sentiment Analysis\",\nbooktitle=\"Computational Linguistics and Intelligent Text Processing\",\nyear=\"2015\",\npublisher=\"Springer International Publishing\",\naddress=\"Cham\",\npages=\"23--34\",\nisbn=\"978-3-319-18117-2\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d70", "disabled": false, "gated": false, "likes": 5, "downloads": 377, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ar_sarcasm", "sha": "8ed550e17740a8045feaeb8dff398fff6eb3372a", "lastModified": "2023-03-16T14:13:22.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-semeval_2017", "source_datasets:extended|other-astd", "language:ar", "license:mit", "sarcasm-detection", "region:us"], "private": false, "author": null, "description": "ArSarcasm is a new Arabic sarcasm detection dataset.\nThe dataset was created using previously available Arabic sentiment analysis datasets (SemEval 2017 and ASTD)\n and adds sarcasm and dialect labels to them. The dataset contains 10,547 tweets, 1,682 (16%) of which are sarcastic.", "citation": "@inproceedings{abu-farha-magdy-2020-arabic,\n    title = \"From {A}rabic Sentiment Analysis to Sarcasm Detection: The {A}r{S}arcasm Dataset\",\n    author = \"Abu Farha, Ibrahim  and Magdy, Walid\",\n    booktitle = \"Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resource Association\",\n    url = \"https://www.aclweb.org/anthology/2020.osact-1.5\",\n    pages = \"32--39\",\n    language = \"English\",\n    ISBN = \"979-10-95546-51-1\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d71", "disabled": false, "gated": false, "likes": 8, "downloads": 417, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arabic_billion_words", "sha": "aeb210f8a0665bfb3aba23e91f82aa6e78d0c8e6", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:ar", "license:unknown", "arxiv:1611.04033", "region:us"], "private": false, "author": null, "description": "Abu El-Khair Corpus is an Arabic text corpus, that includes more than five million newspaper articles.\nIt contains over a billion and a half words in total, out of which, there are about three million unique words.\nThe corpus is encoded with two types of encoding, namely: UTF-8, and Windows CP-1256.\nAlso it was marked with two mark-up languages, namely: SGML, and XML.", "citation": "@article{el20161,\n  title={1.5 billion words arabic corpus},\n  author={El-Khair, Ibrahim Abu},\n  journal={arXiv preprint arXiv:1611.04033},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d72", "disabled": false, "gated": false, "likes": 13, "downloads": 1740, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arabic_pos_dialect", "sha": "1c36271a1adad5a8b8feb131d44e6fadab5185c8", "lastModified": "2022-11-03T16:31:33.000Z", "tags": ["task_categories:token-classification", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:extended", "language:ar", "license:apache-2.0", "arxiv:1708.05891", "region:us"], "private": false, "author": null, "description": "The Dialectal Arabic Datasets contain four dialects of Arabic, Etyptian (EGY), Levantine (LEV), Gulf (GLF), and Maghrebi (MGR). Each dataset consists of a set of 350 manually segmented and POS tagged tweets.", "citation": "@InProceedings{DARWISH18.562,  author = {Kareem Darwish ,Hamdy Mubarak ,Ahmed Abdelali ,Mohamed Eldesouki ,Younes Samih ,Randah Alharbi ,Mohammed Attia ,Walid Magdy and Laura Kallmeyer},\ntitle = {Multi-Dialect Arabic POS Tagging: A CRF Approach},\nbooktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\nyear = {2018},\nmonth = {may},\ndate = {7-12},\nlocation = {Miyazaki, Japan},\neditor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and H\u00e9l\u00e8ne Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},\npublisher = {European Language Resources Association (ELRA)},\naddress = {Paris, France},\nisbn = {979-10-95546-00-9},\nlanguage = {english}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d73", "disabled": false, "gated": false, "likes": 2, "downloads": 878, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arabic_speech_corpus", "sha": "0ce1cc248c8d909e8581677db6096c5565447173", "lastModified": "2022-11-18T18:29:09.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "This Speech corpus has been developed as part of PhD work carried out by Nawar Halabi at the University of Southampton.\nThe corpus was recorded in south Levantine Arabic\n(Damascian accent) using a professional studio. Synthesized speech as an output using this corpus has produced a high quality, natural voice.\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@phdthesis{halabi2016modern,\n  title={Modern standard Arabic phonetics for speech synthesis},\n  author={Halabi, Nawar},\n  year={2016},\n  school={University of Southampton}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d74", "disabled": false, "gated": false, "likes": 17, "downloads": 1103, "paperswithcode_id": "arabic-speech-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arcd", "sha": "cf18961d83b615154ef5feda04e324136db8c4ac", "lastModified": "2023-04-05T09:35:12.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:mit", "region:us"], "private": false, "author": null, "description": " Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions      posed by crowdworkers on Wikipedia articles.", "citation": "@inproceedings{mozannar-etal-2019-neural,\n    title = {Neural {A}rabic Question Answering},\n    author = {Mozannar, Hussein  and Maamary, Elie  and El Hajal, Karl  and Hajj, Hazem},\n    booktitle = {Proceedings of the Fourth Arabic Natural Language Processing Workshop},\n    month = {aug},\n    year = {2019},\n    address = {Florence, Italy},\n    publisher = {Association for Computational Linguistics},\n    url = {https://www.aclweb.org/anthology/W19-4612},\n    doi = {10.18653/v1/W19-4612},\n    pages = {108--118},\n    abstract = {This paper tackles the problem of open domain factual Arabic question answering (QA) using Wikipedia as our knowledge source. This constrains the answer of any question to be a span of text in Wikipedia. Open domain QA for Arabic entails three challenges: annotated QA datasets in Arabic, large scale efficient information retrieval and machine reading comprehension. To deal with the lack of Arabic QA datasets we present the Arabic Reading Comprehension Dataset (ARCD) composed of 1,395 questions posed by crowdworkers on Wikipedia articles, and a machine translation of the Stanford Question Answering Dataset (Arabic-SQuAD). Our system for open domain question answering in Arabic (SOQAL) is based on two components: (1) a document retriever using a hierarchical TF-IDF approach and (2) a neural reading comprehension model using the pre-trained bi-directional transformer BERT. Our experiments on ARCD indicate the effectiveness of our approach with our BERT-based reader achieving a 61.3 F1 score, and our open domain system SOQAL achieving a 27.6 F1 score.}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d75", "disabled": false, "gated": false, "likes": 3, "downloads": 497, "paperswithcode_id": "arcd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arsentd_lev", "sha": "028b279dab19c1e411f942cc922d70bb17b19c25", "lastModified": "2023-01-25T14:26:36.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:topic-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:apc", "language:ajp", "license:other", "arxiv:1906.01830", "region:us"], "private": false, "author": null, "description": "The Arabic Sentiment Twitter Dataset for Levantine dialect (ArSenTD-LEV) contains 4,000 tweets written in Arabic and equally retrieved from Jordan, Lebanon, Palestine and Syria.", "citation": "@article{ArSenTDLev2018,\ntitle={ArSentD-LEV: A Multi-Topic Corpus for Target-based Sentiment Analysis in Arabic Levantine Tweets},\nauthor={Baly, Ramy, and Khaddaj, Alaa and Hajj, Hazem and El-Hajj, Wassim and Bashir Shaban, Khaled},\njournal={OSACT3},\npages={},\nyear={2018}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d76", "disabled": false, "gated": false, "likes": 3, "downloads": 318, "paperswithcode_id": "arsentd-lev", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "art", "sha": "1ac0124f79d0b65499bbf0a2395e27901c3eba1d", "lastModified": "2023-04-05T09:36:25.000Z", "tags": ["task_categories:multiple-choice", "task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "abductive-natural-language-inference", "arxiv:1908.05739", "region:us"], "private": false, "author": null, "description": "the Abductive Natural Language Inference Dataset from AI2", "citation": "@InProceedings{anli,\n  author = {Chandra, Bhagavatula and Ronan, Le Bras and Chaitanya, Malaviya and Keisuke, Sakaguchi and Ari, Holtzman\n    and Hannah, Rashkin and Doug, Downey and Scott, Wen-tau Yih and Yejin, Choi},\n  title = {Abductive Commonsense Reasoning},\n  year = {2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d77", "disabled": false, "gated": false, "likes": 3, "downloads": 541, "paperswithcode_id": "art-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "arxiv_dataset", "sha": "03f5afc04118f5d2599283e577584ddb3416f9b2", "lastModified": "2023-10-26T10:45:45.000Z", "tags": ["task_categories:translation", "task_categories:summarization", "task_categories:text-retrieval", "task_ids:document-retrieval", "task_ids:entity-linking-retrieval", "task_ids:explanation-generation", "task_ids:fact-checking-retrieval", "task_ids:text-simplification", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc0-1.0", "arxiv:1905.00075", "region:us"], "private": false, "author": null, "description": "A dataset of 1.7 million arXiv articles for applications like trend analysis, paper recommender engines, category prediction, co-citation networks, knowledge graph construction and semantic search interfaces.", "citation": "@misc{clement2019arxiv,\n    title={On the Use of ArXiv as a Dataset},\n    author={Colin B. Clement and Matthew Bierbaum and Kevin P. O'Keeffe and Alexander A. Alemi},\n    year={2019},\n    eprint={1905.00075},\n    archivePrefix={arXiv},\n    primaryClass={cs.IR}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d78", "disabled": false, "gated": false, "likes": 41, "downloads": 624, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ascent_kb", "sha": "3d1fe338bc0a449c4b6ccaa0f31674ed32096231", "lastModified": "2022-11-03T16:30:39.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "knowledge-base", "arxiv:2011.00905", "region:us"], "private": false, "author": null, "description": "This dataset contains 8.9M commonsense assertions extracted by the Ascent pipeline (https://ascent.mpi-inf.mpg.de/).", "citation": "@InProceedings{nguyen2021www,\n  title={Advanced Semantics for Commonsense Knowledge Extraction},\n  author={Nguyen, Tuan-Phong and Razniewski, Simon and Weikum, Gerhard},\n  year={2021},\n  booktitle={The Web Conference 2021},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d79", "disabled": false, "gated": false, "likes": 2, "downloads": 513, "paperswithcode_id": "ascentkb", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "aslg_pc12", "sha": "4e0d9bd4e7f3529509603684b26156d618160d8c", "lastModified": "2023-04-05T09:36:28.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:ase", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "A large synthetic collection of parallel English and ASL-Gloss texts.\nThere are two string features: text, and gloss.", "citation": "@inproceedings{othman2012english,\n  title={English-asl gloss parallel corpus 2012: Aslg-pc12},\n  author={Othman, Achraf and Jemni, Mohamed},\n  booktitle={5th Workshop on the Representation and Processing of Sign Languages: Interactions between Corpus and Lexicon LREC},\n  year={2012}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7a", "disabled": false, "gated": false, "likes": 2, "downloads": 457, "paperswithcode_id": "aslg-pc12", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "asnq", "sha": "772b8e0cc903548bc34b9af7872a64e13345e900", "lastModified": "2023-05-16T08:28:22.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:extended|natural_questions", "language:en", "license:cc-by-nc-sa-3.0", "arxiv:1911.04118", "region:us"], "private": false, "author": null, "description": "ASNQ is a dataset for answer sentence selection derived from\nGoogle's Natural Questions (NQ) dataset (Kwiatkowski et al. 2019).\n\nEach example contains a question, candidate sentence, label indicating whether or not\nthe sentence answers the question, and two additional features --\nsentence_in_long_answer and short_answer_in_sentence indicating whether ot not the\ncandidate sentence is contained in the long_answer and if the short_answer is in the candidate sentence.\n\nFor more details please see\nhttps://arxiv.org/pdf/1911.04118.pdf\n\nand\n\nhttps://research.google/pubs/pub47761/", "citation": "@article{garg2019tanda,\n    title={TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection},\n    author={Siddhant Garg and Thuy Vu and Alessandro Moschitti},\n    year={2019},\n    eprint={1911.04118},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7b", "disabled": false, "gated": false, "likes": 1, "downloads": 409, "paperswithcode_id": "asnq", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "asset", "sha": "b44bea65d455281810ee9c167a55629ac85ace33", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-classification", "task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|other-turkcorpus", "language:en", "license:cc-by-sa-4.0", "simplification-evaluation", "region:us"], "private": false, "author": null, "description": "ASSET is a dataset for evaluating Sentence Simplification systems with multiple rewriting transformations,\nas described in \"ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations\".\nThe corpus is composed of 2000 validation and 359 test original sentences that were each simplified 10 times by different annotators.\nThe corpus also contains human judgments of meaning preservation, fluency and simplicity for the outputs of several automatic text simplification systems.", "citation": "@inproceedings{alva-manchego-etal-2020-asset,\n    title = \"{ASSET}: {A} Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations\",\n    author = \"Alva-Manchego, Fernando  and\n      Martin, Louis  and\n      Bordes, Antoine  and\n      Scarton, Carolina  and\n      Sagot, Benoit  and\n      Specia, Lucia\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.424\",\n    pages = \"4668--4679\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7c", "disabled": false, "gated": false, "likes": 9, "downloads": 785, "paperswithcode_id": "asset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "assin", "sha": "c69f21213a28d2c0ee5e7d9aca908dfebe09eda0", "lastModified": "2023-01-25T14:26:50.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pt", "license:unknown", "region:us"], "private": false, "author": null, "description": "The ASSIN (Avalia\u00e7\u00e3o de Similaridade Sem\u00e2ntica e INfer\u00eancia textual) corpus is a corpus annotated with pairs of sentences written in\nPortuguese that is suitable for the  exploration of textual entailment and paraphrasing classifiers. The corpus contains pairs of sentences\nextracted from news articles written in European Portuguese (EP) and Brazilian Portuguese (BP), obtained from Google News Portugal\nand Brazil, respectively. To create the corpus, the authors started by collecting a set of news articles describing the\nsame event (one news article from Google News Portugal and another from Google News Brazil) from Google News.\nThen, they employed Latent Dirichlet Allocation (LDA) models to retrieve pairs of similar sentences between sets of news\narticles that were grouped together around the same topic. For that, two LDA models were trained (for EP and for BP)\non external and large-scale collections of unannotated news articles from Portuguese and Brazilian news providers, respectively.\nThen, the authors defined a lower and upper threshold for the sentence similarity score of the retrieved pairs of sentences,\ntaking into account that high similarity scores correspond to sentences that contain almost the same content (paraphrase candidates),\nand low similarity scores correspond to sentences that are very different in content from each other (no-relation candidates).\nFrom the collection of pairs of sentences obtained at this stage, the authors performed some manual grammatical corrections\nand discarded some of the pairs wrongly retrieved. Furthermore, from a preliminary analysis made to the retrieved sentence pairs\nthe authors noticed that the number of contradictions retrieved during the previous stage was very low. Additionally, they also\nnoticed that event though paraphrases are not very frequent, they occur with some frequency in news articles. Consequently,\nin contrast with the majority of the currently available corpora for other languages, which consider as labels \u201cneutral\u201d, \u201centailment\u201d\nand \u201ccontradiction\u201d for the task of RTE, the authors of the ASSIN corpus decided to use as labels \u201cnone\u201d, \u201centailment\u201d and \u201cparaphrase\u201d.\nFinally, the manual annotation of pairs of sentences was performed by human annotators. At least four annotators were randomly\nselected to annotate each pair of sentences, which is done in two steps: (i) assigning a semantic similarity label (a score between 1 and 5,\nfrom unrelated to very similar); and (ii) providing an entailment label (one sentence entails the other, sentences are paraphrases,\nor no relation). Sentence pairs where at least three annotators do not agree on the entailment label were considered controversial\nand thus discarded from the gold standard annotations. The full dataset has 10,000 sentence pairs, half of which in Brazilian Portuguese\nand half in European Portuguese. Either language variant has 2,500 pairs for training, 500 for validation and 2,000 for testing.", "citation": "@inproceedings{fonseca2016assin,\n  title={ASSIN: Avaliacao de similaridade semantica e inferencia textual},\n  author={Fonseca, E and Santos, L and Criscuolo, Marcelo and Aluisio, S},\n  booktitle={Computational Processing of the Portuguese Language-12th International Conference, Tomar, Portugal},\n  pages={13--15},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7d", "disabled": false, "gated": false, "likes": 8, "downloads": 869, "paperswithcode_id": "assin", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "assin2", "sha": "2ec4bf3f58b49faf9026e0548d94bcb7fc947304", "lastModified": "2023-01-25T14:26:53.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pt", "license:unknown", "region:us"], "private": false, "author": null, "description": "The ASSIN 2 corpus is composed of rather simple sentences. Following the procedures of SemEval 2014 Task 1.\nThe training and validation data are composed, respectively, of 6,500 and 500 sentence pairs in Brazilian Portuguese,\nannotated for entailment and semantic similarity. Semantic similarity values range from 1 to 5, and text entailment\nclasses are either entailment or none. The test data are composed of approximately 3,000 sentence pairs with the same\nannotation. All data were manually annotated.", "citation": "@inproceedings{real2020assin,\n  title={The assin 2 shared task: a quick overview},\n  author={Real, Livy and Fonseca, Erick and Oliveira, Hugo Goncalo},\n  booktitle={International Conference on Computational Processing of the Portuguese Language},\n  pages={406--412},\n  year={2020},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7e", "disabled": false, "gated": false, "likes": 9, "downloads": 1522, "paperswithcode_id": "assin2", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "atomic", "sha": "c1d0d9ce67e77e5826cd7768c976a9b1ce9e5a05", "lastModified": "2022-11-18T18:56:37.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "common-sense-if-then-reasoning", "region:us"], "private": false, "author": null, "description": "This dataset provides the template sentences and\nrelationships defined in the ATOMIC common sense dataset. There are\nthree splits - train, test, and dev.\n\nFrom the authors.\n\nDisclaimer/Content warning: the events in atomic have been\nautomatically extracted from blogs, stories and books written at\nvarious times. The events might depict violent or problematic actions,\nwhich we left in the corpus for the sake of learning the (probably\nnegative but still important) commonsense implications associated with\nthe events. We removed a small set of truly out-dated events, but\nmight have missed some so please email us (msap@cs.washington.edu) if\nyou have any concerns.", "citation": "@article{Sap2019ATOMICAA,\n  title={ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning},\n  author={Maarten Sap and Ronan Le Bras and Emily Allaway and Chandra Bhagavatula and Nicholas Lourie and Hannah Rashkin and Brendan Roof and Noah A. Smith and Yejin Choi},\n  journal={ArXiv},\n  year={2019},\n  volume={abs/1811.00146}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d7f", "disabled": false, "gated": false, "likes": 6, "downloads": 315, "paperswithcode_id": "atomic", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "autshumato", "sha": "9e0ec3cdda321375d063ee1116e6b4fdb96898cf", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:tn", "language:ts", "language:zu", "license:cc-by-2.5", "region:us"], "private": false, "author": null, "description": "Multilingual information access is stipulated in the South African constitution. In practise, this\nis hampered by a lack of resources and capacity to perform the large volumes of translation\nwork required to realise multilingual information access. One of the aims of the Autshumato\nproject is to develop machine translation systems for three South African languages pairs.", "citation": "@article{groenewald2010processing,\n  title={Processing parallel text corpora for three South African language pairs in the Autshumato project},\n  author={Groenewald, Hendrik J and du Plooy, Liza},\n  journal={AfLaT 2010},\n  pages={27},\n  year={2010}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d80", "disabled": false, "gated": false, "likes": 2, "downloads": 1073, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "facebook/babi_qa", "sha": "021d7aeb7307b7856dd0632f92827bc607dc2f1b", "lastModified": "2023-01-25T14:26:58.000Z", "tags": ["task_categories:question-answering", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-3.0", "chained-qa", "arxiv:1502.05698", "arxiv:1511.06931", "region:us"], "private": false, "author": "facebook", "description": "The (20) QA bAbI tasks are a set of proxy tasks that evaluate reading\ncomprehension via question answering. Our tasks measure understanding\nin several ways: whether a system is able to answer questions via chaining facts,\nsimple induction, deduction and many more. The tasks are designed to be prerequisites\nfor any system that aims to be capable of conversing with a human.\nThe aim is to classify these tasks into skill sets,so that researchers\ncan identify (and then rectify)the failings of their systems.", "citation": "@misc{weston2015aicomplete,\n      title={Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks},\n      author={Jason Weston and Antoine Bordes and Sumit Chopra and Alexander M. Rush and Bart van Merri\u00ebnboer and Armand Joulin and Tomas Mikolov},\n      year={2015},\n      eprint={1502.05698},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d81", "disabled": false, "gated": false, "likes": 5, "downloads": 1945, "paperswithcode_id": "babi-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "banking77", "sha": "d85bf5785707deabf276bf2dbcfe68f43ea8d20d", "lastModified": "2023-04-17T13:46:23.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2003.04807", "region:us"], "private": false, "author": null, "description": "BANKING77 dataset provides a very fine-grained set of intents in a banking domain.\nIt comprises 13,083 customer service queries labeled with 77 intents.\nIt focuses on fine-grained single-domain intent detection.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d82", "disabled": false, "gated": false, "likes": 26, "downloads": 5093, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bbaw_egyptian", "sha": "42a1c1473b56e56db7ed985d1b35c284e840fd14", "lastModified": "2023-04-05T09:36:39.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended|wikipedia", "language:de", "language:egy", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "This dataset comprises parallel sentences of hieroglyphic encodings, transcription and translation\nas used in the paper Multi-Task Modeling of Phonographic Languages: Translating Middle Egyptian\nHieroglyph. The data triples are extracted from the digital corpus of Egyptian texts compiled by\nthe project \"Strukturen und Transformationen des Wortschatzes der \u00e4gyptischen Sprache\".", "citation": "@misc{OPUS4-2919,\ntitle  = {Teilauszug der Datenbank des Vorhabens \"Strukturen und Transformationen des Wortschatzes der {\\\"a}gyptischen Sprache\" vom Januar 2018},\ninstitution = {Akademienvorhaben Strukturen und Transformationen des Wortschatzes der {\\\"a}gyptischen Sprache. Text- und Wissenskultur im alten {\\\"A}gypten},\ntype = {other},\nyear = {2018},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d83", "disabled": false, "gated": false, "likes": 5, "downloads": 344, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bbc_hindi_nli", "sha": "ff897a19c2a26f64106b44e86b7a59fcf72217ee", "lastModified": "2023-01-25T14:27:06.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|bbc__hindi_news_classification", "language:hi", "license:mit", "region:us"], "private": false, "author": null, "description": "This dataset is used to train models for Natural Language Inference Tasks in Low-Resource Languages like Hindi.", "citation": "    @inproceedings{uppal-etal-2020-two,\n    title = \"Two-Step Classification using Recasted Data for Low Resource Settings\",\n    author = \"Uppal, Shagun  and\n      Gupta, Vivek  and\n      Swaminathan, Avinash  and\n      Zhang, Haimin  and\n      Mahata, Debanjan  and\n      Gosangi, Rakesh  and\n      Shah, Rajiv Ratn  and\n      Stent, Amanda\",\n    booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\",\n    month = dec,\n    year = \"2020\",\n    address = \"Suzhou, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.aacl-main.71\",\n    pages = \"706--719\",\n    abstract = \"An NLP model{'}s ability to reason should be independent of language. Previous works utilize Natural Language Inference (NLI) to understand the reasoning ability of models, mostly focusing on high resource languages like English. To address scarcity of data in low-resource languages such as Hindi, we use data recasting to create NLI datasets for four existing text classification datasets. Through experiments, we show that our recasted dataset is devoid of statistical irregularities and spurious patterns. We further study the consistency in predictions of the textual entailment models and propose a consistency regulariser to remove pairwise-inconsistencies in predictions. We propose a novel two-step classification method which uses textual-entailment predictions for classification task. We further improve the performance by using a joint-objective for classification and textual entailment. We therefore highlight the benefits of data recasting and improvements on classification performance using our approach with supporting experimental results.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d84", "disabled": false, "gated": false, "likes": 0, "downloads": 380, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bc2gm_corpus", "sha": "fe41a26f473deec2c1fd9c5c9f3518dd0bfab16f", "lastModified": "2023-08-30T12:13:12.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Nineteen teams presented results for the Gene Mention Task at the BioCreative II Workshop.\nIn this task participants designed systems to identify substrings in sentences corresponding to gene name mentions.\nA variety of different methods were used and the results varied with a highest achieved F1 score of 0.8721.\nHere we present brief descriptions of all the methods used and a statistical analysis of the results.\nWe also demonstrate that, by combining the results from all submissions, an F score of 0.9066 is feasible,\nand furthermore that the best result makes use of the lowest scoring submissions.\n\nFor more details, see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559986/\n\nThe original dataset can be downloaded from: https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-ii-corpus/\nThis dataset has been converted to CoNLL format for NER using the following tool: https://github.com/spyysalo/standoff2conll", "citation": "@article{smith2008overview,\n        title={Overview of BioCreative II gene mention recognition},\n        author={Smith, Larry and Tanabe, Lorraine K and nee Ando, Rie Johnson and Kuo, Cheng-Ju and Chung, I-Fang and Hsu, Chun-Nan and Lin, Yu-Shi and Klinger, Roman and Friedrich, Christoph M and Ganchev, Kuzman and others},\n        journal={Genome biology},\n        volume={9},\n        number={S2},\n        pages={S2},\n        year={2008},\n        publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d85", "disabled": false, "gated": false, "likes": 5, "downloads": 670, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "beans", "sha": "ff99f4013946ad6c578bd070712b10fa0664fc9f", "lastModified": "2023-01-25T14:27:13.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "Beans is a dataset of images of beans taken in the field using smartphone\ncameras. It consists of 3 classes: 2 disease classes and the healthy class.\nDiseases depicted include Angular Leaf Spot and Bean Rust. Data was annotated\nby experts from the National Crops Resources Research Institute (NaCRRI) in\nUganda and collected by the Makerere AI research lab.", "citation": "@ONLINE {beansdata,\n    author=\"Makerere AI Lab\",\n    title=\"Bean disease dataset\",\n    month=\"January\",\n    year=\"2020\",\n    url=\"https://github.com/AI-Lab-Makerere/ibean/\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d86", "disabled": false, "gated": false, "likes": 17, "downloads": 17645, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "best2009", "sha": "cb854e4aafa7d4715c9181daeec70ccfe916ac48", "lastModified": "2023-01-25T14:27:17.000Z", "tags": ["task_categories:token-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:th", "license:cc-by-nc-sa-3.0", "word-tokenization", "region:us"], "private": false, "author": null, "description": "`best2009` is a Thai word-tokenization dataset from encyclopedia, novels, news and articles by\n[NECTEC](https://www.nectec.or.th/) (148,995/2,252 lines of train/test). It was created for\n[BEST 2010: Word Tokenization Competition](https://thailang.nectec.or.th/archive/indexa290.html?q=node/10).\nThe test set answers are not provided publicly.", "citation": "@inproceedings{kosawat2009best,\n  title={BEST 2009: Thai word segmentation software contest},\n  author={Kosawat, Krit and Boriboon, Monthika and Chootrakool, Patcharika and Chotimongkol, Ananlada and Klaithin, Supon and Kongyoung, Sarawoot and Kriengket, Kanyanut and Phaholphinyo, Sitthaa and Purodakananda, Sumonmas and Thanakulwarapas, Tipraporn and others},\n  booktitle={2009 Eighth International Symposium on Natural Language Processing},\n  pages={83--88},\n  year={2009},\n  organization={IEEE}\n}\n@inproceedings{boriboon2009best,\n  title={Best corpus development and analysis},\n  author={Boriboon, Monthika and Kriengket, Kanyanut and Chootrakool, Patcharika and Phaholphinyo, Sitthaa and Purodakananda, Sumonmas and Thanakulwarapas, Tipraporn and Kosawat, Krit},\n  booktitle={2009 International Conference on Asian Language Processing},\n  pages={322--327},\n  year={2009},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d87", "disabled": false, "gated": false, "likes": 0, "downloads": 335, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bianet", "sha": "c2f33d069ae69d58adfe50d65f520786921936a4", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:ku", "language:tr", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel news corpus in Turkish, Kurdish and English.\nBianet collects 3,214 Turkish articles with their sentence-aligned Kurdish or English translations from the Bianet online newspaper.\n3 languages, 3 bitexts\ntotal number of files: 6\ntotal number of tokens: 2.25M\ntotal number of sentence fragments: 0.14M", "citation": "@InProceedings{ATAMAN18.6,\n  author = {Duygu Ataman},\n  title = {Bianet: A Parallel News Corpus in Turkish, Kurdish and English},\n  booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n  year = {2018},\n  month = {may},\n  date = {7-12},\n  location = {Miyazaki, Japan},\n  editor = {Jinhua Du and Mihael Arcan and Qun Liu and Hitoshi Isahara},\n  publisher = {European Language Resources Association (ELRA)},\n  address = {Paris, France},\n  isbn = {979-10-95546-15-3},\n  language = {english}\n  }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d88", "disabled": false, "gated": false, "likes": 0, "downloads": 669, "paperswithcode_id": "bianet", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bible_para", "sha": "2e74af6334810a0b4b06b7915b331996526ef538", "lastModified": "2022-11-03T16:31:57.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:acu", "language:af", "language:agr", "language:ake", "language:am", "language:amu", "language:ar", "language:bg", "language:bsn", "language:cak", "language:ceb", "language:ch", "language:chq", "language:chr", "language:cjp", "language:cni", "language:cop", "language:crp", "language:cs", "language:da", "language:de", "language:dik", "language:dje", "language:djk", "language:dop", "language:ee", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fi", "language:fr", "language:gbi", "language:gd", "language:gu", "language:gv", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:is", "language:it", "language:ja", "language:jak", "language:jiv", "language:kab", "language:kbh", "language:kek", "language:kn", "language:ko", "language:la", "language:lt", "language:lv", "language:mam", "language:mi", "language:ml", "language:mr", "language:my", "language:ne", "language:nhg", "language:nl", "language:no", "language:ojb", "language:pck", "language:pes", "language:pl", "language:plt", "language:pot", "language:ppk", "language:pt", "language:quc", "language:quw", "language:ro", "language:rom", "language:ru", "language:shi", "language:sk", "language:sl", "language:sn", "language:so", "language:sq", "language:sr", "language:ss", "language:sv", "language:syr", "language:te", "language:th", "language:tl", "language:tmh", "language:tr", "language:uk", "language:usp", "language:vi", "language:wal", "language:wo", "language:xh", "language:zh", "language:zu", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "This is a multilingual parallel corpus created from translations of the Bible compiled by Christos Christodoulopoulos and Mark Steedman.\n\n102 languages, 5,148 bitexts\ntotal number of files: 107\ntotal number of tokens: 56.43M\ntotal number of sentence fragments: 2.84M", "citation": "OPUS and A massively parallel corpus: the Bible in 100 languages, Christos Christodoulopoulos and Mark Steedman, *Language Resources and Evaluation*, 49 (2)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d89", "disabled": false, "gated": false, "likes": 10, "downloads": 1193, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "big_patent", "sha": "cc72d536615ac5aede5ab536a01d194389391f8d", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:summarization", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "patent-summarization", "arxiv:1906.03741", "region:us"], "private": false, "author": null, "description": "BIGPATENT, consisting of 1.3 million records of U.S. patent documents\nalong with human written abstractive summaries.\nEach US patent application is filed under a Cooperative Patent Classification\n(CPC) code. There are nine such classification categories:\nA (Human Necessities), B (Performing Operations; Transporting),\nC (Chemistry; Metallurgy), D (Textiles; Paper), E (Fixed Constructions),\nF (Mechanical Engineering; Lightning; Heating; Weapons; Blasting),\nG (Physics), H (Electricity), and\nY (General tagging of new or cross-sectional technology)\nThere are two features:\n  - description: detailed description of patent.\n  - abstract: Patent abastract.", "citation": "@misc{sharma2019bigpatent,\n    title={BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization},\n    author={Eva Sharma and Chen Li and Lu Wang},\n    year={2019},\n    eprint={1906.03741},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8a", "disabled": false, "gated": false, "likes": 27, "downloads": 2904, "paperswithcode_id": "bigpatent", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "billsum", "sha": "b622e61e3a575199f6fe44021faf9ecbbddbb40d", "lastModified": "2023-04-05T09:41:39.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc0-1.0", "bills-summarization", "arxiv:1910.00523", "region:us"], "private": false, "author": null, "description": "BillSum, summarization of US Congressional and California state bills.\n\nThere are several features:\n  - text: bill text.\n  - summary: summary of the bills.\n  - title: title of the bills.\nfeatures for us bills. ca bills does not have.\n  - text_len: number of chars in text.\n  - sum_len: number of chars in summary.", "citation": "@misc{kornilova2019billsum,\n    title={BillSum: A Corpus for Automatic Summarization of US Legislation},\n    author={Anastassia Kornilova and Vlad Eidelman},\n    year={2019},\n    eprint={1910.00523},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8b", "disabled": false, "gated": false, "likes": 20, "downloads": 4516, "paperswithcode_id": "billsum", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bing_coronavirus_query_set", "sha": "52dc8b2b3516ff47aaa5c833f2df8a17a1e8516d", "lastModified": "2022-11-03T16:30:54.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "This dataset was curated from the Bing search logs (desktop users only) over the period of Jan 1st, 2020 \u2013 (Current Month - 1). Only searches that were issued many times by multiple users were included. The dataset includes queries from all over the world that had an intent related to the Coronavirus or Covid-19. In some cases this intent is explicit in the query itself (e.g., \u201cCoronavirus updates Seattle\u201d), in other cases it is implicit , e.g. \u201cShelter in place\u201d. The implicit intent of search queries (e.g., \u201cToilet paper\u201d) was extracted using random walks on the click graph as outlined in this paper by Microsoft Research. All personal data were removed.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8c", "disabled": false, "gated": false, "likes": 0, "downloads": 371, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biomrc", "sha": "504a2603c5da9fcbb064e50f74ffd4803fc4700d", "lastModified": "2023-04-05T09:41:42.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). Experiments show that simple heuristics do not perform well on the new dataset and that two neural MRC models that had been tested on BIOREAD perform much better on BIOMRC, indicating that the new dataset is indeed less noisy or at least that its task is more feasible. Non-expert human performance is also higher on the new dataset compared to BIOREAD, and biomedical experts perform even better. We also introduce a new BERT-based MRC model, the best version of which substantially outperforms all other methods tested, reaching or surpassing the accuracy of biomedical experts in some experiments. We make the new dataset available in three different sizes, also releasing our code, and providing a leaderboard.", "citation": "@inproceedings{pappas-etal-2020-biomrc,\n    title = \"{B}io{MRC}: A Dataset for Biomedical Machine Reading Comprehension\",\n    author = \"Pappas, Dimitris  and\n      Stavropoulos, Petros  and\n      Androutsopoulos, Ion  and\n      McDonald, Ryan\",\n    booktitle = \"Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.bionlp-1.15\",\n    pages = \"140--149\",\n    abstract = \"We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the previous BIOREAD dataset of Pappas et al. (2018). Experiments show that simple heuristics do not perform well on the new dataset and that two neural MRC models that had been tested on BIOREAD perform much better on BIOMRC, indicating that the new dataset is indeed less noisy or at least that its task is more feasible. Non-expert human performance is also higher on the new dataset compared to BIOREAD, and biomedical experts perform even better. We also introduce a new BERT-based MRC model, the best version of which substantially outperforms all other methods tested, reaching or surpassing the accuracy of biomedical experts in some experiments. We make the new dataset available in three different sizes, also releasing our code, and providing a leaderboard.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8d", "disabled": false, "gated": false, "likes": 4, "downloads": 1415, "paperswithcode_id": "biomrc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biosses", "sha": "41a7d298fb653c08143706f4542dad04bebcd337", "lastModified": "2022-11-03T16:31:20.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "BIOSSES is a benchmark dataset for biomedical sentence similarity estimation. The dataset comprises 100 sentence pairs, in which each sentence was selected from the TAC (Text Analysis Conference) Biomedical Summarization Track Training Dataset containing articles from the biomedical domain. The sentence pairs were evaluated by five different human experts that judged their similarity and gave scores ranging from 0 (no relation) to 4 (equivalent).", "citation": "@article{souganciouglu2017biosses,\n  title={BIOSSES: a semantic sentence similarity estimation system for the biomedical domain},\n  author={So{\\\\u{g}}anc{\\\\i}o{\\\\u{g}}lu, Gizem and {\\\\\"O}zt{\\\\\"u}rk, Hakime and {\\\\\"O}zg{\\\\\"u}r, Arzucan},\n  journal={Bioinformatics},\n  volume={33},\n  number={14},\n  pages={i49--i58},\n  year={2017},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8e", "disabled": false, "gated": false, "likes": 4, "downloads": 1330, "paperswithcode_id": "biosses", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "TheBritishLibrary/blbooks", "sha": "37e47767e1b557bdc6ffbb37115d7784f8694f22", "lastModified": "2022-11-03T16:31:29.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:other", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:nl", "license:cc0-1.0", "digital-humanities-research", "region:us"], "private": false, "author": "TheBritishLibrary", "description": "A dataset comprising of text created by OCR from the 49,455 digitised books, equating to 65,227 volumes (25+ million pages), published between c. 1510 - c. 1900.\nThe books cover a wide range of subject areas including philosophy, history, poetry and literature.", "citation": "@misc{BritishLibraryBooks2021,\n  author = {British Library Labs},\n  title = {Digitised Books. c. 1510 - c. 1900. JSONL (OCR derived text + metadata)},\n  year = {2021},\n  publisher = {British Library},\n  howpublished={https://doi.org/10.23636/r7w6-zy15}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d8f", "disabled": false, "gated": false, "likes": 6, "downloads": 778, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "TheBritishLibrary/blbooksgenre", "sha": "de087348b4ef8c44c2978f8ff819e9e3862089e6", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-classification", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:topic-classification", "task_ids:multi-label-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:de", "language:en", "language:fr", "language:nl", "license:cc0-1.0", "region:us"], "private": false, "author": "TheBritishLibrary", "description": "This dataset contains metadata for resources belonging to the British Library\u2019s digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\nThis metadata has been extracted from British Library catalogue records.\nThe metadata held within our main catalogue is updated regularly.\nThis metadata dataset should be considered a snapshot of this metadata.", "citation": "@misc{british library_genre,\ntitle={ 19th Century Books - metadata with additional crowdsourced annotations},\nurl={https://doi.org/10.23636/BKHQ-0312},\nauthor={{British Library} and  Morris, Victoria and van Strien, Daniel and Tolfo, Giorgia and Afric, Lora and Robertson, Stewart and Tiney, Patricia and Dogterom, Annelies and Wollner, Ildi},\nyear={2021}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d90", "disabled": false, "gated": false, "likes": 4, "downloads": 662, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "blended_skill_talk", "sha": "877b97e51b588509da21d69572a3feac8334db7b", "lastModified": "2023-04-05T09:41:47.000Z", "tags": ["task_categories:conversational", "task_ids:dialogue-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "arxiv:2004.08449", "region:us"], "private": false, "author": null, "description": "A dataset of 7k conversations explicitly designed to exhibit multiple conversation modes: displaying personality, having empathy, and demonstrating knowledge.", "citation": "@misc{smith2020evaluating,\n    title={Can You Put it All Together: Evaluating Conversational Agents' Ability to Blend Skills},\n    author={Eric Michael Smith and Mary Williamson and Kurt Shuster and Jason Weston and Y-Lan Boureau},\n    year={2020},\n    eprint={2004.08449},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d91", "disabled": false, "gated": false, "likes": 52, "downloads": 615, "paperswithcode_id": "blended-skill-talk", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "blimp", "sha": "6ce3ab7c57eff25795892cf8056db91b1ed0e1ab", "lastModified": "2023-04-05T09:41:50.000Z", "tags": ["task_categories:text-classification", "task_ids:acceptability-classification", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "BLiMP is a challenge set for evaluating what language models (LMs) know about\nmajor grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each\ncontaining 1000 minimal pairs isolating specific contrasts in syntax,\nmorphology, or semantics. The data is automatically generated according to\nexpert-crafted grammars.", "citation": "@article{warstadt2019blimp,\n  title={BLiMP: A Benchmark of Linguistic Minimal Pairs for English},\n  author={Warstadt, Alex and Parrish, Alicia and Liu, Haokun and Mohananey, Anhad and Peng, Wei, and Wang, Sheng-Fu and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1912.00582},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d92", "disabled": false, "gated": false, "likes": 30, "downloads": 36055, "paperswithcode_id": "blimp", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "blog_authorship_corpus", "sha": "728947f6c98ade87aa396004440cb3b58f173cb8", "lastModified": "2023-06-06T16:16:13.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person.\n\nEach blog is presented as a separate file, the name of which indicates a blogger id# and the blogger\u2019s self-provided gender, age, industry and astrological sign. (All are labeled for gender and age but for many, industry and/or sign is marked as unknown.)\n\nAll bloggers included in the corpus fall into one of three age groups:\n- 8240 \"10s\" blogs (ages 13-17),\n- 8086 \"20s\" blogs (ages 23-27),\n- 2994 \"30s\" blogs (ages 33-47).\n\nFor each age group there are an equal number of male and female bloggers.\n\nEach blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label urllink.\n\nThe corpus may be freely used for non-commercial research purposes.", "citation": "@inproceedings{schler2006effects,\n    title={Effects of age and gender on blogging.},\n    author={Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W},\n    booktitle={AAAI spring symposium: Computational approaches to analyzing weblogs},\n    volume={6},\n    pages={199--205},\n    year={2006}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d93", "disabled": false, "gated": false, "likes": 6, "downloads": 406, "paperswithcode_id": "blog-authorship-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bn_hate_speech", "sha": "380262922e93586e4092c718580b9b1e8046bd8b", "lastModified": "2023-01-25T14:27:23.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:bn", "license:mit", "hate-speech-topic-classification", "arxiv:2004.07807", "region:us"], "private": false, "author": null, "description": "The Bengali Hate Speech Dataset is a collection of Bengali articles collected from Bengali news articles,\nnews dump of Bengali TV channels, books, blogs, and social media. Emphasis was placed on Facebook pages and\nnewspaper sources because they attract close to 50 million followers and is a common source of opinions\nand hate speech. The raw text corpus contains 250 million articles and the full dataset is being prepared\nfor release. This is a subset of the full dataset.\n\nThis dataset was prepared for hate-speech text classification benchmark on Bengali, an under-resourced language.", "citation": "@misc{karim2020classification,\n      title={Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network},\n      author={Md. Rezaul Karim and Bharathi Raja Chakravarthi and John P. McCrae and Michael Cochez},\n      year={2020},\n      eprint={2004.07807},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d94", "disabled": false, "gated": false, "likes": 1, "downloads": 1094, "paperswithcode_id": "bengali-hate-speech", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bnl_newspapers", "sha": "6a222a2c64a6541fa1601af9f973f373616ae340", "lastModified": "2023-01-25T14:27:26.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "language:da", "language:de", "language:fi", "language:fr", "language:lb", "language:nl", "language:pt", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Digitised historic newspapers from the Biblioth\u00e8que nationale (BnL) - the National Library of Luxembourg.", "citation": "@misc{bnl_newspapers,\ntitle={Historical Newspapers},\nurl={https://data.bnl.lu/data/historical-newspapers/},\nauthor={ Biblioth\u00e8que nationale du Luxembourg},", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d95", "disabled": false, "gated": false, "likes": 1, "downloads": 303, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bookcorpus", "sha": "4bc8a9f81f95682973a334ac59591200508773c5", "lastModified": "2023-04-05T09:41:56.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:unknown", "arxiv:2105.05241", "region:us"], "private": false, "author": null, "description": "Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story.This work aims to align books to their movie releases in order to providerich descriptive explanations for visual content that go semantically farbeyond the captions available in current datasets. \\", "citation": "@InProceedings{Zhu_2015_ICCV,\n    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},\n    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},\n    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},\n    month = {December},\n    year = {2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d96", "disabled": false, "gated": false, "likes": 156, "downloads": 16732, "paperswithcode_id": "bookcorpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bookcorpusopen", "sha": "817f291474dcb4fa865ed7c8298e709cd8a20266", "lastModified": "2023-11-24T14:42:08.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:2105.05241", "region:us"], "private": false, "author": null, "description": "Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story.\nThis version of bookcorpus has 17868 dataset items (books). Each item contains two fields: title and text. The title is the name of the book (just the file name) while text contains unprocessed book text. The bookcorpus has been prepared by Shawn Presser and is generously hosted by The-Eye. The-Eye is a non-profit, community driven platform dedicated to the archiving and long-term preservation of any and all data including but by no means limited to... websites, books, games, software, video, audio, other digital-obscura and ideas.", "citation": "@InProceedings{Zhu_2015_ICCV,\n    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},\n    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},\n    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},\n    month = {December},\n    year = {2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d97", "disabled": false, "gated": false, "likes": 26, "downloads": 372, "paperswithcode_id": "bookcorpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "boolq", "sha": "223972799f5e6cfcab42fe099439930192bb9623", "lastModified": "2023-04-05T09:42:01.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "BoolQ is a question answering dataset for yes/no questions containing 15942 examples. These questions are naturally\noccurring ---they are generated in unprompted and unconstrained settings.\nEach example is a triplet of (question, passage, answer), with the title of the page as optional additional context.\nThe text-pair classification setup is similar to existing natural language inference tasks.", "citation": "@inproceedings{clark2019boolq,\n  title =     {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},\n  author =    {Clark, Christopher and Lee, Kenton and Chang, Ming-Wei, and Kwiatkowski, Tom and Collins, Michael, and Toutanova, Kristina},\n  booktitle = {NAACL},\n  year =      {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d98", "disabled": false, "gated": false, "likes": 28, "downloads": 27215, "paperswithcode_id": "boolq", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bprec", "sha": "85c58974e811fb1496dc77e7e58187d4393f0d0b", "lastModified": "2023-01-25T14:27:30.000Z", "tags": ["task_categories:text-retrieval", "task_ids:entity-linking-retrieval", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:unknown", "region:us"], "private": false, "author": null, "description": "Dataset consisting of Polish language texts annotated to recognize brand-product relations.", "citation": "@inproceedings{inproceedings,\nauthor = {Janz, Arkadiusz and Kopoci\u0144ski, \u0141ukasz and Piasecki, Maciej and Pluwak, Agnieszka},\nyear = {2020},\nmonth = {05},\npages = {},\ntitle = {Brand-Product Relation Extraction Using Heterogeneous Vector Space Representations}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d99", "disabled": false, "gated": false, "likes": 0, "downloads": 901, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "break_data", "sha": "06f07116b91240aa0ff17e160caf99354601df60", "lastModified": "2023-04-05T09:42:04.000Z", "tags": ["task_categories:text2text-generation", "task_ids:open-domain-abstractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Break is a human annotated dataset of natural language questions and their Question Decomposition Meaning Representations\n(QDMRs). Break consists of 83,978 examples sampled from 10 question answering datasets over text, images and databases.\nThis repository contains the Break dataset along with information on the exact data format.", "citation": "@article{Wolfson2020Break,\n  title={Break It Down: A Question Understanding Benchmark},\n  author={Wolfson, Tomer and Geva, Mor and Gupta, Ankit and Gardner, Matt and Goldberg, Yoav and Deutch, Daniel and Berant, Jonathan},\n  journal={Transactions of the Association for Computational Linguistics},\n  year={2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9a", "disabled": false, "gated": false, "likes": 0, "downloads": 1170, "paperswithcode_id": "break", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "brwac", "sha": "56b613a900d088f45485bd5d9912794307686952", "lastModified": "2022-11-03T16:16:00.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:pt", "license:unknown", "region:us"], "private": false, "author": null, "description": "The BrWaC (Brazilian Portuguese Web as Corpus) is a large corpus constructed following the Wacky framework,\nwhich was made public for research purposes. The current corpus version, released in January 2017, is composed by\n3.53 million documents, 2.68 billion tokens and 5.79 million types. Please note that this resource is available\nsolely for academic research purposes, and you agreed not to use it for any commercial applications.\nManually download at https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC", "citation": "@inproceedings{wagner2018brwac,\n  title={The brwac corpus: A new open resource for brazilian portuguese},\n  author={Wagner Filho, Jorge A and Wilkens, Rodrigo and Idiart, Marco and Villavicencio, Aline},\n  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9b", "disabled": false, "gated": false, "likes": 8, "downloads": 5474, "paperswithcode_id": "brwac", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bsd_ja_en", "sha": "0f75b3a3ff9b52d710721c95059bd821a8d37932", "lastModified": "2022-11-18T19:24:36.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:ja", "license:cc-by-nc-sa-4.0", "business-conversations-translation", "region:us"], "private": false, "author": null, "description": "This is the Business Scene Dialogue (BSD) dataset,\na Japanese-English parallel corpus containing written conversations\nin various business scenarios.\n\nThe dataset was constructed in 3 steps:\n  1) selecting business scenes,\n  2) writing monolingual conversation scenarios according to the selected scenes, and\n  3) translating the scenarios into the other language.\n\nHalf of the monolingual scenarios were written in Japanese\nand the other half were written in English.\n\nFields:\n- id: dialogue identifier\n- no: sentence pair number within a dialogue\n- en_speaker: speaker name in English\n- ja_speaker: speaker name in Japanese\n- en_sentence: sentence in English\n- ja_sentence: sentence in Japanese\n- original_language: language in which monolingual scenario was written\n- tag: scenario\n- title: scenario title", "citation": "@inproceedings{rikters-etal-2019-designing,\n    title = \"Designing the Business Conversation Corpus\",\n    author = \"Rikters, Mat\u012bss  and\n      Ri, Ryokan  and\n      Li, Tong  and\n      Nakazawa, Toshiaki\",\n    booktitle = \"Proceedings of the 6th Workshop on Asian Translation\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D19-5204\",\n    doi = \"10.18653/v1/D19-5204\",\n    pages = \"54--61\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9c", "disabled": false, "gated": false, "likes": 4, "downloads": 443, "paperswithcode_id": "business-scene-dialogue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bswac", "sha": "818a0e388c429c0e54749e48fe1a8f6708809b28", "lastModified": "2022-11-03T16:15:55.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100M<n<1B", "source_datasets:original", "language:bs", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The Bosnian web corpus bsWaC was built by crawling the .ba top-level domain in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Bosnian vs. Croatian vs. Serbian).\n\nVersion 1.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 1.1 contains newer and better linguistic annotations.", "citation": "@misc{11356/1062,\n title = {Bosnian web corpus {bsWaC} 1.1},\n author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n url = {http://hdl.handle.net/11356/1062},\n note = {Slovenian language resource repository {CLARIN}.{SI}},\n copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n year = {2016} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9d", "disabled": false, "gated": false, "likes": 0, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "c3", "sha": "92d5052cbb5fd2cb1b58fe9b5e591f3d66e79772", "lastModified": "2022-11-18T19:24:46.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:other", "arxiv:1904.09679", "region:us"], "private": false, "author": null, "description": "Machine reading comprehension tasks require a machine reader to answer questions relevant to the given document. In this paper, we present the first free-form multiple-Choice Chinese machine reading Comprehension dataset (C^3), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chinese-as-a-second-language examinations.\nWe present a comprehensive analysis of the prior knowledge (i.e., linguistic, domain-specific, and general world knowledge) needed for these real-world problems. We implement rule-based and popular neural methods and find that there is still a significant performance gap between the best performing model (68.5%) and human readers (96.0%), especially on problems that require prior knowledge. We further study the effects of distractor plausibility and data augmentation based on translated relevant datasets for English on model performance. We expect C^3 to present great challenges to existing systems as answering 86.8% of questions requires both knowledge within and beyond the accompanying document, and we hope that C^3 can serve as a platform to study how to leverage various kinds of prior knowledge to better understand a given written or orally oriented text.", "citation": "@article{sun2019investigating,\n  title={Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension},\n  author={Sun, Kai and Yu, Dian and Yu, Dong and Cardie, Claire},\n  journal={Transactions of the Association for Computational Linguistics},\n  year={2020},\n  url={https://arxiv.org/abs/1904.09679v3}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9e", "disabled": false, "gated": false, "likes": 8, "downloads": 1234, "paperswithcode_id": "c3", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "c4", "sha": "920e15393295f51a42b0f87e1461ce128935e76f", "lastModified": "2022-11-03T16:47:14.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:100M<n<1B", "source_datasets:original", "language:en", "license:odc-by", "arxiv:1910.10683", "region:us"], "private": false, "author": null, "description": "A colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's C4 dataset by AllenAI.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181d9f", "disabled": false, "gated": false, "likes": 169, "downloads": 68692, "paperswithcode_id": "c4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cail2018", "sha": "148a68ff767c7664d751061cd665a54037612efc", "lastModified": "2022-11-18T19:24:58.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:zh", "license:unknown", "judgement-prediction", "arxiv:1807.02478", "region:us"], "private": false, "author": null, "description": "In this paper, we introduce Chinese AI and Law challenge dataset (CAIL2018),\nthe first large-scale Chinese legal dataset for judgment prediction. CAIL contains more than 2.6 million\ncriminal cases published by the Supreme People's Court of China, which are several times larger than other\ndatasets in existing works on judgment prediction. Moreover, the annotations of judgment results are more\ndetailed and rich. It consists of applicable law articles, charges, and prison terms, which are expected\nto be inferred according to the fact descriptions of cases. For comparison, we implement several conventional\ntext classification baselines for judgment prediction and experimental results show that it is still a\nchallenge for current models to predict the judgment results of legal cases, especially on prison terms.\nTo help the researchers make improvements on legal judgment prediction.", "citation": "@misc{xiao2018cail2018,\n      title={CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction},\n      author={Chaojun Xiao and Haoxi Zhong and Zhipeng Guo and Cunchao Tu and Zhiyuan Liu and Maosong Sun and Yansong Feng and Xianpei Han and Zhen Hu and Heng Wang and Jianfeng Xu},\n      year={2018},\n      eprint={1807.02478},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da0", "disabled": false, "gated": false, "likes": 8, "downloads": 362, "paperswithcode_id": "chinese-ai-and-law-cail-2018", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "caner", "sha": "a64a471c57ad3ed746c4ba449e58393c4822fe3a", "lastModified": "2023-03-16T14:47:48.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "Classical Arabic Named Entity Recognition corpus as a new corpus of tagged data that can be useful for handling the issues in recognition of Arabic named entities.", "citation": "@article{article,\nauthor = {Salah, Ramzi and Zakaria, Lailatul},\nyear = {2018},\nmonth = {12},\npages = {},\ntitle = {BUILDING THE CLASSICAL ARABIC NAMED ENTITY RECOGNITION CORPUS (CANERCORPUS)},\nvolume = {96},\njournal = {Journal of Theoretical and Applied Information Technology}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da1", "disabled": false, "gated": false, "likes": 1, "downloads": 347, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "capes", "sha": "2b60fcb29e0ca31883424866bce10e3d0e94f5c9", "lastModified": "2022-11-03T16:15:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "language:pt", "license:unknown", "dissertation-abstracts-translation", "theses-translation", "region:us"], "private": false, "author": null, "description": "A parallel corpus of theses and dissertations abstracts in English and Portuguese were collected from the CAPES website (Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal de N\u00edvel Superior) - Brazil. The corpus is sentence aligned for all language pairs. Approximately 240,000 documents were collected and aligned using the Hunalign algorithm.", "citation": "@inproceedings{soares2018parallel,\n  title={A Parallel Corpus of Theses and Dissertations Abstracts},\n  author={Soares, Felipe and Yamashita, Gabrielli Harumi and Anzanello, Michel Jose},\n  booktitle={International Conference on Computational Processing of the Portuguese Language},\n  pages={345--352},\n  year={2018},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da2", "disabled": false, "gated": false, "likes": 2, "downloads": 317, "paperswithcode_id": "capes", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "casino", "sha": "512596943b4c783831b5929b71316ea84682df40", "lastModified": "2022-11-03T16:16:00.000Z", "tags": ["task_categories:conversational", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "We provide a novel dataset (referred to as CaSiNo) of 1030 negotiation dialogues. Two participants take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. This design keeps the task tractable, while still facilitating linguistically rich and personal conversations. This helps to overcome the limitations of prior negotiation datasets such as Deal or No Deal and Craigslist Bargain. Each dialogue consists of rich meta-data including participant demographics, personality, and their subjective evaluation of the negotiation in terms of satisfaction and opponent likeness.", "citation": "@inproceedings{chawla2021casino,\n  title={CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems},\n  author={Chawla, Kushal and Ramirez, Jaysa and Clever, Rene and Lucas, Gale and May, Jonathan and Gratch, Jonathan},\n  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},\n  pages={3167--3185},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da3", "disabled": false, "gated": false, "likes": 3, "downloads": 338, "paperswithcode_id": "casino", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "catalonia_independence", "sha": "5deb408a681d91c4aaac2634b6e0fb725696e204", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ca", "language:es", "license:cc-by-nc-sa-4.0", "stance-detection", "region:us"], "private": false, "author": null, "description": "This dataset contains two corpora in Spanish and Catalan that consist of annotated Twitter messages for automatic stance detection. The data was collected over 12 days during February and March of 2019 from tweets posted in Barcelona, and during September of 2018 from tweets posted in the town of Terrassa, Catalonia.\n\nEach corpus is annotated with three classes: AGAINST, FAVOR and NEUTRAL, which express the stance towards the target - independence of Catalonia.", "citation": "@inproceedings{zotova-etal-2020-multilingual,\n    title = \"Multilingual Stance Detection in Tweets: The {C}atalonia Independence Corpus\",\n    author = \"Zotova, Elena  and\n      Agerri, Rodrigo  and\n      Nunez, Manuel  and\n      Rigau, German\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.171\",\n    pages = \"1368--1375\",\n    abstract = \"Stance detection aims to determine the attitude of a given text with respect to a specific topic or claim. While stance detection has been fairly well researched in the last years, most the work has been focused on English. This is mainly due to the relative lack of annotated data in other languages. The TW-10 referendum Dataset released at IberEval 2018 is a previous effort to provide multilingual stance-annotated data in Catalan and Spanish. Unfortunately, the TW-10 Catalan subset is extremely imbalanced. This paper addresses these issues by presenting a new multilingual dataset for stance detection in Twitter for the Catalan and Spanish languages, with the aim of facilitating research on stance detection in multilingual and cross-lingual settings. The dataset is annotated with stance towards one topic, namely, the ndependence of Catalonia. We also provide a semi-automatic method to annotate the dataset based on a categorization of Twitter users. We experiment on the new corpus with a number of supervised approaches, including linear classifiers and deep learning methods. Comparison of our new corpus with the with the TW-1O dataset shows both the benefits and potential of a well balanced corpus for multilingual and cross-lingual research on stance detection. Finally, we establish new state-of-the-art results on the TW-10 dataset, both for Catalan and Spanish.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da4", "disabled": false, "gated": false, "likes": 1, "downloads": 510, "paperswithcode_id": "cic", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cawac", "sha": "b8fe93682658cef962fc065ddc8c8e5ec8411bd7", "lastModified": "2022-11-03T16:15:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:ca", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "caWaC is a 780-million-token web corpus of Catalan built from the .cat top-level-domain in late 2013.", "citation": "@inproceedings{DBLP:conf/lrec/LjubesicT14,\n  author    = {Nikola Ljubesic and\n               Antonio Toral},\n  editor    = {Nicoletta Calzolari and\n               Khalid Choukri and\n               Thierry Declerck and\n               Hrafn Loftsson and\n               Bente Maegaard and\n               Joseph Mariani and\n               Asunci{\\'{o}}n Moreno and\n               Jan Odijk and\n               Stelios Piperidis},\n  title     = {caWaC - {A} web corpus of Catalan and its application to language\n               modeling and machine translation},\n  booktitle = {Proceedings of the Ninth International Conference on Language Resources\n               and Evaluation, {LREC} 2014, Reykjavik, Iceland, May 26-31, 2014},\n  pages     = {1728--1732},\n  publisher = {European Language Resources Association {(ELRA)}},\n  year      = {2014},\n  url       = {http://www.lrec-conf.org/proceedings/lrec2014/summaries/841.html},\n  timestamp = {Mon, 19 Aug 2019 15:23:35 +0200},\n  biburl    = {https://dblp.org/rec/conf/lrec/LjubesicT14.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da6", "disabled": false, "gated": false, "likes": 0, "downloads": 298, "paperswithcode_id": "cawac", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cbt", "sha": "7503a0643517afe02a86e4750d375a9686008efa", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:other", "task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:n<1K", "source_datasets:original", "language:en", "license:gfdl", "arxiv:1511.02301", "region:us"], "private": false, "author": null, "description": "The Children\u2019s Book Test (CBT) is designed to measure directly\nhow well language models can exploit wider linguistic context.\nThe CBT is built from books that are freely available.", "citation": "@misc{hill2016goldilocks,\n      title={The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations},\n      author={Felix Hill and Antoine Bordes and Sumit Chopra and Jason Weston},\n      year={2016},\n      eprint={1511.02301},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da7", "disabled": false, "gated": false, "likes": 9, "downloads": 1667, "paperswithcode_id": "cbt", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cc100", "sha": "85ba129f06b61a9dd471b163525f790629b7c2b2", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:af", "language:am", "language:ar", "language:as", "language:az", "language:be", "language:bg", "language:bn", "language:br", "language:bs", "language:ca", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:ff", "language:fi", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:gu", "language:ha", "language:he", "language:hi", "language:hr", "language:ht", "language:hu", "language:hy", "language:id", "language:ig", "language:is", "language:it", "language:ja", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lg", "language:li", "language:ln", "language:lo", "language:lt", "language:lv", "language:mg", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:my", "language:ne", "language:nl", "language:no", "language:ns", "language:om", "language:or", "language:pa", "language:pl", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:ru", "language:sa", "language:sc", "language:sd", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:ss", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:th", "language:tl", "language:tn", "language:tr", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:wo", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "license:unknown", "region:us"], "private": false, "author": null, "description": "This corpus is an attempt to recreate the dataset used for training XLM-R. This corpus comprises of monolingual data for 100+ languages and also includes data for romanized languages (indicated by *_rom). This was constructed using the urls and paragraph indices provided by the CC-Net repository by processing January-December 2018 Commoncrawl snapshots. Each file comprises of documents separated by double-newlines and paragraphs within the same document separated by a newline. The data is generated using the open source CC-Net repository. No claims of intellectual property are made on the work of preparation of the corpus.", "citation": "@inproceedings{conneau-etal-2020-unsupervised,\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\n    author = \"Conneau, Alexis  and\n      Khandelwal, Kartikay  and\n      Goyal, Naman  and\n      Chaudhary, Vishrav  and\n      Wenzek, Guillaume  and\n      Guzm{'a}n, Francisco  and\n      Grave, Edouard  and\n      Ott, Myle  and\n      Zettlemoyer, Luke  and\n      Stoyanov, Veselin\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\n    doi = \"10.18653/v1/2020.acl-main.747\",\n    pages = \"8440--8451\",\n    abstract = \"This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and 11.4{%} for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.\",\n}\n@inproceedings{wenzek-etal-2020-ccnet,\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\n    author = \"Wenzek, Guillaume  and\n      Lachaux, Marie-Anne  and\n      Conneau, Alexis  and\n      Chaudhary, Vishrav  and\n      Guzm{'a}n, Francisco  and\n      Joulin, Armand  and\n      Grave, Edouard\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\n    pages = \"4003--4012\",\n    abstract = \"Pre-training text representations have led to significant improvements in many areas of natural language processing. The quality of these models benefits greatly from the size of the pretraining corpora as long as its quality is preserved. In this paper, we describe an automatic pipeline to extract massive high-quality monolingual datasets from Common Crawl for a variety of languages. Our pipeline follows the data processing introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that deduplicates documents and identifies their language. We augment this pipeline with a filtering step to select documents that are close to high quality corpora like Wikipedia.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da8", "disabled": false, "gated": false, "likes": 35, "downloads": 9293, "paperswithcode_id": "cc100", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cc_news", "sha": "0ae17dffa45f621cb8061a8393e2dd225d0876a0", "lastModified": "2023-06-12T06:42:15.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "CC-News containing news articles from news sites all over the world The data is available on AWS S3 in the Common Crawl bucket at /crawl-data/CC-NEWS/. This version of the dataset has 708241 articles. It represents a small portion of English  language subset of the CC-News dataset created using news-please(Hamborg et al.,2017) to collect and extract English language portion of CC-News.", "citation": "@InProceedings{Hamborg2017,\n  author     = {Hamborg, Felix and Meuschke, Norman and Breitinger, Corinna and Gipp, Bela},\n  title      = {news-please: A Generic News Crawler and Extractor},\n  year       = {2017},\n  booktitle  = {Proceedings of the 15th International Symposium of Information Science},\n  location   = {Berlin},\n  doi        = {10.5281/zenodo.4120316},\n  pages      = {218--223},\n  month      = {March}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181da9", "disabled": false, "gated": false, "likes": 37, "downloads": 2681, "paperswithcode_id": "cc-news", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccaligned_multilingual", "sha": "0de0120bbfd3c364007448f60f1d27133b45f4e5", "lastModified": "2022-11-03T16:31:56.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "source_datasets:original", "language:af", "language:ak", "language:am", "language:ar", "language:as", "language:ay", "language:az", "language:be", "language:bg", "language:bm", "language:bn", "language:br", "language:bs", "language:ca", "language:ceb", "language:ckb", "language:cs", "language:cy", "language:de", "language:dv", "language:el", "language:eo", "language:es", "language:fa", "language:ff", "language:fi", "language:fo", "language:fr", "language:fy", "language:ga", "language:gl", "language:gn", "language:gu", "language:he", "language:hi", "language:hr", "language:hu", "language:id", "language:ig", "language:is", "language:it", "language:iu", "language:ja", "language:ka", "language:kac", "language:kg", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lg", "language:li", "language:ln", "language:lo", "language:lt", "language:lv", "language:mg", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:ne", "language:nl", "language:no", "language:nso", "language:ny", "language:om", "language:or", "language:pa", "language:pl", "language:ps", "language:pt", "language:rm", "language:ro", "language:ru", "language:rw", "language:sc", "language:sd", "language:se", "language:shn", "language:si", "language:sk", "language:sl", "language:sn", "language:so", "language:sq", "language:sr", "language:ss", "language:st", "language:su", "language:sv", "language:sw", "language:syc", "language:szl", "language:ta", "language:te", "language:tg", "language:th", "language:ti", "language:tl", "language:tn", "language:tr", "language:ts", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:ve", "language:vi", "language:war", "language:wo", "language:xh", "language:yi", "language:yo", "language:zgh", "language:zh", "language:zu", "language:zza", "license:unknown", "region:us"], "private": false, "author": null, "description": "CCAligned consists of parallel or comparable web-document pairs in 137 languages aligned with English. These web-document pairs were constructed by performing language identification on raw web-documents, and ensuring corresponding language codes were corresponding in the URLs of web documents. This pattern matching approach yielded more than 100 million aligned documents paired with English. Recognizing that each English document was often aligned to mulitple documents in different target language, we can join on English documents to obtain aligned documents that directly pair two non-English documents (e.g., Arabic-French).", "citation": "@inproceedings{elkishky_ccaligned_2020,\n author = {El-Kishky, Ahmed and Chaudhary, Vishrav and Guzm{\\'a}n, Francisco and Koehn, Philipp},\n booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020)},\n month = {November},\n title = {{CCAligned}: A Massive Collection of Cross-lingual Web-Document Pairs},\n year = {2020}\n address = \"Online\",\n publisher = \"Association for Computational Linguistics\",\n url = \"https://www.aclweb.org/anthology/2020.emnlp-main.480\",\n doi = \"10.18653/v1/2020.emnlp-main.480\",\n pages = \"5960--5969\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181daa", "disabled": false, "gated": false, "likes": 3, "downloads": 1220, "paperswithcode_id": "ccaligned", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cdsc", "sha": "1e67a06e7396a825bc7929eefc8e2d784ea3756f", "lastModified": "2023-01-25T14:27:43.000Z", "tags": ["task_categories:other", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:cc-by-nc-sa-4.0", "sentences entailment and relatedness", "region:us"], "private": false, "author": null, "description": "Polish CDSCorpus consists of 10K Polish sentence pairs which are human-annotated for semantic relatedness and entailment. The dataset may be used for the evaluation of compositional distributional semantics models of Polish. The dataset was presented at ACL 2017. Please refer to the Wr\u00f3blewska and Krasnowska-Kiera\u015b (2017) for a detailed description of the resource.", "citation": "@inproceedings{wroblewska2017polish,\ntitle={Polish evaluation dataset for compositional distributional semantics models},\nauthor={Wr{\\'o}blewska, Alina and Krasnowska-Kiera{\\'s}, Katarzyna},\nbooktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\npages={784--792},\nyear={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dab", "disabled": false, "gated": false, "likes": 0, "downloads": 507, "paperswithcode_id": "polish-cdscorpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cdt", "sha": "b517fc54e80428210d926d22dbbd4c553d6101e7", "lastModified": "2023-01-25T14:27:46.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:bsd-3-clause", "region:us"], "private": false, "author": null, "description": "The Cyberbullying Detection task was part of 2019 edition of PolEval competition. The goal is to predict if a given Twitter message contains a cyberbullying (harmful) content.", "citation": "@article{ptaszynski2019results,\ntitle={Results of the PolEval 2019 Shared Task 6: First Dataset and Open Shared Task for Automatic Cyberbullying Detection in Polish Twitter},\nauthor={Ptaszynski, Michal and Pieciukiewicz, Agata and Dybala, Pawel},\njournal={Proceedings of the PolEval 2019 Workshop},\npublisher={Institute of Computer Science, Polish Academy of Sciences},\npages={89},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dac", "disabled": false, "gated": false, "likes": 0, "downloads": 356, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cedr", "sha": "b0e4b76523dbe04b879536bf78721fc9f3099dbd", "lastModified": "2023-01-25T14:27:50.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ru", "license:apache-2.0", "emotion-classification", "region:us"], "private": false, "author": null, "description": "This new dataset is designed to solve emotion recognition task for text data in Russian. The Corpus for Emotions Detecting in\nRussian-language text sentences of different social sources (CEDR) contains 9410 sentences in Russian labeled for 5 emotion\ncategories. The data collected from different sources: posts of the LiveJournal social network, texts of the online news\nagency Lenta.ru, and Twitter microblog posts. There are two variants of the corpus: main and enriched. The enriched variant\nis include tokenization and lemmatization. Dataset with predefined train/test splits.", "citation": "@article{sboev2021data,\n  title={Data-Driven Model for Emotion Detection in Russian Texts},\n  author={Sboev, Alexander and Naumov, Aleksandr and Rybka, Roman},\n  journal={Procedia Computer Science},\n  volume={190},\n  pages={637--642},\n  year={2021},\n  publisher={Elsevier}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dad", "disabled": false, "gated": false, "likes": 4, "downloads": 922, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cfq", "sha": "831b6f8943ff90ea2a2b97e719c53efb220e52db", "lastModified": "2023-04-05T09:42:18.000Z", "tags": ["task_categories:question-answering", "task_categories:other", "task_ids:open-domain-qa", "task_ids:closed-domain-qa", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "compositionality", "arxiv:1912.09713", "region:us"], "private": false, "author": null, "description": "The CFQ dataset (and it's splits) for measuring compositional generalization.\n\nSee https://arxiv.org/abs/1912.09713.pdf for background.\n\nExample usage:\ndata = datasets.load_dataset('cfq/mcd1')", "citation": "@inproceedings{Keysers2020,\n  title={Measuring Compositional Generalization: A Comprehensive Method on\n         Realistic Data},\n  author={Daniel Keysers and Nathanael Sch\\\"{a}rli and Nathan Scales and\n          Hylke Buisman and Daniel Furrer and Sergii Kashubin and\n          Nikola Momchev and Danila Sinopalnikov and Lukasz Stafiniak and\n          Tibor Tihon and Dmitry Tsarkov and Xiao Wang and Marc van Zee and\n          Olivier Bousquet},\n  booktitle={ICLR},\n  year={2020},\n  url={https://arxiv.org/abs/1912.09713.pdf},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dae", "disabled": false, "gated": false, "likes": 2, "downloads": 1466, "paperswithcode_id": "cfq", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "chr_en", "sha": "15a7fb34c3f3a2757b6af3edc3d7ccd0b4d5e631", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_categories:translation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "annotations_creators:found", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "multilinguality:multilingual", "multilinguality:translation", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:chr", "language:en", "license:other", "arxiv:2010.04791", "region:us"], "private": false, "author": null, "description": "ChrEn is a Cherokee-English parallel dataset to facilitate machine translation research between Cherokee and English.\nChrEn is extremely low-resource contains 14k sentence pairs in total, split in ways that facilitate both in-domain and out-of-domain evaluation.\nChrEn also contains 5k Cherokee monolingual data to enable semi-supervised learning.", "citation": "@inproceedings{zhang2020chren,\n  title={ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization},\n  author={Zhang, Shiyue and Frey, Benjamin and Bansal, Mohit},\n  booktitle={EMNLP2020},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181daf", "disabled": false, "gated": false, "likes": 3, "downloads": 775, "paperswithcode_id": "chren", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cifar10", "sha": "d5fb971ec3f84df3eacb49775b714cd7fddb1f9c", "lastModified": "2023-01-25T14:27:53.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-80-Million-Tiny-Images", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images\nper class. There are 50000 training images and 10000 test images.", "citation": "@TECHREPORT{Krizhevsky09learningmultiple,\n    author = {Alex Krizhevsky},\n    title = {Learning multiple layers of features from tiny images},\n    institution = {},\n    year = {2009}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db0", "disabled": false, "gated": false, "likes": 29, "downloads": 51261, "paperswithcode_id": "cifar-10", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cifar100", "sha": "030c4fa274855172f49d65c95b0263eaad62f16e", "lastModified": "2023-01-25T14:27:57.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-80-Million-Tiny-Images", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images\nper class. There are 500 training images and 100 testing images per class. There are 50000 training images and 10000 test images. The 100 classes are grouped into 20 superclasses.\nThere are two labels per image - fine label (actual class) and coarse label (superclass).", "citation": "@TECHREPORT{Krizhevsky09learningmultiple,\n    author = {Alex Krizhevsky},\n    title = {Learning multiple layers of features from tiny images},\n    institution = {},\n    year = {2009}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db1", "disabled": false, "gated": false, "likes": 17, "downloads": 12771, "paperswithcode_id": "cifar-100", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "circa", "sha": "516fd572919b3dfe2abb33716a2cc93e15fc8499", "lastModified": "2023-01-25T14:28:00.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "question-answer-pair-classification", "arxiv:2010.03450", "region:us"], "private": false, "author": null, "description": "The Circa (meaning \u2018approximately\u2019) dataset aims to help machine learning systems\nto solve the problem of interpreting indirect answers to polar questions.\n\nThe dataset contains pairs of yes/no questions and indirect answers, together with\nannotations for the interpretation of the answer. The data is collected in 10\ndifferent social conversational situations (eg. food preferences of a friend).\n\nNOTE: There might be missing labels in the dataset and we have replaced them with -1.\nThe original dataset contains no train/dev/test splits.", "citation": "@InProceedings{louis_emnlp2020,\n  author =      \"Annie Louis and Dan Roth and Filip Radlinski\",\n  title =       \"\"{I}'d rather just go to bed\": {U}nderstanding {I}ndirect {A}nswers\",\n  booktitle =   \"Proceedings of the 2020 Conference on Empirical Methods\n  in Natural Language Processing\",\n  year =        \"2020\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db2", "disabled": false, "gated": false, "likes": 2, "downloads": 1184, "paperswithcode_id": "circa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "civil_comments", "sha": "227d95cd015fe31237c532d03ebeda16acf5fefc", "lastModified": "2023-06-30T11:26:30.000Z", "tags": ["language:en", "license:cc0-1.0", "arxiv:1903.04561", "region:us"], "private": false, "author": null, "description": "The comments in this dataset come from an archive of the Civil Comments\nplatform, a commenting plugin for independent news sites. These public comments\nwere created from 2015 - 2017 and appeared on approximately 50 English-language\nnews sites across the world. When Civil Comments shut down in 2017, they chose\nto make the public comments available in a lasting open archive to enable future\nresearch. The original data, published on figshare, includes the public comment\ntext, some associated metadata such as article IDs, timestamps and\ncommenter-generated \"civility\" labels, but does not include user ids. Jigsaw\nextended this dataset by adding additional labels for toxicity and identity\nmentions. This data set is an exact replica of the data released for the\nJigsaw Unintended Bias in Toxicity Classification Kaggle challenge.  This\ndataset is released under CC0, as is the underlying comment text.", "citation": "@article{DBLP:journals/corr/abs-1903-04561,\n  author    = {Daniel Borkan and\n               Lucas Dixon and\n               Jeffrey Sorensen and\n               Nithum Thain and\n               Lucy Vasserman},\n  title     = {Nuanced Metrics for Measuring Unintended Bias with Real Data for Text\n               Classification},\n  journal   = {CoRR},\n  volume    = {abs/1903.04561},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1903.04561},\n  archivePrefix = {arXiv},\n  eprint    = {1903.04561},\n  timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-04561},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db3", "disabled": false, "gated": false, "likes": 3, "downloads": 1244, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clickbait_news_bg", "sha": "91a7ba185a20b1af5dd318653eb5c0c09f8c829d", "lastModified": "2023-01-25T14:28:03.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:bg", "license:unknown", "region:us"], "private": false, "author": null, "description": "Dataset with clickbait and fake news in Bulgarian. Introduced for the Hack the Fake News 2017.", "citation": "@InProceedings{clickbait_news_bg,\ntitle = {Dataset with clickbait and fake news in Bulgarian. Introduced for the Hack the Fake News 2017.},\nauthors={Data Science Society},\nyear={2017},\nurl={https://gitlab.com/datasciencesociety/case_fake_news/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db4", "disabled": false, "gated": false, "likes": 0, "downloads": 345, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "climate_fever", "sha": "5c925b721e83e34ed622e54911fdb99f95c8d149", "lastModified": "2023-03-16T14:57:07.000Z", "tags": ["task_categories:text-classification", "task_categories:text-retrieval", "task_ids:text-scoring", "task_ids:fact-checking", "task_ids:fact-checking-retrieval", "task_ids:semantic-similarity-scoring", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|wikipedia", "source_datasets:original", "language:en", "license:unknown", "arxiv:2012.00614", "region:us"], "private": false, "author": null, "description": "A dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change collected on the internet. Each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim totalling in 7,675 claim-evidence pairs. The dataset features challenging claims that relate multiple facets and disputed cases of claims where both supporting and refuting evidence are present.", "citation": "@misc{diggelmann2020climatefever,\n      title={CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims},\n      author={Thomas Diggelmann and Jordan Boyd-Graber and Jannis Bulian and Massimiliano Ciaramita and Markus Leippold},\n      year={2020},\n      eprint={2012.00614},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db5", "disabled": false, "gated": false, "likes": 12, "downloads": 1331, "paperswithcode_id": "climate-fever", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clinc_oos", "sha": "7332e6a956d55345cace15b5592188a4890e1d88", "lastModified": "2023-01-25T14:28:10.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "    This dataset is for evaluating the performance of intent classification systems in the\n    presence of \"out-of-scope\" queries. By \"out-of-scope\", we mean queries that do not fall\n    into any of the system-supported intent classes. Most datasets include only data that is\n    \"in-scope\". Our dataset includes both in-scope and out-of-scope data. You might also know\n    the term \"out-of-scope\" by other terms, including \"out-of-domain\" or \"out-of-distribution\".", "citation": "    @inproceedings{larson-etal-2019-evaluation,\n    title = \"An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction\",\n    author = \"Larson, Stefan  and\n      Mahendran, Anish  and\n      Peper, Joseph J.  and\n      Clarke, Christopher  and\n      Lee, Andrew  and\n      Hill, Parker  and\n      Kummerfeld, Jonathan K.  and\n      Leach, Kevin  and\n      Laurenzano, Michael A.  and\n      Tang, Lingjia  and\n      Mars, Jason\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n    year = \"2019\",\n    url = \"https://www.aclweb.org/anthology/D19-1131\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db6", "disabled": false, "gated": false, "likes": 10, "downloads": 2021, "paperswithcode_id": "clinc150", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clue", "sha": "47fe1be9d8f299682382d4344511f966e8e405b6", "lastModified": "2023-05-25T06:34:47.000Z", "tags": ["task_categories:text-classification", "task_categories:multiple-choice", "task_ids:topic-classification", "task_ids:semantic-similarity-scoring", "task_ids:natural-language-inference", "task_ids:multiple-choice-qa", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:zh", "license:unknown", "coreference-nli", "qa-nli", "region:us"], "private": false, "author": null, "description": "CLUE, A Chinese Language Understanding Evaluation Benchmark\n(https://www.cluebenchmarks.com/) is a collection of resources for training,\nevaluating, and analyzing Chinese language understanding systems.", "citation": "@misc{xu2020clue,\n    title={CLUE: A Chinese Language Understanding Evaluation Benchmark},\n    author={Liang Xu and Xuanwei Zhang and Lu Li and Hai Hu and Chenjie Cao and Weitang Liu and Junyi Li and Yudong Li and Kai Sun and Yechen Xu and Yiming Cui and Cong Yu and Qianqian Dong and Yin Tian and Dian Yu and Bo Shi and Jun Zeng and Rongzhao Wang and Weijian Xie and Yanting Li and Yina Patterson and Zuoyu Tian and Yiwen Zhang and He Zhou and Shaoweihua Liu and Qipeng Zhao and Cong Yue and Xinrui Zhang and Zhengliang Yang and Zhenzhong Lan},\n    year={2020},\n    eprint={2004.05986},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db7", "disabled": false, "gated": false, "likes": 29, "downloads": 4602, "paperswithcode_id": "clue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cmrc2018", "sha": "4f1ebb46ecfbf4aa70660d80834b02cadcf99f93", "lastModified": "2023-04-05T09:42:31.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:zh", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "A Span-Extraction dataset for Chinese machine reading comprehension to add language\ndiversities in this area. The dataset is composed by near 20,000 real questions annotated\non Wikipedia paragraphs by human experts. We also annotated a challenge set which\ncontains the questions that need comprehensive understanding and multi-sentence\ninference throughout the context.", "citation": "@inproceedings{cui-emnlp2019-cmrc2018,\n    title = {A Span-Extraction Dataset for {C}hinese Machine Reading Comprehension},\n    author = {Cui, Yiming  and\n      Liu, Ting  and\n      Che, Wanxiang  and\n      Xiao, Li  and\n      Chen, Zhipeng  and\n      Ma, Wentao  and\n      Wang, Shijin  and\n      Hu, Guoping},\n    booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n    month = {nov},\n    year = {2019},\n    address = {Hong Kong, China},\n    publisher = {Association for Computational Linguistics},\n    url = {https://www.aclweb.org/anthology/D19-1600},\n    doi = {10.18653/v1/D19-1600},\n    pages = {5886--5891}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db8", "disabled": false, "gated": false, "likes": 14, "downloads": 888, "paperswithcode_id": "cmrc-2018", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cmu_hinglish_dog", "sha": "39a500e85584d4cd21320e8b50162538b9b289fd", "lastModified": "2023-03-17T10:14:14.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:hi", "license:cc-by-sa-3.0", "license:gfdl", "arxiv:1809.07358", "region:us"], "private": false, "author": null, "description": "This is a collection of text conversations in Hinglish (code mixing between Hindi-English) and their corresponding English only versions. Can be used for Translating between the two.", "citation": "@inproceedings{cmu_dog_emnlp18,\n    title={A Dataset for Document Grounded Conversations},\n    author={Zhou, Kangyan and Prabhumoye, Shrimai and Black, Alan W},\n    year={2018},\n    booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing}\n}\n\n@inproceedings{khanuja-etal-2020-gluecos,\n    title = \"{GLUEC}o{S}: An Evaluation Benchmark for Code-Switched {NLP}\",\n    author = \"Khanuja, Simran  and\n      Dandapat, Sandipan  and\n      Srinivasan, Anirudh  and\n      Sitaram, Sunayana  and\n      Choudhury, Monojit\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.329\",\n    pages = \"3575--3585\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181db9", "disabled": false, "gated": false, "likes": 4, "downloads": 506, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cnn_dailymail", "sha": "2d2c6100ccd17c0b215f85c38e36c4e7a5746425", "lastModified": "2022-11-18T19:30:01.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "CNN/DailyMail non-anonymized summarization dataset.\n\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary", "citation": "@article{DBLP:journals/corr/SeeLM17,\n  author    = {Abigail See and\n               Peter J. Liu and\n               Christopher D. Manning},\n  title     = {Get To The Point: Summarization with Pointer-Generator Networks},\n  journal   = {CoRR},\n  volume    = {abs/1704.04368},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.04368},\n  archivePrefix = {arXiv},\n  eprint    = {1704.04368},\n  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{hermann2015teaching,\n  title={Teaching machines to read and comprehend},\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n  booktitle={Advances in neural information processing systems},\n  pages={1693--1701},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dba", "disabled": false, "gated": false, "likes": 123, "downloads": 86023, "paperswithcode_id": "cnn-daily-mail-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "coached_conv_pref", "sha": "512f1d1749d70e5b65ef4cd6afa25010284f30e4", "lastModified": "2023-01-25T14:28:17.000Z", "tags": ["task_categories:other", "task_categories:text-generation", "task_categories:fill-mask", "task_categories:token-classification", "task_ids:dialogue-modeling", "task_ids:parsing", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "Conversational Recommendation", "region:us"], "private": false, "author": null, "description": "A dataset consisting of 502 English dialogs with 12,000 annotated utterances between a user and an assistant discussing\nmovie preferences in natural language. It was collected using a Wizard-of-Oz methodology between two paid crowd-workers,\nwhere one worker plays the role of an 'assistant', while the other plays the role of a 'user'. The 'assistant' elicits\nthe 'user\u2019s' preferences about movies following a Coached Conversational Preference Elicitation (CCPE) method. The\nassistant asks questions designed to minimize the bias in the terminology the 'user' employs to convey his or her\npreferences as much as possible, and to obtain these preferences in natural language. Each dialog is annotated with\nentity mentions, preferences expressed about entities, descriptions of entities provided, and other statements of\nentities.", "citation": "@inproceedings{48414,\ntitle\t= {Coached Conversational Preference Elicitation: A Case Study in Understanding Movie Preferences},\nauthor\t= {Filip Radlinski and Krisztian Balog and Bill Byrne and Karthik Krishnamoorthi},\nyear\t= {2019},\nbooktitle\t= {Proceedings of the Annual SIGdial Meeting on Discourse and Dialogue}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dbb", "disabled": false, "gated": false, "likes": 2, "downloads": 296, "paperswithcode_id": "coached-conversational-preference-elicitation", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "coarse_discourse", "sha": "8d5fb2e33f8d030a1a51f817852c830e85848d93", "lastModified": "2023-04-05T10:01:55.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "dataset contains discourse annotation and relation on threads from reddit during 2016", "citation": "@inproceedings{coarsediscourse, title={Characterizing Online Discussion Using Coarse Discourse Sequences}, author={Zhang, Amy X. and Culbertson, Bryan and Paritosh, Praveen}, booktitle={Proceedings of the 11th International AAAI Conference on Weblogs and Social Media}, series={ICWSM '17}, year={2017}, location = {Montreal, Canada} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dbc", "disabled": false, "gated": false, "likes": 3, "downloads": 449, "paperswithcode_id": "coarse-discourse", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "codah", "sha": "b0cf0686d711057d646a8298dbc5b8fad80be1be", "lastModified": "2023-01-25T14:28:20.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The COmmonsense Dataset Adversarially-authored by Humans (CODAH) is an evaluation set for commonsense question-answering in the sentence completion style of SWAG. As opposed to other automatically generated NLI datasets, CODAH is adversarially constructed by humans who can view feedback from a pre-trained model and use this information to design challenging commonsense questions. Our experimental results show that CODAH questions present a complementary extension to the SWAG dataset, testing additional modes of common sense.", "citation": "@inproceedings{chen2019codah,\n  title={CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n  author={Chen, Michael and D'Arcy, Mike and Liu, Alisa and Fernandez, Jared and Downey, Doug},\n  booktitle={Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP},\n  pages={63--69},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dbd", "disabled": false, "gated": false, "likes": 4, "downloads": 1636, "paperswithcode_id": "codah", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_search_net", "sha": "89d68535541a21f192969038c5000f3e1a43373b", "lastModified": "2023-06-06T11:19:59.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:code", "license:other", "arxiv:1909.09436", "region:us"], "private": false, "author": null, "description": "CodeSearchNet corpus contains about 6 million functions from open-source code spanning six programming languages (Go, Java, JavaScript, PHP, Python, and Ruby). The CodeSearchNet Corpus also contains automatically generated query-like natural language for 2 million functions, obtained from mechanically scraping and preprocessing associated function documentation.", "citation": "@article{husain2019codesearchnet,\n    title={{CodeSearchNet} challenge: Evaluating the state of semantic code search},\n    author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\n    journal={arXiv preprint arXiv:1909.09436},\n    year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dbe", "disabled": false, "gated": false, "likes": 157, "downloads": 69261, "paperswithcode_id": "codesearchnet", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_clone_detection_big_clone_bench", "sha": "46c2a16eb196fa7ca8f94e638ba55009843233d2", "lastModified": "2022-11-18T19:30:27.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Given two codes as the input, the task is to do binary classification (0/1), where 1 stands for semantic equivalence and 0 for others. Models are evaluated by F1 score.\nThe dataset we use is BigCloneBench and filtered following the paper Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree.", "citation": "@inproceedings{svajlenko2014towards,\ntitle={Towards a big data curated benchmark of inter-project code clones},\nauthor={Svajlenko, Jeffrey and Islam, Judith F and Keivanloo, Iman and Roy, Chanchal K and Mia, Mohammad Mamun},\nbooktitle={2014 IEEE International Conference on Software Maintenance and Evolution},\npages={476--480},\nyear={2014},\norganization={IEEE}\n}\n\n@inproceedings{wang2020detecting,\ntitle={Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree},\nauthor={Wang, Wenhan and Li, Ge and Ma, Bo and Xia, Xin and Jin, Zhi},\nbooktitle={2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)},\npages={261--271},\nyear={2020},\norganization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dbf", "disabled": false, "gated": false, "likes": 4, "downloads": 648, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_clone_detection_poj104", "sha": "6e305f6bc1001e0d93e604a17494158eb56d5e03", "lastModified": "2023-03-13T11:02:07.000Z", "tags": ["task_categories:text-retrieval", "task_ids:document-retrieval", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Given a code and a collection of candidates as the input, the task is to return Top K codes with the same semantic. Models are evaluated by MAP score.\nWe use POJ-104 dataset on this task.", "citation": "@inproceedings{mou2016convolutional,\ntitle={Convolutional neural networks over tree structures for programming language processing},\nauthor={Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi},\nbooktitle={Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},\npages={1287--1293},\nyear={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc0", "disabled": false, "gated": false, "likes": 3, "downloads": 350, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_cloze_testing_all", "sha": "2d005b7cc4e989525db4cd2d0a17da361fec98e9", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:slot-filling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Cloze tests are widely adopted in Natural Languages Processing to evaluate the performance of the trained language models. The task is aimed to predict the answers for the blank with the context of the blank, which can be formulated as a multi-choice classification problem.\nHere we present the two cloze testing datasets in code domain with six different programming languages: ClozeTest-maxmin and ClozeTest-all. Each instance in the dataset contains a masked code function, its docstring and the target word.\nThe only difference between ClozeTest-maxmin and ClozeTest-all is their selected words sets, where ClozeTest-maxmin only contains two words while ClozeTest-all contains 930 words.", "citation": "@article{CodeXGLUE,\ntitle={CodeXGLUE: An Open Challenge for Code Intelligence},\njournal={arXiv},\nyear={2020},\n}\n@article{feng2020codebert,\ntitle={CodeBERT: A Pre-Trained Model for Programming and Natural Languages},\nauthor={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},\njournal={arXiv preprint arXiv:2002.08155},\nyear={2020}\n}\n@article{husain2019codesearchnet,\ntitle={CodeSearchNet Challenge: Evaluating the State of Semantic Code Search},\nauthor={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\njournal={arXiv preprint arXiv:1909.09436},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc1", "disabled": false, "gated": false, "likes": 3, "downloads": 1031, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_code_completion_line", "sha": "bdc24e9b625615c55a1c541c4454a508d40e7307", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:slot-filling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Complete the unfinished line given previous context. Models are evaluated by exact match and edit similarity.\nWe propose line completion task to test model's ability to autocomplete a line. Majority code completion systems behave well in token level completion, but fail in completing an unfinished line like a method call with specific parameters, a function signature, a loop condition, a variable definition and so on. When a software develop finish one or more tokens of the current line, the line level completion model is expected to generate the entire line of syntactically correct code.\nLine level code completion task shares the train/dev dataset with token level completion. After training a model on CodeCompletion-token, you could directly use it to test on line-level completion.", "citation": "@article{raychev2016probabilistic,\ntitle={Probabilistic Model for Code with Decision Trees},\nauthor={Raychev, Veselin and Bielik, Pavol and Vechev, Martin},\njournal={ACM SIGPLAN Notices},\npages={731--747},\nyear={2016},\npublisher={ACM New York, NY, USA}\n}\n@inproceedings{allamanis2013mining,\ntitle={Mining Source Code Repositories at Massive Scale using Language Modeling},\nauthor={Allamanis, Miltiadis and Sutton, Charles},\nbooktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},\npages={207--216},\nyear={2013},\norganization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc3", "disabled": false, "gated": false, "likes": 1, "downloads": 445, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_code_completion_token", "sha": "9e629d74fd27a5e7c6d7e3d6c61a0ef8c6882f1b", "lastModified": "2023-06-12T08:13:31.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Predict next code token given context of previous tokens. Models are evaluated by token level accuracy.\nCode completion is a one of the most widely used features in software development through IDEs. An effective code completion tool could improve software developers' productivity. We provide code completion evaluation tasks in two granularities -- token level and line level. Here we introduce token level code completion. Token level task is analogous to language modeling. Models should have be able to predict the next token in arbitary types.", "citation": "@article{raychev2016probabilistic,\n    title={Probabilistic Model for Code with Decision Trees},\n    author={Raychev, Veselin and Bielik, Pavol and Vechev, Martin},\n    journal={ACM SIGPLAN Notices},\n    pages={731--747},\n    year={2016},\n    publisher={ACM New York, NY, USA}\n}\n@inproceedings{allamanis2013mining,\n    title={Mining Source Code Repositories at Massive Scale using Language Modeling},\n    author={Allamanis, Miltiadis and Sutton, Charles},\n    booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},\n    pages={207--216},\n    year={2013},\n    organization={IEEE}\n}\n@dataset{rafael_michael_karampatsis_2020_3628665,\n  author       = {Rafael - Michael Karampatsis and\n                  Hlib Babii and\n                  Romain Robbes and\n                  Charles Sutton and\n                  Andrea Janes},\n  title        = {Preprocessed Java Code Corpus},\n  month        = jan,\n  year         = 2020,\n  publisher    = {Zenodo},\n  version      = {1.0},\n  doi          = {10.5281/zenodo.3628665},\n  url          = {https://doi.org/10.5281/zenodo.3628665}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc4", "disabled": false, "gated": false, "likes": 1, "downloads": 457, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_code_refinement", "sha": "2d5f64e7e90e9a4bd3fec86354f23291c8164985", "lastModified": "2023-07-27T14:09:03.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:other-programming-languages", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "license:c-uda", "debugging", "arxiv:2102.04664", "arxiv:1812.08693", "region:us"], "private": false, "author": null, "description": "We use the dataset released by this paper(https://arxiv.org/pdf/1812.08693.pdf). The source side is a Java function with bugs and the target side is the refined one. All the function and variable names are normalized. Their dataset contains two subsets ( i.e.small and medium) based on the function length.", "citation": "@article{10.1145/3340544,\nauthor = {Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys},\ntitle = {An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation},\nyear = {2019},\nissue_date = {October 2019},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {28},\nnumber = {4},\nissn = {1049-331X},\nurl = {https://doi-org.proxy.wm.edu/10.1145/3340544},\ndoi = {10.1145/3340544},\nabstract = {Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.},\njournal = {ACM Trans. Softw. Eng. Methodol.},\nmonth = sep,\narticleno = {19},\nnumpages = {29},\nkeywords = {bug-fixes, Neural machine translation}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc5", "disabled": false, "gated": false, "likes": 2, "downloads": 647, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_code_to_code_trans", "sha": "fdeb80789638fa341a651e587ca79167880e9a63", "lastModified": "2023-07-27T14:11:43.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:other-programming-languages", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "license:c-uda", "code-to-code", "arxiv:2102.04664", "region:us"], "private": false, "author": null, "description": "The dataset is collected from several public repos, including Lucene(http://lucene.apache.org/), POI(http://poi.apache.org/), JGit(https://github.com/eclipse/jgit/) and Antlr(https://github.com/antlr/).\n        We collect both the Java and C# versions of the codes and find the parallel functions. After removing duplicates and functions with the empty body, we split the whole dataset into training, validation and test sets.", "citation": "@article{DBLP:journals/corr/abs-2102-04664,\n  author    = {Shuai Lu and\n               Daya Guo and\n               Shuo Ren and\n               Junjie Huang and\n               Alexey Svyatkovskiy and\n               Ambrosio Blanco and\n               Colin B. Clement and\n               Dawn Drain and\n               Daxin Jiang and\n               Duyu Tang and\n               Ge Li and\n               Lidong Zhou and\n               Linjun Shou and\n               Long Zhou and\n               Michele Tufano and\n               Ming Gong and\n               Ming Zhou and\n               Nan Duan and\n               Neel Sundaresan and\n               Shao Kun Deng and\n               Shengyu Fu and\n               Shujie Liu},\n  title     = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding\n               and Generation},\n  journal   = {CoRR},\n  volume    = {abs/2102.04664},\n  year      = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc6", "disabled": false, "gated": false, "likes": 3, "downloads": 566, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_cc_defect_detection", "sha": "b00e079e4aba92fcbf0526f0a56eeef7a7e6c49a", "lastModified": "2022-11-18T19:31:11.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "multilinguality:other-programming-languages", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "license:c-uda", "region:us"], "private": false, "author": null, "description": "Given a source code, the task is to identify whether it is an insecure code that may attack software systems, such as resource leaks, use-after-free vulnerabilities and DoS attack. We treat the task as binary classification (0/1), where 1 stands for insecure code and 0 for secure code.\nThe dataset we use comes from the paper Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks. We combine all projects and split 80%/10%/10% for training/dev/test.", "citation": "@inproceedings{zhou2019devign,\ntitle={Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks},\nauthor={Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},\nbooktitle={Advances in Neural Information Processing Systems},\npages={10197--10207}, year={2019}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc7", "disabled": false, "gated": false, "likes": 6, "downloads": 526, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_ct_code_to_text", "sha": "5dc851c6020a5c2c53b47ea3d8540c1c191bef82", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:other-programming-languages", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:code", "language:en", "license:c-uda", "code-to-text", "region:us"], "private": false, "author": null, "description": "The dataset we use comes from CodeSearchNet and we filter the dataset as the following:\n- Remove examples that codes cannot be parsed into an abstract syntax tree.\n- Remove examples that #tokens of documents is < 3 or >256\n- Remove examples that documents contain special tokens (e.g. <img ...> or https:...)\n- Remove examples that documents are not English.", "citation": "@article{husain2019codesearchnet,\ntitle={Codesearchnet challenge: Evaluating the state of semantic code search},\nauthor={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},\njournal={arXiv preprint arXiv:1909.09436},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dc8", "disabled": false, "gated": false, "likes": 37, "downloads": 2591, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_tc_text_to_code", "sha": "45c1f2e32f20ed619444bfb15bc6037401a6dc74", "lastModified": "2022-11-18T19:31:29.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:other-programming-languages", "size_categories:100K<n<1M", "source_datasets:original", "language:code", "language:en", "license:c-uda", "text-to-code", "region:us"], "private": false, "author": null, "description": "We use concode dataset which is a widely used code generation dataset from Iyer's EMNLP 2018 paper Mapping Language to Code in Programmatic Context. See paper for details.", "citation": "@article{iyer2018mapping,\ntitle={Mapping language to code in programmatic context},\nauthor={Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Zettlemoyer, Luke},\njournal={arXiv preprint arXiv:1808.09588},\nyear={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dca", "disabled": false, "gated": false, "likes": 18, "downloads": 1246, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "code_x_glue_tt_text_to_text", "sha": "5c28537d40e9161e20e78dae878d27bde1b2e27d", "lastModified": "2023-07-27T15:29:15.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:da", "language:en", "language:lv", "language:nb", "language:zh", "license:c-uda", "code-documentation-translation", "arxiv:2102.04664", "region:us"], "private": false, "author": null, "description": "The dataset we use is crawled and filtered from Microsoft Documentation, whose document located at https://github.com/MicrosoftDocs/.", "citation": "@article{DBLP:journals/corr/abs-2102-04664,\n  author    = {Shuai Lu and\n               Daya Guo and\n               Shuo Ren and\n               Junjie Huang and\n               Alexey Svyatkovskiy and\n               Ambrosio Blanco and\n               Colin B. Clement and\n               Dawn Drain and\n               Daxin Jiang and\n               Duyu Tang and\n               Ge Li and\n               Lidong Zhou and\n               Linjun Shou and\n               Long Zhou and\n               Michele Tufano and\n               Ming Gong and\n               Ming Zhou and\n               Nan Duan and\n               Neel Sundaresan and\n               Shao Kun Deng and\n               Shengyu Fu and\n               Shujie Liu},\n  title     = {CodeXGLUE: {A} Machine Learning Benchmark Dataset for Code Understanding\n               and Generation},\n  journal   = {CoRR},\n  volume    = {abs/2102.04664},\n  year      = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dcb", "disabled": false, "gated": false, "likes": 1, "downloads": 821, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "com_qa", "sha": "b085903f1cc04ac76a69217370f8fd3598aa820d", "lastModified": "2023-06-27T07:38:08.000Z", "tags": ["task_categories:question-answering", "language:en", "region:us"], "private": false, "author": null, "description": "ComQA is a dataset of 11,214 questions, which were collected from WikiAnswers, a community question answering website.\nBy collecting questions from such a site we ensure that the information needs are ones of interest to actual users.\nMoreover, questions posed there are often cannot be answered by commercial search engines or QA technology, making them\nmore interesting for driving future research compared to those collected from an engine's query log. The dataset contains\nquestions with various challenging phenomena such as the need for temporal reasoning, comparison (e.g., comparatives,\nsuperlatives, ordinals), compositionality (multiple, possibly nested, subquestions with multiple entities), and\nunanswerable questions (e.g., Who was the first human being on Mars?). Through a large crowdsourcing effort, questions\nin ComQA are grouped into 4,834 paraphrase clusters that express the same information need. Each cluster is annotated\nwith its answer(s). ComQA answers come in the form of Wikipedia entities wherever possible. Wherever the answers are\ntemporal or measurable quantities, TIMEX3 and the International System of Units (SI) are used for normalization.", "citation": "@inproceedings{abujabal-etal-2019-comqa,\n    title = \"{ComQA: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters\",\n    author = {Abujabal, Abdalghani  and\n      Saha Roy, Rishiraj  and\n      Yahya, Mohamed  and\n      Weikum, Gerhard},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    month = {jun},\n    year = {2019},\n    address = {Minneapolis, Minnesota},\n    publisher = {Association for Computational Linguistics},\n    url = {https://www.aclweb.org/anthology/N19-1027},\n    doi = {10.18653/v1/N19-1027{,\n    pages = {307--317},\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dcc", "disabled": false, "gated": false, "likes": 2, "downloads": 334, "paperswithcode_id": "comqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "common_gen", "sha": "1740c86298771b0f203d388e7defccb863e66b5d", "lastModified": "2023-04-05T10:02:11.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:found", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "concepts-to-text", "arxiv:1911.03705", "region:us"], "private": false, "author": null, "description": "CommonGen is a constrained text generation task, associated with a benchmark dataset,\nto explicitly test machines for the ability of generative commonsense reasoning. Given\na set of common concepts; the task is to generate a coherent sentence describing an\neveryday scenario using these concepts.\n\nCommonGen is challenging because it inherently requires 1) relational reasoning using\nbackground commonsense knowledge, and 2) compositional generalization ability to work\non unseen concept combinations. Our dataset, constructed through a combination of\ncrowd-sourcing from AMT and existing caption corpora, consists of 30k concept-sets and\n50k sentences in total.", "citation": "@inproceedings{lin-etal-2020-commongen,\n    title = \"{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Zhou, Wangchunshu  and\n      Shen, Ming  and\n      Zhou, Pei  and\n      Bhagavatula, Chandra  and\n      Choi, Yejin  and\n      Ren, Xiang\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.165\",\n    doi = \"10.18653/v1/2020.findings-emnlp.165\",\n    pages = \"1823--1840\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dcd", "disabled": false, "gated": false, "likes": 18, "downloads": 5845, "paperswithcode_id": "commongen", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "common_language", "sha": "16ea653dd7d6a92f8fd80839466b1c6be1df300a", "lastModified": "2023-06-12T13:29:01.000Z", "tags": ["task_categories:audio-classification", "task_ids:speaker-identification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended|common_voice", "language:ar", "language:br", "language:ca", "language:cnh", "language:cs", "language:cv", "language:cy", "language:de", "language:dv", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fr", "language:fy", "language:ia", "language:id", "language:it", "language:ja", "language:ka", "language:kab", "language:ky", "language:lv", "language:mn", "language:mt", "language:nl", "language:pl", "language:pt", "language:rm", "language:ro", "language:ru", "language:rw", "language:sah", "language:sl", "language:sv", "language:ta", "language:tr", "language:tt", "language:uk", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "This dataset is composed of speech recordings from languages that were carefully selected from the CommonVoice database.\nThe total duration of audio recordings is 45.1 hours (i.e., 1 hour of material for each language).\nThe dataset has been extracted from CommonVoice to train language-id systems.", "citation": "@dataset{ganesh_sinisetty_2021_5036977,\n  author       = {Ganesh Sinisetty and\n                  Pavlo Ruban and\n                  Oleksandr Dymov and\n                  Mirco Ravanelli},\n  title        = {CommonLanguage},\n  month        = jun,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = {0.1},\n  doi          = {10.5281/zenodo.5036977},\n  url          = {https://doi.org/10.5281/zenodo.5036977}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dce", "disabled": false, "gated": false, "likes": 13, "downloads": 8914, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "common_voice", "sha": "4e0b5223fffb5ab8bda6f1b708377a19054ddab2", "lastModified": "2023-06-27T07:46:51.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:extended|common_voice", "language:ab", "language:ar", "language:as", "language:br", "language:ca", "language:cnh", "language:cs", "language:cv", "language:cy", "language:de", "language:dv", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:fy", "language:ga", "language:hi", "language:hsb", "language:hu", "language:ia", "language:id", "language:it", "language:ja", "language:ka", "language:kab", "language:ky", "language:lg", "language:lt", "language:lv", "language:mn", "language:mt", "language:nl", "language:or", "language:pa", "language:pl", "language:pt", "language:rm", "language:ro", "language:ru", "language:rw", "language:sah", "language:sl", "language:sv", "language:ta", "language:th", "language:tr", "language:tt", "language:uk", "language:vi", "language:vot", "language:zh", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Common Voice is Mozilla's initiative to help teach machines how real people speak.\nThe dataset currently consists of 7,335 validated hours of speech in 60 languages, but we\u2019re always adding more voices and languages.", "citation": "@inproceedings{commonvoice:2020,\n  author = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\n  title = {Common Voice: A Massively-Multilingual Speech Corpus},\n  booktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n  pages = {4211--4215},\n  year = 2020\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dcf", "disabled": false, "gated": false, "likes": 107, "downloads": 12278, "paperswithcode_id": "common-voice", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "commonsense_qa", "sha": "2cb02c2ac79f346e098f36f776f3c751a2464c27", "lastModified": "2023-04-05T10:02:16.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "arxiv:1811.00937", "region:us"], "private": false, "author": null, "description": "CommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.", "citation": "@inproceedings{talmor-etal-2019-commonsenseqa,\n    title = \"{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge\",\n    author = \"Talmor, Alon  and\n      Herzig, Jonathan  and\n      Lourie, Nicholas  and\n      Berant, Jonathan\",\n    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n    month = jun,\n    year = \"2019\",\n    address = \"Minneapolis, Minnesota\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/N19-1421\",\n    doi = \"10.18653/v1/N19-1421\",\n    pages = \"4149--4158\",\n    archivePrefix = \"arXiv\",\n    eprint        = \"1811.00937\",\n    primaryClass  = \"cs\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd0", "disabled": false, "gated": false, "likes": 27, "downloads": 29428, "paperswithcode_id": "commonsenseqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hendrycks/competition_math", "sha": "71b758ecc688b2822d07ffa7f8393299f1dc7cac", "lastModified": "2023-06-08T06:40:09.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "explanation-generation", "arxiv:2103.03874", "region:us"], "private": false, "author": "hendrycks", "description": "The Mathematics Aptitude Test of Heuristics (MATH) dataset consists of problems\nfrom mathematics competitions, including the AMC 10, AMC 12, AIME, and more.\nEach problem in MATH has a full step-by-step solution, which can be used to teach\nmodels to generate answer derivations and explanations.", "citation": "@article{hendrycksmath2021,\n  title={Measuring Mathematical Problem Solving With the MATH Dataset},\n  author={Dan Hendrycks\n    and Collin Burns\n    and Saurav Kadavath\n    and Akul Arora\n    and Steven Basart\n    and Eric Tang\n    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2103.03874},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd1", "disabled": false, "gated": false, "likes": 58, "downloads": 1045, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "compguesswhat", "sha": "90da5b13e9eedde7db753ca90d0a4780ee0c3a94", "lastModified": "2023-04-05T10:02:19.000Z", "tags": ["task_categories:visual-question-answering", "task_ids:visual-question-answering", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other-guesswhat", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "CompGuessWhat?! is an instance of a multi-task framework for evaluating the quality of learned neural representations,\n        in particular concerning attribute grounding. Use this dataset if you want to use the set of games whose reference\n        scene is an image in VisualGenome. Visit the website for more details: https://compguesswhat.github.io", "citation": "        @inproceedings{suglia2020compguesswhat,\n          title={CompGuessWhat?!: a Multi-task Evaluation Framework for Grounded Language Learning},\n          author={Suglia, Alessandro, Konstas, Ioannis, Vanzo, Andrea, Bastianelli, Emanuele, Desmond Elliott, Stella Frank and Oliver Lemon},\n          booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n          year={2020}\n        }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd2", "disabled": false, "gated": false, "likes": 1, "downloads": 480, "paperswithcode_id": "compguesswhat", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conceptnet5", "sha": "98f0ad17b9f8d71f1f2bc8276adf777d4cbeeb17", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:ja", "language:nl", "language:pt", "language:ru", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "This dataset is designed to provide training data\r\nfor common sense relationships pulls together from various sources.\r\n\r\nThe dataset is multi-lingual. See langauge codes and language info\r\nhere: https://github.com/commonsense/conceptnet5/wiki/Languages\r\n\r\n\r\nThis dataset provides an interface for the conceptnet5 csv file, and\r\nsome (but not all) of the raw text data used to build conceptnet5:\r\nomcsnet_sentences_free.txt, and omcsnet_sentences_more.txt.\r\n\r\nOne use of this dataset would be to learn to extract the conceptnet\r\nrelationship from the omcsnet sentences.\r\n\r\nConceptnet5 has 34,074,917 relationships. Of those relationships,\r\nthere are 2,176,099 surface text sentences related to those 2M\r\nentries.\r\n\r\nomcsnet_sentences_free has 898,161 lines. omcsnet_sentences_more has\r\n2,001,736 lines.\r\n\r\nOriginal downloads are available here\r\nhttps://github.com/commonsense/conceptnet5/wiki/Downloads. For more\r\ninformation, see: https://github.com/commonsense/conceptnet5/wiki\r\n\r\nThe omcsnet data comes with the following warning from the authors of\r\nthe above site: Remember: this data comes from various forms of\r\ncrowdsourcing. Sentences in these files are not necessarily true,\r\nuseful, or appropriate.", "citation": "\\\r\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017. \"ConceptNet 5.5: An Open Multilingual Graph of General Knowledge.\" In proceedings of AAAI 31.\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd3", "disabled": false, "gated": false, "likes": 15, "downloads": 713, "paperswithcode_id": "conceptnet", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conll2000", "sha": "ce1947a0302ee3ede3bf53750c16f7b6be5daf0e", "lastModified": "2023-04-05T10:02:23.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": " Text chunking consists of dividing a text in syntactically correlated parts of words. For example, the sentence\n He reckons the current account deficit will narrow to only # 1.8 billion in September . can be divided as follows:\n[NP He ] [VP reckons ] [NP the current account deficit ] [VP will narrow ] [PP to ] [NP only # 1.8 billion ]\n[PP in ] [NP September ] .\n\nText chunking is an intermediate step towards full parsing. It was the shared task for CoNLL-2000. Training and test\ndata for this task is available. This data consists of the same partitions of the Wall Street Journal corpus (WSJ)\nas the widely used data for noun phrase chunking: sections 15-18 as training data (211727 tokens) and section 20 as\ntest data (47377 tokens). The annotation of the data has been derived from the WSJ corpus by a program written by\nSabine Buchholz from Tilburg University, The Netherlands.", "citation": "@inproceedings{tksbuchholz2000conll,\n   author     = \"Tjong Kim Sang, Erik F. and Sabine Buchholz\",\n   title      = \"Introduction to the CoNLL-2000 Shared Task: Chunking\",\n   editor     = \"Claire Cardie and Walter Daelemans and Claire\n                 Nedellec and Tjong Kim Sang, Erik\",\n   booktitle  = \"Proceedings of CoNLL-2000 and LLL-2000\",\n   publisher  = \"Lisbon, Portugal\",\n   pages      = \"127--132\",\n   year       = \"2000\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd4", "disabled": false, "gated": false, "likes": 2, "downloads": 327, "paperswithcode_id": "conll-2000-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conll2002", "sha": "f272d859c2d4c70224e71c7354ee0156154a792e", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:es", "language:nl", "license:unknown", "region:us"], "private": false, "author": null, "description": "Named entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n\nExample:\n[PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\n\nThe shared task of CoNLL-2002 concerns language-independent named entity recognition.\nWe will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups.\nThe participants of the shared task will be offered training and test data for at least two languages.\nThey will use the data for developing a named-entity recognition system that includes a machine learning component.\nInformation sources other than the training data may be used in this shared task.\nWe are especially interested in methods that can use additional unannotated data for improving their performance (for example co-training).\n\nThe train/validation/test sets are available in Spanish and Dutch.\n\nFor more details see https://www.clips.uantwerpen.be/conll2002/ner/ and https://www.aclweb.org/anthology/W02-2024/", "citation": "@inproceedings{tjong-kim-sang-2002-introduction,\n    title = \"Introduction to the {C}o{NLL}-2002 Shared Task: Language-Independent Named Entity Recognition\",\n    author = \"Tjong Kim Sang, Erik F.\",\n    booktitle = \"{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002)\",\n    year = \"2002\",\n    url = \"https://www.aclweb.org/anthology/W02-2024\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd5", "disabled": false, "gated": false, "likes": 3, "downloads": 862, "paperswithcode_id": "conll-2002", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conll2003", "sha": "01ad4ad271976c5258b9ed9b910469a806ff3288", "lastModified": "2023-04-05T10:02:26.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-reuters-corpus", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\nnot belong to the previous three groups.\n\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\ntagging scheme, whereas the original dataset uses IOB1.\n\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419", "citation": "@inproceedings{tjong-kim-sang-de-meulder-2003-introduction,\n    title = \"Introduction to the {C}o{NLL}-2003 Shared Task: Language-Independent Named Entity Recognition\",\n    author = \"Tjong Kim Sang, Erik F.  and\n      De Meulder, Fien\",\n    booktitle = \"Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003\",\n    year = \"2003\",\n    url = \"https://www.aclweb.org/anthology/W03-0419\",\n    pages = \"142--147\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd6", "disabled": false, "gated": false, "likes": 77, "downloads": 77284, "paperswithcode_id": "conll-2003", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conllpp", "sha": "3e6012875a688903477cca9bf1ba644e65480bd6", "lastModified": "2023-04-05T10:02:29.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|conll2003", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "CoNLLpp is a corrected version of the CoNLL2003 NER dataset where labels of 5.38% of the sentences in the test set\nhave been manually corrected. The training set and development set are included for completeness.\nFor more details see https://www.aclweb.org/anthology/D19-1519/ and https://github.com/ZihanWangKi/CrossWeigh", "citation": "@inproceedings{wang2019crossweigh,\n  title={CrossWeigh: Training Named Entity Tagger from Imperfect Annotations},\n  author={Wang, Zihan and Shang, Jingbo and Liu, Liyuan and Lu, Lihao and Liu, Jiacheng and Han, Jiawei},\n  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n  pages={5157--5166},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd7", "disabled": false, "gated": false, "likes": 5, "downloads": 1229, "paperswithcode_id": "conll", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conv_ai", "sha": "6ea3599d4683e70680ad01e171df860b9e5c2361", "lastModified": "2022-11-03T16:30:55.000Z", "tags": ["task_categories:conversational", "task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "evaluating-dialogue-systems", "region:us"], "private": false, "author": null, "description": "ConvAI is a dataset of human-to-bot conversations labelled for quality. This data can be used to train a metric for evaluating dialogue systems. Moreover, it can be used in the development of chatbots themselves: it contains the information on the quality of utterances and entire dialogues, that can guide a dialogue system in search of better answers.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dd9", "disabled": false, "gated": false, "likes": 2, "downloads": 406, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conv_ai_3", "sha": "eb0fce2361d4a28f810424d7c042af08213c8a42", "lastModified": "2022-11-03T16:30:50.000Z", "tags": ["task_categories:conversational", "task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "evaluating-dialogue-systems", "arxiv:2009.11352", "region:us"], "private": false, "author": null, "description": "The Conv AI 3 challenge is organized as part of the Search-oriented Conversational AI (SCAI) EMNLP workshop in 2020. The main aim of the conversational systems is to return an appropriate answer in response to the user requests. However, some user requests might be ambiguous. In Information Retrieval (IR) settings such a situation is handled mainly through the diversification of search result page. It is however much more challenging in dialogue settings. Hence, we aim to study the following situation for dialogue settings:\n- a user is asking an ambiguous question (where ambiguous question is a question to which one can return > 1 possible answers)\n- the system must identify that the question is ambiguous, and, instead of trying to answer it directly, ask a good clarifying question.", "citation": "@misc{aliannejadi2020convai3,\n      title={ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue Systems (ClariQ)},\n      author={Mohammad Aliannejadi and Julia Kiseleva and Aleksandr Chuklin and Jeff Dalton and Mikhail Burtsev},\n      year={2020},\n      eprint={2009.11352},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ddb", "disabled": false, "gated": false, "likes": 13, "downloads": 396, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "conv_questions", "sha": "7bc521a6f3116f1ea9b18f3e41447d69cbd6be9f", "lastModified": "2023-06-02T12:18:49.000Z", "tags": ["task_categories:question-answering", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:open-domain-qa", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1910.03262", "region:us"], "private": false, "author": null, "description": "ConvQuestions is the first realistic benchmark for conversational question answering over knowledge graphs.\nIt contains 11,200 conversations which can be evaluated over Wikidata. The questions feature a variety of complex\nquestion phenomena like comparisons, aggregations, compositionality, and temporal reasoning.", "citation": "@InProceedings{christmann2019look,\n  title={Look before you hop: Conversational question answering over knowledge graphs using judicious context expansion},\n  author={Christmann, Philipp and Saha Roy, Rishiraj and Abujabal, Abdalghani and Singh, Jyotsna and Weikum, Gerhard},\n  booktitle={Proceedings of the 28th ACM International Conference on Information and Knowledge Management},\n  pages={729--738},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ddc", "disabled": false, "gated": false, "likes": 2, "downloads": 332, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "coqa", "sha": "b6f6babae405ebc0a7cfd97f8cb33899255b7558", "lastModified": "2023-04-05T10:02:34.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|race", "source_datasets:extended|cnn_dailymail", "source_datasets:extended|wikipedia", "source_datasets:extended|other", "language:en", "license:other", "conversational-qa", "arxiv:1808.07042", "arxiv:1704.04683", "arxiv:1506.03340", "region:us"], "private": false, "author": null, "description": "CoQA: A Conversational Question Answering Challenge", "citation": "@article{reddy-etal-2019-coqa,\n    title = \"{C}o{QA}: A Conversational Question Answering Challenge\",\n    author = \"Reddy, Siva  and\n      Chen, Danqi  and\n      Manning, Christopher D.\",\n    journal = \"Transactions of the Association for Computational Linguistics\",\n    volume = \"7\",\n    year = \"2019\",\n    address = \"Cambridge, MA\",\n    publisher = \"MIT Press\",\n    url = \"https://aclanthology.org/Q19-1016\",\n    doi = \"10.1162/tacl_a_00266\",\n    pages = \"249--266\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ddd", "disabled": false, "gated": false, "likes": 29, "downloads": 1660, "paperswithcode_id": "coqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/cord19", "sha": "50508938c74b7faee130f9b164b1d4d55d4e77e0", "lastModified": "2022-11-03T16:31:53.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-nd-4.0", "license:cc-by-sa-4.0", "license:other", "arxiv:2004.07180", "region:us"], "private": false, "author": "allenai", "description": "The Covid-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on Covid-19 and related\nhistorical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information\nretrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19\nhas been downloaded over 75K times and has served as the basis of many Covid-19 text mining and discovery systems.\n\nThe dataset itself isn't defining a specific task, but there is a Kaggle challenge that define 17 open research\nquestions to be solved with the dataset: https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks", "citation": "@article{Wang2020CORD19TC,\n  title={CORD-19: The Covid-19 Open Research Dataset},\n  author={Lucy Lu Wang and Kyle Lo and Yoganand Chandrasekhar and Russell Reas and Jiangjiang Yang and Darrin Eide and\n  K. Funk and Rodney Michael Kinney and Ziyang Liu and W. Merrill and P. Mooney and D. Murdick and Devvret Rishi and\n  Jerry Sheehan and Zhihong Shen and B. Stilson and A. Wade and K. Wang and Christopher Wilhelm and Boya Xie and\n  D. Raymond and Daniel S. Weld and Oren Etzioni and Sebastian Kohlmeier},\n  journal={ArXiv},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dde", "disabled": false, "gated": false, "likes": 2, "downloads": 594, "paperswithcode_id": "cord-19", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cornell_movie_dialog", "sha": "7d5459371902b6681bd263227e340865b531f9d7", "lastModified": "2023-04-05T10:02:37.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts:\n- 220,579 conversational exchanges between 10,292 pairs of movie characters\n- involves 9,035 characters from 617 movies\n- in total 304,713 utterances\n- movie metadata included:\n    - genres\n    - release year\n    - IMDB rating\n    - number of IMDB votes\n    - IMDB rating\n- character metadata included:\n    - gender (for 3,774 characters)\n    - position on movie credits (3,321 characters)", "citation": "  @InProceedings{Danescu-Niculescu-Mizil+Lee:11a,\n\n  author={Cristian Danescu-Niculescu-Mizil and Lillian Lee},\n\n  title={Chameleons in imagined conversations:\n  A new approach to understanding coordination of linguistic style in dialogs.},\n\n  booktitle={Proceedings of the\n\n        Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011},\n\n  year={2011}\n\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ddf", "disabled": false, "gated": false, "likes": 11, "downloads": 365, "paperswithcode_id": "cornell-movie-dialogs-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cos_e", "sha": "7f101e04c2e0e719317bf497c727875558df8f36", "lastModified": "2023-04-05T10:02:39.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|commonsense_qa", "language:en", "license:unknown", "arxiv:1906.02361", "region:us"], "private": false, "author": null, "description": "Common Sense Explanations (CoS-E) allows for training language models to\nautomatically generate explanations that can be used during training and\ninference in a novel Commonsense Auto-Generated Explanation (CAGE) framework.", "citation": "@inproceedings{rajani2019explain,\n     title = {Explain Yourself! Leveraging Language models for Commonsense Reasoning},\n    author = {Rajani, Nazneen Fatema  and\n      McCann, Bryan  and\n      Xiong, Caiming  and\n      Socher, Richard}\n      year={2019}\n    booktitle = {Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019)}\n    url ={https://arxiv.org/abs/1906.02361}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de0", "disabled": false, "gated": false, "likes": 6, "downloads": 3784, "paperswithcode_id": "cos-e", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cosmos_qa", "sha": "81c52136f12ed9f0dc90582cd490304f3176c744", "lastModified": "2023-04-05T10:02:42.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1909.00277", "region:us"], "private": false, "author": null, "description": "Cosmos QA is a large-scale dataset of 35.6K problems that require commonsense-based reading comprehension, formulated as multiple-choice questions. It focuses on reading between the lines over a diverse collection of people's everyday narratives, asking questions concerning on the likely causes or effects of events that require reasoning beyond the exact text spans in the context", "citation": "@inproceedings{huang-etal-2019-cosmos,\n    title = \"Cosmos {QA}: Machine Reading Comprehension with Contextual Commonsense Reasoning\",\n    author = \"Huang, Lifu  and\n      Le Bras, Ronan  and\n      Bhagavatula, Chandra  and\n      Choi, Yejin\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D19-1243\",\n    doi = \"10.18653/v1/D19-1243\",\n    pages = \"2391--2401\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de1", "disabled": false, "gated": false, "likes": 9, "downloads": 18607, "paperswithcode_id": "cosmosqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "counter", "sha": "bb1ffbf35fd22ae0dfc5288858c744fb30f5c254", "lastModified": "2023-01-25T14:28:41.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:ur", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": " The COrpus of Urdu News TExt Reuse (COUNTER) corpus contains 1200 documents with real examples of text reuse from the field of journalism. It has been manually annotated at document level with three levels of reuse: wholly derived, partially derived and non derived.", "citation": "@Article{Sharjeel2016,\nauthor=\"Sharjeel, Muhammad\nand Nawab, Rao Muhammad Adeel\nand Rayson, Paul\",\ntitle=\"COUNTER: corpus of Urdu news text reuse\",\njournal=\"Language Resources and Evaluation\",\nyear=\"2016\",\npages=\"1--27\",\nissn=\"1574-0218\",\ndoi=\"10.1007/s10579-016-9367-2\",\nurl=\"http://dx.doi.org/10.1007/s10579-016-9367-2\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de2", "disabled": false, "gated": false, "likes": 0, "downloads": 293, "paperswithcode_id": "counter", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "covid_qa_castorini", "sha": "830827bcdd1304c084c05d6f3511878ba39b1cf3", "lastModified": "2022-11-03T16:30:54.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2004.11339", "region:us"], "private": false, "author": null, "description": "CovidQA is the beginnings of a question answering dataset specifically designed for COVID-19, built by hand from knowledge gathered from Kaggle's COVID-19 Open Research Dataset Challenge.", "citation": "@article{tang2020rapidly,\n  title={Rapidly Bootstrapping a Question Answering Dataset for COVID-19},\n  author={Tang, Raphael and Nogueira, Rodrigo and Zhang, Edwin and Gupta, Nikhil and Cam, Phuong and Cho, Kyunghyun and Lin, Jimmy},\n  journal={arXiv preprint arXiv:2004.11339},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de3", "disabled": false, "gated": false, "likes": 0, "downloads": 359, "paperswithcode_id": "covidqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "covid_qa_deepset", "sha": "1aaf679526aae36f371c5f3c5a304d8358e509b7", "lastModified": "2022-11-03T16:31:16.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "COVID-QA is a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19.", "citation": "@inproceedings{moller2020covid,\n  title={COVID-QA: A Question Answering Dataset for COVID-19},\n  author={M{\\\"o}ller, Timo and Reina, Anthony and Jayakumar, Raghavan and Pietsch, Malte},\n  booktitle={Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de4", "disabled": false, "gated": false, "likes": 1, "downloads": 535, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "covid_tweets_japanese", "sha": "5073fe82988519826dda8aa71d78c1b76a1a6fd3", "lastModified": "2023-01-25T14:28:47.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ja", "license:cc-by-nd-4.0", "region:us"], "private": false, "author": null, "description": "53,640 Japanese tweets with annotation if a tweet is related to COVID-19 or not. The annotation is by majority decision by 5 - 10 crowd workers. Target tweets include \"COVID\" or \"\u30b3\u30ed\u30ca\". The period of the tweets is from around January 2020 to around June 2020. The original tweets are not contained. Please use Twitter API to get them, for example.", "citation": "No paper about this dataset is published yet. Please cite this dataset as \"\u9234\u6728 \u512a: COVID-19 \u65e5\u672c\u8a9e Twitter \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 \uff08http://www.db.info.gifu-u.ac.jp/covid-19-twitter-dataset/\uff09\"", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de6", "disabled": false, "gated": false, "likes": 1, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "covost2", "sha": "6a2a56c88d7e3df5fe6ab637241153c23c6b984a", "lastModified": "2022-11-18T19:46:56.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended|other-common-voice", "language:ar", "language:ca", "language:cy", "language:de", "language:es", "language:et", "language:fa", "language:fr", "language:id", "language:it", "language:ja", "language:lv", "language:mn", "language:nl", "language:pt", "language:ru", "language:sl", "language:sv", "language:ta", "language:tr", "language:zh", "license:cc-by-nc-4.0", "arxiv:2007.10310", "region:us"], "private": false, "author": null, "description": "CoVoST 2, a large-scale multilingual speech translation corpus covering translations from 21 languages into English and from English into 15 languages. The dataset is created using Mozilla\u2019s open source Common Voice database of crowdsourced voice recordings.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .mp3 format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport torchaudio\n\ndef map_to_array(batch):\n    speech_array, _ = torchaudio.load(batch[\"file\"])\n    batch[\"speech\"] = speech_array.numpy()\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@misc{wang2020covost,\n    title={CoVoST 2: A Massively Multilingual Speech-to-Text Translation Corpus},\n    author={Changhan Wang and Anne Wu and Juan Pino},\n    year={2020},\n    eprint={2007.10310},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de7", "disabled": false, "gated": false, "likes": 8, "downloads": 5437, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cppe-5", "sha": "4d1d3ae0f6b666ca409f27fca5fe3f0f20ec6f61", "lastModified": "2023-03-06T18:48:26.000Z", "tags": ["task_categories:object-detection", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "medical-personal-protective-equipment-detection", "arxiv:2112.09569", "region:us"], "private": false, "author": null, "description": "CPPE - 5 (Medical Personal Protective Equipment) is a new challenging dataset with the goal\nto allow the study of subordinate categorization of medical personal protective equipments,\nwhich is not possible with other popular data sets that focus on broad level categories.", "citation": "@misc{dagli2021cppe5,\n      title={CPPE-5: Medical Personal Protective Equipment Dataset},\n      author={Rishit Dagli and Ali Mustufa Shaikh},\n      year={2021},\n      eprint={2112.09569},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de8", "disabled": false, "gated": false, "likes": 7, "downloads": 1825, "paperswithcode_id": "cppe-5", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "craigslist_bargains", "sha": "a3d49d1268893727b44f37ba3064bcc1b55deff6", "lastModified": "2022-11-18T19:47:08.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1808.09637", "region:us"], "private": false, "author": null, "description": "We study negotiation dialogues where two agents, a buyer and a seller,\nnegotiate over the price of an time for sale. We collected a dataset of more\nthan 6K negotiation dialogues over multiple categories of products scraped from Craigslist.\nOur goal is to develop an agent that negotiates with humans through such conversations.\nThe challenge is to handle both the negotiation strategy and the rich language for bargaining.", "citation": "@misc{he2018decoupling,\n    title={Decoupling Strategy and Generation in Negotiation Dialogues},\n    author={He He and Derek Chen and Anusha Balakrishnan and Percy Liang},\n    year={2018},\n    eprint={1808.09637},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181de9", "disabled": false, "gated": false, "likes": 9, "downloads": 2554, "paperswithcode_id": "craigslistbargains", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "crawl_domain", "sha": "b7aaebf3ebb05321055f667332005cb4e2f5c70a", "lastModified": "2022-11-18T19:47:14.000Z", "tags": ["task_categories:other", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-Common-Crawl", "source_datasets:original", "language:en", "license:mit", "web-search", "text-to-speech", "arxiv:2011.03138", "region:us"], "private": false, "author": null, "description": "Corpus of domain names scraped from Common Crawl and manually annotated to add word boundaries (e.g. \"commoncrawl\" to \"common crawl\"). Breaking domain names such as \"openresearch\" into component words \"open\" and \"research\" is important for applications such as Text-to-Speech synthesis and web search. Common Crawl is an open repository of web crawl data that can be accessed and analyzed by anyone. Specifically, we scraped the plaintext (WET) extracts for domain names from URLs that contained diverse letter casing (e.g. \"OpenBSD\"). Although in the previous example, segmentation is trivial using letter casing, this was not always the case (e.g. \"NASA\"), so we had to manually annotate the data. The dataset is stored as plaintext file where each line is an example of space separated segments of a domain name. The examples are stored in their original letter casing, but harder and more interesting examples can be generated by lowercasing the input first.", "citation": "@inproceedings{zrs2020urlsegmentation,\n  title={Semi-supervised URL Segmentation with Recurrent Neural Networks Pre-trained on Knowledge Graph Entities},\n  author={Hao Zhang and Jae Ro and Richard William Sproat},\n  booktitle={The 28th International Conference on Computational Linguistics (COLING 2020)},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dea", "disabled": false, "gated": false, "likes": 0, "downloads": 321, "paperswithcode_id": "common-crawl-domain-names", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "crd3", "sha": "f5ae50dbfe2a982c4b1aa461c9b44dc11e5f7e3b", "lastModified": "2022-11-18T19:47:20.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset.\nCritical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an open-ended role-playing game.\nThe dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding\nabstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player\ncollaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail,\nand semantic ties to the previous dialogues.", "citation": "@inproceedings{\ntitle = {Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset},\nauthor = {Rameshkumar, Revanth  and Bailey, Peter},\nyear = {2020},\npublisher = {Association for Computational Linguistics},\nconference = {ACL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181deb", "disabled": false, "gated": false, "likes": 12, "downloads": 313, "paperswithcode_id": "crd3", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "crows_pairs", "sha": "7accd3148a6d0a561188b83406addf18a406e18b", "lastModified": "2023-07-06T09:23:23.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "bias-evaluation", "region:us"], "private": false, "author": null, "description": "CrowS-Pairs, a challenge dataset for measuring the degree to which U.S. stereotypical biases present in the masked language models (MLMs).", "citation": "@inproceedings{nangia2020crows,\n    title = \"{CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models}\",\n    author = \"Nangia, Nikita  and\n      Vania, Clara  and\n      Bhalerao, Rasika  and\n      Bowman, Samuel R.\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ded", "disabled": false, "gated": false, "likes": 4, "downloads": 1859, "paperswithcode_id": "crows-pairs", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cryptonite", "sha": "f1eb43a73d0b65da836aaab999fa1a2349299c7d", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "arxiv:2103.01242", "region:us"], "private": false, "author": null, "description": "Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language\nCurrent NLP datasets targeting ambiguity can be solved by a native speaker with relative ease. We present Cryptonite,\na large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced. Each\nexample in Cryptonite is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving\nrequires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. Cryptic clues pose a\nchallenge even for experienced solvers, though top-tier experts can solve them with almost 100% accuracy. Cryptonite\nis a challenging task for current models; fine-tuning T5-Large on 470k cryptic clues achieves only 7.6% accuracy, on\npar with the accuracy of a rule-based clue solver (8.6%).", "citation": "@misc{efrat2021cryptonite,\n      title={Cryptonite: A Cryptic Crossword Benchmark for Extreme Ambiguity in Language},\n      author={Avia Efrat and Uri Shaham and Dan Kilman and Omer Levy},\n      year={2021},\n      eprint={2103.01242},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dee", "disabled": false, "gated": false, "likes": 2, "downloads": 301, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cs_restaurants", "sha": "a35de126306169ba45cff070f55bce4378db2ad0", "lastModified": "2022-11-18T19:49:56.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-san-francisco-restaurants", "language:cs", "license:cc-by-4.0", "intent-to-text", "arxiv:1910.05298", "region:us"], "private": false, "author": null, "description": "This is a dataset for NLG in task-oriented spoken dialogue systems with Czech as the target language. It originated as\na translation of the English San Francisco Restaurants dataset by Wen et al. (2015).", "citation": "@article{DBLP:journals/corr/abs-1910-05298,\n  author    = {Ondrej Dusek and\n               Filip Jurcicek},\n  title     = {Neural Generation for Czech: Data and Baselines},\n  journal   = {CoRR},\n  volume    = {abs/1910.05298},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1910.05298},\n  archivePrefix = {arXiv},\n  eprint    = {1910.05298},\n  timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-05298.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181def", "disabled": false, "gated": false, "likes": 1, "downloads": 721, "paperswithcode_id": "czech-restaurant-information", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cuad", "sha": "27f1ab3e6147121ba2d74c15316e9d8f601bd3f6", "lastModified": "2022-11-18T19:50:02.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2103.06268", "region:us"], "private": false, "author": null, "description": "Contract Understanding Atticus Dataset (CUAD) v1 is a corpus of more than 13,000 labels in 510\ncommercial legal contracts that have been manually labeled to identify 41 categories of important\nclauses that lawyers look for when reviewing contracts in connection with corporate transactions.", "citation": "@article{hendrycks2021cuad,\n      title={CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review},\n      author={Dan Hendrycks and Collin Burns and Anya Chen and Spencer Ball},\n      journal={arXiv preprint arXiv:2103.06268},\n      year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df0", "disabled": false, "gated": false, "likes": 30, "downloads": 1065, "paperswithcode_id": "cuad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "curiosity_dialogs", "sha": "1252b91d7d5b9b0d49b2d078a5a7664682b59bbe", "lastModified": "2023-01-25T14:28:58.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "conversational-curiosity", "region:us"], "private": false, "author": null, "description": "This dataset contains 14K dialogs (181K utterances) where users and assistants converse about geographic topics like\ngeopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, message-level dialog\nacts, grounding to Wikipedia, and user reactions to messages.", "citation": "@inproceedings{rodriguez2020curiosity,\n    title = {Information Seeking in the Spirit of Learning: a Dataset for Conversational Curiosity},\n    author = {Pedro Rodriguez and Paul Crook and Seungwhan Moon and Zhiguang Wang},\n    year = 2020,\n    booktitle = {Empirical Methods in Natural Language Processing}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df1", "disabled": false, "gated": false, "likes": 7, "downloads": 312, "paperswithcode_id": "curiosity", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "daily_dialog", "sha": "40096e2c18738d9f73dc416663958375968f5f4b", "lastModified": "2023-05-07T15:20:15.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "emotion-classification", "dialog-act-classification", "region:us"], "private": false, "author": null, "description": "We develop a high-quality multi-turn dialog dataset, DailyDialog, which is intriguing in several aspects.\nThe language is human-written and less noisy. The dialogues in the dataset reflect our daily communication way\nand cover various topics about our daily life. We also manually label the developed dataset with communication\nintention and emotion information. Then, we evaluate existing approaches on DailyDialog dataset and hope it\nbenefit the research field of dialog systems.", "citation": "@InProceedings{li2017dailydialog,\n    author = {Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and Cao, Ziqiang and Niu, Shuzi},\n    title = {DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},\n    booktitle = {Proceedings of The 8th International Joint Conference on Natural Language Processing (IJCNLP 2017)},\n    year = {2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df2", "disabled": false, "gated": false, "likes": 75, "downloads": 8948, "paperswithcode_id": "dailydialog", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dane", "sha": "5833322fa80398f4a3b9f77830d335667997de7e", "lastModified": "2023-01-25T14:29:05.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-Danish-Universal-Dependencies-treebank", "language:da", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "The DaNE dataset has been annotated with Named Entities for PER, ORG and LOC\nby the Alexandra Institute.\nIt is a reannotation of the UD-DDT (Universal Dependency - Danish Dependency Treebank)\nwhich has annotations for dependency parsing and part-of-speech (POS) tagging.\nThe Danish UD treebank (Johannsen et al., 2015, UD-DDT) is a conversion of\nthe Danish Dependency Treebank (Buch-Kromann et al. 2003) based on texts\nfrom Parole (Britt, 1998).", "citation": "@inproceedings{hvingelby-etal-2020-dane,\n    title = \"{D}a{NE}: A Named Entity Resource for {D}anish\",\n    author = \"Hvingelby, Rasmus  and\n      Pauli, Amalie Brogaard  and\n      Barrett, Maria  and\n      Rosted, Christina  and\n      Lidegaard, Lasse Malm  and\n      S\u00f8gaard, Anders\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.565\",\n    pages = \"4597--4604\",\n    abstract = \"We present a named entity annotation for the Danish Universal Dependencies treebank using the CoNLL-2003 annotation scheme: DaNE. It is the largest publicly available, Danish named entity gold annotation. We evaluate the quality of our annotations intrinsically by double annotating the entire treebank and extrinsically by comparing our annotations to a recently released named entity annotation of the validation and test sections of the Danish Universal Dependencies treebank. We benchmark the new resource by training and evaluating competitive architectures for supervised named entity recognition (NER), including FLAIR, monolingual (Danish) BERT and multilingual BERT. We explore cross-lingual transfer in multilingual BERT from five related languages in zero-shot and direct transfer setups, and we show that even with our modestly-sized training set, we improve Danish NER over a recent cross-lingual approach, as well as over zero-shot transfer from five related languages. Using multilingual BERT, we achieve higher performance by fine-tuning on both DaNE and a larger Bokm{\\aa}l (Norwegian) training set compared to only using DaNE. However, the highest performance isachieved by using a Danish BERT fine-tuned on DaNE. Our dataset enables improvements and applicability for Danish NER beyond cross-lingual methods. We employ a thorough error analysis of the predictions of the best models for seen and unseen entities, as well as their robustness on un-capitalized text. The annotated dataset and all the trained models are made publicly available.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df3", "disabled": false, "gated": false, "likes": 3, "downloads": 857, "paperswithcode_id": "dane", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "danish_political_comments", "sha": "ad1ac3916f8bf72d138aeda9f350c1638bbb4e39", "lastModified": "2023-11-24T16:12:39.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:da", "license:unknown", "region:us"], "private": false, "author": null, "description": "The dataset consists of 9008 sentences that are labelled with fine-grained polarity in the range from -2 to 2 (negative to postive). The quality of the fine-grained is not cross validated and is therefore subject to uncertainties; however, the simple polarity has been cross validated and therefore is considered to be more correct.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df4", "disabled": false, "gated": false, "likes": 0, "downloads": 362, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dart", "sha": "c8cd33ecbcc26b64feefb0457988dfcae27b8df4", "lastModified": "2022-11-18T19:57:00.000Z", "tags": ["task_categories:tabular-to-text", "task_ids:rdf-to-text", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|wikitable_questions", "source_datasets:extended|wikisql", "source_datasets:extended|web_nlg", "source_datasets:extended|cleaned_e2e", "language:en", "license:mit", "arxiv:2007.02871", "region:us"], "private": false, "author": null, "description": "DART is a large and open-domain structured DAta Record to Text generation corpus with high-quality\nsentence annotations with each input being a set of entity-relation triples following a tree-structured ontology.\nIt consists of 82191 examples across different domains with each input being a semantic RDF triple set derived\nfrom data records in tables and the tree ontology of table schema, annotated with sentence description that\ncovers all facts in the triple set.\n\nDART is released in the following paper where you can find more details and baseline results:\nhttps://arxiv.org/abs/2007.02871", "citation": "@article{radev2020dart,\n  title={DART: Open-Domain Structured Data Record to Text Generation},\n  author={Dragomir Radev and Rui Zhang and Amrit Rau and Abhinand Sivaprasad and Chiachun Hsieh and Nazneen Fatema Rajani and Xiangru Tang and Aadit Vyas and Neha Verma and Pranav Krishna and Yangxiaokang Liu and Nadia Irwanto and Jessica Pan and Faiaz Rahman and Ahmad Zaidi and Murori Mutuma and Yasin Tarabar and Ankit Gupta and Tao Yu and Yi Chern Tan and Xi Victoria Lin and Caiming Xiong and Richard Socher},\n  journal={arXiv preprint arXiv:2007.02871},\n  year={2020}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df5", "disabled": false, "gated": false, "likes": 4, "downloads": 1029, "paperswithcode_id": "dart", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "datacommons_factcheck", "sha": "77d91cdde804e973863178c91a58329fcf5b4aa7", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "A dataset of fact checked claims by news media maintained by datacommons.org", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Data Commons 2019 Fact Checks},\nauthors={datacommons.org},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df6", "disabled": false, "gated": false, "likes": 3, "downloads": 481, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dbpedia_14", "sha": "3144f92e156130ec98e332548bcbb00f58a2644e", "lastModified": "2023-01-25T14:29:11.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The DBpedia ontology classification dataset is constructed by picking 14 non-overlapping classes\nfrom DBpedia 2014. They are listed in classes.txt. From each of thse 14 ontology classes, we\nrandomly choose 40,000 training samples and 5,000 testing samples. Therefore, the total size\nof the training dataset is 560,000 and testing dataset 70,000.\nThere are 3 columns in the dataset (same for train and test splits), corresponding to class index\n(1 to 14), title and content. The title and content are escaped using double quotes (\"), and any\ninternal double quote is escaped by 2 double quotes (\"\"). There are no new lines in title or content.", "citation": "@article{lehmann2015dbpedia,\n  title={DBpedia--a large-scale, multilingual knowledge base extracted from Wikipedia},\n  author={Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas,\n  Dimitris and Mendes, Pablo N and Hellmann, Sebastian and Morsey, Mohamed and Van Kleef,\n  Patrick and Auer, S{\\\"o}ren and others},\n  journal={Semantic web},\n  volume={6},\n  number={2},\n  pages={167--195},\n  year={2015},\n  publisher={IOS Press}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df7", "disabled": false, "gated": false, "likes": 10, "downloads": 6357, "paperswithcode_id": "dbpedia", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dbrd", "sha": "5f313da5d8e8035ca1da453e96f684247a374399", "lastModified": "2023-01-25T14:29:14.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:nl", "license:cc-by-nc-sa-4.0", "arxiv:1910.00896", "region:us"], "private": false, "author": null, "description": "The Dutch Book Review Dataset (DBRD) contains over 110k book reviews of which 22k have associated binary sentiment polarity labels. It is intended as a benchmark for sentiment classification in Dutch and created due to a lack of annotated datasets in Dutch that are suitable for this task.", "citation": "@article{DBLP:journals/corr/abs-1910-00896,\n  author    = {Benjamin van der Burgh and\n               Suzan Verberne},\n  title     = {The merits of Universal Language Model Fine-tuning for Small Datasets\n               - a case with Dutch book reviews},\n  journal   = {CoRR},\n  volume    = {abs/1910.00896},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1910.00896},\n  archivePrefix = {arXiv},\n  eprint    = {1910.00896},\n  timestamp = {Fri, 04 Oct 2019 12:28:06 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-00896.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df8", "disabled": false, "gated": false, "likes": 4, "downloads": 1256, "paperswithcode_id": "dbrd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "deal_or_no_dialog", "sha": "809ed233cac4b05fcadca317d906a2727e879034", "lastModified": "2022-11-18T19:57:59.000Z", "tags": ["task_categories:conversational", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1706.05125", "region:us"], "private": false, "author": null, "description": "A large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other\u2019s reward functions must reach anagreement (o a deal) via natural language dialogue.", "citation": "@article{lewis2017deal,\n  title={Deal or no deal? end-to-end learning for negotiation dialogues},\n  author={Lewis, Mike and Yarats, Denis and Dauphin, Yann N and Parikh, Devi and Batra, Dhruv},\n  journal={arXiv preprint arXiv:1706.05125},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181df9", "disabled": false, "gated": false, "likes": 5, "downloads": 875, "paperswithcode_id": "negotiation-dialogues-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "definite_pronoun_resolution", "sha": "d126f548312cc2a90ec2b940865a8a19182bbf72", "lastModified": "2023-04-05T10:04:44.000Z", "tags": ["task_categories:token-classification", "task_ids:word-sense-disambiguation", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Composed by 30 students from one of the author's undergraduate classes. These\nsentence pairs cover topics ranging from real events (e.g., Iran's plan to\nattack the Saudi ambassador to the U.S.) to events/characters in movies (e.g.,\nBatman) and purely imaginary situations, largely reflecting the pop culture as\nperceived by the American kids born in the early 90s. Each annotated example\nspans four lines: the first line contains the sentence, the second line contains\nthe target pronoun, the third line contains the two candidate antecedents, and\nthe fourth line contains the correct antecedent. If the target pronoun appears\nmore than once in the sentence, its first occurrence is the one to be resolved.", "citation": "@inproceedings{rahman2012resolving,\n  title={Resolving complex cases of definite pronouns: the winograd schema challenge},\n  author={Rahman, Altaf and Ng, Vincent},\n  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},\n  pages={777--789},\n  year={2012},\n  organization={Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dfa", "disabled": false, "gated": false, "likes": 3, "downloads": 338, "paperswithcode_id": "definite-pronoun-resolution-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dengue_filipino", "sha": "d81e2d1cbcf6049ecb324a872d4e3aac60b87743", "lastModified": "2023-01-25T14:29:21.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:tl", "license:unknown", "region:us"], "private": false, "author": null, "description": "    Benchmark dataset for low-resource multiclass classification, with 4,015 training, 500 testing, and 500 validation examples, each labeled as part of five classes. Each sample can be a part of multiple classes. Collected as tweets.", "citation": "    @INPROCEEDINGS{8459963,\n      author={E. D. {Livelo} and C. {Cheng}},\n      booktitle={2018 IEEE International Conference on Agents (ICA)},\n      title={Intelligent Dengue Infoveillance Using Gated Recurrent Neural Learning and Cross-Label Frequencies},\n      year={2018},\n      volume={},\n      number={},\n      pages={2-7},\n      doi={10.1109/AGENTS.2018.8459963}}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dfb", "disabled": false, "gated": false, "likes": 1, "downloads": 307, "paperswithcode_id": "dengue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dialog_re", "sha": "0f7f9923250e3de0be82120b8f638691b9d915a8", "lastModified": "2022-11-18T19:58:15.000Z", "tags": ["task_categories:other", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "relation-extraction", "arxiv:2004.08056", "region:us"], "private": false, "author": null, "description": "DialogRE is the first human-annotated dialogue based relation extraction (RE) dataset aiming\nto support the prediction of relation(s) between two arguments that appear in a dialogue.\nThe dataset annotates all occurrences of 36 possible relation types that exist between pairs\nof arguments in the 1,788 dialogues originating from the complete transcripts of Friends.", "citation": "@inproceedings{yu2020dialogue,\n  title={Dialogue-Based Relation Extraction},\n  author={Yu, Dian and Sun, Kai and Cardie, Claire and Yu, Dong},\n  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n  year={2020},\n  url={https://arxiv.org/abs/2004.08056v1}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dfc", "disabled": false, "gated": false, "likes": 7, "downloads": 293, "paperswithcode_id": "dialogre", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "disaster_response_messages", "sha": "edcb59c9e9b5af53580dd519bfe6635f83a1f775", "lastModified": "2023-01-25T14:29:29.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-classification", "task_ids:intent-classification", "task_ids:sentiment-classification", "task_ids:text-simplification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:es", "language:fr", "language:ht", "language:ur", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset contains 30,000 messages drawn from events including an earthquake in Haiti in 2010, an earthquake in Chile in 2010, floods in Pakistan in 2010, super-storm Sandy in the U.S.A. in 2012, and news articles spanning a large number of years and 100s of different disasters.\nThe data has been encoded with 36 different categories related to disaster response and has been stripped of messages with sensitive information in their entirety.\nUpon release, this is the featured dataset of a new Udacity course on Data Science and the AI4ALL summer school and is especially utile for text analytics and natural language processing (NLP) tasks and models.\nThe input data in this job contains thousands of untranslated disaster-related messages and their English translations.", "citation": "@inproceedings{title={Multilingual Disaster Response Messages}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dfe", "disabled": false, "gated": false, "likes": 3, "downloads": 356, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "discofuse", "sha": "0a4a73c22474fcd7c9940032202188066852564d", "lastModified": "2023-04-05T10:04:50.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "sentence-fusion", "arxiv:1902.10526", "region:us"], "private": false, "author": null, "description": " DISCOFUSE is a large scale dataset for discourse-based sentence fusion.", "citation": "@InProceedings{GevaEtAl2019,\n  title = {DiscoFuse: A Large-Scale Dataset for Discourse-Based Sentence Fusion},\n  author = {Geva, Mor and Malmi, Eric and Szpektor, Idan and Berant, Jonathan},\n  booktitle = {Proceedings of the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics},\n  note = {arXiv preprint arXiv:1902.10526},\n  year = {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181dff", "disabled": false, "gated": false, "likes": 4, "downloads": 546, "paperswithcode_id": "discofuse", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "disfl_qa", "sha": "47600012d52a0b00d834ac938e4fe3f9bcf787a8", "lastModified": "2022-11-18T19:58:47.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2106.04016", "region:us"], "private": false, "author": null, "description": "Disfl-QA is a targeted dataset for contextual disfluencies in an information seeking setting,\nnamely question answering over Wikipedia passages. Disfl-QA builds upon the SQuAD-v2 (Rajpurkar et al., 2018)\ndataset, where each question in the dev set is annotated to add a contextual disfluency using the paragraph as\na source of distractors.\n\nThe final dataset consists of ~12k (disfluent question, answer) pairs. Over 90% of the disfluencies are\ncorrections or restarts, making it a much harder test set for disfluency correction. Disfl-QA aims to fill a\nmajor gap between speech and NLP research community. We hope the dataset can serve as a benchmark dataset for\ntesting robustness of models against disfluent inputs.\n\nOur expriments reveal that the state-of-the-art models are brittle when subjected to disfluent inputs from\nDisfl-QA. Detailed experiments and analyses can be found in our paper.", "citation": "@inproceedings{gupta-etal-2021-disflqa,\n    title = \"{Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering}\",\n    author = \"Gupta, Aditya and Xu, Jiacheng and Upadhyay, Shyam and Yang, Diyi and Faruqui, Manaal\",\n    booktitle = \"Findings of ACL\",\n    year = \"2021\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e01", "disabled": false, "gated": false, "likes": 1, "downloads": 310, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "doc2dial", "sha": "5848f2d9e6c5e36b2e5e0311a2ef2323f9e12421", "lastModified": "2022-11-18T19:58:53.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "Doc2dial is dataset of goal-oriented dialogues that are grounded in the associated documents. It includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets this dataset covers a variety of dialogue scenes in information-seeking conversations.", "citation": "@inproceedings{feng-etal-2020-doc2dial,\n    title = \"doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset\",\n    author = \"Feng, Song  and Wan, Hui  and Gunasekara, Chulaka  and Patel, Siva  and Joshi, Sachindra  and Lastras, Luis\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.652\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e02", "disabled": false, "gated": false, "likes": 2, "downloads": 601, "paperswithcode_id": "doc2dial", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "docred", "sha": "7985b4e0371e6c61a756feb41b7b27becf71c666", "lastModified": "2023-06-14T14:07:55.000Z", "tags": ["task_categories:text-retrieval", "task_ids:entity-linking-retrieval", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:mit", "arxiv:1906.06127", "region:us"], "private": false, "author": null, "description": "Multiple entities in a document generally exhibit complex inter-sentence relations, and cannot be well handled by existing relation extraction (RE) methods that typically focus on extracting intra-sentence relations for single entity pairs. In order to accelerate the research on document-level RE, we introduce DocRED, a new dataset constructed from Wikipedia and Wikidata with three features:\n    - DocRED annotates both named entities and relations, and is the largest human-annotated dataset for document-level RE from plain text.\n    - DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.\n    - Along with the human-annotated data, we also offer large-scale distantly supervised data, which enables DocRED to be adopted for both supervised and weakly supervised scenarios.", "citation": "@inproceedings{yao-etal-2019-docred,\n    title = \"{D}oc{RED}: A Large-Scale Document-Level Relation Extraction Dataset\",\n    author = \"Yao, Yuan  and\n      Ye, Deming  and\n      Li, Peng  and\n      Han, Xu  and\n      Lin, Yankai  and\n      Liu, Zhenghao  and\n      Liu, Zhiyuan  and\n      Huang, Lixin  and\n      Zhou, Jie  and\n      Sun, Maosong\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P19-1074\",\n    doi = \"10.18653/v1/P19-1074\",\n    pages = \"764--777\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e03", "disabled": false, "gated": false, "likes": 8, "downloads": 608, "paperswithcode_id": "docred", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "doqa", "sha": "213aac854f5fd7ddc715ecee1ab0eb9162eb83fd", "lastModified": "2023-04-05T10:04:58.000Z", "tags": ["language:en", "arxiv:2005.01328", "region:us"], "private": false, "author": null, "description": "DoQA is a dataset for accessing Domain Specific FAQs via conversational QA that contains 2,437 information-seeking question/answer dialogues\n(10,917 questions in total) on three different domains: cooking, travel and movies. Note that we include in the generic concept of FAQs also\nCommunity Question Answering sites, as well as corporate information in intranets which is maintained in textual form similar to FAQs, often\nreferred to as internal \u201cknowledge bases\u201d.\n\nThese dialogues are created by crowd workers that play the following two roles: the user who asks questions about a given topic posted in Stack\nExchange (https://stackexchange.com/), and the domain expert who replies to the questions by selecting a short span of text from the long textual\nreply in the original post. The expert can rephrase the selected span, in order to make it look more natural. The dataset covers unanswerable\nquestions and some relevant dialogue acts.\n\nDoQA enables the development and evaluation of conversational QA systems that help users access the knowledge buried in domain specific FAQs.", "citation": "@misc{campos2020doqa,\n    title={DoQA -- Accessing Domain-Specific FAQs via Conversational QA},\n    author={Jon Ander Campos and Arantxa Otegi and Aitor Soroa and Jan Deriu and Mark Cieliebak and Eneko Agirre},\n    year={2020},\n    eprint={2005.01328},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e04", "disabled": false, "gated": false, "likes": 0, "downloads": 621, "paperswithcode_id": "doqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dream", "sha": "9f4140852ab77960c03d993b4a4276a824e29bcc", "lastModified": "2022-11-18T19:59:12.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "DREAM is a multiple-choice Dialogue-based REAding comprehension exaMination dataset. In contrast to existing reading comprehension datasets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.", "citation": "@article{sundream2018,\n  title={{DREAM}: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension},\n  author={Sun, Kai and Yu, Dian and Chen, Jianshu and Yu, Dong and Choi, Yejin and Cardie, Claire},\n  journal={Transactions of the Association for Computational Linguistics},\n  year={2019},\n  url={https://arxiv.org/abs/1902.00164v1}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e05", "disabled": false, "gated": false, "likes": 6, "downloads": 7604, "paperswithcode_id": "dream", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "drop", "sha": "210a4d21519a0e8f976c778d39d25c7d975dbf8d", "lastModified": "2023-04-05T10:05:02.000Z", "tags": ["task_categories:question-answering", "task_categories:text2text-generation", "task_ids:extractive-qa", "task_ids:abstractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs.\n. DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a\nquestion, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or\n sorting). These operations require a much more comprehensive understanding of the content of paragraphs than what was\n necessary for prior datasets.", "citation": "@inproceedings{Dua2019DROP,\n  author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n  title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n  booktitle={Proc. of NAACL},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e06", "disabled": false, "gated": false, "likes": 11, "downloads": 2571, "paperswithcode_id": "drop", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "duorc", "sha": "2fe9cee69f70f3d5466df0add08dd7889e8ab47a", "lastModified": "2023-06-01T14:59:57.000Z", "tags": ["task_categories:question-answering", "task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "arxiv:1804.07927", "region:us"], "private": false, "author": null, "description": "DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie.", "citation": "@inproceedings{DuoRC,\nauthor = { Amrita Saha and Rahul Aralikatte and Mitesh M. Khapra and Karthik Sankaranarayanan},title = {{DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension}},\nbooktitle = {Meeting of the Association for Computational Linguistics (ACL)},\nyear = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e07", "disabled": false, "gated": false, "likes": 26, "downloads": 5632, "paperswithcode_id": "duorc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dutch_social", "sha": "60440936c9bea2d71604102f32eedd65dabec364", "lastModified": "2023-01-25T14:29:36.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:multi-label-classification", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:nl", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "The dataset contains around 271,342 tweets. The tweets are filtered via the official Twitter API to\ncontain tweets in Dutch language or by users who have specified their location information within Netherlands\ngeographical boundaries. Using natural language processing we have classified the tweets for their HISCO codes.\nIf the user has provided their location within Dutch boundaries, we have also classified them to their respective\nprovinces The objective of this dataset is to make research data available publicly in a FAIR (Findable, Accessible,\nInteroperable, Reusable) way. Twitter's Terms of Service Licensed under Attribution-NonCommercial 4.0 International\n(CC BY-NC 4.0) (2020-10-27)", "citation": "@data{FK2/MTPTL7_2020,\nauthor = {Gupta, Aakash},\npublisher = {COVID-19 Data Hub},\ntitle = {{Dutch social media collection}},\nyear = {2020},\nversion = {DRAFT VERSION},\ndoi = {10.5072/FK2/MTPTL7},\nurl = {https://doi.org/10.5072/FK2/MTPTL7}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e08", "disabled": false, "gated": false, "likes": 6, "downloads": 319, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dyk", "sha": "4430b6322c71f329e361675e9e2798819a091baf", "lastModified": "2023-01-25T14:29:39.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:bsd-3-clause", "region:us"], "private": false, "author": null, "description": "The Did You Know (pol. Czy wiesz?) dataset consists of human-annotated question-answer pairs. The task is to predict if the answer is correct. We chose the negatives which have the largest token overlap with a question.", "citation": "@inproceedings{marcinczuk2013open,\ntitle={Open dataset for development of Polish Question Answering systems},\nauthor={Marcinczuk, Michal and Ptak, Marcin and Radziszewski, Adam and Piasecki, Maciej},\nbooktitle={Proceedings of the 6th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, Wydawnictwo Poznanskie, Fundacja Uniwersytetu im. Adama Mickiewicza},\nyear={2013}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e09", "disabled": false, "gated": false, "likes": 0, "downloads": 382, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "e2e_nlg", "sha": "f7c625f64fbcc12ad024c826b12ce747d72b118e", "lastModified": "2022-11-18T19:59:40.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "meaning-representation-to-text", "arxiv:1706.09254", "arxiv:1901.11528", "region:us"], "private": false, "author": null, "description": "The E2E dataset is used for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area.\nThe E2E dataset poses new challenges:\n(1) its human reference texts show more lexical richness and syntactic variation, including discourse phenomena;\n(2) generating from this set requires content selection. As such, learning from this dataset promises more natural, varied and less template-like system utterances.\n\nE2E is released in the following paper where you can find more details and baseline results:\nhttps://arxiv.org/abs/1706.09254", "citation": "@article{dusek.etal2020:csl,\n  title = {Evaluating the {{State}}-of-the-{{Art}} of {{End}}-to-{{End Natural Language Generation}}: {{The E2E NLG Challenge}}},\n  author = {Du{\\v{s}}ek, Ond\\v{r}ej and Novikova, Jekaterina and Rieser, Verena},\n  year = {2020},\n  month = jan,\n  volume = {59},\n  pages = {123--156},\n  doi = {10.1016/j.csl.2019.06.009},\n  archivePrefix = {arXiv},\n  eprint = {1901.11528},\n  eprinttype = {arxiv},\n  journal = {Computer Speech & Language}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0a", "disabled": false, "gated": false, "likes": 10, "downloads": 1908, "paperswithcode_id": "e2e", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "e2e_nlg_cleaned", "sha": "b6c16fb7db115c708125ac39da9f62e061575a53", "lastModified": "2022-11-18T19:59:46.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "meaning-representation-to-text", "arxiv:1706.09254", "arxiv:1901.11528", "region:us"], "private": false, "author": null, "description": "An update release of E2E NLG Challenge data with cleaned MRs and scripts, accompanying the following paper:\n\nOnd\u0159ej Du\u0161ek, David M. Howcroft, and Verena Rieser (2019): Semantic Noise Matters for Neural Natural Language Generation. In INLG, Tokyo, Japan.", "citation": "@inproceedings{dusek-etal-2019-semantic,\n    title = \"Semantic Noise Matters for Neural Natural Language Generation\",\n    author = \"Du{\\v{s}}ek, Ond{\\v{r}}ej  and\n      Howcroft, David M.  and\n      Rieser, Verena\",\n    booktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\n    month = oct # \"{--}\" # nov,\n    year = \"2019\",\n    address = \"Tokyo, Japan\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/W19-8652\",\n    doi = \"10.18653/v1/W19-8652\",\n    pages = \"421--426\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0b", "disabled": false, "gated": false, "likes": 2, "downloads": 830, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ecb", "sha": "72a0cf3a1cfd704f678156302d1013ab2dc74584", "lastModified": "2022-11-03T16:31:41.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:sk", "language:sl", "license:unknown", "region:us"], "private": false, "author": null, "description": "Original source: Website and documentatuion from the European Central Bank, compiled and made available by Alberto Simoes (thank you very much!)\n19 languages, 170 bitexts\ntotal number of files: 340\ntotal number of tokens: 757.37M\ntotal number of sentence fragments: 30.55M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0c", "disabled": false, "gated": false, "likes": 0, "downloads": 991, "paperswithcode_id": "ecb", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ecthr_cases", "sha": "4ea28b65e35f7103145e94f18a6354dd25c60f3e", "lastModified": "2022-11-18T19:59:57.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "rationale-extraction", "legal-judgment-prediction", "arxiv:2103.13084", "region:us"], "private": false, "author": null, "description": "The ECtHR Cases dataset is designed for experimentation of neural judgment prediction and rationale extraction considering ECtHR cases.", "citation": "@InProceedings{chalkidis-et-al-2021-ecthr,\n    title = \"Paragraph-level Rationale Extraction through Regularization: A case study on European Court of Human Rights Cases\",\n    author = \"Chalkidis, Ilias and Fergadiotis, Manos and Tsarapatsanis, Dimitrios and Aletras, Nikolaos and Androutsopoulos, Ion and Malakasiotis, Prodromos\",\n    booktitle = \"Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics\",\n    year = \"2021\",\n    address = \"Mexico City, Mexico\",\n    publisher = \"Association for Computational Linguistics\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0d", "disabled": false, "gated": false, "likes": 8, "downloads": 1024, "paperswithcode_id": "ecthr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eduge", "sha": "ea3bcbe27ad1b65655311ffb2ad6234a82d4c723", "lastModified": "2023-01-25T14:29:42.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:mn", "license:unknown", "region:us"], "private": false, "author": null, "description": "Eduge news classification dataset is provided by Bolorsoft LLC. It is used for training the Eduge.mn production news classifier\n75K news articles in 9 categories: \u0443\u0440\u043b\u0430\u0433 \u0441\u043e\u0451\u043b, \u044d\u0434\u0438\u0439\u043d \u0437\u0430\u0441\u0430\u0433, \u044d\u0440\u04af\u04af\u043b \u043c\u044d\u043d\u0434, \u0445\u0443\u0443\u043b\u044c, \u0443\u043b\u0441 \u0442\u04e9\u0440, \u0441\u043f\u043e\u0440\u0442, \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438, \u0431\u043e\u043b\u043e\u0432\u0441\u0440\u043e\u043b and \u0431\u0430\u0439\u0433\u0430\u043b \u043e\u0440\u0447\u0438\u043d", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0e", "disabled": false, "gated": false, "likes": 3, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ehealth_kd", "sha": "6a29cc2fd6d61ab30e4ac2b0e2391861982900b8", "lastModified": "2023-01-25T14:29:46.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:es", "license:cc-by-nc-sa-4.0", "relation-prediction", "region:us"], "private": false, "author": null, "description": "Dataset of the eHealth Knowledge Discovery Challenge at IberLEF 2020. It is designed for\nthe identification of semantic entities and relations in Spanish health documents.", "citation": "@inproceedings{overview_ehealthkd2020,\n  author    = {Piad{-}Morffis, Alejandro and\n               Guti{\\'{e}}rrez, Yoan and\n               Ca\u00f1izares-Diaz, Hian and\n               Estevez{-}Velarde, Suilan and\n               Almeida{-}Cruz, Yudivi{\\'{a}}n and\n               Mu\u00f1oz, Rafael and\n               Montoyo, Andr{\\'{e}}s},\n  title     = {Overview of the eHealth Knowledge Discovery Challenge at IberLEF 2020},\n  booktitle = ,\n  year      = {2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e0f", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eitb_parcc", "sha": "a3df155544c9b00ae6a6978638cbf390beabdfbf", "lastModified": "2022-11-03T16:15:31.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:es", "language:eu", "license:unknown", "region:us"], "private": false, "author": null, "description": "EiTB-ParCC: Parallel Corpus of Comparable News. A Basque-Spanish parallel corpus provided by Vicomtech (https://www.vicomtech.org), extracted from comparable news produced by the Basque public broadcasting group Euskal Irrati Telebista.", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e10", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "paperswithcode_id": "eitb-parcc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "electricity_load_diagrams", "sha": "a281f35b75544ed4bcc2d4aac064587f910ce7d5", "lastModified": "2022-11-18T20:00:21.000Z", "tags": ["task_categories:time-series-forecasting", "task_ids:univariate-time-series-forecasting", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "license:unknown", "region:us"], "private": false, "author": null, "description": "This new dataset contains hourly kW electricity consumption time series of 370 Portuguese clients from 2011 to 2014.", "citation": "@inproceedings{10.1145/3209978.3210006,\n    author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},\n    title = {Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks},\n    year = {2018},\n    isbn = {9781450356572},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3209978.3210006},\n    doi = {10.1145/3209978.3210006},\n    booktitle = {The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval},\n    pages = {95--104},\n    numpages = {10},\n    location = {Ann Arbor, MI, USA},\n    series = {SIGIR '18}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e11", "disabled": false, "gated": false, "likes": 5, "downloads": 446, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eli5", "sha": "949cc58a4d111602b51cab5d2a99848ccc099a3f", "lastModified": "2023-06-08T12:42:30.000Z", "tags": ["task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:open-domain-abstractive-qa", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1907.09190", "arxiv:1904.04047", "region:us"], "private": false, "author": null, "description": "Explain Like I'm 5 long form QA dataset", "citation": "@inproceedings{DBLP:conf/acl/FanJPGWA19,\n  author    = {Angela Fan and\n               Yacine Jernite and\n               Ethan Perez and\n               David Grangier and\n               Jason Weston and\n               Michael Auli},\n  editor    = {Anna Korhonen and\n               David R. Traum and\n               Lluis Marquez},\n  title     = {{ELI5:} Long Form Question Answering},\n  booktitle = {Proceedings of the 57th Conference of the Association for Computational\n               Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,\n               Volume 1: Long Papers},\n  pages     = {3558--3567},\n  publisher = {Association for Computational Linguistics},\n  year      = {2019},\n  url       = {https://doi.org/10.18653/v1/p19-1346},\n  doi       = {10.18653/v1/p19-1346},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e12", "disabled": false, "gated": false, "likes": 39, "downloads": 31020, "paperswithcode_id": "eli5", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eli5_category", "sha": "f873f3508ff2128b7e5249fc0b52f1674e9b27b3", "lastModified": "2022-11-18T20:00:33.000Z", "tags": ["task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:open-domain-abstractive-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|eli5", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The ELI5-Category dataset is a smaller but newer and categorized version of the original ELI5 dataset. After 2017, a tagging system was introduced to this subreddit so that the questions can be categorized into different topics according to their tags. Since the training and validation set is built by questions in different topics, the dataset is expected to alleviate the train/validation overlapping issue in the original ELI5 dataset.", "citation": "@inproceedings{eli5-category,\n  author    = {Jingsong Gao and\n               Qingren Zhou and\n               Rui Qiu},\n  title     = {{ELI5-Category:} A categorized open-domain QA dataset},\n  year      = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e13", "disabled": false, "gated": false, "likes": 4, "downloads": 411, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "emea", "sha": "0a4a2bfee3d880ee7ff1727d90542cbcdf85f5c5", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a parallel corpus made out of PDF documents from the European Medicines Agency. All files are automatically converted from PDF to plain text using pdftotext with the command line arguments -layout -nopgbrk -eol unix. There are some known problems with tables and multi-column layouts - some of them are fixed in the current version.\n\nsource: http://www.emea.europa.eu/\n\n22 languages, 231 bitexts\ntotal number of files: 41,957\ntotal number of tokens: 311.65M\ntotal number of sentence fragments: 26.51M", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e14", "disabled": false, "gated": false, "likes": 1, "downloads": 858, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "emo", "sha": "87fde6db292a841a7dd8f002f57571ccb187d6d9", "lastModified": "2023-04-05T10:05:14.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "In this dataset, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others.", "citation": "@inproceedings{chatterjee-etal-2019-semeval,\n    title={SemEval-2019 Task 3: EmoContext Contextual Emotion Detection in Text},\n    author={Ankush Chatterjee and Kedhar Nath Narahari and Meghana Joshi and Puneet Agrawal},\n    booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},\n    year={2019},\n    address={Minneapolis, Minnesota, USA},\n    publisher={Association for Computational Linguistics},\n    url={https://www.aclweb.org/anthology/S19-2005},\n    doi={10.18653/v1/S19-2005},\n    pages={39--48},\n    abstract={In this paper, we present the SemEval-2019 Task 3 - EmoContext: Contextual Emotion Detection in Text. Lack of facial expressions and voice modulations make detecting emotions in text a challenging problem. For instance, as humans, on reading ''Why don't you ever text me!'' we can either interpret it as a sad or angry emotion and the same ambiguity exists for machines. However, the context of dialogue can prove helpful in detection of the emotion. In this task, given a textual dialogue i.e. an utterance along with two previous turns of context, the goal was to infer the underlying emotion of the utterance by choosing from four emotion classes - Happy, Sad, Angry and Others. To facilitate the participation in this task, textual dialogues from user interaction with a conversational agent were taken and annotated for emotion classes after several data processing steps. A training data set of 30160 dialogues, and two evaluation data sets, Test1 and Test2, containing 2755 and 5509 dialogues respectively were released to the participants. A total of 311 teams made submissions to this task. The final leader-board was evaluated on Test2 data set, and the highest ranked submission achieved 79.59 micro-averaged F1 score. Our analysis of systems submitted to the task indicate that Bi-directional LSTM was the most common choice of neural architecture used, and most of the systems had the best performance for the Sad emotion class, and the worst for the Happy emotion class}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e15", "disabled": false, "gated": false, "likes": 3, "downloads": 657, "paperswithcode_id": "emocontext", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dair-ai/emotion", "sha": "9ce63038044ae35ec1305d998d1882fcecd70ec8", "lastModified": "2023-04-20T08:08:15.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "emotion-classification", "region:us"], "private": false, "author": "dair-ai", "description": "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.", "citation": "@inproceedings{saravia-etal-2018-carer,\n    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n    author = \"Saravia, Elvis  and\n      Liu, Hsien-Chi Toby  and\n      Huang, Yen-Hao  and\n      Wu, Junlin  and\n      Chen, Yi-Shin\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D18-1404\",\n    doi = \"10.18653/v1/D18-1404\",\n    pages = \"3687--3697\",\n    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e16", "disabled": false, "gated": false, "likes": 143, "downloads": 22353, "paperswithcode_id": "emotion", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "emotone_ar", "sha": "fc4b3e9fe2a47cb4a62ca51a3b2ced1624208576", "lastModified": "2023-01-25T14:29:56.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "Dataset of 10065 tweets in Arabic for Emotion detection in Arabic text", "citation": "@inbook{inbook,\nauthor = {Al-Khatib, Amr and El-Beltagy, Samhaa},\nyear = {2018},\nmonth = {01},\npages = {105-114},\ntitle = {Emotional Tone Detection in Arabic Tweets: 18th International Conference, CICLing 2017, Budapest, Hungary, April 17\u201323, 2017, Revised Selected Papers, Part II},\nisbn = {978-3-319-77115-1},\ndoi = {10.1007/978-3-319-77116-8_8}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e17", "disabled": false, "gated": false, "likes": 6, "downloads": 399, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "empathetic_dialogues", "sha": "d8b8066548b8bc2bb36af41f878f1ec5f03badd2", "lastModified": "2023-04-05T10:05:17.000Z", "tags": ["task_categories:conversational", "task_categories:question-answering", "task_ids:dialogue-generation", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "arxiv:1811.00207", "region:us"], "private": false, "author": null, "description": "PyTorch original implementation of Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset", "citation": "@inproceedings{rashkin2019towards,\n  title = {Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset},\n  author = {Hannah Rashkin and Eric Michael Smith and Margaret Li and Y-Lan Boureau},\n  booktitle = {ACL},\n  year = {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e18", "disabled": false, "gated": false, "likes": 57, "downloads": 1076, "paperswithcode_id": "empatheticdialogues", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "enriched_web_nlg", "sha": "e2d5ffe87aa192ef696c32ff7068c2d97870bab1", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:tabular-to-text", "task_ids:rdf-to-text", "annotations_creators:found", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-web-nlg", "language:de", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "WebNLG is a valuable resource and benchmark for the Natural Language Generation (NLG) community. However, as other NLG benchmarks, it only consists of a collection of parallel raw representations and their corresponding textual realizations. This work aimed to provide intermediate representations of the data for the development and evaluation of popular tasks in the NLG pipeline architecture (Reiter and Dale, 2000), such as Discourse Ordering, Lexicalization, Aggregation and Referring Expression Generation.", "citation": "@InProceedings{ferreiraetal2018,\n  author = \t\"Castro Ferreira, Thiago and Moussallem, Diego and Wubben, Sander and Krahmer, Emiel\",\n  title = \t\"Enriching the WebNLG corpus\",\n  booktitle = \t\"Proceedings of the 11th International Conference on Natural Language Generation\",\n  year = \t\"2018\",\n  series = {INLG'18},\n  publisher = \t\"Association for Computational Linguistics\",\n  address = \t\"Tilburg, The Netherlands\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e19", "disabled": false, "gated": false, "likes": 1, "downloads": 3910, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eraser_multi_rc", "sha": "186c1dc944c6c05dbd51acd6ce5eab32bd3ad3ee", "lastModified": "2023-04-05T10:05:21.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Eraser Multi RC is a dataset for queries over multi-line passages, along with\nanswers and a rationalte. Each example in this dataset has the following 5 parts\n1. A Mutli-line Passage\n2. A Query about the passage\n3. An Answer to the query\n4. A Classification as to whether the answer is right or wrong\n5. An Explanation justifying the classification", "citation": "@unpublished{eraser2019,\n    title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n    author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n}\n@inproceedings{MultiRC2018,\n    author = {Daniel Khashabi and Snigdha Chaturvedi and Michael Roth and Shyam Upadhyay and Dan Roth},\n    title = {Looking Beyond the Surface:A Challenge Set for Reading Comprehension over Multiple Sentences},\n    booktitle = {NAACL},\n    year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1a", "disabled": false, "gated": false, "likes": 3, "downloads": 694, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "esnli", "sha": "e78477f3a4e5d738fcd45dbed73b834bc00d4719", "lastModified": "2023-04-05T10:05:24.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\ninclude human-annotated natural language explanations of the entailment\nrelations.", "citation": "@incollection{NIPS2018_8163,\ntitle = {e-SNLI: Natural Language Inference with Natural Language Explanations},\nauthor = {Camburu, Oana-Maria and Rockt\\\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},\nbooktitle = {Advances in Neural Information Processing Systems 31},\neditor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\npages = {9539--9549},\nyear = {2018},\npublisher = {Curran Associates, Inc.},\nurl = {http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1b", "disabled": false, "gated": false, "likes": 14, "downloads": 2302, "paperswithcode_id": "e-snli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eth_py150_open", "sha": "480e8b123f82dab1f1a1f7d1eb6d8b111ae35e8b", "lastModified": "2022-11-18T20:01:17.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:apache-2.0", "contextual-embeddings", "region:us"], "private": false, "author": null, "description": "A redistributable subset of the ETH Py150 corpus, introduced in the ICML 2020 paper 'Learning and Evaluating Contextual Embedding of Source Code'", "citation": "@inproceedings{kanade2020learning,\n  title={Learning and Evaluating Contextual Embedding of Source Code},\n  author={Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi, Kensen},\n  booktitle={International Conference on Machine Learning},\n  pages={5110--5121},\n  year={2020},\n  organization={PMLR}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1c", "disabled": false, "gated": false, "likes": 0, "downloads": 296, "paperswithcode_id": "eth-py150-open", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ethos", "sha": "ce3466aafbf94bcb2533294816ed41795c9bc567", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "language_creators:other", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:agpl-3.0", "Hate Speech Detection", "arxiv:2006.08328", "region:us"], "private": false, "author": null, "description": "ETHOS: onlinE haTe speecH detectiOn dataSet. This repository contains a dataset for hate speech\ndetection on social media platforms, called Ethos. There are two variations of the dataset:\n\nEthos_Dataset_Binary: contains 998 comments in the dataset alongside with a label\nabout hate speech presence or absence. 565 of them do not contain hate speech,\nwhile the rest of them, 433, contain.\n\nEthos_Dataset_Multi_Label: which contains 8 labels for the 433 comments with hate speech content.\nThese labels are violence (if it incites (1) or not (0) violence), directed_vs_general (if it is\ndirected to a person (1) or a group (0)), and 6 labels about the category of hate speech like,\ngender, race, national_origin, disability, religion and sexual_orientation.", "citation": "@misc{mollas2020ethos,\n      title={ETHOS: an Online Hate Speech Detection Dataset},\n      author={Ioannis Mollas and Zoe Chrysopoulou and Stamatis Karlos and Grigorios Tsoumakas},\n      year={2020},\n      eprint={2006.08328},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1d", "disabled": false, "gated": false, "likes": 11, "downloads": 7060, "paperswithcode_id": "ethos", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eu_regulatory_ir", "sha": "80e9941fca231b490e8846690cc6a42a23a7a612", "lastModified": "2022-11-18T20:01:28.000Z", "tags": ["task_categories:text-retrieval", "task_ids:document-retrieval", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "document-to-document-retrieval", "arxiv:2101.10726", "region:us"], "private": false, "author": null, "description": "EURegIR: Regulatory Compliance IR (EU/UK)", "citation": "@inproceedings{chalkidis-etal-2021-regir,\n    title = \"Regulatory Compliance through Doc2Doc Information Retrieval: A case study in EU/UK legislation where text similarity has limitations\",\n    author = \"Chalkidis, Ilias  and Fergadiotis, Emmanouil and Manginas, Nikos and Katakalou, Eva,  and Malakasiotis, Prodromos\",\n    booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021)\",\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://arxiv.org/abs/2101.10726\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1e", "disabled": false, "gated": false, "likes": 1, "downloads": 444, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eurlex", "sha": "a362c9b523150a29ecfc74217cd066315f603ce5", "lastModified": "2022-11-18T20:01:34.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "legal-topic-classification", "region:us"], "private": false, "author": null, "description": "EURLEX57K contains 57k legislative documents in English from EUR-Lex portal, annotated with EUROVOC concepts.", "citation": "@inproceedings{chalkidis-etal-2019-large,\n    title = \"Large-Scale Multi-Label Text Classification on {EU} Legislation\",\n    author = \"Chalkidis, Ilias  and Fergadiotis, Emmanouil  and Malakasiotis, Prodromos  and Androutsopoulos, Ion\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1636\",\n    doi = \"10.18653/v1/P19-1636\",\n    pages = \"6314--6322\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e1f", "disabled": false, "gated": false, "likes": 4, "downloads": 417, "paperswithcode_id": "eurlex57k", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "euronews", "sha": "ec0b7e68faabed64c00dd1a0b0056867a450a7eb", "lastModified": "2023-01-25T14:30:08.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:de", "language:fr", "language:nl", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "The corpora comprise of files per data provider that are encoded in the IOB format (Ramshaw & Marcus, 1995). The IOB format is a simple text chunking format that divides texts into single tokens per line, and, separated by a whitespace, tags to mark named entities. The most commonly used categories for tags are PER (person), LOC (location) and ORG (organization). To mark named entities that span multiple tokens, the tags have a prefix of either B- (beginning of named entity) or I- (inside of named entity). O (outside of named entity) tags are used to mark tokens that are not a named entity.", "citation": "@InProceedings{NEUDECKER16.110,\n  author = {Clemens Neudecker},\n  title = {An Open Corpus for Named Entity Recognition in Historic Newspapers},\n  booktitle = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)},\n  year = {2016},\n  month = {may},\n  date = {23-28},\n  location = {Portoro\u017e, Slovenia},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Sara Goggi and Marko Grobelnik and Bente Maegaard and Joseph Mariani and Helene Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  address = {Paris, France},\n  isbn = {978-2-9517408-9-1},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e20", "disabled": false, "gated": false, "likes": 3, "downloads": 965, "paperswithcode_id": "europeana-newspapers", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "europa_eac_tm", "sha": "b3ebf187a47f1fb2e7817a75ab5e74d8762fe41a", "lastModified": "2023-01-25T14:30:11.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hr", "language:hu", "language:is", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "language:tr", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "In October 2012, the European Union's (EU) Directorate General for Education and Culture ( DG EAC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-six languages. This resource bears the name EAC Translation Memory, short EAC-TM.\n\nEAC-TM covers up to 26 languages: 22 official languages of the EU (all except Irish) plus Icelandic, Croatian, Norwegian and Turkish. EAC-TM thus contains translations from English into the following 25 languages: Bulgarian, Czech, Danish, Dutch, Estonian, German, Greek, Finnish, French, Croatian, Hungarian, Icelandic, Italian, Latvian, Lithuanian, Maltese, Norwegian, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish, Swedish and Turkish.\n\nAll documents and sentences were originally written in English (source language is English) and then translated into the other languages. The texts were translated by staff of the National Agencies of the Lifelong Learning and Youth in Action programmes. They are typically professionals in the field of education/youth and EU programmes. They are thus not professional translators, but they are normally native speakers of the target language.", "citation": "@Article{Steinberger2014,\n        author={Steinberger, Ralf\n                and Ebrahim, Mohamed\n                and Poulis, Alexandros\n                and Carrasco-Benitez, Manuel\n                and Schl{\\\"u}ter, Patrick\n                and Przybyszewski, Marek\n                and Gilbro, Signe},\n        title={An overview of the European Union's highly multilingual parallel corpora},\n        journal={Language Resources and Evaluation},\n        year={2014},\n        month={Dec},\n        day={01},\n        volume={48},\n        number={4},\n        pages={679-707},\n        issn={1574-0218},\n        doi={10.1007/s10579-014-9277-0},\n        url={https://doi.org/10.1007/s10579-014-9277-0}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e21", "disabled": false, "gated": false, "likes": 2, "downloads": 584, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "europa_ecdc_tm", "sha": "bb669710f5e686044ffed0ebf8d680a79c26df19", "lastModified": "2022-11-03T16:31:26.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hu", "language:is", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "In October 2012, the European Union (EU) agency 'European Centre for Disease Prevention and Control' (ECDC) released a translation memory (TM), i.e. a collection of sentences and their professionally produced translations, in twenty-five languages. This resource bears the name EAC Translation Memory, short EAC-TM.\nECDC-TM covers 25 languages: the 23 official languages of the EU plus Norwegian (Norsk) and Icelandic. ECDC-TM was created by translating from English into the following 24 languages: Bulgarian, Czech, Danish, Dutch, English, Estonian, Gaelige (Irish), German, Greek, Finnish, French, Hungarian, Icelandic, Italian, Latvian, Lithuanian, Maltese, Norwegian (NOrsk), Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish.\nAll documents and sentences were thus originally written in English. They were then translated into the other languages by professional translators from the Translation Centre CdT in Luxembourg.", "citation": "@Article{Steinberger2014,\n        author={Steinberger, Ralf\n                and Ebrahim, Mohamed\n                and Poulis, Alexandros\n                and Carrasco-Benitez, Manuel\n                and Schl{\\\"u}ter, Patrick\n                and Przybyszewski, Marek\n                and Gilbro, Signe},\n        title={An overview of the European Union's highly multilingual parallel corpora},\n        journal={Language Resources and Evaluation},\n        year={2014},\n        month={Dec},\n        day={01},\n        volume={48},\n        number={4},\n        pages={679-707},\n        issn={1574-0218},\n        doi={10.1007/s10579-014-9277-0},\n        url={https://doi.org/10.1007/s10579-014-9277-0}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e22", "disabled": false, "gated": false, "likes": 1, "downloads": 571, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "europarl_bilingual", "sha": "d53ac07927a7d3bece24ea465bbeac4cbe51d681", "lastModified": "2022-11-03T16:31:58.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hu", "language:it", "language:lt", "language:lv", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus extracted from the European Parliament web site by Philipp Koehn (University of Edinburgh). The main intended use is to aid statistical machine translation research.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e23", "disabled": false, "gated": false, "likes": 8, "downloads": 990, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "event2Mind", "sha": "70ed498f6733f286f951eb9410adf1d7765cab52", "lastModified": "2023-04-05T10:06:10.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "common-sense-inference", "arxiv:1805.06939", "region:us"], "private": false, "author": null, "description": "In Event2Mind, we explore the task of understanding stereotypical intents and reactions to events. Through crowdsourcing, we create a large corpus with 25,000 events and free-form descriptions of their intents and reactions, both of the event's subject and (potentially implied) other participants.", "citation": "@inproceedings{event2Mind,\n    title={Event2Mind: Commonsense Inference on Events, Intents, and Reactions},\n    author={Hannah Rashkin and Maarten Sap and Emily Allaway and Noah A. Smith\u2020 Yejin Choi},\n    year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e24", "disabled": false, "gated": false, "likes": 0, "downloads": 316, "paperswithcode_id": "event2mind", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "evidence_infer_treatment", "sha": "e26db15a11170843856b5307119afe65bcd2e751", "lastModified": "2023-03-16T10:35:23.000Z", "tags": ["task_categories:text-retrieval", "task_ids:fact-checking-retrieval", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "arxiv:2005.04177", "region:us"], "private": false, "author": null, "description": "Data and code from our \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\", NAACL 2019. This work concerns inferring the results reported in clinical trials from text.\n\nThe dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple treatments. Each of these articles will have multiple questions, or 'prompts' associated with them. These prompts will ask about the relationship between an intervention and comparator with respect to an outcome, as reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared to placebo on the duration of headaches. For the sake of this task, we assume that a particular article will report that the intervention of interest either significantly increased, significantly decreased or had significant effect on the outcome, relative to the comparator.\n\nThe dataset could be used for automatic data extraction of the results of a given RCT. This would enable readers to discover the effectiveness of different treatments without needing to read the paper.", "citation": "@inproceedings{lehman-etal-2019-inferring,\n    title = \"Inferring Which Medical Treatments Work from Reports of Clinical Trials\",\n    author = \"Lehman, Eric  and\n      DeYoung, Jay  and\n      Barzilay, Regina  and\n      Wallace, Byron C.\",\n    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n    month = jun,\n    year = \"2019\",\n    address = \"Minneapolis, Minnesota\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/N19-1371\",\n    pages = \"3705--3717\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e25", "disabled": false, "gated": false, "likes": 4, "downloads": 527, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "exams", "sha": "246cdd1fff9d2d5d4248d3c4aab7a9e502b3ba1e", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:ar", "language:bg", "language:de", "language:es", "language:fr", "language:hr", "language:hu", "language:it", "language:lt", "language:mk", "language:pl", "language:pt", "language:sq", "language:sr", "language:tr", "language:vi", "license:cc-by-sa-4.0", "arxiv:2011.03080", "region:us"], "private": false, "author": null, "description": "EXAMS is a benchmark dataset for multilingual and cross-lingual question answering from high school examinations.\nIt consists of more than 24,000 high-quality high school exam questions in 16 languages,\ncovering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.", "citation": "@article{hardalov2020exams,\n  title={EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering},\n  author={Hardalov, Momchil and Mihaylov, Todor and Dimitrina Zlatkova and Yoan Dinkov and Ivan Koychev and Preslav Nvakov},\n  journal={arXiv preprint arXiv:2011.03080},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e26", "disabled": false, "gated": false, "likes": 12, "downloads": 14200, "paperswithcode_id": "exams", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "factckbr", "sha": "6d6e5bdba4e1430017e22f722fbb06e3649590af", "lastModified": "2023-01-25T14:30:15.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pt", "license:mit", "region:us"], "private": false, "author": null, "description": "A dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification.\nThe data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.\nThe FACTCK.BR dataset contains 1309 claims with its corresponding label.", "citation": "@inproceedings{10.1145/3323503.3361698,\n    author = {Moreno, Jo\\\\~{a}o and Bressan, Gra\\\\c{c}a},\n    title = {FACTCK.BR: A New Dataset to Study Fake News},\n    year = {2019},\n    isbn = {9781450367639},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3323503.3361698},\n    doi = {10.1145/3323503.3361698},\n    abstract = {Machine learning algorithms can be used to combat fake news propagation. For the news classification, labeled datasets are required, however, among the existing datasets, few separate verified false from skewed ones with a good variety of sources. This work presents FACTCK.BR, a new dataset to study Fake News in Portuguese, presenting a supposedly false News along with their respective fact check and classification. The data is collected from the ClaimReview, a structured data schema used by fact check agencies to share their results in search engines, enabling data collect in real time.},\n    booktitle = {Proceedings of the 25th Brazillian Symposium on Multimedia and the Web},\n    pages = {525\u2013527},\n    numpages = {3},\n    keywords = {fake news, fact check, information extraction, dataset},\n    location = {Rio de Janeiro, Brazil},\n    series = {WebMedia '19}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e27", "disabled": false, "gated": false, "likes": 3, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "fake_news_english", "sha": "1c195a09c5e682710228ab8b473f14c62ff5aafd", "lastModified": "2023-05-30T04:42:32.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Fake news has become a major societal issue and a technical challenge for social media companies to identify. This content is difficult to identify because the term \"fake news\" covers intentionally false, deceptive stories as well as factual errors, satire, and sometimes, stories that a person just does not like. Addressing the problem requires clear definitions and examples. In this work, we present a dataset of fake news and satire stories that are hand coded, verified, and, in the case of fake news, include rebutting stories. We also include a thematic content analysis of the articles, identifying major themes that include hyperbolic support or condemnation of a gure, conspiracy theories, racist themes, and discrediting of reliable sources. In addition to releasing this dataset for research use, we analyze it and show results based on language that are promising for classification purposes. Overall, our contribution of a dataset and initial analysis are designed to support future work by fake news researchers.", "citation": "@inproceedings{inproceedings,\nauthor = {Golbeck, Jennifer and Everett, Jennine and Falak, Waleed and Gieringer, Carl and Graney, Jack and Hoffman, Kelly and Huth, Lindsay and Ma, Zhenya and Jha, Mayanka and Khan, Misbah and Kori, Varsha and Mauriello, Matthew and Lewis, Elo and Mirano, George and IV, William and Mussenden, Sean and Nelson, Tammie and Mcwillie, Sean and Pant, Akshat and Cheakalos, Paul},\nyear = {2018},\nmonth = {05},\npages = {17-21},\ntitle = {Fake News vs Satire: A Dataset and Analysis},\ndoi = {10.1145/3201064.3201100}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e28", "disabled": false, "gated": false, "likes": 0, "downloads": 346, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "fake_news_filipino", "sha": "f2a392abf508cb7532d59152f2d9560ef4cca861", "lastModified": "2023-01-25T14:30:21.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:tl", "license:unknown", "region:us"], "private": false, "author": null, "description": "    Low-Resource Fake News Detection Corpora in Filipino. The first of its kind. Contains 3,206 expertly-labeled news samples, half of which are real and half of which are fake.", "citation": "    @inproceedings{cruz2020localization,\n      title={Localization of Fake News Detection via Multitask Transfer Learning},\n      author={Cruz, Jan Christian Blaise and Tan, Julianne Agatha and Cheng, Charibeth},\n      booktitle={Proceedings of The 12th Language Resources and Evaluation Conference},\n      pages={2596--2604},\n      year={2020}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e29", "disabled": false, "gated": false, "likes": 0, "downloads": 396, "paperswithcode_id": "fake-news-filipino-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "farsi_news", "sha": "4d21f69c5b3259d7da738f7d5ac641f88d3eddf3", "lastModified": "2022-11-03T16:15:15.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:fa", "license:unknown", "region:us"], "private": false, "author": null, "description": "Contains Farsi (Persian) datasets for Machine Learning tasks, particularly NLP.\nThese datasets have been extracted from the RSS feed of two Farsi news agency websites:\n\n- Hamshahri\n- RadioFarda", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e2a", "disabled": false, "gated": false, "likes": 2, "downloads": 331, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "fashion_mnist", "sha": "81a1a5a68571d3a02ddca9e2a93c3a4b065d6764", "lastModified": "2023-04-17T14:02:05.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "arxiv:1708.07747", "region:us"], "private": false, "author": null, "description": "Fashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of\n60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image,\nassociated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in\nreplacement for the original MNIST dataset for benchmarking machine learning algorithms.\nIt shares the same image size and structure of training and testing splits.", "citation": "@article{DBLP:journals/corr/abs-1708-07747,\n  author    = {Han Xiao and\n               Kashif Rasul and\n               Roland Vollgraf},\n  title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n               Algorithms},\n  journal   = {CoRR},\n  volume    = {abs/1708.07747},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.07747},\n  archivePrefix = {arXiv},\n  eprint    = {1708.07747},\n  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e2b", "disabled": false, "gated": false, "likes": 29, "downloads": 18196, "paperswithcode_id": "fashion-mnist", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "few_rel", "sha": "49f6becb993b8a1dc294090cadb3fe9de1ade254", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:other", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:n<1K", "source_datasets:original", "language:en", "license:mit", "relation-extraction", "arxiv:1810.10147", "arxiv:1910.07124", "region:us"], "private": false, "author": null, "description": "FewRel is a large-scale few-shot relation extraction dataset, which contains more than one hundred relations and tens of thousands of annotated instances cross different domains.", "citation": "@inproceedings{han-etal-2018-fewrel,\n    title = \"{F}ew{R}el: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation\",\n    author = \"Han, Xu and Zhu, Hao and Yu, Pengfei and Wang, Ziyun and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D18-1514\",\n    doi = \"10.18653/v1/D18-1514\",\n    pages = \"4803--4809\"\n}\n\n@inproceedings{gao-etal-2019-fewrel,\n    title = \"{F}ew{R}el 2.0: Towards More Challenging Few-Shot Relation Classification\",\n    author = \"Gao, Tianyu and Han, Xu and Zhu, Hao and Liu, Zhiyuan and Li, Peng and Sun, Maosong and Zhou, Jie\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D19-1649\",\n    doi = \"10.18653/v1/D19-1649\",\n    pages = \"6251--6256\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e2d", "disabled": false, "gated": false, "likes": 2, "downloads": 347, "paperswithcode_id": "fewrel", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "financial_phrasebank", "sha": "580b6ed47bc179ab6384bb3333f26bef1e8dac4f", "lastModified": "2023-07-26T06:27:17.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-3.0", "finance", "arxiv:1307.5336", "region:us"], "private": false, "author": null, "description": "The key arguments for the low utilization of statistical techniques in\nfinancial sentiment analysis have been the difficulty of implementation for\npractical applications and the lack of high quality training data for building\nsuch models. Especially in the case of finance and economic texts, annotated\ncollections are a scarce resource and many are reserved for proprietary use\nonly. To resolve the missing training data problem, we present a collection of\n\u223c 5000 sentences to establish human-annotated standards for benchmarking\nalternative modeling techniques.\n\nThe objective of the phrase level annotation task was to classify each example\nsentence into a positive, negative or neutral category by considering only the\ninformation explicitly available in the given sentence. Since the study is\nfocused only on financial and economic domains, the annotators were asked to\nconsider the sentences from the view point of an investor only; i.e. whether\nthe news may have positive, negative or neutral influence on the stock price.\nAs a result, sentences which have a sentiment that is not relevant from an\neconomic or financial perspective are considered neutral.\n\nThis release of the financial phrase bank covers a collection of 4840\nsentences. The selected collection of phrases was annotated by 16 people with\nadequate background knowledge on financial markets. Three of the annotators\nwere researchers and the remaining 13 annotators were master\u2019s students at\nAalto University School of Business with majors primarily in finance,\naccounting, and economics.\n\nGiven the large number of overlapping annotations (5 to 8 annotations per\nsentence), there are several ways to define a majority vote based gold\nstandard. To provide an objective comparison, we have formed 4 alternative\nreference datasets based on the strength of majority agreement: all annotators\nagree, >=75% of annotators agree, >=66% of annotators agree and >=50% of\nannotators agree.", "citation": "@article{Malo2014GoodDO,\n  title={Good debt or bad debt: Detecting semantic orientations in economic texts},\n  author={P. Malo and A. Sinha and P. Korhonen and J. Wallenius and P. Takala},\n  journal={Journal of the Association for Information Science and Technology},\n  year={2014},\n  volume={65}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e2e", "disabled": false, "gated": false, "likes": 116, "downloads": 9147, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "finer", "sha": "caa0e56a037e566a80c9a6017ebfb8ffe4a93d99", "lastModified": "2023-01-25T14:30:30.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fi", "license:mit", "arxiv:1908.04212", "region:us"], "private": false, "author": null, "description": "The directory data contains a corpus of Finnish technology related news articles with a manually prepared\nnamed entity annotation (digitoday.2014.csv). The text material was extracted from the archives of Digitoday,\na Finnish online technology news source (www.digitoday.fi). The corpus consists of 953 articles\n(193,742 word tokens) with six named entity classes (organization, location, person, product, event, and date).\nThe corpus is available for research purposes and can be readily used for development of NER systems for Finnish.", "citation": "@article{ruokolainen2019finnish,\n  title={A finnish news corpus for named entity recognition},\n  author={Ruokolainen, Teemu and Kauppinen, Pekka and Silfverberg, Miikka and Lind{\\'e}n, Krister},\n  journal={Language Resources and Evaluation},\n  pages={1--26},\n  year={2019},\n  publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e2f", "disabled": false, "gated": false, "likes": 1, "downloads": 289, "paperswithcode_id": "finer", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flores", "sha": "33a2ca57c1b039e5f65956a33c8748ebfebb7ee3", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|wikipedia", "source_datasets:extended|opus_gnome", "source_datasets:extended|opus_ubuntu", "source_datasets:extended|open_subtitles", "source_datasets:extended|paracrawl", "source_datasets:extended|bible_para", "source_datasets:extended|kde4", "source_datasets:extended|other-global-voices", "source_datasets:extended|other-common-crawl", "language:en", "language:ne", "language:si", "license:cc-by-4.0", "arxiv:1902.01382", "region:us"], "private": false, "author": null, "description": "Evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English.", "citation": "@misc{guzmn2019new,\n    title={Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English},\n    author={Francisco Guzman and Peng-Jen Chen and Myle Ott and Juan Pino and Guillaume Lample and Philipp Koehn and Vishrav Chaudhary and Marc'Aurelio Ranzato},\n    year={2019},\n    eprint={1902.01382},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e30", "disabled": false, "gated": false, "likes": 3, "downloads": 500, "paperswithcode_id": "flores", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flue", "sha": "28f21e05c2a3d8a9ea315549f6751953c3816b3e", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:semantic-similarity-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fr", "license:unknown", "Word Sense Disambiguation for Verbs", "arxiv:1912.05372", "region:us"], "private": false, "author": null, "description": "FLUE is an evaluation setup for French NLP systems similar to the popular GLUE benchmark. The goal is to enable further reproducible experiments in the future and to share models and progress on the French language.", "citation": "@misc{le2019flaubert,\n    title={FlauBERT: Unsupervised Language Model Pre-training for French},\n    author={Hang Le and Lo\u00efc Vial and Jibril Frej and Vincent Segonne and Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\u00eet Crabb\u00e9 and Laurent Besacier and Didier Schwab},\n    year={2019},\n    eprint={1912.05372},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e31", "disabled": false, "gated": false, "likes": 5, "downloads": 242, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "fquad", "sha": "0b7f5e3dd7605ff395413392817bf91911797bc6", "lastModified": "2023-04-05T10:06:27.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_ids:extractive-qa", "task_ids:closed-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:fr", "license:cc-by-nc-sa-3.0", "arxiv:2002.06071", "region:us"], "private": false, "author": null, "description": "FQuAD: French Question Answering Dataset\nWe introduce FQuAD, a native French Question Answering Dataset. FQuAD contains 25,000+ question and answer pairs.\nFinetuning CamemBERT on FQuAD yields a F1 score of 88% and an exact match of 77.9%.", "citation": "@ARTICLE{2020arXiv200206071\n       author = {Martin, d'Hoffschmidt and Maxime, Vidal and\n         Wacim, Belblidia and Tom, Brendl\u00e9},\n        title = \"{FQuAD: French Question Answering Dataset}\",\n      journal = {arXiv e-prints},\n     keywords = {Computer Science - Computation and Language},\n         year = \"2020\",\n        month = \"Feb\",\n          eid = {arXiv:2002.06071},\n        pages = {arXiv:2002.06071},\narchivePrefix = {arXiv},\n       eprint = {2002.06071},\n primaryClass = {cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e33", "disabled": false, "gated": false, "likes": 9, "downloads": 327, "paperswithcode_id": "fquad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "freebase_qa", "sha": "7c86b3bf566ed27ff19c9d462f4a6f2b668f24d2", "lastModified": "2022-11-18T20:03:22.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|trivia_qa", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "FreebaseQA is for open-domain factoid question answering (QA) tasks over structured knowledge bases, like Freebase The data set is generated by matching trivia-type question-answer pairs with subject-predicateobject triples in Freebase.", "citation": "@article{jiang2019freebaseqa,\n  title={FreebaseQA: A New Factoid QA Dataset Matching Trivia-Style Question-Answer Pairs with Freebase},\n  author={Jiang, Kelvin and Wu, Dekun and Jiang, Hui},\n  journal={north american chapter of the association for computational linguistics},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e34", "disabled": false, "gated": false, "likes": 2, "downloads": 487, "paperswithcode_id": "freebaseqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gap", "sha": "b458d550ec7528f4d96a6c8777c16199b44b3d87", "lastModified": "2023-04-05T10:06:30.000Z", "tags": ["task_categories:token-classification", "task_ids:coreference-resolution", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1810.05201", "region:us"], "private": false, "author": null, "description": "GAP is a gender-balanced dataset containing 8,908 coreference-labeled pairs of\n(ambiguous pronoun, antecedent name), sampled from Wikipedia and released by\nGoogle AI Language for the evaluation of coreference resolution in practical\napplications.", "citation": "@article{DBLP:journals/corr/abs-1810-05201,\n  author    = {Kellie Webster and\n               Marta Recasens and\n               Vera Axelrod and\n               Jason Baldridge},\n  title     = {Mind the {GAP:} {A} Balanced Corpus of Gendered Ambiguous Pronouns},\n  journal   = {CoRR},\n  volume    = {abs/1810.05201},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1810.05201},\n  archivePrefix = {arXiv},\n  eprint    = {1810.05201},\n  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1810-05201},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e35", "disabled": false, "gated": false, "likes": 2, "downloads": 328, "paperswithcode_id": "gap", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gem", "sha": "9b0b5a5b741ff863fd93739dd978a875d0809ffc", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:fill-mask", "task_categories:summarization", "task_categories:table-to-text", "task_categories:tabular-to-text", "task_categories:text-generation", "task_categories:text2text-generation", "task_ids:dialogue-modeling", "task_ids:rdf-to-text", "task_ids:news-articles-summarization", "task_ids:text-simplification", "annotations_creators:crowdsourced", "annotations_creators:found", "language_creators:crowdsourced", "language_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:extended|other-vision-datasets", "source_datasets:original", "language:cs", "language:de", "language:en", "language:es", "language:ru", "language:tr", "language:vi", "license:other", "intent-to-text", "meaning-representation-to-text", "concepts-to-text", "arxiv:2102.01672", "region:us"], "private": false, "author": null, "description": "GEM is a benchmark environment for Natural Language Generation with a focus on its Evaluation,\nboth through human annotations and automated Metrics.\n\nGEM aims to:\n- measure NLG progress across 13 datasets spanning many NLG tasks and languages.\n- provide an in-depth analysis of data and models presented via data statements and challenge sets.\n- develop standards for evaluation of generated text using both automated and human metrics.\n\nIt is our goal to regularly update GEM and to encourage toward more inclusive practices in dataset development\nby extending existing data or developing datasets for additional languages.", "citation": "@article{gem_benchmark,\n  author    = {Sebastian Gehrmann and\n               Tosin P. Adewumi and\n               Karmanya Aggarwal and\n               Pawan Sasanka Ammanamanchi and\n               Aremu Anuoluwapo and\n               Antoine Bosselut and\n               Khyathi Raghavi Chandu and\n               Miruna{-}Adriana Clinciu and\n               Dipanjan Das and\n               Kaustubh D. Dhole and\n               Wanyu Du and\n               Esin Durmus and\n               Ondrej Dusek and\n               Chris Emezue and\n               Varun Gangal and\n               Cristina Garbacea and\n               Tatsunori Hashimoto and\n               Yufang Hou and\n               Yacine Jernite and\n               Harsh Jhamtani and\n               Yangfeng Ji and\n               Shailza Jolly and\n               Dhruv Kumar and\n               Faisal Ladhak and\n               Aman Madaan and\n               Mounica Maddela and\n               Khyati Mahajan and\n               Saad Mahamood and\n               Bodhisattwa Prasad Majumder and\n               Pedro Henrique Martins and\n               Angelina McMillan{-}Major and\n               Simon Mille and\n               Emiel van Miltenburg and\n               Moin Nadeem and\n               Shashi Narayan and\n               Vitaly Nikolaev and\n               Rubungo Andre Niyongabo and\n               Salomey Osei and\n               Ankur P. Parikh and\n               Laura Perez{-}Beltrachini and\n               Niranjan Ramesh Rao and\n               Vikas Raunak and\n               Juan Diego Rodriguez and\n               Sashank Santhanam and\n               Joao Sedoc and\n               Thibault Sellam and\n               Samira Shaikh and\n               Anastasia Shimorina and\n               Marco Antonio Sobrevilla Cabezudo and\n               Hendrik Strobelt and\n               Nishant Subramani and\n               Wei Xu and\n               Diyi Yang and\n               Akhila Yerukola and\n               Jiawei Zhou},\n  title     = {The {GEM} Benchmark: Natural Language Generation, its Evaluation and\n               Metrics},\n  journal   = {CoRR},\n  volume    = {abs/2102.01672},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2102.01672},\n  archivePrefix = {arXiv},\n  eprint    = {2102.01672}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e36", "disabled": false, "gated": false, "likes": 22, "downloads": 6280, "paperswithcode_id": "gem", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "generated_reviews_enth", "sha": "7449d4b87e38cca864891bc42d840e254b7dda68", "lastModified": "2023-01-25T14:30:46.000Z", "tags": ["task_categories:translation", "task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:th", "license:cc-by-sa-4.0", "arxiv:2007.03541", "arxiv:1909.05858", "region:us"], "private": false, "author": null, "description": " `generated_reviews_enth`\n Generated product reviews dataset for machine translation quality prediction, part of [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf)\n `generated_reviews_enth` is created as part of [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf) for machine translation task.\n This dataset (referred to as `generated_reviews_yn` in [scb-mt-en-th-2020](https://arxiv.org/pdf/2007.03541.pdf)) are English product reviews\n generated by [CTRL](https://arxiv.org/abs/1909.05858), translated by Google Translate API and annotated as accepted or rejected (`correct`)\n based on fluency and adequacy of the translation by human annotators.\n This allows it to be used for English-to-Thai translation quality esitmation (binary label), machine translation, and sentiment analysis.", "citation": "@article{lowphansirikul2020scb,\n  title={scb-mt-en-th-2020: A Large English-Thai Parallel Corpus},\n  author={Lowphansirikul, Lalita and Polpanumas, Charin and Rutherford, Attapol T and Nutanong, Sarana},\n  journal={arXiv preprint arXiv:2007.03541},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e37", "disabled": false, "gated": false, "likes": 3, "downloads": 391, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "generics_kb", "sha": "32a04d2f4369c26541fe5875af5a5d6fe1c221aa", "lastModified": "2023-06-07T12:35:34.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "knowledge-base", "arxiv:2005.00660", "region:us"], "private": false, "author": null, "description": "The GenericsKB contains 3.4M+ generic sentences about the world, i.e., sentences expressing general truths such as \"Dogs bark,\" and \"Trees remove carbon dioxide from the atmosphere.\" Generics are potentially useful as a knowledge source for AI systems requiring general world knowledge. The GenericsKB is the first large-scale resource containing naturally occurring generic sentences (as opposed to extracted or crowdsourced triples), and is rich in high-quality, general, semantically complete statements. Generics were primarily extracted from three large text sources, namely the Waterloo Corpus, selected parts of Simple Wikipedia, and the ARC Corpus. A filtered, high-quality subset is also available in GenericsKB-Best, containing 1,020,868 sentences. We recommend you start with GenericsKB-Best.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {GenericsKB: A Knowledge Base of Generic Statements},\nauthors={Sumithra Bhakthavatsalam, Chloe Anastasiades, Peter Clark},\nyear={2020},\npublisher = {Allen Institute for AI},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e38", "disabled": false, "gated": false, "likes": 2, "downloads": 945, "paperswithcode_id": "genericskb", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "germaner", "sha": "6d2071edd2a10ec8ae0756b175c1facd6f824c1e", "lastModified": "2023-01-25T14:30:52.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "GermaNER is a freely available statistical German Named Entity Tagger based on conditional random fields(CRF). The tagger is trained and evaluated on the NoSta-D Named Entity dataset, which was used in the GermEval 2014 for named entity recognition. The tagger comes close to the performance of the best (proprietary) system in the competition with 77% F-measure (this is the latest result; the one reported in the paper is 76%) test set performance on the four standard NER classes (PERson, LOCation, ORGanisation and OTHer).\n\nWe describe a range of features and their influence on German NER classification and provide a comparative evaluation and some analysis of the results. The software components, the training data and all data used for feature generation are distributed under permissive licenses, thus this tagger can be used in academic and commercial settings without restrictions or fees. The tagger is available as a command-line tool and as an Apache UIMA component.", "citation": "@inproceedings{Benikova2015GermaNERFO,\n  title={GermaNER: Free Open German Named Entity Recognition Tool},\n  author={Darina Benikova and S. Yimam and Prabhakaran Santhanam and Chris Biemann},\n  booktitle={GSCL},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3a", "disabled": false, "gated": false, "likes": 0, "downloads": 316, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "germeval_14", "sha": "a42b58956d04adac9e8e6adfda6f1a8ca9adb023", "lastModified": "2023-04-05T10:06:39.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The GermEval 2014 NER Shared Task builds on a new dataset with German Named Entity annotation with the following properties:    - The data was sampled from German Wikipedia and News Corpora as a collection of citations.    - The dataset covers over 31,000 sentences corresponding to over 590,000 tokens.    - The NER annotation uses the NoSta-D guidelines, which extend the T\u00fcbingen Treebank guidelines,      using four main NER categories with sub-structure, and annotating embeddings among NEs      such as [ORG FC Kickers [LOC Darmstadt]].", "citation": "@inproceedings{benikova-etal-2014-nosta,\n    title = {NoSta-D Named Entity Annotation for German: Guidelines and Dataset},\n    author = {Benikova, Darina  and\n      Biemann, Chris  and\n      Reznicek, Marc},\n    booktitle = {Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)},\n    month = {may},\n    year = {2014},\n    address = {Reykjavik, Iceland},\n    publisher = {European Language Resources Association (ELRA)},\n    url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/276_Paper.pdf},\n    pages = {2524--2531},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3b", "disabled": false, "gated": false, "likes": 3, "downloads": 387, "paperswithcode_id": "nosta-d-named-entity-annotation-for-german", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "giga_fren", "sha": "f3928e9b0cfc2a1c571dd4c9765a2b14fcc259a5", "lastModified": "2022-11-03T16:15:21.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "language:fr", "license:unknown", "region:us"], "private": false, "author": null, "description": "Giga-word corpus for French-English from WMT2010 collected by Chris Callison-Burch\n2 languages, total number of files: 452\ntotal number of tokens: 1.43G\ntotal number of sentence fragments: 47.55M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3c", "disabled": false, "gated": false, "likes": 0, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gigaword", "sha": "f362bc725d92ea76022e5147f4d3642ba4aea226", "lastModified": "2023-04-05T10:06:42.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|gigaword_2003", "language:en", "license:mit", "headline-generation", "arxiv:1509.00685", "region:us"], "private": false, "author": null, "description": "Headline-generation on a corpus of article pairs from Gigaword consisting of\naround 4 million articles. Use the 'org_data' provided by\nhttps://github.com/microsoft/unilm/ which is identical to\nhttps://github.com/harvardnlp/sent-summary but with better format.\n\nThere are two features:\n  - document: article.\n  - summary: headline.", "citation": "@article{graff2003english,\n  title={English gigaword},\n  author={Graff, David and Kong, Junbo and Chen, Ke and Maeda, Kazuaki},\n  journal={Linguistic Data Consortium, Philadelphia},\n  volume={4},\n  number={1},\n  pages={34},\n  year={2003}\n}\n\n@article{Rush_2015,\n   title={A Neural Attention Model for Abstractive Sentence Summarization},\n   url={http://dx.doi.org/10.18653/v1/D15-1044},\n   DOI={10.18653/v1/d15-1044},\n   journal={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},\n   publisher={Association for Computational Linguistics},\n   author={Rush, Alexander M. and Chopra, Sumit and Weston, Jason},\n   year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3d", "disabled": false, "gated": false, "likes": 21, "downloads": 5564, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "glucose", "sha": "e5f56e37da9ae7cce54365ca5d38880964c752b1", "lastModified": "2022-11-18T20:04:16.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-ROC-stories", "language:en", "license:cc-by-4.0", "commonsense-inference", "arxiv:2009.07758", "region:us"], "private": false, "author": null, "description": "When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context.", "citation": "@inproceedings{mostafazadeh2020glucose,\n      title={GLUCOSE: GeneraLized and COntextualized Story Explanations},\n      author={Nasrin Mostafazadeh and Aditya Kalyanpur and Lori Moon and David Buchanan and Lauren Berkowitz and Or Biran and Jennifer Chu-Carroll},\n      year={2020},\n      booktitle={The Conference on Empirical Methods in Natural Language Processing},\n      publisher={Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3e", "disabled": false, "gated": false, "likes": 2, "downloads": 306, "paperswithcode_id": "glucose", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "glue", "sha": "fd8e86499fa5c264fcaad392a8f49ddf58bf4037", "lastModified": "2023-06-01T14:59:59.000Z", "tags": ["task_categories:text-classification", "task_ids:acceptability-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "task_ids:sentiment-classification", "task_ids:text-scoring", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "qa-nli", "coreference-nli", "paraphrase-identification", "region:us"], "private": false, "author": null, "description": "GLUE, the General Language Understanding Evaluation benchmark\n(https://gluebenchmark.com/) is a collection of resources for training,\nevaluating, and analyzing natural language understanding systems.", "citation": "@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e3f", "disabled": false, "gated": false, "likes": 253, "downloads": 1321871, "paperswithcode_id": "glue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gnad10", "sha": "ed4485572d4a21ad6a5d9b97d5c887115dcf2339", "lastModified": "2023-01-25T14:31:03.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-from-One-Million-Posts-Corpus", "language:de", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": "This dataset is intended to advance topic classification for German texts. A classifier that is efffective in\nEnglish may not be effective in German dataset because it has a higher inflection and longer compound words.\nThe 10kGNAD dataset contains 10273 German news articles from an Austrian online newspaper categorized into\n9 categories. Article titles and text are concatenated together and authors are removed to avoid a keyword-like\nclassification on authors that write frequently about one category. This dataset can be used as a benchmark\nfor German topic classification.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e40", "disabled": false, "gated": false, "likes": 3, "downloads": 532, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "go_emotions", "sha": "bcf4b7207fa70e67a444228294cedffbf94134db", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "emotion", "arxiv:2005.00547", "region:us"], "private": false, "author": null, "description": "The GoEmotions dataset contains 58k carefully curated Reddit comments labeled for 27 emotion categories or Neutral.\nThe emotion categories are admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire,\ndisappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness,\noptimism, pride, realization, relief, remorse, sadness, surprise.", "citation": "@inproceedings{demszky2020goemotions,\n author = {Demszky, Dorottya and Movshovitz-Attias, Dana and Ko, Jeongwoo and Cowen, Alan and Nemade, Gaurav and Ravi, Sujith},\n booktitle = {58th Annual Meeting of the Association for Computational Linguistics (ACL)},\n title = {{GoEmotions: A Dataset of Fine-Grained Emotions}},\n year = {2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e41", "disabled": false, "gated": false, "likes": 67, "downloads": 7166, "paperswithcode_id": "goemotions", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gooaq", "sha": "8857312909978ac1059684309a072462e24dcea6", "lastModified": "2023-01-25T14:31:10.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2104.08727", "region:us"], "private": false, "author": null, "description": "GooAQ is a large-scale dataset with a variety of answer types. This dataset contains over\n5 million questions and 3 million answers collected from Google. GooAQ questions are collected\nsemi-automatically from the Google search engine using its autocomplete feature. This results in\nnaturalistic questions of practical interest that are nonetheless short and expressed using simple\nlanguage. GooAQ answers are mined from Google's responses to our collected questions, specifically from\nthe answer boxes in the search results. This yields a rich space of answer types, containing both\ntextual answers (short and long) as well as more structured ones such as collections.", "citation": "@article{gooaq2021,\n  title={GooAQ: Open Question Answering with Diverse Answer Types},\n  author={Khashabi, Daniel and Ng, Amos and Khot, Tushar and Sabharwal, Ashish and Hajishirzi, Hannaneh and Callison-Burch, Chris},\n  journal={arXiv preprint},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e42", "disabled": false, "gated": false, "likes": 3, "downloads": 309, "paperswithcode_id": "gooaq", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "google_wellformed_query", "sha": "a47db7412352fd7546ffe3b8118fbb3624e224c1", "lastModified": "2022-11-18T20:04:48.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended", "language:en", "license:cc-by-sa-4.0", "arxiv:1808.09419", "region:us"], "private": false, "author": null, "description": "Google's query wellformedness dataset was created by crowdsourcing well-formedness annotations for 25,100 queries from the Paralex corpus. Every query was annotated by five raters each with 1/0 rating of whether or not the query is well-formed.", "citation": "@misc{faruqui2018identifying,\n      title={Identifying Well-formed Natural Language Questions},\n      author={Manaal Faruqui and Dipanjan Das},\n      year={2018},\n      eprint={1808.09419},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e43", "disabled": false, "gated": false, "likes": 8, "downloads": 486, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "grail_qa", "sha": "502b56b49609dc49e541e420697b40507cdf6883", "lastModified": "2022-11-18T20:04:54.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "knowledge-base-qa", "arxiv:2011.07743", "region:us"], "private": false, "author": null, "description": "Strongly Generalizable Question Answering (GrailQA) is a new large-scale, high-quality dataset for question answering on knowledge bases (KBQA) on Freebase with 64,331 questions annotated with both answers and corresponding logical forms in different syntax (i.e., SPARQL, S-expression, etc.). It can be used to test three levels of generalization in KBQA: i.i.d., compositional, and zero-shot.", "citation": "@misc{gu2020iid,\n    title={Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases},\n    author={Yu Gu and Sue Kase and Michelle Vanni and Brian Sadler and Percy Liang and Xifeng Yan and Yu Su},\n    year={2020},\n    eprint={2011.07743},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e44", "disabled": false, "gated": false, "likes": 2, "downloads": 378, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "great_code", "sha": "67caa22b74425cb9fa47aed6b825ddfe308b4bdf", "lastModified": "2022-11-18T20:05:00.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The dataset for the variable-misuse task, described in the ICLR 2020 paper 'Global Relational Models of Source Code' [https://openreview.net/forum?id=B1lnbRNtwr]\n\nThis is the public version of the dataset used in that paper. The original, used to produce the graphs in the paper, could not be open-sourced due to licensing issues. See the public associated code repository [https://github.com/VHellendoorn/ICLR20-Great] for results produced from this dataset.\n\nThis dataset was generated synthetically from the corpus of Python code in the ETH Py150 Open dataset [https://github.com/google-research-datasets/eth_py150_open].", "citation": "@inproceedings{DBLP:conf/iclr/HellendoornSSMB20,\n  author    = {Vincent J. Hellendoorn and\n               Charles Sutton and\n               Rishabh Singh and\n               Petros Maniatis and\n               David Bieber},\n  title     = {Global Relational Models of Source Code},\n  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,\n               Addis Ababa, Ethiopia, April 26-30, 2020},\n  publisher = {OpenReview.net},\n  year      = {2020},\n  url       = {https://openreview.net/forum?id=B1lnbRNtwr},\n  timestamp = {Thu, 07 May 2020 17:11:47 +0200},\n  biburl    = {https://dblp.org/rec/conf/iclr/HellendoornSSMB20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e45", "disabled": false, "gated": false, "likes": 1, "downloads": 355, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "greek_legal_code", "sha": "d1506c0113e06988c584173e2c417964ddff0b0f", "lastModified": "2023-06-12T14:25:00.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:el", "license:cc-by-4.0", "arxiv:2109.15298", "region:us"], "private": false, "author": null, "description": "Greek_Legal_Code contains 47k classified legal resources from Greek Legislation. Its origin is \u201cPermanent Greek Legislation Code - Raptarchis\u201d,\na collection of Greek legislative documents classified into multi-level (from broader to more specialized) categories.", "citation": "@inproceedings{papaloukas-etal-2021-glc,\n    title = \"Multi-granular Legal Topic Classification on Greek Legislation\",\n    author = \"Papaloukas, Christos and Chalkidis, Ilias and Athinaios, Konstantinos and Pantazi, Despina-Athanasia and Koubarakis, Manolis\",\n    booktitle = \"Proceedings of the 3rd Natural Legal Language Processing (NLLP) Workshop\",\n    year = \"2021\",\n    address = \"Punta Cana, Dominican Republic\",\n    publisher = \"\",\n    url = \"\",\n    doi = \"\",\n    pages = \"\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e46", "disabled": false, "gated": false, "likes": 8, "downloads": 661, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "guardian_authorship", "sha": "faec76108f57a0dbd417e857185ab787c5461d10", "lastModified": "2023-04-05T10:06:55.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "A dataset cross-topic authorship attribution. The dataset is provided by Stamatatos 2013.\n1- The cross-topic scenarios are based on Table-4 in Stamatatos 2017 (Ex. cross_topic_1 => row 1:P S U&W ).\n2- The cross-genre scenarios are based on Table-5 in the same paper. (Ex. cross_genre_1 => row 1:B P S&U&W).\n\n3- The same-topic/genre scenario is created by grouping all the datasts as follows.\nFor ex., to use same_topic and split the data 60-40 use:\ntrain_ds = load_dataset('guardian_authorship', name=\"cross_topic_<<#>>\",\n                        split='train[:60%]+validation[:60%]+test[:60%]')\ntests_ds = load_dataset('guardian_authorship', name=\"cross_topic_<<#>>\",\n                        split='train[-40%:]+validation[-40%:]+test[-40%:]')\n\nIMPORTANT: train+validation+test[:60%] will generate the wrong splits because the data is imbalanced\n\n* See https://huggingface.co/docs/datasets/splits.html for detailed/more examples", "citation": "@article{article,\n    author = {Stamatatos, Efstathios},\n    year = {2013},\n    month = {01},\n    pages = {421-439},\n    title = {On the robustness of authorship attribution based on character n-gram features},\n    volume = {21},\n    journal = {Journal of Law and Policy}\n}\n\n@inproceedings{stamatatos2017authorship,\n    title={Authorship attribution using text distortion},\n    author={Stamatatos, Efstathios},\n    booktitle={Proc. of the 15th Conf. of the European Chapter of the Association for Computational Linguistics},\n    volume={1}\n    pages={1138--1149},\n    year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e47", "disabled": false, "gated": false, "likes": 3, "downloads": 3388, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gutenberg_time", "sha": "07f088bc2c0708a006adbb14e84355a95b4da27b", "lastModified": "2022-11-03T16:32:34.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:2011.04124", "region:us"], "private": false, "author": null, "description": "A clean data resource containing all explicit time references in a dataset of 52,183 novels whose full text is available via Project Gutenberg.", "citation": "@misc{kim2020time,\n      title={What time is it? Temporal Analysis of Novels},\n      author={Allen Kim and Charuta Pethe and Steven Skiena},\n      year={2020},\n      eprint={2011.04124},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e48", "disabled": false, "gated": false, "likes": 3, "downloads": 382, "paperswithcode_id": "gutenberg-time-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hans", "sha": "9f429828e712a26017b86d95ea2f43e913d5d5c7", "lastModified": "2023-04-05T10:06:58.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1902.01007", "region:us"], "private": false, "author": null, "description": "The HANS dataset is an NLI evaluation set that tests specific hypotheses about invalid heuristics that NLI models are likely to learn.", "citation": "@article{DBLP:journals/corr/abs-1902-01007,\n  author    = {R. Thomas McCoy and\n               Ellie Pavlick and\n               Tal Linzen},\n  title     = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural\n               Language Inference},\n  journal   = {CoRR},\n  volume    = {abs/1902.01007},\n  year      = {2019},\n  url       = {http://arxiv.org/abs/1902.01007},\n  archivePrefix = {arXiv},\n  eprint    = {1902.01007},\n  timestamp = {Tue, 21 May 2019 18:03:36 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-01007.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e49", "disabled": false, "gated": false, "likes": 3, "downloads": 1517, "paperswithcode_id": "hans", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hansards", "sha": "2b83480f3162c813081e019e9329a8fa7baf7c52", "lastModified": "2023-04-05T10:07:00.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "This release contains 1.3 million pairs of aligned text chunks (sentences or smaller fragments)\nfrom the official records (Hansards) of the 36th Canadian Parliament.\n\nThe complete Hansards of the debates in the House and Senate of the 36th Canadian Parliament,\nas far as available, were aligned. The corpus was then split into 5 sets of sentence pairs:\ntraining (80% of the sentence pairs), two sets of sentence pairs for testing (5% each), and\ntwo sets of sentence pairs for final evaluation (5% each). The current release consists of the\ntraining and testing sets. The evaluation sets are reserved for future MT evaluation purposes\nand currently not available.\n\nCaveats\n1. This release contains only sentence pairs. Even though the order of the sentences is the same\nas in the original, there may be gaps resulting from many-to-one, many-to-many, or one-to-many\nalignments that were filtered out. Therefore, this release may not be suitable for\ndiscourse-related research.\n2. Neither the sentence splitting nor the alignments are perfect. In particular, watch out for\npairs that differ considerably in length. You may want to filter these out before you do\nany statistical training.\n\nThe alignment of the Hansards was performed as part of the ReWrite project under funding\nfrom the DARPA TIDES program.", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e4a", "disabled": false, "gated": false, "likes": 0, "downloads": 446, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hard", "sha": "f020e27bb1cdc60853d356d2818bc39dec756d32", "lastModified": "2023-01-25T14:31:26.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset contains 93700 hotel reviews in Arabic language.The hotel reviews were collected from Booking.com website during June/July 2016.The reviews are expressed in Modern Standard Arabic as well as dialectal Arabic.The following table summarize some tatistics on the HARD Dataset.", "citation": "@incollection{elnagar2018hotel,\n  title={Hotel Arabic-reviews dataset construction for sentiment analysis applications},\n  author={Elnagar, Ashraf and Khalifa, Yasmin S and Einea, Anas},\n  booktitle={Intelligent Natural Language Processing: Trends and Applications},\n  pages={35--52},\n  year={2018},\n  publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e4b", "disabled": false, "gated": false, "likes": 1, "downloads": 321, "paperswithcode_id": "hard", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "harem", "sha": "4c395ff567a3842e806dc74f7c50227f5709d22d", "lastModified": "2023-01-25T14:31:29.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:pt", "license:unknown", "region:us"], "private": false, "author": null, "description": "The HAREM is a Portuguese language corpus commonly used for Named Entity Recognition tasks. It includes about 93k words, from 129 different texts,\nfrom several genres, and language varieties. The split of this dataset version follows the division made by [1], where 7% HAREM\ndocuments are the validation set and the miniHAREM corpus (with about 65k words) is the test set. There are two versions of the dataset set,\na version that has a total of 10 different named entity classes (Person, Organization, Location, Value, Date, Title, Thing, Event,\nAbstraction, and Other) and a \"selective\" version with only 5 classes (Person, Organization, Location, Value, and Date).\n\nIt's important to note that the original version of the HAREM dataset has 2 levels of NER details, namely \"Category\" and \"Sub-type\".\nThe dataset version processed here ONLY USE the \"Category\" level of the original dataset.\n\n[1] Souza, F\u00e1bio, Rodrigo Nogueira, and Roberto Lotufo. \"BERTimbau: Pretrained BERT Models for Brazilian Portuguese.\" Brazilian Conference on Intelligent Systems. Springer, Cham, 2020.", "citation": "@inproceedings{santos2006harem,\n  title={Harem: An advanced ner evaluation contest for portuguese},\n  author={Santos, Diana and Seco, Nuno and Cardoso, Nuno and Vilela, Rui},\n  booktitle={quot; In Nicoletta Calzolari; Khalid Choukri; Aldo Gangemi; Bente Maegaard; Joseph Mariani; Jan Odjik; Daniel Tapias (ed) Proceedings of the 5 th International Conference on Language Resources and Evaluation (LREC'2006)(Genoa Italy 22-28 May 2006)},\n  year={2006}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e4c", "disabled": false, "gated": false, "likes": 5, "downloads": 518, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "has_part", "sha": "29650bca049f78caa438e72a95d65480ea556840", "lastModified": "2022-11-03T16:15:21.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-Generics-KB", "language:en", "license:unknown", "Meronym-Prediction", "arxiv:2006.07510", "region:us"], "private": false, "author": null, "description": "This dataset is a new knowledge-base (KB) of hasPart relationships, extracted from a large corpus of generic statements. Complementary to other resources available, it is the first which is all three of: accurate (90% precision), salient (covers relationships a person may mention), and has high coverage of common terms (approximated as within a 10 year old\u2019s vocabulary), as well as having several times more hasPart entries than in the popular ontologies ConceptNet and WordNet. In addition, it contains information about quantifiers, argument modifiers, and links the entities to appropriate concepts in Wikipedia and WordNet.", "citation": "@misc{bhakthavatsalam2020dogs,\n      title={Do Dogs have Whiskers? A New Knowledge Base of hasPart Relations},\n      author={Sumithra Bhakthavatsalam and Kyle Richardson and Niket Tandon and Peter Clark},\n      year={2020},\n      eprint={2006.07510},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e4d", "disabled": false, "gated": false, "likes": 0, "downloads": 318, "paperswithcode_id": "haspart-kb", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hate_speech18", "sha": "12a7f2a31da5bff9e120a7de55192f6b06dd1959", "lastModified": "2023-03-27T14:11:55.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "These files contain text extracted from Stormfront, a white supremacist forum. A random set of\nforums posts have been sampled from several subforums and split into sentences. Those sentences\nhave been manually labelled as containing hate speech or not, according to certain annotation guidelines.", "citation": "@inproceedings{gibert2018hate,\n    title = \"{Hate Speech Dataset from a White Supremacy Forum}\",\n    author = \"de Gibert, Ona  and\n      Perez, Naiara  and\n      Garcia-Pablos, Aitor  and\n      Cuadros, Montse\",\n    booktitle = \"Proceedings of the 2nd Workshop on Abusive Language Online ({ALW}2)\",\n    month = oct,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/W18-5102\",\n    doi = \"10.18653/v1/W18-5102\",\n    pages = \"11--20\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e4f", "disabled": false, "gated": false, "likes": 13, "downloads": 12316, "paperswithcode_id": "hate-speech", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hate_speech_filipino", "sha": "329f20c3ee9a135f43e483affc3308be67c3dd15", "lastModified": "2023-01-25T14:31:38.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-analysis", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-twitter-data-philippine-election", "language:tl", "license:unknown", "region:us"], "private": false, "author": null, "description": "    Contains 10k tweets (training set) that are labeled as hate speech or non-hate speech. Released with 4,232 validation and 4,232 testing samples. Collected during the 2016 Philippine Presidential Elections.", "citation": "@article{Cabasag-2019-hate-speech,\n  title={Hate speech in Philippine election-related tweets: Automatic detection and classification using natural language processing.},\n  author={Neil Vicente Cabasag, Vicente Raphael Chan, Sean Christian Lim, Mark Edward Gonzales, and Charibeth Cheng},\n  journal={Philippine Computing Journal},\n  volume={XIV},\n  number={1},\n  month={August},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e50", "disabled": false, "gated": false, "likes": 5, "downloads": 314, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hate_speech_offensive", "sha": "46ff5f98edd1b55581dddad5b6727f53f7b0103b", "lastModified": "2023-01-25T14:31:41.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "hate-speech-detection", "arxiv:1703.04009", "region:us"], "private": false, "author": null, "description": "An annotated dataset for hate speech and offensive language detection on tweets.", "citation": "@inproceedings{hateoffensive,\ntitle = {Automated Hate Speech Detection and the Problem of Offensive Language},\nauthor = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar},\nbooktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media},\nseries = {ICWSM '17},\nyear = {2017},\nlocation = {Montreal, Canada},\npages = {512-515}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e51", "disabled": false, "gated": false, "likes": 9, "downloads": 8425, "paperswithcode_id": "hate-speech-and-offensive-language", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hate_speech_pl", "sha": "ae975330419c551c244ea03dc5c9dd591577d999", "lastModified": "2022-11-03T16:15:27.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": null, "description": "HateSpeech corpus in the current version contains over 2000 posts crawled from public Polish web. They represent various types and degrees of offensive language, expressed toward minorities (eg. ethnical, racial). The data were annotated manually.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e52", "disabled": false, "gated": false, "likes": 2, "downloads": 314, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hate_speech_portuguese", "sha": "0d9d97ac12a92459852a5c4de652eb2cdcdd86e9", "lastModified": "2023-11-24T10:27:25.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pt", "license:unknown", "hate-speech-detection", "region:us"], "private": false, "author": null, "description": "Portuguese dataset for hate speech detection composed of 5,668 tweets with binary annotations (i.e. 'hate' vs. 'no-hate').", "citation": "@inproceedings{fortuna-etal-2019-hierarchically,\ntitle = \"A Hierarchically-Labeled {P}ortuguese Hate Speech Dataset\",\nauthor = \"Fortuna, Paula  and\n    Rocha da Silva, Jo{\\\\~a}o  and\n    Soler-Company, Juan  and\n    Wanner, Leo  and\n    Nunes, S{\\'e}rgio\",\nbooktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\nmonth = aug,\nyear = \"2019\",\naddress = \"Florence, Italy\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://www.aclweb.org/anthology/W19-3510\",\ndoi = \"10.18653/v1/W19-3510\",\npages = \"94--104\",\nabstract = \"Over the past years, the amount of online offensive speech has been growing steadily. To successfully cope with it, machine learning are applied. However, ML-based techniques require sufficiently large annotated datasets. In the last years, different datasets were published, mainly for English. In this paper, we present a new dataset for Portuguese, which has not been in focus so far. The dataset is composed of 5,668 tweets. For its annotation, we defined two different schemes used by annotators with different levels of expertise. Firstly, non-experts annotated the tweets with binary labels ({`}hate{'} vs. {`}no-hate{'}). Secondly, expert annotators classified the tweets following a fine-grained hierarchical multiple label scheme with 81 hate speech categories in total. The inter-annotator agreement varied from category to category, which reflects the insight that some types of hate speech are more subtle than others and that their detection depends on personal perception. This hierarchical annotation scheme is the main contribution of the presented work, as it facilitates the identification of different types of hate speech and their intersections. To demonstrate the usefulness of our dataset, we carried a baseline classification experiment with pre-trained word embeddings and LSTM on the binary classified data, with a state-of-the-art outcome.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e53", "disabled": false, "gated": false, "likes": 2, "downloads": 322, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hatexplain", "sha": "5a137fd039fe1a157869f80c591fe32d1c1c3458", "lastModified": "2023-01-25T14:31:48.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "hate-speech-detection", "arxiv:2012.10289", "arxiv:1703.04009", "arxiv:1908.11049", "arxiv:1812.01693", "region:us"], "private": false, "author": null, "description": "Hatexplain is the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in the dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based.", "citation": "@misc{mathew2020hatexplain,\n      title={HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection},\n      author={Binny Mathew and Punyajoy Saha and Seid Muhie Yimam and Chris Biemann and Pawan Goyal and Animesh Mukherjee},\n      year={2020},\n      eprint={2012.10289},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e54", "disabled": false, "gated": false, "likes": 7, "downloads": 1393, "paperswithcode_id": "hatexplain", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hausa_voa_ner", "sha": "d1a3d06806fffe77d0c0813125973bf1ff3901c6", "lastModified": "2023-01-25T14:31:51.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ha", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The Hausa VOA NER dataset is a labeled dataset for named entity recognition in Hausa. The texts were obtained from\nHausa Voice of America News articles https://www.voahausa.com/ . We concentrate on\nfour types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n\nThe Hausa VOA NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\nthere is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\nis the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\nof type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\nhave tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n\nFor more details, see https://www.aclweb.org/anthology/2020.emnlp-main.204/", "citation": "@inproceedings{hedderich-etal-2020-transfer,\n    title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on {A}frican Languages\",\n    author = \"Hedderich, Michael A.  and\n      Adelani, David  and\n      Zhu, Dawei  and\n      Alabi, Jesujoba  and\n      Markus, Udia  and\n      Klakow, Dietrich\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n    doi = \"10.18653/v1/2020.emnlp-main.204\",\n    pages = \"2580--2591\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e55", "disabled": false, "gated": false, "likes": 2, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hausa_voa_topics", "sha": "19fda3214d57fe81fc5e93389afcb9c01a1df826", "lastModified": "2023-01-25T14:31:55.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ha", "license:unknown", "region:us"], "private": false, "author": null, "description": "A collection of news article headlines in Hausa from VOA Hausa.\nEach headline is labeled with one of the following classes: Nigeria,\nAfrica, World, Health or Politics.\n\nThe dataset was presented in the paper:\nHedderich, Adelani, Zhu, Alabi, Markus, Klakow: Transfer Learning and\nDistant Supervision for Multilingual Transformer Models: A Study on\nAfrican Languages (EMNLP 2020).", "citation": "@inproceedings{hedderich-etal-2020-transfer,\n    title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages\",\n    author = \"Hedderich, Michael A.  and\n      Adelani, David  and\n      Zhu, Dawei  and\n      Alabi, Jesujoba  and\n      Markus, Udia  and\n      Klakow, Dietrich\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n    doi = \"10.18653/v1/2020.emnlp-main.204\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e56", "disabled": false, "gated": false, "likes": 0, "downloads": 311, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hda_nli_hindi", "sha": "d2e6eea75594ff55b8487c1d76456a6be94fb12c", "lastModified": "2023-01-25T14:31:58.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|hindi_discourse", "language:hi", "license:mit", "region:us"], "private": false, "author": null, "description": "This dataset is a recasted version of the Hindi Discourse Analysis Dataset used to train models for Natural Language Inference Tasks in Low-Resource Languages like Hindi.", "citation": "    @inproceedings{uppal-etal-2020-two,\n    title = \"Two-Step Classification using Recasted Data for Low Resource Settings\",\n    author = \"Uppal, Shagun  and\n      Gupta, Vivek  and\n      Swaminathan, Avinash  and\n      Zhang, Haimin  and\n      Mahata, Debanjan  and\n      Gosangi, Rakesh  and\n      Shah, Rajiv Ratn  and\n      Stent, Amanda\",\n    booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing\",\n    month = dec,\n    year = \"2020\",\n    address = \"Suzhou, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.aacl-main.71\",\n    pages = \"706--719\",\n    abstract = \"An NLP model{'}s ability to reason should be independent of language. Previous works utilize Natural Language Inference (NLI) to understand the reasoning ability of models, mostly focusing on high resource languages like English. To address scarcity of data in low-resource languages such as Hindi, we use data recasting to create NLI datasets for four existing text classification datasets. Through experiments, we show that our recasted dataset is devoid of statistical irregularities and spurious patterns. We further study the consistency in predictions of the textual entailment models and propose a consistency regulariser to remove pairwise-inconsistencies in predictions. We propose a novel two-step classification method which uses textual-entailment predictions for classification task. We further improve the performance by using a joint-objective for classification and textual entailment. We therefore highlight the benefits of data recasting and improvements on classification performance using our approach with supporting experimental results.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e57", "disabled": false, "gated": false, "likes": 0, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "head_qa", "sha": "6be594abd481701ec132165d8f74e1a4cc4d06b8", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:es", "license:mit", "region:us"], "private": false, "author": null, "description": "HEAD-QA is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the\nSpanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio\nde Sanidad, Consumo y Bienestar Social.\n\nThe dataset contains questions about the following topics: medicine, nursing, psychology, chemistry, pharmacology and biology.", "citation": "@inproceedings{vilares-gomez-rodriguez-2019-head,\n    title = \"{HEAD}-{QA}: A Healthcare Dataset for Complex Reasoning\",\n    author = \"Vilares, David  and\n      G{\\'o}mez-Rodr{\\'i}guez, Carlos\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1092\",\n    doi = \"10.18653/v1/P19-1092\",\n    pages = \"960--966\",\n    abstract = \"We present HEAD-QA, a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. We then consider monolingual (Spanish) and cross-lingual (to English) experiments with information retrieval and neural techniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the results lag well behind human performance, demonstrating its usefulness as a benchmark for future work.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e58", "disabled": false, "gated": false, "likes": 7, "downloads": 1148, "paperswithcode_id": "headqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "health_fact", "sha": "6f98859fb48cbfdb3300ea5c851c37e088b3ab77", "lastModified": "2023-01-25T14:32:02.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "arxiv:2010.09926", "region:us"], "private": false, "author": null, "description": "PUBHEALTH is a comprehensive dataset for explainable automated fact-checking of\npublic health claims. Each instance in the PUBHEALTH dataset has an associated\nveracity label (true, false, unproven, mixture). Furthermore each instance in the\ndataset has an explanation text field. The explanation is a justification for which\nthe claim has been assigned a particular veracity label.\n\nThe dataset was created to explore fact-checking of difficult to verify claims i.e.,\nthose which require expertise from outside of the journalistics domain, in this case\nbiomedical and public health expertise.\n\nIt was also created in response to the lack of fact-checking datasets which provide\ngold standard natural language explanations for verdicts/labels.\n\nNOTE: There are missing labels in the dataset and we have replaced them with -1.", "citation": "@inproceedings{kotonya-toni-2020-explainable,\n    title = \"Explainable Automated Fact-Checking for Public Health Claims\",\n    author = \"Kotonya, Neema and Toni, Francesca\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods\n    in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.623\",\n    pages = \"7740--7754\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e59", "disabled": false, "gated": false, "likes": 16, "downloads": 719, "paperswithcode_id": "pubhealth", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hebrew_projectbenyehuda", "sha": "dbd611ebf182d1a197decc309936cd7d5e253666", "lastModified": "2022-11-03T16:15:45.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:he", "license:mit", "region:us"], "private": false, "author": null, "description": "This repository contains a dump of thousands of public domain works in Hebrew, from Project Ben-Yehuda, in plaintext UTF-8 files, with and without diacritics (nikkud). The metadata (pseudocatalogue.csv) file is a list of titles, authors, genres, and file paths, to help you process the dump.\nAll these works are in the public domain, so you are free to make any use of them, and do not need to ask for permission.\nThere are 10078 files, 3181136 lines", "citation": "@article{,\n  author = {},\n  title = {Public domain texts from Project Ben-Yehuda},\n  journal = {},\n  url = {https://github.com/projectbenyehuda/public_domain_dump},\n  year = {2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5a", "disabled": false, "gated": false, "likes": 2, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hebrew_sentiment", "sha": "e2534e7f2baceb8dccfcaf550be63ec7682c653d", "lastModified": "2023-01-25T14:32:05.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:he", "license:mit", "region:us"], "private": false, "author": null, "description": "HebrewSentiment is a data set consists of 12,804 user comments to posts on the official Facebook page of Israel\u2019s\npresident, Mr. Reuven Rivlin. In October 2015, we used the open software application Netvizz (Rieder,\n2013) to scrape all the comments to all of the president\u2019s posts in the period of June \u2013 August 2014,\nthe first three months of Rivlin\u2019s presidency.2 While the president\u2019s posts aimed at reconciling tensions\nand called for tolerance and empathy, the sentiment expressed in the comments to the president\u2019s posts\nwas polarized between citizens who warmly thanked the president, and citizens that fiercely critiqued his\npolicy. Of the 12,804 comments, 370 are neutral; 8,512 are positive, 3,922 negative.\n\nData Annotation: A trained researcher examined each comment and determined its sentiment value,\nwhere comments with an overall positive sentiment were assigned the value 1, comments with an overall\nnegative sentiment were assigned the value -1, and comments that are off-topic to the post\u2019s content\nwere assigned the value 0. We validated the coding scheme by asking a second trained researcher to\ncode the same data. There was substantial agreement between raters (N of agreements: 10623, N of\ndisagreements: 2105, Coehn\u2019s Kappa = 0.697, p = 0).", "citation": "@inproceedings{amram-etal-2018-representations,\n    title = \"Representations and Architectures in Neural Sentiment Analysis for Morphologically Rich Languages: A Case Study from {M}odern {H}ebrew\",\n    author = \"Amram, Adam  and\n      Ben David, Anat  and\n      Tsarfaty, Reut\",\n    booktitle = \"Proceedings of the 27th International Conference on Computational Linguistics\",\n    month = aug,\n    year = \"2018\",\n    address = \"Santa Fe, New Mexico, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/C18-1190\",\n    pages = \"2242--2252\",\n    abstract = \"This paper empirically studies the effects of representation choices on neural sentiment analysis for Modern Hebrew, a morphologically rich language (MRL) for which no sentiment analyzer currently exists. We study two dimensions of representational choices: (i) the granularity of the input signal (token-based vs. morpheme-based), and (ii) the level of encoding of vocabulary items (string-based vs. character-based). We hypothesise that for MRLs, languages where multiple meaning-bearing elements may be carried by a single space-delimited token, these choices will have measurable effects on task perfromance, and that these effects may vary for different architectural designs {---} fully-connected, convolutional or recurrent. Specifically, we hypothesize that morpheme-based representations will have advantages in terms of their generalization capacity and task accuracy, due to their better OOV coverage. To empirically study these effects, we develop a new sentiment analysis benchmark for Hebrew, based on 12K social media comments, and provide two instances of these data: in token-based and morpheme-based settings. Our experiments show that representation choices empirical effects vary with architecture type. While fully-connected and convolutional networks slightly prefer token-based settings, RNNs benefit from a morpheme-based representation, in accord with the hypothesis that explicit morphological information may help generalize. Our endeavour also delivers the first state-of-the-art broad-coverage sentiment analyzer for Hebrew, with over 89% accuracy, alongside an established benchmark to further study the effects of linguistic representation choices on neural networks{'} task performance.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5b", "disabled": false, "gated": false, "likes": 2, "downloads": 500, "paperswithcode_id": "modern-hebrew-sentiment-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hebrew_this_world", "sha": "81385c1382abc334d097e5050ac82b2d727caaf7", "lastModified": "2022-11-03T16:08:08.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:he", "license:agpl-3.0", "region:us"], "private": false, "author": null, "description": "HebrewThisWorld is a data set consists of 2028 issues of the newspaper 'This World' edited by Uri Avnery and were published between 1950 and 1989. Released under the AGPLv3 license.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5c", "disabled": false, "gated": false, "likes": 1, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Rowan/hellaswag", "sha": "6002345709e0801764318f06bf06ce1e7d1a1fe3", "lastModified": "2023-09-28T14:49:00.000Z", "tags": ["language:en", "arxiv:1905.07830", "region:us"], "private": false, "author": "Rowan", "description": "HellaSwag: Can a Machine Really Finish Your Sentence? is a new dataset for commonsense NLI. A paper was published at ACL2019.", "citation": "@inproceedings{zellers2019hellaswag,\n    title={HellaSwag: Can a Machine Really Finish Your Sentence?},\n    author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},\n    booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n    year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5d", "disabled": false, "gated": false, "likes": 33, "downloads": 2165, "paperswithcode_id": "hellaswag", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cais/mmlu", "sha": "7a00892cd331d78a88c8c869d0224a5cdd149848", "lastModified": "2023-10-07T11:24:05.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "arxiv:2009.03300", "arxiv:2005.00700", "arxiv:2005.14165", "arxiv:2008.02275", "region:us"], "private": false, "author": "cais", "description": "This is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks including elementary mathematics, US history, computer science, law, and more.", "citation": "@article{hendryckstest2021,\n      title={Measuring Massive Multitask Language Understanding},\n      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n      journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n      year={2021}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5e", "disabled": false, "gated": false, "likes": 107, "downloads": 2493802, "paperswithcode_id": "mmlu", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hind_encorp", "sha": "eeae2e522f7ae6019f3c3335f13e4a5bfd5b7314", "lastModified": "2022-11-03T16:15:40.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:hi", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": null, "description": "HindEnCorp parallel texts (sentence-aligned) come from the following sources:\nTides, which contains 50K sentence pairs taken mainly from news articles. This dataset was originally col- lected for the DARPA-TIDES surprise-language con- test in 2002, later refined at IIIT Hyderabad and provided for the NLP Tools Contest at ICON 2008 (Venkatapathy, 2008).\n\nCommentaries by Daniel Pipes contain 322 articles in English written by a journalist Daniel Pipes and translated into Hindi.\n\nEMILLE. This corpus (Baker et al., 2002) consists of three components: monolingual, parallel and annotated corpora. There are fourteen monolingual sub- corpora, including both written and (for some lan- guages) spoken data for fourteen South Asian lan- guages. The EMILLE monolingual corpora contain in total 92,799,000 words (including 2,627,000 words of transcribed spoken data for Bengali, Gujarati, Hindi, Punjabi and Urdu). The parallel corpus consists of 200,000 words of text in English and its accompanying translations into Hindi and other languages.\n\nSmaller datasets as collected by Bojar et al. (2010) include the corpus used at ACL 2005 (a subcorpus of EMILLE), a corpus of named entities from Wikipedia (crawled in 2009), and Agriculture domain parallel corpus.\n\ufffc\nFor the current release, we are extending the parallel corpus using these sources:\nIntercorp (\u010cerm\u00e1k and Rosen,2012) is a large multilingual parallel corpus of 32 languages including Hindi. The central language used for alignment is Czech. Intercorp\u2019s core texts amount to 202 million words. These core texts are most suitable for us because their sentence alignment is manually checked and therefore very reliable. They cover predominately short sto- ries and novels. There are seven Hindi texts in Inter- corp. Unfortunately, only for three of them the English translation is available; the other four are aligned only with Czech texts. The Hindi subcorpus of Intercorp contains 118,000 words in Hindi.\n\nTED talks 3 held in various languages, primarily English, are equipped with transcripts and these are translated into 102 languages. There are 179 talks for which Hindi translation is available.\n\nThe Indic multi-parallel corpus (Birch et al., 2011; Post et al., 2012) is a corpus of texts from Wikipedia translated from the respective Indian language into English by non-expert translators hired over Mechanical Turk. The quality is thus somewhat mixed in many respects starting from typesetting and punctuation over capi- talization, spelling, word choice to sentence structure. A little bit of control could be in principle obtained from the fact that every input sentence was translated 4 times. We used the 2012 release of the corpus.\n\nLaunchpad.net is a software collaboration platform that hosts many open-source projects and facilitates also collaborative localization of the tools. We downloaded all revisions of all the hosted projects and extracted the localization (.po) files.\n\nOther smaller datasets. This time, we added Wikipedia entities as crawled in 2013 (including any morphological variants of the named entitity that appears on the Hindi variant of the Wikipedia page) and words, word examples and quotes from the Shabdkosh online dictionary.", "citation": "@InProceedings{hindencorp05:lrec:2014,\n  author = {Ond{\\v{r}}ej Bojar and Vojt{\\v{e}}ch Diatka\n            and Pavel Rychl{\\'{y}} and Pavel Stra{\\v{n}}{\\'{a}}k\n            and V{\\'{}}t Suchomel and Ale{\\v{s}} Tamchyna and Daniel Zeman},\n  title = \"{HindEnCorp - Hindi-English and Hindi-only Corpus for Machine\n            Translation}\",\n  booktitle = {Proceedings of the Ninth International Conference on Language\n               Resources and Evaluation (LREC'14)},\n  year = {2014},\n  month = {may},\n  date = {26-31},\n  address = {Reykjavik, Iceland},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and\n     Thierry Declerck and Hrafn Loftsson and Bente Maegaard and Joseph Mariani\n     and Asuncion Moreno and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-8-4},\n  language = {english}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e5f", "disabled": false, "gated": false, "likes": 1, "downloads": 301, "paperswithcode_id": "hindencorp", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hindi_discourse", "sha": "9564f3c3d7d28a0d1965bf3bbe058e7a3e778e05", "lastModified": "2023-01-25T14:32:13.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:other", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:hi", "license:other", "discourse-analysis", "region:us"], "private": false, "author": null, "description": "The Hindi Discourse Analysis dataset is a corpus for analyzing discourse modes present in its sentences.\nIt contains sentences from stories written by 11 famous authors from the 20th Century.\n4-5 stories by each author have been selected which were available in the public domain resulting\nin a collection of 53 stories. Most of these short stories were originally written in Hindi\nbut some of them were written in other Indian languages and later translated to Hindi.", "citation": "@inproceedings{swapnil2020,\n    title={An Annotated Dataset of Discourse Modes in Hindi Stories},\n    author={Swapnil Dhanwal, Hritwik Dutta, Hitesh Nankani, Nilay Shrivastava, Yaman Kumar, Junyi Jessy Li, Debanjan Mahata, Rakesh Gosangi, Haimin Zhang, Rajiv Ratn Shah, Amanda Stent},\n    booktitle={Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n    volume={12},\n    pages={1191\u20131196},\n    year={2020}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e60", "disabled": false, "gated": false, "likes": 1, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hippocorpus", "sha": "0fceaffb57487c2b825971a95ac19abf4ad74269", "lastModified": "2022-11-03T16:15:25.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "narrative-flow", "region:us"], "private": false, "author": null, "description": "To examine the cognitive processes of remembering and imagining and their traces in language, we introduce Hippocorpus, a dataset of 6,854 English diary-like short stories about recalled and imagined events. Using a crowdsourcing framework, we first collect recalled stories and summaries from workers, then provide these summaries to other workers who write imagined stories. Finally, months later, we collect a retold version of the recalled stories from a subset of recalled authors. Our dataset comes paired with author demographics (age, gender, race), their openness to experience, as well as some variables regarding the author's relationship to the event (e.g., how personal the event is, how often they tell its story, etc.).", "citation": "@inproceedings{sap-etal-2020-recollection,\n    title = \"Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models\",\n    author = \"Sap, Maarten  and\n      Horvitz, Eric  and\n      Choi, Yejin  and\n      Smith, Noah A.  and\n      Pennebaker, James\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.178\",\n    doi = \"10.18653/v1/2020.acl-main.178\",\n    pages = \"1970--1978\",\n    abstract = \"We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release Hippocorpus, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932). Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e61", "disabled": false, "gated": false, "likes": 3, "downloads": 294, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hkcancor", "sha": "828708b90bf8d8008eb000e9ec5a5a89c22c8d68", "lastModified": "2023-02-23T08:43:12.000Z", "tags": ["task_categories:translation", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:yue", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The Hong Kong Cantonese Corpus (HKCanCor) comprise transcribed conversations\nrecorded between March 1997 and August 1998. It contains recordings of\nspontaneous speech (51 texts) and radio programmes (42 texts),\nwhich involve 2 to 4 speakers, with 1 text of monologue.\n\nIn total, the corpus contains around 230,000 Chinese words.\nThe text is word-segmented, annotated with part-of-speech (POS) tags and\nromanised Cantonese pronunciation.\n\nRomanisation scheme - Linguistic Society of Hong Kong (LSHK)\nPOS scheme - Peita-Fujitsu-Renmin Ribao (PRF) corpus (Duan et al., 2000),\n             with extended tags for Cantonese-specific phenomena added by\n             Luke and Wang (see original paper for details).", "citation": "@article{luke2015hong,\n  author={Luke, Kang-Kwong and Wong, May LY},\n  title={The Hong Kong Cantonese corpus: design and uses},\n  journal={Journal of Chinese Linguistics},\n  year={2015},\n  pages={309-330},\n  month={12}\n}\n@misc{lee2020,\n  author = {Lee, Jackson},\n  title = {PyCantonese: Cantonese Linguistics and NLP in Python},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {https://github.com/jacksonllee/pycantonese},\n  commit = {1d58f44e1cb097faa69de6b617e1d28903b84b98}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e62", "disabled": false, "gated": false, "likes": 11, "downloads": 316, "paperswithcode_id": "hong-kong-cantonese-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hlgd", "sha": "0fd23fedd037cd6490fb1acb30c17c55acba5979", "lastModified": "2023-01-25T14:32:19.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "headline-grouping", "region:us"], "private": false, "author": null, "description": "HLGD is a binary classification dataset consisting of 20,056 labeled news headlines pairs indicating\nwhether the two headlines describe the same underlying world event or not.", "citation": "@inproceedings{Laban2021NewsHG,\n  title={News Headline Grouping as a Challenging NLU Task},\n  author={Philippe Laban and Lucas Bandarkar},\n  booktitle={NAACL 2021},\n  publisher = {Association for Computational Linguistics},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e63", "disabled": false, "gated": false, "likes": 2, "downloads": 365, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hope_edi", "sha": "4dbd11b8d8157c5afed36111585589facbcf529b", "lastModified": "2023-06-01T14:59:49.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:ml", "language:ta", "license:cc-by-4.0", "hope-speech-classification", "region:us"], "private": false, "author": null, "description": "A Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not.", "citation": "@inproceedings{chakravarthi-2020-hopeedi,\ntitle = \"{H}ope{EDI}: A Multilingual Hope Speech Detection Dataset for Equality, Diversity, and Inclusion\",\nauthor = \"Chakravarthi, Bharathi Raja\",\nbooktitle = \"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media\",\nmonth = dec,\nyear = \"2020\",\naddress = \"Barcelona, Spain (Online)\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://www.aclweb.org/anthology/2020.peoples-1.5\",\npages = \"41--53\",\nabstract = \"Over the past few years, systems have been developed to control online content and eliminate abusive, offensive or hate speech content. However, people in power sometimes misuse this form of censorship to obstruct the democratic right of freedom of speech. Therefore, it is imperative that research should take a positive reinforcement approach towards online content that is encouraging, positive and supportive contents. Until now, most studies have focused on solving this problem of negativity in the English language, though the problem is much more than just harmful content. Furthermore, it is multilingual as well. Thus, we have constructed a Hope Speech dataset for Equality, Diversity and Inclusion (HopeEDI) containing user-generated comments from the social media platform YouTube with 28,451, 20,198 and 10,705 comments in English, Tamil and Malayalam, respectively, manually labelled as containing hope speech or not. To our knowledge, this is the first research of its kind to annotate hope speech for equality, diversity and inclusion in a multilingual setting. We determined that the inter-annotator agreement of our dataset using Krippendorff{'}s alpha. Further, we created several baselines to benchmark the resulting dataset and the results have been expressed using precision, recall and F1-score. The dataset is publicly available for the research community. We hope that this resource will spur further research on encouraging inclusive and responsive speech that reinforces positiveness.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e64", "disabled": false, "gated": false, "likes": 1, "downloads": 609, "paperswithcode_id": "hopeedi", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hotpot_qa", "sha": "cb440e4e72efe5808fe5df497ffa0b4e8da85c32", "lastModified": "2023-04-05T10:07:23.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "multi-hop", "arxiv:1809.09600", "region:us"], "private": false, "author": null, "description": "HotpotQA is a new dataset with 113k Wikipedia-based question-answer pairs with four key features:\n(1) the questions require finding and reasoning over multiple supporting documents to answer;\n(2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas;\n(3) we provide sentence-level supporting facts required for reasoning, allowingQA systems to reason with strong supervisionand explain the predictions;\n(4) we offer a new type of factoid comparison questions to testQA systems\u2019 ability to extract relevant facts and perform necessary comparison.", "citation": "@inproceedings{yang2018hotpotqa,\n  title={{HotpotQA}: A Dataset for Diverse, Explainable Multi-hop Question Answering},\n  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W. and Salakhutdinov, Ruslan and Manning, Christopher D.},\n  booktitle={Conference on Empirical Methods in Natural Language Processing ({EMNLP})},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e65", "disabled": false, "gated": false, "likes": 21, "downloads": 10926, "paperswithcode_id": "hotpotqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hover", "sha": "703407899639d63a56a87bd1d41131071969a02d", "lastModified": "2023-01-25T14:32:26.000Z", "tags": ["task_categories:text-retrieval", "task_ids:fact-checking-retrieval", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:2011.03088", "region:us"], "private": false, "author": null, "description": "HoVer is an open-domain, many-hop fact extraction and claim verification dataset built upon the Wikipedia corpus. The original 2-hop claims are adapted from question-answer pairs from HotpotQA. It is collected by a team of NLP researchers at UNC Chapel Hill and Verisk Analytics.", "citation": "@inproceedings{jiang2020hover,\n  title={{HoVer}: A Dataset for Many-Hop Fact Extraction And Claim Verification},\n  author={Yichen Jiang and Shikha Bordia and Zheng Zhong and Charles Dognin and Maneesh Singh and Mohit Bansal.},\n  booktitle={Findings of the Conference on Empirical Methods in Natural Language Processing ({EMNLP})},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e66", "disabled": false, "gated": false, "likes": 1, "downloads": 303, "paperswithcode_id": "hover", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hrenwac_para", "sha": "b47abd9d1f683ff8e5db3df1fca90ebd906c184f", "lastModified": "2022-11-03T16:07:49.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:hr", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The hrenWaC corpus version 2.0 consists of parallel Croatian-English texts crawled from the .hr top-level domain for Croatia.\nThe corpus was built with Spidextor (https://github.com/abumatran/spidextor), a tool that glues together the output of SpiderLing used for crawling and Bitextor used for bitext extraction. The accuracy of the extracted bitext on the segment level is around 80% and on the word level around 84%.", "citation": "@misc{11356/1058,\n title = {Croatian-English parallel corpus {hrenWaC} 2.0},\n author = {Ljube{\\v s}i{\\'c}, Nikola and Espl{\\'a}-Gomis, Miquel and Ortiz Rojas, Sergio and Klubi{\\v c}ka, Filip and Toral, Antonio},\n url = {http://hdl.handle.net/11356/1058},\n note = {Slovenian language resource repository {CLARIN}.{SI}},\n copyright = {{CLARIN}.{SI} User Licence for Internet Corpora},\n year = {2016} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e67", "disabled": false, "gated": false, "likes": 0, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hrwac", "sha": "555e03f2291780a71a3c6ff1f8fd64d3a11a2eac", "lastModified": "2022-11-03T16:15:15.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1B<n<10B", "source_datasets:original", "language:hr", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The Croatian web corpus hrWaC was built by crawling the .hr top-level domain in 2011 and again in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Croatian vs. Serbian).\n\nVersion 2.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 2.1 contains newer and better linguistic annotations.", "citation": "@misc{11356/1064,\n title = {Croatian web corpus {hrWaC} 2.1},\n author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n url = {http://hdl.handle.net/11356/1064},\n note = {Slovenian language resource repository {CLARIN}.{SI}},\n copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n year = {2016} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e68", "disabled": false, "gated": false, "likes": 0, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "humicroedit", "sha": "9cc4a12f9212c056769afd9db1d3dd52873d00e9", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "funnier-headline-identification", "funniness-score-prediction", "region:us"], "private": false, "author": null, "description": "This new dataset is designed to assess the funniness of edited news headlines.", "citation": "@article{hossain2019president,\n  title={\" President Vows to Cut< Taxes> Hair\": Dataset and Analysis of Creative Text Editing for Humorous Headlines},\n  author={Hossain, Nabil and Krumm, John and Gamon, Michael},\n  journal={arXiv preprint arXiv:1906.00274},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e69", "disabled": false, "gated": false, "likes": 2, "downloads": 595, "paperswithcode_id": "humicroedit", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hybrid_qa", "sha": "2962e06819564a6bcfd72bfc939f3ed0b9ac63ef", "lastModified": "2023-03-28T12:23:49.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "multihop-tabular-text-qa", "arxiv:1909.05358", "region:us"], "private": false, "author": null, "description": "Existing question answering datasets focus on dealing with homogeneous information, based either only on text or KB/Table information alone. However, as human knowledge is distributed over heterogeneous forms, using homogeneous information alone might lead to severe coverage problems. To fill in the gap, we present HybridQA, a new large-scale question-answering dataset that requires reasoning on heterogeneous information. Each question is aligned with a Wikipedia table and multiple free-form corpora linked with the entities in the table. The questions are designed to aggregate both tabular information and text information, i.e., lack of either form would render the question unanswerable.", "citation": "@article{chen2020hybridqa,\n  title={HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data},\n  author={Chen, Wenhu and Zha, Hanwen and Chen, Zhiyu and Xiong, Wenhan and Wang, Hong and Wang, William},\n  journal={Findings of EMNLP 2020},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6a", "disabled": false, "gated": false, "likes": 1, "downloads": 310, "paperswithcode_id": "hybridqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hyperpartisan_news_detection", "sha": "c315cc4a12a27cde08fd55c0beda41ced8b75923", "lastModified": "2023-06-13T07:46:19.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "bias-classification", "region:us"], "private": false, "author": null, "description": "Hyperpartisan News Detection was a dataset created for PAN @ SemEval 2019 Task 4.\nGiven a news article text, decide whether it follows a hyperpartisan argumentation, i.e., whether it exhibits blind, prejudiced, or unreasoning allegiance to one party, faction, cause, or person.\n\nThere are 2 parts:\n- byarticle: Labeled through crowdsourcing on an article basis. The data contains only articles for which a consensus among the crowdsourcing workers existed.\n- bypublisher: Labeled by the overall bias of the publisher as provided by BuzzFeed journalists or MediaBiasFactCheck.com.", "citation": "@inproceedings{kiesel-etal-2019-semeval,\n    title = \"{S}em{E}val-2019 Task 4: Hyperpartisan News Detection\",\n    author = \"Kiesel, Johannes  and\n      Mestre, Maria  and\n      Shukla, Rishabh  and\n      Vincent, Emmanuel  and\n      Adineh, Payam  and\n      Corney, David  and\n      Stein, Benno  and\n      Potthast, Martin\",\n    booktitle = \"Proceedings of the 13th International Workshop on Semantic Evaluation\",\n    month = jun,\n    year = \"2019\",\n    address = \"Minneapolis, Minnesota, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/S19-2145\",\n    doi = \"10.18653/v1/S19-2145\",\n    pages = \"829--839\",\n    abstract = \"Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes : no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6b", "disabled": false, "gated": false, "likes": 8, "downloads": 717, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "iapp_wiki_qa_squad", "sha": "c80a4184f37ed04394bdd04a5c065be57ff5c966", "lastModified": "2022-11-18T20:08:21.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-iapp-wiki-qa-dataset", "language:th", "license:mit", "region:us"], "private": false, "author": null, "description": "`iapp_wiki_qa_squad` is an extractive question answering dataset from Thai Wikipedia articles.\nIt is adapted from [the original iapp-wiki-qa-dataset](https://github.com/iapp-technology/iapp-wiki-qa-dataset)\nto [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format, resulting in\n5761/742/739 questions from 1529/191/192 articles.", "citation": "@dataset{kobkrit_viriyayudhakorn_2021_4539916,\n  author       = {Kobkrit Viriyayudhakorn and\n                  Charin Polpanumas},\n  title        = {iapp_wiki_qa_squad},\n  month        = feb,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = 1,\n  doi          = {10.5281/zenodo.4539916},\n  url          = {https://doi.org/10.5281/zenodo.4539916}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6c", "disabled": false, "gated": false, "likes": 2, "downloads": 460, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_clickbait", "sha": "ebdd7b6e1fc050874fe7cae0306f3babc945ecdf", "lastModified": "2023-01-25T14:32:36.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.", "citation": "@inproceedings{id_clickbait,\n  author    = {Andika William, Yunita Sari},\n  title     = {CLICK-ID: A Novel Dataset for Indonesian Clickbait Headlines},\n  year      = {2020},\n  url       = {http://dx.doi.org/10.17632/k42j7x2kpn.1},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6d", "disabled": false, "gated": false, "likes": 0, "downloads": 436, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_liputan6", "sha": "955dbcbfb09536c29615056edc37f99fc10aa7c6", "lastModified": "2022-11-18T20:08:31.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:id", "license:unknown", "extractive-summarization", "arxiv:2011.00679", "region:us"], "private": false, "author": null, "description": "In this paper, we introduce a large-scale Indonesian summarization dataset. We harvest articles from this http URL,\nan online news portal, and obtain 215,827 document-summary pairs. We leverage pre-trained language models to develop\nbenchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual\nBERT-based models. We include a thorough error analysis by examining machine-generated summaries that have\nlow ROUGE scores, and expose both issues with ROUGE it-self, as well as with extractive and abstractive\nsummarization models.", "citation": "@inproceedings{id_liputan6,\n  author    = {Fajri Koto, Jey Han Lau, Timothy Baldwin},\n  title     = {Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2011.00679},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6e", "disabled": false, "gated": false, "likes": 5, "downloads": 695, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_nergrit_corpus", "sha": "5a4737b6797ace849377de8e07777e24f0491998", "lastModified": "2023-01-25T14:32:40.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "license:other", "region:us"], "private": false, "author": null, "description": "Nergrit Corpus is a dataset collection for Indonesian Named Entity Recognition, Statement Extraction, and Sentiment\nAnalysis. id_nergrit_corpus is the Named Entity Recognition of this dataset collection which contains 18 entities as\nfollow:\n    'CRD': Cardinal\n    'DAT': Date\n    'EVT': Event\n    'FAC': Facility\n    'GPE': Geopolitical Entity\n    'LAW': Law Entity (such as Undang-Undang)\n    'LOC': Location\n    'MON': Money\n    'NOR': Political Organization\n    'ORD': Ordinal\n    'ORG': Organization\n    'PER': Person\n    'PRC': Percent\n    'PRD': Product\n    'QTY': Quantity\n    'REG': Religion\n    'TIM': Time\n    'WOA': Work of Art\n    'LAN': Language", "citation": "@inproceedings{id_nergrit_corpus,\n  author    = {Gria Inovasi Teknologi},\n  title     = {NERGRIT CORPUS},\n  year      = {2019},\n  url       = {https://github.com/grit-id/nergrit-corpus},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e6f", "disabled": false, "gated": false, "likes": 3, "downloads": 690, "paperswithcode_id": "nergrit-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_newspapers_2018", "sha": "5461ad850d416d6a2c22312b4ff5bde05ef19575", "lastModified": "2022-11-03T16:16:15.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:id", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The dataset contains around 500K articles (136M of words) from 7 Indonesian newspapers: Detik, Kompas, Tempo,\nCNN Indonesia, Sindo, Republika and Poskota. The articles are dated between 1st January 2018 and 20th August 2018\n(with few exceptions dated earlier). The size of uncompressed 500K json files (newspapers-json.tgz) is around 2.2GB,\nand the cleaned uncompressed in a big text file (newspapers.txt.gz) is about 1GB. The original source in Google Drive\ncontains also a dataset in html format which include raw data (pictures, css, javascript, ...)\nfrom the online news website", "citation": "@inproceedings{id_newspapers_2018,\n  author    = {},\n  title     = {Indonesian Newspapers 2018},\n  year      = {2019},\n  url       = {https://github.com/feryandi/Dataset-Artikel},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e70", "disabled": false, "gated": false, "likes": 4, "downloads": 385, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_panl_bppt", "sha": "e67e7c27f1a9f6cb843489af9cc176f973ad65f3", "lastModified": "2023-01-25T14:32:43.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:id", "license:unknown", "region:us"], "private": false, "author": null, "description": "Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\nCapacity in Asia). The dataset contains around 24K sentences divided in 4 difference topics (Economic, international,\nScience and Technology and Sport).", "citation": "@inproceedings{id_panl_bppt,\n  author    = {PAN Localization - BPPT},\n  title     = {Parallel Text Corpora, English Indonesian},\n  year      = {2009},\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e71", "disabled": false, "gated": false, "likes": 1, "downloads": 305, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "id_puisi", "sha": "634e8616c1b484e65ca225897c1038ffe2b4e519", "lastModified": "2022-11-03T16:08:09.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "task_categories:fill-mask", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:id", "license:mit", "poem-generation", "region:us"], "private": false, "author": null, "description": "Puisi (poem) is an Indonesian poetic form. The dataset contains 7223 Indonesian puisi with its title and author.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e72", "disabled": false, "gated": false, "likes": 2, "downloads": 303, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "igbo_monolingual", "sha": "dc1187a9d52fcc64235a44bf2ac1eeb9c11f8a22", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:ig", "license:unknown", "arxiv:2004.00648", "region:us"], "private": false, "author": null, "description": "A dataset is a collection of Monolingual Igbo sentences.", "citation": "@misc{ezeani2020igboenglish,\ntitle={Igbo-English Machine Translation: An Evaluation Benchmark},\nauthor={Ignatius Ezeani and Paul Rayson and Ikechukwu Onyenwe and Chinedu Uchechukwu and Mark Hepple},\nyear={2020},\neprint={2004.00648},\narchivePrefix={arXiv},\nprimaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e74", "disabled": false, "gated": false, "likes": 1, "downloads": 1430, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "igbo_ner", "sha": "c8513fa5dd0c00fc606214925fd23c147b275fdb", "lastModified": "2022-11-03T16:16:30.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ig", "license:unknown", "arxiv:2004.00648", "region:us"], "private": false, "author": null, "description": "Igbo Named Entity Recognition Dataset", "citation": "@misc{ezeani2020igboenglish,\n    title={Igbo-English Machine Translation: An Evaluation Benchmark},\n    author={Ignatius Ezeani and Paul Rayson and Ikechukwu Onyenwe and Chinedu Uchechukwu and Mark Hepple},\n    year={2020},\n    eprint={2004.00648},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e75", "disabled": false, "gated": false, "likes": 0, "downloads": 430, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ilist", "sha": "3edfb9ce0b9953639a288b831f4a043419fff671", "lastModified": "2023-01-25T14:32:46.000Z", "tags": ["task_categories:text-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:awa", "language:bho", "language:bra", "language:hi", "language:mag", "license:cc-by-4.0", "language-identification", "region:us"], "private": false, "author": null, "description": "This dataset is introduced in a task which aimed at identifying 5 closely-related languages of Indo-Aryan language family \u2013\nHindi (also known as Khari Boli), Braj Bhasha, Awadhi, Bhojpuri, and Magahi.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e76", "disabled": false, "gated": false, "likes": 1, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "imdb", "sha": "9c6ede893febf99215a29cc7b72992bb1138b06b", "lastModified": "2023-04-05T10:07:38.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Large Movie Review Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\\", "citation": "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n  title     = {Learning Word Vectors for Sentiment Analysis},\n  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n  month     = {June},\n  year      = {2011},\n  address   = {Portland, Oregon, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {142--150},\n  url       = {http://www.aclweb.org/anthology/P11-1015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e77", "disabled": false, "gated": false, "likes": 129, "downloads": 252065, "paperswithcode_id": "imdb-movie-reviews", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "imdb_urdu_reviews", "sha": "6c078c25f6422d14a018c25fb632b87e7f9c9ca9", "lastModified": "2023-01-25T14:32:49.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ur", "license:odbl", "region:us"], "private": false, "author": null, "description": "Large Movie translated Urdu Reviews Dataset.\nThis is a dataset for binary sentiment classification containing substantially more data than previous\nbenchmark datasets. We provide a set of 40,000 highly polar movie reviews for training, and 10,000 for testing.\nTo increase the availability of sentiment analysis dataset for a low recourse language like Urdu,\nwe opted to use the already available IMDB Dataset. we have translated this dataset using google translator.\nThis is a binary classification dataset having two classes as positive and negative.\nThe reason behind using this dataset is high polarity for each class.\nIt contains 50k samples equally divided in two classes.", "citation": "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n  author    = {Maas, Andrew L. and Daly,nRaymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y...},\n  title     = {Learning Word Vectors for Sentiment Analysis},\n  month     = {June},\n  year      = {2011},\n  address   = {Portland, Oregon, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {142--150},\n  url       = {http://www.aclweb.org/anthology/P11-1015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e78", "disabled": false, "gated": false, "likes": 0, "downloads": 300, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "imppres", "sha": "aec5b37bab8857d552e9e042297ee2879eeed70b", "lastModified": "2023-01-25T14:32:53.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "Over >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. IMPPRES is an NLI dataset following the format of SNLI (Bowman et al., 2015), MultiNLI (Williams et al., 2018) and XNLI (Conneau et al., 2018), which was created to evaluate how well trained NLI models recognize several classes of presuppositions and scalar implicatures.", "citation": "@inproceedings{jeretic-etal-2020-natural,\n    title = \"Are Natural Language Inference Models {IMPPRESsive}? {L}earning {IMPlicature} and {PRESupposition}\",\n    author = \"Jereti\\v{c}, Paloma  and\n      Warstadt, Alex  and\n      Bhooshan, Suvrat  and\n      Williams, Adina\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.768\",\n    doi = \"10.18653/v1/2020.acl-main.768\",\n    pages = \"8690--8705\",\n    abstract = \"Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied. We create an IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of 32K semi-automatically generated sentence pairs illustrating well-studied pragmatic inference types. We use IMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we find that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by {``}some{''} as entailments. For some presupposition triggers like {``}only{''}, BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e79", "disabled": false, "gated": false, "likes": 0, "downloads": 2443, "paperswithcode_id": "imppres", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "indic_glue", "sha": "13ba30c9228cb5b605cf005a22f4c9e122f54878", "lastModified": "2023-06-09T13:57:14.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_categories:multiple-choice", "task_ids:topic-classification", "task_ids:natural-language-inference", "task_ids:sentiment-analysis", "task_ids:semantic-similarity-scoring", "task_ids:named-entity-recognition", "task_ids:multiple-choice-qa", "annotations_creators:other", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended|other", "language:as", "language:bn", "language:en", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:other", "discourse-mode-classification", "paraphrase-identification", "cross-lingual-similarity", "headline-classification", "region:us"], "private": false, "author": null, "description": "    IndicGLUE is a natural language understanding benchmark for Indian languages. It contains a wide\n    variety of tasks and covers 11 major Indian languages - as, bn, gu, hi, kn, ml, mr, or, pa, ta, te.", "citation": "    @inproceedings{kakwani2020indicnlpsuite,\n    title={{IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages}},\n    author={Divyanshu Kakwani and Anoop Kunchukuttan and Satish Golla and Gokul N.C. and Avik Bhattacharyya and Mitesh M. Khapra and Pratyush Kumar},\n    year={2020},\n    booktitle={Findings of EMNLP},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7a", "disabled": false, "gated": false, "likes": 4, "downloads": 9193, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "indonli", "sha": "a68ff62b14a49157838ccc8540fd39aef239f181", "lastModified": "2023-01-25T14:33:00.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "  IndoNLI is the first human-elicited Natural Language Inference (NLI) dataset for Indonesian.\n  IndoNLI is annotated by both crowd workers and experts. The expert-annotated data is used exclusively as a test set.\n  It is designed to provide a challenging test-bed for Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural changes, idioms, or temporal and spatial reasoning.", "citation": "  @inproceedings{mahendra-etal-2021-indonli,\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\n    pages = \"10511--10527\",\n  }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7b", "disabled": false, "gated": false, "likes": 6, "downloads": 478, "paperswithcode_id": "indonli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "indonlp/indonlu", "sha": "939bfb4e87cd0f4f717f4222ec19c55cdc302982", "lastModified": "2023-02-03T05:49:02.000Z", "tags": ["task_categories:question-answering", "task_categories:text-classification", "task_categories:token-classification", "task_ids:closed-domain-qa", "task_ids:multi-class-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "task_ids:semantic-similarity-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:id", "license:mit", "keyphrase-extraction", "span-extraction", "aspect-based-sentiment-analysis", "arxiv:1809.03391", "region:us"], "private": false, "author": "indonlp", "description": "The IndoNLU benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems for Bahasa Indonesia.", "citation": "@inproceedings{wilie2020indonlu,\ntitle = {{IndoNLU}: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\nauthors={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\nbooktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7c", "disabled": false, "gated": false, "likes": 24, "downloads": 2186, "paperswithcode_id": "indonlu-benchmark", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "inquisitive_qg", "sha": "0c7f7266eedc8cb7a2c654a40ac3b20c57c73fc2", "lastModified": "2022-11-18T20:09:50.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "question-generation", "region:us"], "private": false, "author": null, "description": "A dataset of about 20k questions that are elicited from readers as they naturally read through a document sentence by sentence. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text. Because these questions are generated while the readers are processing the information, the questions directly communicate gaps between the reader\u2019s and writer\u2019s knowledge about the events described in the text, and are not necessarily answered in the document itself. This type of question reflects a real-world scenario: if one has questions during reading, some of them are answered by the text later on, the rest are not, but any of them would help further the reader\u2019s understanding at the particular point when they asked it. This resource could enable question generation models to simulate human-like curiosity and cognitive processing, which may open up a new realm of applications.", "citation": "@InProceedings{ko2020inquisitive,\n  author    = {Ko, Wei-Jen and Chen, Te-Yuan and Huang, Yiyan and Durrett, Greg and Li, Junyi Jessy},\n  title     = {Inquisitive Question Generation for High Level Text Comprehension},\n  booktitle = {Proceedings of EMNLP},\n  year      = {2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7d", "disabled": false, "gated": false, "likes": 1, "downloads": 306, "paperswithcode_id": "inquisitive", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "interpress_news_category_tr", "sha": "9557df1f568998a1e7db5f4ca0a0acec1d6682be", "lastModified": "2023-01-25T14:33:03.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tr", "license:unknown", "news-category-classification", "region:us"], "private": false, "author": null, "description": "It is a Turkish news data set consisting of 273601 news in 17 categories, compiled from print media and news websites between 2010 and 2017 by the Interpress (https://www.interpress.com/) media monitoring company.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7e", "disabled": false, "gated": false, "likes": 6, "downloads": 330, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "interpress_news_category_tr_lite", "sha": "1fd73343b6a202a3fbe6e21eb8efd63f59cd42d7", "lastModified": "2023-01-25T14:33:07.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|interpress_news_category_tr", "language:tr", "license:unknown", "news-category-classification", "region:us"], "private": false, "author": null, "description": "It is a Turkish news data set consisting of 273601 news in 10 categories, compiled from print media and news websites between 2010 and 2017 by the Interpress (https://www.interpress.com/) media monitoring company. It has been rearranged as easily separable and with fewer classes.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e7f", "disabled": false, "gated": false, "likes": 10, "downloads": 313, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "irc_disentangle", "sha": "6f3397f211fafdea41e0e8f9c84327fe217142b0", "lastModified": "2022-11-18T20:10:09.000Z", "tags": ["task_categories:token-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "conversation-disentanglement", "arxiv:1810.11118", "region:us"], "private": false, "author": null, "description": "Disentangling conversations mixed together in a single stream of messages is\na difficult task, made harder by the lack of large manually annotated\ndatasets. This new dataset of 77,563 messages manually annotated with\nreply-structure graphs that both disentangle conversations and define\ninternal conversation structure. The dataset is 16 times larger than all\npreviously released datasets combined, the first to include adjudication of\nannotation disagreements, and the first to include context.", "citation": "@inproceedings{kummerfeld-etal-2019-large,\n    title = \"A Large-Scale Corpus for Conversation Disentanglement\",\n    author = \"Kummerfeld, Jonathan K.  and\n      Gouravajhala, Sai R.  and\n      Peper, Joseph J.  and\n      Athreya, Vignesh  and\n      Gunasekara, Chulaka  and\n      Ganhotra, Jatin  and\n      Patel, Siva Sankalp  and\n      Polymenakos, Lazaros C  and\n      Lasecki, Walter\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P19-1374\",\n    doi = \"10.18653/v1/P19-1374\",\n    pages = \"3846--3856\",\n    arxiv = \"https://arxiv.org/abs/1810.11118\",\n    software = \"https://jkk.name/irc-disentanglement\",\n    data = \"https://jkk.name/irc-disentanglement\",\n    abstract = \"Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our data is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include context. We use our data to re-examine prior work, in particular, finding that 89% of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e80", "disabled": false, "gated": false, "likes": 4, "downloads": 441, "paperswithcode_id": "irc-disentanglement", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "iwslt2017", "sha": "c18a4f81a47ae6fa079fe9d32db288ddde38451d", "lastModified": "2023-04-05T10:07:51.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "language:ar", "language:de", "language:en", "language:fr", "language:it", "language:ja", "language:ko", "language:nl", "language:ro", "language:zh", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": null, "description": "The IWSLT 2017 Multilingual Task addresses text translation, including zero-shot translation, with a single MT system across all directions including English, German, Dutch, Italian and Romanian. As unofficial task, conventional bilingual text translation is offered between English and Arabic, French, Japanese, Chinese, German and Korean.", "citation": "@inproceedings{cettolo-etal-2017-overview,\n    title = \"Overview of the {IWSLT} 2017 Evaluation Campaign\",\n    author = {Cettolo, Mauro  and\n      Federico, Marcello  and\n      Bentivogli, Luisa  and\n      Niehues, Jan  and\n      St{\\\\\"u}ker, Sebastian  and\n      Sudoh, Katsuhito  and\n      Yoshino, Koichiro  and\n      Federmann, Christian},\n    booktitle = \"Proceedings of the 14th International Conference on Spoken Language Translation\",\n    month = dec # \" 14-15\",\n    year = \"2017\",\n    address = \"Tokyo, Japan\",\n    publisher = \"International Workshop on Spoken Language Translation\",\n    url = \"https://aclanthology.org/2017.iwslt-1.1\",\n    pages = \"2--14\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e83", "disabled": false, "gated": false, "likes": 15, "downloads": 6757, "paperswithcode_id": "iwslt-2017", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jeopardy", "sha": "a4481a49b616d824d0080f107c138a5d81989efe", "lastModified": "2023-04-05T10:07:53.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "Dataset containing 216,930 Jeopardy questions, answers and other data.\n\nThe json file is an unordered list of questions where each question has\n'category' : the question category, e.g. \"HISTORY\"\n'value' : integer $ value of the question as string, e.g. \"200\"\nNote: This is \"None\" for Final Jeopardy! and Tiebreaker questions\n'question' : text of question\nNote: This sometimes contains hyperlinks and other things messy text such as when there's a picture or video question\n'answer' : text of answer\n'round' : one of \"Jeopardy!\",\"Double Jeopardy!\",\"Final Jeopardy!\" or \"Tiebreaker\"\nNote: Tiebreaker questions do happen but they're very rare (like once every 20 years)\n'show_number' : int of show number, e.g '4680'\n'air_date' : string of the show air date in format YYYY-MM-DD", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e84", "disabled": false, "gated": false, "likes": 4, "downloads": 465, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jfleg", "sha": "9e947fd62bffb105bdb80caad7193375c6d28492", "lastModified": "2022-11-18T20:15:50.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "multilinguality:other-language-learner", "size_categories:1K<n<10K", "source_datasets:extended|other-GUG-grammaticality-judgements", "language:en", "license:cc-by-nc-sa-4.0", "grammatical-error-correction", "region:us"], "private": false, "author": null, "description": "JFLEG (JHU FLuency-Extended GUG) is an English grammatical error correction (GEC) corpus.\nIt is a gold standard benchmark for developing and evaluating GEC systems with respect to\nfluency (extent to which a text is native-sounding) as well as grammaticality.\n\nFor each source document, there are four human-written corrections (ref0 to ref3).", "citation": "@InProceedings{napoles-sakaguchi-tetreault:2017:EACLshort,\n  author    = {Napoles, Courtney\n               and  Sakaguchi, Keisuke\n               and  Tetreault, Joel},\n  title     = {JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction},\n  booktitle = {Proceedings of the 15th Conference of the European Chapter of the\n               Association for Computational Linguistics: Volume 2, Short Papers},\n  month     = {April},\n  year      = {2017},\n  address   = {Valencia, Spain},\n  publisher = {Association for Computational Linguistics},\n  pages     = {229--234},\n  url       = {http://www.aclweb.org/anthology/E17-2037}\n}\n@InProceedings{heilman-EtAl:2014:P14-2,\n  author    = {Heilman, Michael\n               and  Cahill, Aoife\n               and  Madnani, Nitin\n               and  Lopez, Melissa\n               and  Mulholland, Matthew\n               and  Tetreault, Joel},\n  title     = {Predicting Grammaticality on an Ordinal Scale},\n  booktitle = {Proceedings of the 52nd Annual Meeting of the\n               Association for Computational Linguistics (Volume 2: Short Papers)},\n  month     = {June},\n  year      = {2014},\n  address   = {Baltimore, Maryland},\n  publisher = {Association for Computational Linguistics},\n  pages     = {174--180},\n  url       = {http://www.aclweb.org/anthology/P14-2029}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e85", "disabled": false, "gated": false, "likes": 36, "downloads": 11397, "paperswithcode_id": "jfleg", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jigsaw_toxicity_pred", "sha": "a3ed3709806cbc041cc979831724c877c3b0508c", "lastModified": "2023-01-25T14:33:17.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "This dataset consists of a large number of Wikipedia comments which have been labeled by human raters for toxic behavior.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e86", "disabled": false, "gated": false, "likes": 16, "downloads": 2437, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jigsaw_unintended_bias", "sha": "0f189ceca9af2b97c8512f9c4c03e5eb07bc731c", "lastModified": "2023-01-25T14:33:20.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc0-1.0", "toxicity-prediction", "region:us"], "private": false, "author": null, "description": "A collection of comments from the defunct Civil Comments platform that have been annotated for their toxicity.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e87", "disabled": false, "gated": false, "likes": 3, "downloads": 495, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jnlpba", "sha": "ea8f67e09f902a02e70aa004bded3d944ff63cfa", "lastModified": "2023-04-14T13:49:49.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-genia-v3.02", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The data came from the GENIA version 3.02 corpus (Kim et al., 2003). This was formed from a controlled search\non MEDLINE using the MeSH terms \u0018human\u0019, \u0018blood cells\u0019 and \u0018transcription factors\u0019. From this search 2,000 abstracts\nwere selected and hand annotated according to a small taxonomy of 48 classes based on a chemical classification.\nAmong the classes, 36 terminal classes were used to annotate the GENIA corpus.", "citation": "@inproceedings{kim2004introduction,\n               title={Introduction to the bio-entity recognition task at JNLPBA},\n               author={Kim, Jin-Dong and Ohta, Tomoko and Tsuruoka, Yoshimasa and Tateisi, Yuka and Collier, Nigel},\n               booktitle={Proceedings of the international joint workshop on natural language processing in biomedicine and its applications},\n               pages={70--75},\n               year={2004},\n               organization={Citeseer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e88", "disabled": false, "gated": false, "likes": 5, "downloads": 517, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "journalists_questions", "sha": "d5204f63fefd6f788116b990afa0b686e7434861", "lastModified": "2023-01-25T14:33:26.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "license:unknown", "question-identification", "region:us"], "private": false, "author": null, "description": "\\\r\nThe journalists_questions corpus (version 1.0) is a collection of 10K human-written Arabic\r\ntweets manually labeled for question identification over Arabic tweets posted by journalists.", "citation": "\\\r\n@inproceedings{hasanain2016questions,\r\n  title={What Questions Do Journalists Ask on Twitter?},\r\n  author={Hasanain, Maram and Bagdouri, Mossaab and Elsayed, Tamer and Oard, Douglas W},\r\n  booktitle={Tenth International AAAI Conference on Web and Social Media},\r\n  year={2016}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e89", "disabled": false, "gated": false, "likes": 0, "downloads": 302, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kan_hope", "sha": "65fd1e173385731586856749e42ad58c9dc18452", "lastModified": "2023-01-25T14:33:30.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:kn", "license:cc-by-4.0", "hope-speech-detection", "arxiv:2108.04616", "region:us"], "private": false, "author": null, "description": "Numerous methods have been developed to monitor the spread of negativity in modern years by\neliminating vulgar, offensive, and fierce comments from social media platforms. However, there are relatively\nlesser amounts of study that converges on embracing positivity, reinforcing supportive and reassuring content in online forums.\nConsequently, we propose creating an English Kannada Hope speech dataset, KanHope and comparing several experiments to benchmark the dataset.\nThe dataset consists of 6,176 user generated comments in code mixed Kannada scraped from YouTube and manually annotated as bearing hope\nspeech or Not-hope speech.\nThis dataset was prepared for hope-speech text classification benchmark on code-mixed Kannada, an under-resourced language.", "citation": "@misc{hande2021hope,\n      title={Hope Speech detection in under-resourced Kannada language},\n      author={Adeep Hande and Ruba Priyadharshini and Anbukkarasi Sampath and Kingston Pal Thamburaj and Prabakaran Chandran and Bharathi Raja Chakravarthi},\n      year={2021},\n      eprint={2108.04616},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8a", "disabled": false, "gated": false, "likes": 1, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kannada_news", "sha": "94b6719f36520a9ba14cdd09b06dd87f7940e064", "lastModified": "2023-01-25T14:33:33.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:kn", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "The Kannada news dataset contains only the headlines of news article in three categories:\nEntertainment, Tech, and Sports.\n\nThe data set contains around 6300 news article headlines which collected from Kannada news websites.\nThe data set has been cleaned and contains train and test set using which can be used to benchmark\nclassification models in Kannada.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8b", "disabled": false, "gated": false, "likes": 1, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kd_conv", "sha": "0d087520d62a1d6dced193daf276ae4f7ecf9c7d", "lastModified": "2023-03-28T14:17:47.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "KdConv is a Chinese multi-domain Knowledge-driven Conversionsation dataset, grounding the topics in multi-turn conversations to knowledge graphs. KdConv contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics, while the corpus can also used for exploration of transfer learning and domain adaptation.\\", "citation": "@inproceedings{zhou-etal-2020-kdconv,\n    title = \"{K}d{C}onv: A {C}hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation\",\n    author = \"Zhou, Hao  and\n      Zheng, Chujie  and\n      Huang, Kaili  and\n      Huang, Minlie  and\n      Zhu, Xiaoyan\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.635\",\n    doi = \"10.18653/v1/2020.acl-main.635\",\n    pages = \"7098--7108\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8c", "disabled": false, "gated": false, "likes": 9, "downloads": 1418, "paperswithcode_id": "kdconv", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kde4", "sha": "12cd06d961fae220f6ef1ab533321b8e9ddc3533", "lastModified": "2022-11-03T16:32:20.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:af", "language:ar", "language:as", "language:ast", "language:be", "language:bg", "language:bn", "language:br", "language:ca", "language:crh", "language:cs", "language:csb", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:fy", "language:ga", "language:gl", "language:gu", "language:ha", "language:he", "language:hi", "language:hne", "language:hr", "language:hsb", "language:hu", "language:hy", "language:id", "language:is", "language:it", "language:ja", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:lb", "language:lt", "language:lv", "language:mai", "language:mk", "language:ml", "language:mr", "language:ms", "language:mt", "language:nb", "language:nds", "language:ne", "language:nl", "language:nn", "language:nso", "language:oc", "language:or", "language:pa", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:rw", "language:se", "language:si", "language:sk", "language:sl", "language:sr", "language:sv", "language:ta", "language:te", "language:tg", "language:th", "language:tr", "language:uk", "language:uz", "language:vi", "language:wa", "language:xh", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus of KDE4 localization files (v.2).\n\n92 languages, 4,099 bitexts\ntotal number of files: 75,535\ntotal number of tokens: 60.75M\ntotal number of sentence fragments: 8.89M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8d", "disabled": false, "gated": false, "likes": 12, "downloads": 2447, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kelm", "sha": "cee05ec7e39324fa9dc2d919ece4c9e12257bd79", "lastModified": "2022-11-18T20:16:37.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "data-to-text-generation", "arxiv:2010.12688", "region:us"], "private": false, "author": null, "description": "Data-To-Text Generation involves converting knowledge graph (KG) triples of the form (subject, relation, object) into\na natural language sentence(s). This dataset consists of English KG data converted into paired natural language text.\nThe generated corpus consists of \u223c18M sentences spanning \u223c45M triples with \u223c1500 distinct relations.", "citation": "@misc{agarwal2020large,\n      title={Large Scale Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training},\n      author={Oshin Agarwal and Heming Ge and Siamak Shakeri and Rami Al-Rfou},\n      year={2020},\n      eprint={2010.12688},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8e", "disabled": false, "gated": false, "likes": 6, "downloads": 449, "paperswithcode_id": "kelm", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kilt_tasks", "sha": "ad175715bf139265bf5647925f73d366310bf2ae", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:fill-mask", "task_categories:question-answering", "task_categories:text-classification", "task_categories:text-generation", "task_categories:text-retrieval", "task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:dialogue-modeling", "task_ids:document-retrieval", "task_ids:entity-linking-retrieval", "task_ids:extractive-qa", "task_ids:fact-checking", "task_ids:fact-checking-retrieval", "task_ids:open-domain-abstractive-qa", "task_ids:open-domain-qa", "task_ids:slot-filling", "annotations_creators:crowdsourced", "annotations_creators:found", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "source_datasets:extended|natural_questions", "source_datasets:extended|other-aidayago", "source_datasets:extended|other-fever", "source_datasets:extended|other-hotpotqa", "source_datasets:extended|other-trex", "source_datasets:extended|other-triviaqa", "source_datasets:extended|other-wizardsofwikipedia", "source_datasets:extended|other-wned-cweb", "source_datasets:extended|other-wned-wiki", "source_datasets:extended|other-zero-shot-re", "source_datasets:original", "language:en", "license:mit", "arxiv:2009.02252", "region:us"], "private": false, "author": null, "description": "KILT tasks training and evaluation data.\n- [FEVER](https://fever.ai) | Fact Checking | fever\n- [AIDA CoNLL-YAGO](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/ambiverse-nlu/aida/downloads) | Entity Linking | aidayago2\n- [WNED-WIKI](https://github.com/U-Alberta/wned) | Entity Linking | wned\n- [WNED-CWEB](https://github.com/U-Alberta/wned) | Entity Linking | cweb\n- [T-REx](https://hadyelsahar.github.io/t-rex) | Slot Filling | trex\n- [Zero-Shot RE](http://nlp.cs.washington.edu/zeroshot) | Slot Filling | structured_zeroshot\n- [Natural Questions](https://ai.google.com/research/NaturalQuestions) | Open Domain QA  | nq\n- [HotpotQA](https://hotpotqa.github.io) | Open Domain QA | hotpotqa\n- [TriviaQA](http://nlp.cs.washington.edu/triviaqa) | Open Domain QA | triviaqa\n- [ELI5](https://facebookresearch.github.io/ELI5/explore.html) | Open Domain QA | eli5\n- [Wizard of Wikipedia](https://parl.ai/projects/wizard_of_wikipedia) | Dialogue | wow\n\nTo finish linking TriviaQA questions to the IDs provided, follow the instructions [here](http://github.com/huggingface/datasets/datasets/kilt_tasks/README.md).", "citation": "@inproceedings{fb_kilt,\n    author    = {Fabio Petroni and\n                 Aleksandra Piktus and\n                 Angela Fan and\n                 Patrick Lewis and\n                 Majid Yazdani and\n                 Nicola De Cao and\n                 James Thorne and\n                 Yacine Jernite and\n                 Vassilis Plachouras and\n                 Tim Rockt\\\"aschel and\n                 Sebastian Riedel},\n    title     = {{KILT:} a {B}enchmark for {K}nowledge {I}ntensive {L}anguage {T}asks},\n    journal   = {CoRR},\n    archivePrefix = {arXiv},\n    year      = {2020},", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e8f", "disabled": false, "gated": false, "likes": 34, "downloads": 3983, "paperswithcode_id": "kilt", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kilt_wikipedia", "sha": "bef96d2843c139b9fc7e41a67cdd273bc46cb452", "lastModified": "2023-04-05T10:08:59.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "KILT-Wikipedia: Wikipedia pre-processed for KILT.", "citation": "@inproceedings{fb_kilt,\n    author    = {Fabio Petroni and\n                 Aleksandra Piktus and\n                 Angela Fan and\n                 Patrick Lewis and\n                 Majid Yazdani and\n                 Nicola De Cao and\n                 James Thorne and\n                 Yacine Jernite and\n                 Vassilis Plachouras and\n                 Tim Rockt\\\"aschel and\n                 Sebastian Riedel},\n    title     = {{KILT:} a {B}enchmark for {K}nowledge {I}ntensive {L}anguage {T}asks},\n    journal   = {CoRR},\n    archivePrefix = {arXiv},\n    year      = {2020},", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e90", "disabled": false, "gated": false, "likes": 10, "downloads": 412, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kinnews_kirnews", "sha": "baedeea93650336565fc4045b9d2f77a40404321", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:rn", "language:rw", "license:mit", "arxiv:2010.12174", "region:us"], "private": false, "author": null, "description": "Kinyarwanda and Kirundi news classification datasets", "citation": "@article{niyongabo2020kinnews,\n  title={KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi},\n  author={Niyongabo, Rubungo Andre and Qu, Hong and Kreutzer, Julia and Huang, Li},\n  journal={arXiv preprint arXiv:2010.12174},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e91", "disabled": false, "gated": false, "likes": 1, "downloads": 812, "paperswithcode_id": "kinnews-and-kirnews", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "klue", "sha": "750599ffad2ab30bb45502714a1bd37d0d7f1cec", "lastModified": "2023-06-01T14:59:57.000Z", "tags": ["task_categories:fill-mask", "task_categories:question-answering", "task_categories:text-classification", "task_categories:text-generation", "task_categories:token-classification", "task_ids:extractive-qa", "task_ids:named-entity-recognition", "task_ids:natural-language-inference", "task_ids:parsing", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "license:cc-by-sa-4.0", "relation-extraction", "arxiv:2105.09680", "region:us"], "private": false, "author": null, "description": "KLUE (Korean Language Understanding Evaluation)\nKorean Language Understanding Evaluation (KLUE) benchmark is a series of datasets to evaluate natural language\nunderstanding capability of Korean language models. KLUE consists of 8 diverse and representative tasks, which are accessible\nto anyone without any restrictions. With ethical considerations in mind, we deliberately design annotation guidelines to obtain\nunambiguous annotations for all datasets. Futhermore, we build an evaluation system and carefully choose evaluations metrics\nfor every task, thus establishing fair comparison across Korean language models.", "citation": "@misc{park2021klue,\n      title={KLUE: Korean Language Understanding Evaluation},\n      author={Sungjoon Park and Jihyung Moon and Sungdong Kim and Won Ik Cho and Jiyoon Han and Jangwon Park and Chisung Song and Junseong Kim and Yongsook Song and Taehwan Oh and Joohong Lee and Juhyun Oh and Sungwon Lyu and Younghoon Jeong and Inkwon Lee and Sangwoo Seo and Dongjun Lee and Hyunwoo Kim and Myeonghwa Lee and Seongbo Jang and Seungwon Do and Sunkyoung Kim and Kyungtae Lim and Jongwon Lee and Kyumin Park and Jamin Shin and Seonghyun Kim and Lucy Park and Alice Oh and Jungwoo Ha and Kyunghyun Cho},\n      year={2021},\n      eprint={2105.09680},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e92", "disabled": false, "gated": false, "likes": 28, "downloads": 7079, "paperswithcode_id": "klue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_3i4k", "sha": "3078568f1fc9b28253e9ea229caefd3948f0eef8", "lastModified": "2023-01-25T14:33:43.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "license:cc-by-4.0", "arxiv:1811.04231", "region:us"], "private": false, "author": null, "description": "This dataset is designed to identify speaker intention based on real-life spoken utterance in Korean into one of\n7 categories: fragment, description, question, command, rhetorical question, rhetorical command, utterances.", "citation": "@article{cho2018speech,\n    title={Speech Intention Understanding in a Head-final Language: A Disambiguation Utilizing Intonation-dependency},\n    author={Cho, Won Ik and Lee, Hyeon Seung and Yoon, Ji Won and Kim, Seok Min and Kim, Nam Soo},\n    journal={arXiv preprint arXiv:1811.04231},\n    year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e93", "disabled": false, "gated": false, "likes": 1, "downloads": 308, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_hate", "sha": "fd5bc3e9935b937473663ec0f6c1620fab5bac05", "lastModified": "2023-01-25T14:33:47.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ko", "license:cc-by-sa-4.0", "arxiv:2005.12503", "region:us"], "private": false, "author": null, "description": "Human-annotated Korean corpus collected from a popular domestic entertainment news aggregation platform\nfor toxic speech detection. Comments are annotated for gender bias, social bias and hate speech.", "citation": "@inproceedings{moon-etal-2020-beep,\n    title = \"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\",\n    author = \"Moon, Jihyung  and\n      Cho, Won Ik  and\n      Lee, Junbum\",\n    booktitle = \"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.socialnlp-1.4\",\n    pages = \"25--31\",\n    abstract = \"Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff{'}s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e94", "disabled": false, "gated": false, "likes": 4, "downloads": 366, "paperswithcode_id": "korean-hatespeech-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_ner", "sha": "7f7131d4a6faaa2a74a5263cb400bd80f4d279b0", "lastModified": "2023-01-25T14:33:50.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ko", "license:mit", "region:us"], "private": false, "author": null, "description": "Korean named entity recognition dataset", "citation": "@InProceedings{Kim:2016,\n  title     = \"Korean Named Entity Recognition Dataset\",\n  authors   = \"Jae-Hoon Kim\",\n  publisher = \"GitHub\",\n  year      = \"2016\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e95", "disabled": false, "gated": false, "likes": 3, "downloads": 325, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_nli", "sha": "36c1d37d5fb92c3736e73e2b9140ae9d8136e0fe", "lastModified": "2023-04-05T10:09:06.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|multi_nli", "source_datasets:extended|snli", "source_datasets:extended|xnli", "language:ko", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "Korean Natural  Language Inference datasets", "citation": "@article{ham2020kornli,\n  title={KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding},\n  author={Ham, Jiyeon and Choe, Yo Joong and Park, Kyubyong and Choi, Ilji and Soh, Hyungjoon},\n  journal={arXiv preprint arXiv:2004.03289},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e96", "disabled": false, "gated": false, "likes": 5, "downloads": 656, "paperswithcode_id": "kornli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_nlu", "sha": "c012d1feb358e39bea4fb6fa4bc35c8b85c543bf", "lastModified": "2023-01-25T14:33:57.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:found", "language_creators:expert-generated", "language_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|snli", "language:ko", "license:cc-by-sa-4.0", "arxiv:2004.03289", "region:us"], "private": false, "author": null, "description": "    The dataset contains data for bechmarking korean models on NLI and STS", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e97", "disabled": false, "gated": false, "likes": 1, "downloads": 630, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_qpair", "sha": "169a77df7fbb36568c2dba92680b185d1caa01b0", "lastModified": "2023-01-25T14:34:00.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ko", "license:mit", "region:us"], "private": false, "author": null, "description": "This is a Korean paired question dataset containing labels indicating whether two questions in a given pair are semantically identical. This dataset was used to evaluate the performance of [KoGPT2](https://github.com/SKT-AI/KoGPT2#subtask-evaluations) on a phrase detection downstream task.", "citation": "@misc{Song:2018,\n  title     = \"Paired Question v.2\",\n  authors   = \"Youngsook Song\",\n  publisher = \"GitHub\",\n  year      = \"2018\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e98", "disabled": false, "gated": false, "likes": 2, "downloads": 315, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_sae", "sha": "33690551757da7b84e5344db2046e218d5d08456", "lastModified": "2023-01-25T14:34:03.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "license:cc-by-sa-4.0", "arxiv:1912.00342", "arxiv:1811.04231", "region:us"], "private": false, "author": null, "description": "This new dataset is designed to extract intent from non-canonical directives which will help dialog managers\nextract intent from user dialog that may have no clear objective or are paraphrased forms of utterances.", "citation": "@article{cho2019machines,\n  title={Machines Getting with the Program: Understanding Intent Arguments of Non-Canonical Directives},\n  author={Cho, Won Ik and Moon, Young Ki and Moon, Sangwhan and Kim, Seok Min and Kim, Nam Soo},\n  journal={arXiv preprint arXiv:1912.00342},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e99", "disabled": false, "gated": false, "likes": 3, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kor_sarcasm", "sha": "9d23b3177596fd6d014a7b41d554923abff63c35", "lastModified": "2023-03-21T14:49:40.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ko", "license:mit", "sarcasm-detection", "region:us"], "private": false, "author": null, "description": "This is a dataset designed to detect sarcasm in Korean because it distorts the literal meaning of a sentence\nand is highly related to sentiment classification.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9a", "disabled": false, "gated": false, "likes": 2, "downloads": 329, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "labr", "sha": "c2945215917203defb7c71a9f8d2fdb25bed1ae2", "lastModified": "2023-01-25T14:34:10.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset contains over 63,000 book reviews in Arabic.It is the largest sentiment analysis dataset for Arabic to-date.The book reviews were harvested from the website Goodreads during the month or March 2013.Each book review comes with the goodreads review id, the user id, the book id, the rating (1 to 5) and the text of the review.", "citation": "@inproceedings{aly2013labr,\n  title={Labr: A large scale arabic book reviews dataset},\n  author={Aly, Mohamed and Atiya, Amir},\n  booktitle={Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},\n  pages={494--498},\n  year={2013}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9b", "disabled": false, "gated": false, "likes": 0, "downloads": 343, "paperswithcode_id": "labr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lama", "sha": "3c4ed3a8906fd15577bc8c0afbe615f16a2d247d", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:text-retrieval", "task_categories:text-classification", "task_ids:fact-checking-retrieval", "task_ids:text-scoring", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:extended|conceptnet5", "source_datasets:extended|squad", "language:en", "license:cc-by-4.0", "probing", "region:us"], "private": false, "author": null, "description": "LAMA is a dataset used to probe and analyze the factual and commonsense knowledge contained in pretrained language models. See https://github.com/facebookresearch/LAMA.", "citation": "@inproceedings{petroni2019language,\r\n  title={Language Models as Knowledge Bases?},\r\n  author={F. Petroni, T. Rockt{\\\"{a}}schel, A. H. Miller, P. Lewis, A. Bakhtin, Y. Wu and S. Riedel},\r\n  booktitle={In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2019},\r\n  year={2019}\r\n}\r\n@inproceedings{petroni2020how,\r\n  title={How Context Affects Language Models' Factual Predictions},\r\n  author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rockt{\\\"a}schel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},\r\n  booktitle={Automated Knowledge Base Construction},\r\n  year={2020},\r\n  url={https://openreview.net/forum?id=025X0zPfn}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9c", "disabled": false, "gated": false, "likes": 11, "downloads": 2652, "paperswithcode_id": "lama", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lambada", "sha": "8d50a2b0b4dec16c5f9b12f40f3b07acca14e242", "lastModified": "2023-06-13T09:14:12.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|bookcorpus", "language:en", "license:cc-by-4.0", "long-range-dependency", "region:us"], "private": false, "author": null, "description": "The LAMBADA evaluates the capabilities of computational models\nfor text understanding by means of a word prediction task.\nLAMBADA is a collection of narrative passages sharing the characteristic\nthat human subjects are able to guess their last word if\nthey are exposed to the whole passage, but not if they\nonly see the last sentence preceding the target word.\nTo succeed on LAMBADA, computational models cannot\nsimply rely on local context, but must be able to\nkeep track of information in the broader discourse.\n\nThe LAMBADA dataset is extracted from BookCorpus and\nconsists of 10'022 passages, divided into 4'869 development\nand 5'153 test passages. The training data for language\nmodels to be tested on LAMBADA include the full text\nof 2'662 novels (disjoint from those in dev+test),\ncomprising 203 million words.", "citation": "@InProceedings{paperno-EtAl:2016:P16-1,\n  author    = {Paperno, Denis  and  Kruszewski, Germ\\'{a}n  and  Lazaridou,\nAngeliki  and  Pham, Ngoc Quan  and  Bernardi, Raffaella  and  Pezzelle,\nSandro  and  Baroni, Marco  and  Boleda, Gemma  and  Fernandez, Raquel},\n  title     = {The {LAMBADA} dataset: Word prediction requiring a broad\ndiscourse context},\n  booktitle = {Proceedings of the 54th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers)},\n  month     = {August},\n  year      = {2016},\n  address   = {Berlin, Germany},\n  publisher = {Association for Computational Linguistics},\n  pages     = {1525--1534},\n  url       = {http://www.aclweb.org/anthology/P16-1144}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9d", "disabled": false, "gated": false, "likes": 34, "downloads": 52077, "paperswithcode_id": "lambada", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "large_spanish_corpus", "sha": "b140e17cb4a8f2721083f7e6517c24441e67662a", "lastModified": "2023-06-07T21:20:55.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:100M<n<1B", "size_categories:10K<n<100K", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:es", "license:mit", "region:us"], "private": false, "author": null, "description": "The Large Spanish Corpus is a compilation of 15 unlabelled Spanish corpora spanning Wikipedia to European parliament notes. Each config contains the data corresponding to a different corpus. For example, \"all_wiki\" only includes examples from Spanish Wikipedia. By default, the config is set to \"combined\" which loads all the corpora; with this setting you can also specify the number of samples to return per corpus by configuring the \"split\" argument.", "citation": "@dataset{jose_canete_2019_3247731,\n  author       = {Jos\u00e9 Ca\u00f1ete},\n  title        = {Compilation of Large Spanish Unannotated Corpora},\n  month        = may,\n  year         = 2019,\n  publisher    = {Zenodo},\n  doi          = {10.5281/zenodo.3247731},\n  url          = {https://doi.org/10.5281/zenodo.3247731}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9e", "disabled": false, "gated": false, "likes": 16, "downloads": 3014, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "laroseda", "sha": "88161991b1ae20695848f4473871a2ba92c6a3a5", "lastModified": "2022-11-18T20:18:11.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ro", "license:cc-by-4.0", "arxiv:2101.04197", "arxiv:1901.06543", "region:us"], "private": false, "author": null, "description": "        LaRoSeDa (A Large Romanian Sentiment Data Set) contains 15,000 reviews written in Romanian, of which 7,500 are positive and 7,500 negative.\n        Star ratings of 1 and 2 and of 4 and 5 are provided for negative and positive reviews respectively.\n        The current dataset uses star rating as the label for multi-class classification.", "citation": "@article{\n    tache2101clustering,\n    title={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa -- A Large Romanian Sentiment Data Set},\n    author={Anca Maria Tache and Mihaela Gaman and Radu Tudor Ionescu},\n    journal={ArXiv},\n    year = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181e9f", "disabled": false, "gated": false, "likes": 0, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lc_quad", "sha": "4f638d3d82c417b88bd0ff53eacaef5f966d6d02", "lastModified": "2023-04-05T10:09:15.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-3.0", "knowledge-base-qa", "region:us"], "private": false, "author": null, "description": "LC-QuAD 2.0 is a Large Question Answering dataset with 30,000 pairs of question and its corresponding SPARQL query. The target knowledge base is Wikidata and DBpedia, specifically the 2018 version. Please see our paper for details about the dataset creation process and framework.", "citation": "@inproceedings{dubey2017lc2,\ntitle={LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and DBpedia},\nauthor={Dubey, Mohnish and Banerjee, Debayan and Abdelkawi, Abdelrahman and Lehmann, Jens},\nbooktitle={Proceedings of the 18th International Semantic Web Conference (ISWC)},\nyear={2019},\norganization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea0", "disabled": false, "gated": false, "likes": 6, "downloads": 325, "paperswithcode_id": "lc-quad-2-0", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lener_br", "sha": "2a0446e5ef27fb5b7f8b6073146747844c979205", "lastModified": "2023-09-25T07:35:39.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pt", "license:unknown", "legal", "region:us"], "private": false, "author": null, "description": "LeNER-Br is a Portuguese language dataset for named entity recognition\napplied to legal documents. LeNER-Br consists entirely of manually annotated\nlegislation and legal cases texts and contains tags for persons, locations,\ntime entities, organizations, legislation and legal cases.\nTo compose the dataset, 66 legal documents from several Brazilian Courts were\ncollected. Courts of superior and state levels were considered, such as Supremo\nTribunal Federal, Superior Tribunal de Justi\u00e7a, Tribunal de Justi\u00e7a de Minas\nGerais and Tribunal de Contas da Uni\u00e3o. In addition, four legislation documents\nwere collected, such as \"Lei Maria da Penha\", giving a total of 70 documents", "citation": "@inproceedings{luz_etal_propor2018,\n    author = {Pedro H. {Luz de Araujo} and Te\\'{o}filo E. {de Campos} and\n    Renato R. R. {de Oliveira} and Matheus Stauffer and\n    Samuel Couto and Paulo Bermejo},\n    title = {{LeNER-Br}: a Dataset for Named Entity Recognition in {Brazilian} Legal Text},\n    booktitle = {International Conference on the Computational Processing of Portuguese ({PROPOR})},\n    publisher = {Springer},\n    series = {Lecture Notes on Computer Science ({LNCS})},\n    pages = {313--323},\n    year = {2018},\n    month = {September 24-26},\n    address = {Canela, RS, Brazil},\n    doi = {10.1007/978-3-319-99722-3_32},\n    url = {https://cic.unb.br/~teodecampos/LeNER-Br/},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea1", "disabled": false, "gated": false, "likes": 22, "downloads": 383, "paperswithcode_id": "lener-br", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lex_glue", "sha": "ffaa9c42d045272139621689b58081b040d8a5a7", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:question-answering", "task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:multiple-choice-qa", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended", "language:en", "license:cc-by-4.0", "arxiv:2110.00976", "arxiv:2109.00904", "arxiv:1805.01217", "arxiv:2104.08671", "region:us"], "private": false, "author": null, "description": "Legal General Language Understanding Evaluation (LexGLUE) benchmark is\na collection of datasets for evaluating model performance across a diverse set of legal NLU tasks", "citation": "@article{chalkidis-etal-2021-lexglue,\n      title={{LexGLUE}: A Benchmark Dataset for Legal Language Understanding in English},\n      author={Chalkidis, Ilias and\n      Jana, Abhik and\n      Hartung, Dirk and\n      Bommarito, Michael and\n      Androutsopoulos, Ion and\n      Katz, Daniel Martin and\n      Aletras, Nikolaos},\n      year={2021},\n      eprint={2110.00976},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      note = {arXiv: 2110.00976},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea2", "disabled": false, "gated": false, "likes": 33, "downloads": 17702, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "liar", "sha": "247e49faa3487975089eeeab017f2cf431c459ea", "lastModified": "2023-01-25T14:34:21.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "fake-news-detection", "arxiv:1705.00648", "region:us"], "private": false, "author": null, "description": "LIAR is a dataset for fake news detection with 12.8K human labeled short statements from politifact.com's API, and each statement is evaluated by a politifact.com editor for its truthfulness. The distribution of labels in the LIAR dataset is relatively well-balanced: except for 1,050 pants-fire cases, the instances for all other labels range from 2,063 to 2,638. In each case, the labeler provides a lengthy analysis report to ground each judgment.", "citation": "@inproceedings{wang-2017-liar,\ntitle = \"{``}Liar, Liar Pants on Fire{''}: A New Benchmark Dataset for Fake News Detection\",\nauthor = \"Wang, William Yang\",\nbooktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\nmonth = jul,\nyear = \"2017\",\naddress = \"Vancouver, Canada\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://www.aclweb.org/anthology/P17-2067\",\ndoi = \"10.18653/v1/P17-2067\",\npages = \"422--426\",\nabstract = \"Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea3", "disabled": false, "gated": false, "likes": 8, "downloads": 1140, "paperswithcode_id": "liar", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "librispeech_asr", "sha": "5fdb18cee9f2d47ae8d48b1d6b5d888b610a8c3a", "lastModified": "2022-11-18T20:18:42.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_ids:speaker-identification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.87", "citation": "@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea4", "disabled": false, "gated": false, "likes": 67, "downloads": 21682, "paperswithcode_id": "librispeech-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "librispeech_lm", "sha": "79b46c1e3976de62f57339ac3b61db82005c695e", "lastModified": "2023-04-05T10:09:21.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Language modeling resources to be used in conjunction with the LibriSpeech ASR corpus.", "citation": "@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea5", "disabled": false, "gated": false, "likes": 0, "downloads": 306, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "limit", "sha": "237574fd5bb4eb03afa725f0fdf7afb5b9af1a4b", "lastModified": "2022-11-18T20:18:52.000Z", "tags": ["task_categories:token-classification", "task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|net-activities-captions", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. Literal-Motion-in-Text (LiMiT) dataset, is a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion.", "citation": "@inproceedings{manotas-etal-2020-limit,\n    title = \"{L}i{M}i{T}: The Literal Motion in Text Dataset\",\n    author = \"Manotas, Irene  and\n      Vo, Ngoc Phuoc An  and\n      Sheinin, Vadim\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.88\",\n    doi = \"10.18653/v1/2020.findings-emnlp.88\",\n    pages = \"991--1000\",\n    abstract = \"Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. We present the Literal-Motion-in-Text (LiMiT) dataset, a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion. We describe the annotation process for the dataset, analyze its scale and diversity, and report results of several baseline models. We also present future research directions and applications of the LiMiT dataset and share it publicly as a new resource for the research community.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea6", "disabled": false, "gated": false, "likes": 3, "downloads": 392, "paperswithcode_id": "limit", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lince", "sha": "2ad124d8092fe467591673b2b2ccb3163e7c1d17", "lastModified": "2023-04-05T10:09:24.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "LinCE is a centralized Linguistic Code-switching Evaluation benchmark\n(https://ritual.uh.edu/lince/) that contains data for training and evaluating\nNLP systems on code-switching tasks.", "citation": "@inproceedings{aguilar-etal-2020-lince,\n    title = \"{L}in{CE}: A Centralized Benchmark for Linguistic Code-switching Evaluation\",\n    author = \"Aguilar, Gustavo  and\n      Kar, Sudipta  and\n      Solorio, Thamar\",\n    booktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.223\",\n    pages = \"1803--1813\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}\n\nNote that each LinCE dataset has its own citation. Please see the source to see\nthe correct citation for each contained dataset.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea7", "disabled": false, "gated": false, "likes": 5, "downloads": 1944, "paperswithcode_id": "lince", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "linnaeus", "sha": "0f7960610ecb15ddb6a2c4811d1e230379c31c6e", "lastModified": "2023-06-15T14:40:39.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "A novel corpus of full-text documents manually annotated for species mentions.", "citation": "@article{gerner2010linnaeus,\n         title={LINNAEUS: a species name identification system for biomedical literature},\n         author={Gerner, Martin and Nenadic, Goran and Bergman, Casey M},\n         journal={BMC bioinformatics},\n         volume={11},\n         number={1},\n         pages={85},\n         year={2010},\n         publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea8", "disabled": false, "gated": false, "likes": 1, "downloads": 305, "paperswithcode_id": "linnaeus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "liveqa", "sha": "0a266e868920e5043c16b24eb1a1e996cc2244b8", "lastModified": "2022-11-03T16:15:28.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is LiveQA, a Chinese dataset constructed from play-by-play live broadcast.\nIt contains 117k multiple-choice questions written by human commentators for over 1,670 NBA games,\nwhich are collected from the Chinese Hupu website.", "citation": "@inproceedings{qianying-etal-2020-liveqa,\n    title = \"{L}ive{QA}: A Question Answering Dataset over Sports Live\",\n    author = \"Qianying, Liu  and\n      Sicong, Jiang  and\n      Yizhong, Wang  and\n      Sujian, Li\",\n    booktitle = \"Proceedings of the 19th Chinese National Conference on Computational Linguistics\",\n    month = oct,\n    year = \"2020\",\n    address = \"Haikou, China\",\n    publisher = \"Chinese Information Processing Society of China\",\n    url = \"https://www.aclweb.org/anthology/2020.ccl-1.98\",\n    pages = \"1057--1067\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ea9", "disabled": false, "gated": false, "likes": 1, "downloads": 345, "paperswithcode_id": "liveqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lj_speech", "sha": "10346be3b2604225c35f26f4c1b472ff6ded5f4b", "lastModified": "2023-11-23T14:05:45.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "task_categories:text-to-audio", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unlicense", "region:us"], "private": false, "author": null, "description": "This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading\npassages from 7 non-fiction books in English. A transcription is provided for each clip. Clips vary in length\nfrom 1 to 10 seconds and have a total length of approximately 24 hours.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@misc{ljspeech17,\n  author       = {Keith Ito and Linda Johnson},\n  title        = {The LJ Speech Dataset},\n  howpublished = {\\\\url{https://keithito.com/LJ-Speech-Dataset/}},\n  year         = 2017\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eaa", "disabled": false, "gated": false, "likes": 10, "downloads": 1116, "paperswithcode_id": "ljspeech", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lm1b", "sha": "48f837c9d9f44909b80b8dd5a47e2fa458615561", "lastModified": "2023-06-27T15:36:19.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "language:en", "arxiv:1312.3005", "region:us"], "private": false, "author": null, "description": "A benchmark corpus to be used for measuring progress in statistical language modeling. This has almost one billion words in the training data.", "citation": "@article{DBLP:journals/corr/ChelbaMSGBK13,\n  author    = {Ciprian Chelba and\n               Tomas Mikolov and\n               Mike Schuster and\n               Qi Ge and\n               Thorsten Brants and\n               Phillipp Koehn},\n  title     = {One Billion Word Benchmark for Measuring Progress in Statistical Language\n               Modeling},\n  journal   = {CoRR},\n  volume    = {abs/1312.3005},\n  year      = {2013},\n  url       = {http://arxiv.org/abs/1312.3005},\n  archivePrefix = {arXiv},\n  eprint    = {1312.3005},\n  timestamp = {Mon, 13 Aug 2018 16:46:16 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/ChelbaMSGBK13},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eab", "disabled": false, "gated": false, "likes": 8, "downloads": 1029, "paperswithcode_id": "billion-word-benchmark", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lst20", "sha": "52ec3db69b3376680976d8ae5d90c803beb042aa", "lastModified": "2023-01-25T14:34:28.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:th", "license:other", "word-segmentation", "clause-segmentation", "sentence-segmentation", "region:us"], "private": false, "author": null, "description": "LST20 Corpus is a dataset for Thai language processing developed by National Electronics and Computer Technology Center (NECTEC), Thailand.\nIt offers five layers of linguistic annotation: word boundaries, POS tagging, named entities, clause boundaries, and sentence boundaries.\nAt a large scale, it consists of 3,164,002 words, 288,020 named entities, 248,181 clauses, and 74,180 sentences, while it is annotated with\n16 distinct POS tags. All 3,745 documents are also annotated with one of 15 news genres. Regarding its sheer size, this dataset is\nconsidered large enough for developing joint neural models for NLP.\nManually download at https://aiforthai.in.th/corpus.php", "citation": "@article{boonkwan2020annotation,\n  title={The Annotation Guideline of LST20 Corpus},\n  author={Boonkwan, Prachya and Luantangsrisuk, Vorapon and Phaholphinyo, Sitthaa and Kriengket, Kanyanat and Leenoi, Dhanon and Phrombut, Charun and Boriboon, Monthika and Kosawat, Krit and Supnithi, Thepchai},\n  journal={arXiv preprint arXiv:2008.05055},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eac", "disabled": false, "gated": false, "likes": 2, "downloads": 424, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "m_lama", "sha": "a55b2300263c90f58ef28ba31c771979574b8c60", "lastModified": "2022-11-03T16:15:15.000Z", "tags": ["task_categories:question-answering", "task_categories:text-classification", "task_ids:open-domain-qa", "task_ids:text-scoring", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:extended|lama", "language:af", "language:ar", "language:az", "language:be", "language:bg", "language:bn", "language:ca", "language:ceb", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:ga", "language:gl", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:it", "language:ja", "language:ka", "language:ko", "language:la", "language:lt", "language:lv", "language:ms", "language:nl", "language:pl", "language:pt", "language:ro", "language:ru", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:ta", "language:th", "language:tr", "language:uk", "language:ur", "language:vi", "language:zh", "license:cc-by-nc-sa-4.0", "probing", "arxiv:2102.00894", "region:us"], "private": false, "author": null, "description": "mLAMA: a multilingual version of the LAMA benchmark (T-REx and GoogleRE) covering 53 languages.", "citation": "@article{kassner2021multilingual,\n  author    = {Nora Kassner and\n               Philipp Dufter and\n               Hinrich Sch{\\\"{u}}tze},\n  title     = {Multilingual {LAMA:} Investigating Knowledge in Multilingual Pretrained\n               Language Models},\n  journal   = {CoRR},\n  volume    = {abs/2102.00894},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2102.00894},\n  archivePrefix = {arXiv},\n  eprint    = {2102.00894},\n  timestamp = {Tue, 09 Feb 2021 13:35:56 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-00894.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org},\n  note      = {to appear in EACL2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ead", "disabled": false, "gated": false, "likes": 4, "downloads": 303, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mac_morpho", "sha": "1c658f53a51ab88cb1f792400e8ff3e1ded5055b", "lastModified": "2023-01-25T14:34:31.000Z", "tags": ["task_categories:token-classification", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pt", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Mac-Morpho is a corpus of Brazilian Portuguese texts annotated with part-of-speech tags.\nIts first version was released in 2003 [1], and since then, two revisions have been made in order\nto improve the quality of the resource [2, 3].\nThe corpus is available for download split into train, development and test sections.\nThese are 76%, 4% and 20% of the corpus total, respectively (the reason for the unusual numbers\nis that the corpus was first split into 80%/20% train/test, and then 5% of the train section was\nset aside for development). This split was used in [3], and new POS tagging research with Mac-Morpho\nis encouraged to follow it in order to make consistent comparisons possible.\n\n\n[1] Alu\u00edsio, S., Pelizzoni, J., Marchi, A.R., de Oliveira, L., Manenti, R., Marquiaf\u00e1vel, V. 2003.\nAn account of the challenge of tagging a reference corpus for brazilian portuguese.\nIn: Proceedings of the 6th International Conference on Computational Processing of the Portuguese Language. PROPOR 2003\n\n[2] Fonseca, E.R., Rosa, J.L.G. 2013. Mac-morpho revisited: Towards robust part-of-speech.\nIn: Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology \u2013 STIL\n\n[3] Fonseca, E.R., Alu\u00edsio, Sandra Maria, Rosa, J.L.G. 2015.\nEvaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese.\nJournal of the Brazilian Computer Society.", "citation": "@article{fonseca2015evaluating,\n  title={Evaluating word embeddings and a revised corpus for part-of-speech tagging in Portuguese},\n  author={Fonseca, Erick R and Rosa, Joao Luis G and Aluisio, Sandra Maria},\n  journal={Journal of the Brazilian Computer Society},\n  volume={21},\n  number={1},\n  pages={2},\n  year={2015},\n  publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eae", "disabled": false, "gated": false, "likes": 4, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "makhzan", "sha": "768c5a742b597d6c5d41f69e4302acb9544148aa", "lastModified": "2022-11-03T16:07:47.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ur", "license:other", "region:us"], "private": false, "author": null, "description": "An Urdu text corpus for machine learning, natural language processing and linguistic analysis.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eaf", "disabled": false, "gated": false, "likes": 0, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "masakhaner", "sha": "9768b1011d4117666cde83e95a4b6057cc1ddff2", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:am", "language:ha", "language:ig", "language:lg", "language:luo", "language:pcm", "language:rw", "language:sw", "language:wo", "language:yo", "license:unknown", "arxiv:2103.11811", "region:us"], "private": false, "author": null, "description": "MasakhaNER is the first large publicly available high-quality dataset for named entity recognition (NER) in ten African languages.\n\nNamed entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n\nExample:\n[PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\nMasakhaNER is a named entity dataset consisting of PER, ORG, LOC, and DATE entities annotated by Masakhane for ten African languages:\n- Amharic\n- Hausa\n- Igbo\n- Kinyarwanda\n- Luganda\n- Luo\n- Nigerian-Pidgin\n- Swahili\n- Wolof\n- Yoruba\n\nThe train/validation/test sets are available for all the ten languages.\n\nFor more details see https://arxiv.org/abs/2103.11811", "citation": "@article{Adelani2021MasakhaNERNE,\n  title={MasakhaNER: Named Entity Recognition for African Languages},\n  author={D. Adelani and Jade Abbott and Graham Neubig and Daniel D'Souza and Julia Kreutzer and Constantine Lignos\n  and Chester Palen-Michel and Happy Buzaaba and Shruti Rijhwani and Sebastian Ruder and Stephen Mayhew and\n  Israel Abebe Azime and S. Muhammad and Chris C. Emezue and Joyce Nakatumba-Nabende and Perez Ogayo and\n  Anuoluwapo Aremu and Catherine Gitau and Derguene Mbaye and J. Alabi and Seid Muhie Yimam and Tajuddeen R. Gwadabe and\n  Ignatius Ezeani and Rubungo Andre Niyongabo and Jonathan Mukiibi and V. Otiende and Iroro Orife and Davis David and\n  Samba Ngom and Tosin P. Adewumi and Paul Rayson and Mofetoluwa Adeyemi and Gerald Muriuki and Emmanuel Anebi and\n  C. Chukwuneke and N. Odu and Eric Peter Wairagala and S. Oyerinde and Clemencia Siro and Tobius Saul Bateesa and\n  Temilola Oloyede and Yvonne Wambui and Victor Akinode and Deborah Nabagereka and Maurice Katusiime and\n  Ayodele Awokoya and Mouhamadane Mboup and D. Gebreyohannes and Henok Tilaye and Kelechi Nwaike and Degaga Wolde and\n   Abdoulaye Faye and Blessing Sibanda and Orevaoghene Ahia and Bonaventure F. P. Dossou and Kelechi Ogueji and\n   Thierno Ibrahima Diop and A. Diallo and Adewale Akinfaderin and T. Marengereke and Salomey Osei},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2103.11811}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb0", "disabled": false, "gated": false, "likes": 4, "downloads": 2048, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "math_dataset", "sha": "4212f9acc0739f73fc8e96cd7a64f6184bd7222c", "lastModified": "2023-04-05T10:09:32.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "Mathematics database.\n\nThis dataset code generates mathematical question and answer pairs,\nfrom a range of question types at roughly school-level difficulty.\nThis is designed to test the mathematical learning and algebraic\nreasoning skills of learning models.\n\nOriginal paper: Analysing Mathematical Reasoning Abilities of Neural Models\n(Saxton, Grefenstette, Hill, Kohli).\n\nExample usage:\ntrain_examples, val_examples = datasets.load_dataset(\n    'math_dataset/arithmetic__mul',\n    split=['train', 'test'],\n    as_supervised=True)", "citation": "@article{2019arXiv,\n  author = {Saxton, Grefenstette, Hill, Kohli},\n  title = {Analysing Mathematical Reasoning Abilities of Neural Models},\n  year = {2019},\n  journal = {arXiv:1904.01557}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb1", "disabled": false, "gated": false, "likes": 49, "downloads": 15813, "paperswithcode_id": "mathematics", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "math_qa", "sha": "24883f18f9191b322354520514b9492c48dcf35e", "lastModified": "2023-04-05T10:09:35.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|aqua_rat", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "Our dataset is gathered by using a new representation language to annotate over the AQuA-RAT dataset. AQuA-RAT has provided the questions, options, rationale, and the correct options.", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb2", "disabled": false, "gated": false, "likes": 47, "downloads": 31555, "paperswithcode_id": "mathqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "matinf", "sha": "4fdf0ce9b8532aeb7da184bcf65210ca65caafae", "lastModified": "2023-04-05T10:09:38.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "MATINF is the first jointly labeled large-scale dataset for classification, question answering and summarization.\n MATINF contains 1.07 million question-answer pairs with human-labeled categories and user-generated question\n descriptions. Based on such rich information, MATINF is applicable for three major NLP tasks, including classification,\n question answering, and summarization. We benchmark existing methods and a novel multi-task baseline over MATINF to\n inspire further research. Our comprehensive comparison and experiments over MATINF and other datasets demonstrate the\n merits held by MATINF.", "citation": "@inproceedings{xu-etal-2020-matinf,\n    title = \"{MATINF}: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization\",\n    author = \"Xu, Canwen  and\n      Pei, Jiaxin  and\n      Wu, Hongtao  and\n      Liu, Yiyu  and\n      Li, Chenliang\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.330\",\n    pages = \"3586--3596\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb3", "disabled": false, "gated": false, "likes": 3, "downloads": 740, "paperswithcode_id": "matinf", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mbpp", "sha": "5a8a3b632e28582ab85087da984bef822e34e415", "lastModified": "2022-11-18T20:20:07.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-4.0", "code-generation", "arxiv:2108.07732", "region:us"], "private": false, "author": null, "description": "The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\nprogramming problems, designed to be solvable by entry level programmers, covering programming\nfundamentals, standard library functionality, and so on. Each problem consists of a task\ndescription, code solution and 3 automated test cases. The sanitized subset of the data has been\nhand-verified by the authors.", "citation": "@article{austin2021program,\n  title={Program Synthesis with Large Language Models},\n  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},\n  journal={arXiv preprint arXiv:2108.07732},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb4", "disabled": false, "gated": false, "likes": 56, "downloads": 12392, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mc4", "sha": "7a59adaeb35b9f744da81f2e56b727d8d5eeb935", "lastModified": "2022-10-28T16:36:33.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "size_categories:100M<n<1B", "size_categories:1B<n<10B", "source_datasets:original", "language:af", "language:am", "language:ar", "language:az", "language:be", "language:bg", "language:bn", "language:ca", "language:ceb", "language:co", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fil", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gu", "language:ha", "language:haw", "language:he", "language:hi", "language:hmn", "language:ht", "language:hu", "language:hy", "language:id", "language:ig", "language:is", "language:it", "language:iw", "language:ja", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lb", "language:lo", "language:lt", "language:lv", "language:mg", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:ne", "language:nl", "language:no", "language:ny", "language:pa", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:sd", "language:si", "language:sk", "language:sl", "language:sm", "language:sn", "language:so", "language:sq", "language:sr", "language:st", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:tg", "language:th", "language:tr", "language:uk", "language:und", "language:ur", "language:uz", "language:vi", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "license:odc-by", "arxiv:1910.10683", "region:us"], "private": false, "author": null, "description": "A colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb5", "disabled": false, "gated": false, "likes": 113, "downloads": 20390, "paperswithcode_id": "mc4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mc_taco", "sha": "396368c6ca9cccebe68149da06a7a343d71bcb14", "lastModified": "2023-01-25T14:40:09.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1909.03065", "region:us"], "private": false, "author": null, "description": "MC-TACO (Multiple Choice TemporAl COmmonsense) is a dataset of 13k question-answer\npairs that require temporal commonsense comprehension. A system receives a sentence\nproviding context information, a question designed to require temporal commonsense\nknowledge, and multiple candidate answers. More than one candidate answer can be plausible.\n\nThe task is framed as binary classification: givent he context, the question,\nand the candidate answer, the task is to determine whether the candidate\nanswer is plausible (\"yes\") or not (\"no\").", "citation": "@inproceedings{ZKNR19,\n    author = {Ben Zhou, Daniel Khashabi, Qiang Ning and Dan Roth},\n    title = {\u201cGoing on a vacation\u201d takes longer than \u201cGoing for a walk\u201d: A Study of Temporal Commonsense Understanding },\n    booktitle = {EMNLP},\n    year = {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb6", "disabled": false, "gated": false, "likes": 1, "downloads": 5467, "paperswithcode_id": "mc-taco", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "md_gender_bias", "sha": "06cf937c2538bbe6f10ca5ec4f1b8f7648323499", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "annotations_creators:found", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:extended|other-convai2", "source_datasets:extended|other-light", "source_datasets:extended|other-opensubtitles", "source_datasets:extended|other-yelp", "source_datasets:original", "language:en", "license:mit", "gender-bias", "arxiv:1811.00552", "region:us"], "private": false, "author": null, "description": "Machine learning models are trained to find patterns in data.\nNLP models can inadvertently learn socially undesirable patterns when training on gender biased text.\nIn this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions:\nbias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker.\nUsing this fine-grained framework, we automatically annotate eight large scale datasets with gender information.\nIn addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites.\nDistinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers.\nWe show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models,\ndetecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.", "citation": "@inproceedings{md_gender_bias,\n  author    = {Emily Dinan and\n               Angela Fan and\n               Ledell Wu and\n               Jason Weston and\n               Douwe Kiela and\n               Adina Williams},\n  editor    = {Bonnie Webber and\n               Trevor Cohn and\n               Yulan He and\n               Yang Liu},\n  title     = {Multi-Dimensional Gender Bias Classification},\n  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural\n               Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},\n  pages     = {314--331},\n  publisher = {Association for Computational Linguistics},\n  year      = {2020},\n  url       = {https://www.aclweb.org/anthology/2020.emnlp-main.23/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb7", "disabled": false, "gated": false, "likes": 14, "downloads": 1919, "paperswithcode_id": "md-gender", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mdd", "sha": "341a015ad13faff310433df8b02914f7faccb296", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-3.0", "arxiv:1511.06931", "region:us"], "private": false, "author": null, "description": "The Movie Dialog dataset (MDD) is designed to measure how well\nmodels can perform at goal and non-goal orientated dialog\ncentered around the topic of movies (question answering,\nrecommendation and discussion).", "citation": "@misc{dodge2016evaluating,\n      title={Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems},\n      author={Jesse Dodge and Andreea Gane and Xiang Zhang and Antoine Bordes and Sumit Chopra and Alexander Miller and Arthur Szlam and Jason Weston},\n      year={2016},\n      eprint={1511.06931},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb8", "disabled": false, "gated": false, "likes": 3, "downloads": 879, "paperswithcode_id": "mdd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "med_hop", "sha": "b1e85d4a355a6c021a84ac5ee21a75d7d83c277f", "lastModified": "2022-11-03T16:16:32.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "multi-hop", "arxiv:1710.06481", "region:us"], "private": false, "author": null, "description": "MedHop is based on research paper abstracts from PubMed, and the queries are about interactions between pairs of drugs. The correct answer has to be inferred by combining information from a chain of reactions of drugs and proteins.", "citation": "@misc{welbl2018constructing,\n      title={Constructing Datasets for Multi-hop Reading Comprehension Across Documents},\n      author={Johannes Welbl and Pontus Stenetorp and Sebastian Riedel},\n      year={2018},\n      eprint={1710.06481},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eb9", "disabled": false, "gated": false, "likes": 3, "downloads": 507, "paperswithcode_id": "medhop", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "medal", "sha": "1b7eb6a1b85ce9849238b5aaac70d1f97a9f04b5", "lastModified": "2023-06-13T12:39:11.000Z", "tags": ["task_categories:other", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:unknown", "disambiguation", "region:us"], "private": false, "author": null, "description": "A large medical text dataset (14Go) curated to 4Go for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. For example, DHF can be disambiguated to dihydrofolate, diastolic heart failure, dengue hemorragic fever or dihydroxyfumarate", "citation": "@inproceedings{wen-etal-2020-medal,\n    title = \"{M}e{DAL}: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining\",\n    author = \"Wen, Zhi  and\n      Lu, Xing Han  and\n      Reddy, Siva\",\n    booktitle = \"Proceedings of the 3rd Clinical Natural Language Processing Workshop\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.clinicalnlp-1.15\",\n    pages = \"130--135\",\n    abstract = \"One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eba", "disabled": false, "gated": false, "likes": 11, "downloads": 382, "paperswithcode_id": "medal", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "medical_dialog", "sha": "1c598b66d82a3ba91e1cd1214e91d0888b1474d8", "lastModified": "2023-09-18T09:07:35.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "annotations_creators:found", "language_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "language:zh", "license:unknown", "arxiv:2004.03329", "region:us"], "private": false, "author": null, "description": "The MedDialog dataset (English) contains conversations (in English) between doctors and patients.It has 0.26 million dialogues. The data is continuously growing and more dialogues will be added. The raw dialogues are from healthcaremagic.com and icliniq.com.\nAll copyrights of the data belong to healthcaremagic.com and icliniq.com.", "citation": "@article{chen2020meddiag,\n  title={MedDialog: a large-scale medical dialogue dataset},\n  author={Chen, Shu and Ju, Zeqian and Dong, Xiangyu and Fang, Hongchao and Wang, Sicheng and Yang, Yue and Zeng, Jiaqi and Zhang, Ruisi and Zhang, Ruoyu and Zhou, Meng and Zhu, Penghui and Xie, Pengtao},\n  journal={arXiv preprint arXiv:2004.03329},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ebb", "disabled": false, "gated": false, "likes": 81, "downloads": 1091, "paperswithcode_id": "meddialog", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "medical_questions_pairs", "sha": "fe509be5bbf2ed379452f7b4d81155baad4d0ebf", "lastModified": "2023-01-25T14:40:20.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "arxiv:2008.13546", "region:us"], "private": false, "author": null, "description": "This dataset consists of 3048 similar and dissimilar medical question pairs hand-generated and labeled by Curai's doctors.", "citation": "@misc{mccreery2020effective,\n      title={Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n      author={Clara H. McCreery and Namit Katariya and Anitha Kannan and Manish Chablani and Xavier Amatriain},\n      year={2020},\n      eprint={2008.13546},\n      archivePrefix={arXiv},\n      primaryClass={cs.IR}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ebc", "disabled": false, "gated": false, "likes": 32, "downloads": 5754, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "menyo20k_mt", "sha": "41b6f3863cbc639e9149ed5e313bc6ae36cde4d5", "lastModified": "2022-12-30T19:38:49.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:yo", "license:cc-by-nc-4.0", "arxiv:2103.08647", "region:us"], "private": false, "author": null, "description": "MENYO-20k is a multi-domain parallel dataset with texts obtained from news articles, ted talks, movie transcripts, radio transcripts, science and technology texts, and other short articles curated from the web and professional translators. The dataset has 20,100 parallel sentences split into 10,070 training sentences, 3,397 development sentences, and 6,633 test sentences (3,419 multi-domain, 1,714 news domain, and 1,500 ted talks speech transcript domain). The development and test sets are available upon request.", "citation": "@dataset{david_ifeoluwa_adelani_2020_4297448,\n  author       = {David Ifeoluwa Adelani and\n                  Jesujoba O. Alabi and\n                  Damilola Adebonojo and\n                  Adesina Ayeni and\n                  Mofe Adeyemi and\n                  Ayodele Awokoya},\n  title        = {MENYO-20k: A Multi-domain English - Yor\u00f9b\u00e1 Corpus\n                  for Machine Translation},\n  month        = nov,\n  year         = 2020,\n  publisher    = {Zenodo},\n  version      = {1.0},\n  doi          = {10.5281/zenodo.4297448},\n  url          = {https://doi.org/10.5281/zenodo.4297448}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ebd", "disabled": false, "gated": false, "likes": 1, "downloads": 291, "paperswithcode_id": "menyo-20k", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "meta_woz", "sha": "e76b5c6515506e1ae604620bad9a05eb33d03e96", "lastModified": "2022-11-18T21:28:56.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "arxiv:2003.01680", "region:us"], "private": false, "author": null, "description": "MetaLWOz: A Dataset of Multi-Domain Dialogues for the Fast Adaptation of Conversation Models. We introduce the Meta-Learning Wizard of Oz (MetaLWOz) dialogue dataset for developing fast adaptation methods for conversation models. This data can be used to train task-oriented dialogue models, specifically to develop methods to quickly simulate user responses with a small amount of data. Such fast-adaptation models fall into the research areas of transfer learning and meta learning. The dataset consists of 37,884 crowdsourced dialogues recorded between two human users in a Wizard of Oz setup, in which one was instructed to behave like a bot, and the other a true human user. The users are assigned a task belonging to a particular domain, for example booking a reservation at a particular restaurant, and work together to complete the task. Our dataset spans 47 domains having 227 tasks total. Dialogues are a minimum of 10 turns long.", "citation": "@InProceedings{shalyminov2020fast,\nauthor = {Shalyminov, Igor and Sordoni, Alessandro and Atkinson, Adam and Schulz, Hannes},\ntitle = {Fast Domain Adaptation For Goal-Oriented Dialogue Using A Hybrid Generative-Retrieval Transformer},\nbooktitle = {2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\nyear = {2020},\nmonth = {April},\nurl = {https://www.microsoft.com/en-us/research/publication/fast-domain-adaptation-for-goal-oriented-dialogue-using-a\n-hybrid-generative-retrieval-transformer/},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ebe", "disabled": false, "gated": false, "likes": 3, "downloads": 549, "paperswithcode_id": "metalwoz", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metooma", "sha": "b08925b3d56214d59194544f2a6e6225bd24fd02", "lastModified": "2023-01-25T14:40:24.000Z", "tags": ["task_categories:text-classification", "task_categories:text-retrieval", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "The dataset consists of tweets belonging to #MeToo movement on Twitter, labelled into different categories.\nDue to Twitter's development policies, we only provide the tweet ID's and corresponding labels,\nother data can be fetched via Twitter API.\nThe data has been labelled by experts, with the majority taken into the account for deciding the final label.\nWe provide these labels for each of the tweets. The labels provided for each data point\nincludes -- Relevance, Directed Hate, Generalized Hate,\nSarcasm, Allegation, Justification, Refutation, Support, Oppose", "citation": "@inproceedings{gautam2020metooma,\n    title={# MeTooMA: Multi-Aspect Annotations of Tweets Related to the MeToo Movement},\n    author={Gautam, Akash and Mathur, Puneet and Gosangi, Rakesh and Mahata, Debanjan and Sawhney, Ramit and Shah, Rajiv Ratn},\n    booktitle={Proceedings of the International AAAI Conference on Web and Social Media},\n    volume={14},\n    pages={209--216},\n    year={2020} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ebf", "disabled": false, "gated": false, "likes": 0, "downloads": 329, "paperswithcode_id": "metooma", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metrec", "sha": "80a09c0c63f516df35c4989fb361380a56bd174e", "lastModified": "2023-01-25T14:40:27.000Z", "tags": ["task_categories:text-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "license:unknown", "poetry-classification", "region:us"], "private": false, "author": null, "description": "Arabic Poetry Metric Classification.\nThe dataset contains the verses and their corresponding meter classes.Meter classes are represented as numbers from 0 to 13. The dataset can be highly useful for further research in order to improve the field of Arabic poems\u2019 meter classification.The train dataset contains 47,124 records and the test dataset contains 8316 records.", "citation": "@article{metrec2020,\n  title={MetRec: A dataset for meter classification of arabic poetry},\n  author={Al-shaibani, Maged S and Alyafeai, Zaid and Ahmad, Irfan},\n  journal={Data in Brief},\n  year={2020},\n  publisher={Elsevier}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec0", "disabled": false, "gated": false, "likes": 2, "downloads": 307, "paperswithcode_id": "metrec", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "miam", "sha": "c7cb89366381c01b307360a52aca8d234b5ebe1a", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:dialogue-modeling", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:it", "license:cc-by-sa-4.0", "dialogue-act-classification", "region:us"], "private": false, "author": null, "description": "Multilingual dIalogAct benchMark is a collection of resources for training, evaluating, and\nanalyzing natural language understanding systems specifically designed for spoken language. Datasets\nare in English, French, German, Italian and Spanish. They cover a variety of domains including\nspontaneous speech, scripted scenarios, and joint task completion. Some datasets additionally include\nemotion and/or sentimant labels.", "citation": "@unpublished{\nanonymous2021cross-lingual,\ntitle={Cross-Lingual Pretraining Methods for Spoken Dialog},\nauthor={Anonymous},\njournal={OpenReview Preprint},\nyear={2021},\nurl{https://openreview.net/forum?id=c1oDhu_hagR},\nnote={anonymous preprint under review}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec1", "disabled": false, "gated": false, "likes": 3, "downloads": 1070, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mkb", "sha": "9ab4c03d10d6256167b12bd0739065c93c9fdc8e", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "multilinguality:translation", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:bn", "language:en", "language:gu", "language:hi", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "language:ur", "license:cc-by-4.0", "arxiv:2007.07691", "region:us"], "private": false, "author": null, "description": "The Prime Minister's speeches - Mann Ki Baat, on All India Radio, translated into many languages.", "citation": "@misc{siripragada2020multilingual,\n      title={A Multilingual Parallel Corpora Collection Effort for Indian Languages},\n      author={Shashank Siripragada and Jerin Philip and Vinay P. Namboodiri and C V Jawahar},\n      year={2020},\n      eprint={2007.07691},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec2", "disabled": false, "gated": false, "likes": 1, "downloads": 6401, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mkqa", "sha": "7902336909c1eae90e2b2899ccdf3cb1ceff635e", "lastModified": "2023-01-25T14:40:34.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:multilingual", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:extended|natural_questions", "source_datasets:original", "language:ar", "language:da", "language:de", "language:en", "language:es", "language:fi", "language:fr", "language:he", "language:hu", "language:it", "language:ja", "language:km", "language:ko", "language:ms", "language:nl", "language:no", "language:pl", "language:pt", "language:ru", "language:sv", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-3.0", "arxiv:2007.15207", "region:us"], "private": false, "author": null, "description": "We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs sampled from the Google Natural Questions dataset, aligned across 26 typologically diverse languages (260k question-answer pairs in total). For each query we collected new passage-independent answers. These queries and answers were then human translated into 25 Non-English languages.", "citation": "@misc{mkqa,\n    title = {MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering},\n    author = {Shayne Longpre and Yi Lu and Joachim Daiber},\n    year = {2020},\n    URL = {https://arxiv.org/pdf/2007.15207.pdf}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec3", "disabled": false, "gated": false, "likes": 13, "downloads": 10576, "paperswithcode_id": "mkqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mlqa", "sha": "f6c80bcc6e9b0b8fa5e4ed137b59066a67d02372", "lastModified": "2023-04-05T10:09:51.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:de", "language:es", "language:ar", "language:zh", "language:vi", "language:hi", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "    MLQA (MultiLingual Question Answering) is a benchmark dataset for evaluating cross-lingual question answering performance.\n    MLQA consists of over 5K extractive QA instances (12K in English) in SQuAD format in seven languages - English, Arabic,\n    German, Spanish, Hindi, Vietnamese and Simplified Chinese. MLQA is highly parallel, with QA instances parallel between\n    4 different languages on average.", "citation": "@article{lewis2019mlqa,\n  title={MLQA: Evaluating Cross-lingual Extractive Question Answering},\n  author={Lewis, Patrick and Oguz, Barlas and Rinott, Ruty and Riedel, Sebastian and Schwenk, Holger},\n  journal={arXiv preprint arXiv:1910.07475},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec4", "disabled": false, "gated": false, "likes": 25, "downloads": 19904, "paperswithcode_id": "mlqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mlsum", "sha": "b5d54f8f3b61ae17845046286940f03c6bc79bc7", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:summarization", "task_categories:translation", "task_categories:text-classification", "task_ids:news-articles-summarization", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:extended|cnn_dailymail", "source_datasets:original", "language:de", "language:es", "language:fr", "language:ru", "language:tr", "license:other", "region:us"], "private": false, "author": null, "description": "We present MLSUM, the first large-scale MultiLingual SUMmarization dataset.\nObtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish.\nTogether with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community.\nWe report cross-lingual comparative analyses based on state-of-the-art systems.\nThese highlight existing biases which motivate the use of a multi-lingual dataset.", "citation": "@article{scialom2020mlsum,\n  title={MLSUM: The Multilingual Summarization Corpus},\n  author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},\n  journal={arXiv preprint arXiv:2004.14900},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec5", "disabled": false, "gated": false, "likes": 30, "downloads": 2326, "paperswithcode_id": "mlsum", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mnist", "sha": "ebfc265d7d30f34e1c092846918d11865c4d2f09", "lastModified": "2023-04-18T08:44:09.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-nist", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "The MNIST dataset consists of 70,000 28x28 black-and-white images in 10 classes (one for each digits), with 7,000\nimages per class. There are 60,000 training images and 10,000 test images.", "citation": "@article{lecun2010mnist,\n  title={MNIST handwritten digit database},\n  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n  volume={2},\n  year={2010}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec6", "disabled": false, "gated": false, "likes": 47, "downloads": 37285, "paperswithcode_id": "mnist", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mocha", "sha": "045248c66d84e80b51a2a0396e3042d2ceef19af", "lastModified": "2022-11-18T21:29:45.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "generative-reading-comprehension-metric", "region:us"], "private": false, "author": null, "description": "Posing reading comprehension as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. To address this, we introduce a benchmark for training and evaluating generative reading comprehension metrics: MOdeling Correctness with Human Annotations. MOCHA contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train an evaluation metric: LERC, a Learned Evaluation metric for Reading Comprehension, to mimic human judgement scores.", "citation": "@inproceedings{Chen2020MOCHAAD,\n    author={Anthony Chen and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n    title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n    booktitle={EMNLP},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec7", "disabled": false, "gated": false, "likes": 2, "downloads": 450, "paperswithcode_id": "mocha", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "moroco", "sha": "c183e4fb8c50ed8919ef077a6a391c8fcb365455", "lastModified": "2023-01-25T14:40:41.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ro", "license:cc-by-4.0", "arxiv:1901.06543", "region:us"], "private": false, "author": null, "description": "The MOROCO (Moldavian and Romanian Dialectal Corpus) dataset contains 33564 samples of text collected from the news domain.\nThe samples belong to one of the following six topics:\n    - culture\n    - finance\n    - politics\n    - science\n    - sports\n    - tech", "citation": "@inproceedings{ Butnaru-ACL-2019,\n    author = {Andrei M. Butnaru and Radu Tudor Ionescu},\n    title = \"{MOROCO: The Moldavian and Romanian Dialectal Corpus}\",\n    booktitle = {Proceedings of ACL},\n    year = {2019},\n    pages={688--698},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec8", "disabled": false, "gated": false, "likes": 0, "downloads": 298, "paperswithcode_id": "moroco", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "movie_rationales", "sha": "bc22b13e205bebf015df02bde57264f118f8499e", "lastModified": "2023-04-05T10:09:59.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The movie rationale dataset contains human annotated rationales for movie\nreviews.", "citation": "@unpublished{eraser2019,\n    title = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},\n    author = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace}\n}\n@InProceedings{zaidan-eisner-piatko-2008:nips,\n  author    =  {Omar F. Zaidan  and  Jason Eisner  and  Christine Piatko},\n  title     =  {Machine Learning with Annotator Rationales to Reduce Annotation Cost},\n  booktitle =  {Proceedings of the NIPS*2008 Workshop on Cost Sensitive Learning},\n  month     =  {December},\n  year      =  {2008}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ec9", "disabled": false, "gated": false, "likes": 3, "downloads": 809, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mrqa", "sha": "e11757383cce7a5fa47fcea0fd7e9b4dd71ff85f", "lastModified": "2022-11-18T21:30:01.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|drop", "source_datasets:extended|hotpot_qa", "source_datasets:extended|natural_questions", "source_datasets:extended|race", "source_datasets:extended|search_qa", "source_datasets:extended|squad", "source_datasets:extended|trivia_qa", "language:en", "license:unknown", "arxiv:1910.09753", "arxiv:1606.05250", "arxiv:1611.09830", "arxiv:1705.03551", "arxiv:1704.05179", "arxiv:1809.09600", "arxiv:1903.00161", "arxiv:1804.07927", "arxiv:1704.04683", "arxiv:1706.04115", "region:us"], "private": false, "author": null, "description": "The MRQA 2019 Shared Task focuses on generalization in question answering.\nAn effective question answering system should do more than merely\ninterpolate from the training set to answer test examples drawn\nfrom the same distribution: it should also be able to extrapolate\nto out-of-distribution examples \u2014 a significantly harder challenge.\n\nThe dataset is a collection of 18 existing QA dataset (carefully selected\nsubset of them) and converted to the same format (SQuAD format). Among\nthese 18 datasets, six datasets were made available for training,\nsix datasets were made available for development, and the final six\nfor testing. The dataset is released as part of the MRQA 2019 Shared Task.", "citation": "@inproceedings{fisch2019mrqa,\n    title={{MRQA} 2019 Shared Task: Evaluating Generalization in Reading Comprehension},\n    author={Adam Fisch and Alon Talmor and Robin Jia and Minjoon Seo and Eunsol Choi and Danqi Chen},\n    booktitle={Proceedings of 2nd Machine Reading for Reading Comprehension (MRQA) Workshop at EMNLP},\n    year={2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eca", "disabled": false, "gated": false, "likes": 10, "downloads": 1286, "paperswithcode_id": "mrqa-2019", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ms_marco", "sha": "320355e7322dbc21ec30d6e656fd1de2d182bad3", "lastModified": "2023-04-05T10:10:02.000Z", "tags": ["language:en", "arxiv:1611.09268", "region:us"], "private": false, "author": null, "description": "Starting with a paper released at NIPS 2016, MS MARCO is a collection of datasets focused on deep learning in search.\n\nThe first dataset was a question answering dataset featuring 100,000 real Bing questions and a human generated answer.\nSince then we released a 1,000,000 question dataset, a natural langauge generation dataset, a passage ranking dataset,\nkeyphrase extraction dataset, crawling dataset, and a conversational search.\n\nThere have been 277 submissions. 20 KeyPhrase Extraction submissions, 87 passage ranking submissions, 0 document ranking\nsubmissions, 73 QnA V2 submissions, 82 NLGEN submisions, and 15 QnA V1 submissions\n\nThis data comes in three tasks/forms: Original QnA dataset(v1.1), Question Answering(v2.1), Natural Language Generation(v2.1).\n\nThe original question answering datset featured 100,000 examples and was released in 2016. Leaderboard is now closed but data is availible below.\n\nThe current competitive tasks are Question Answering and Natural Language Generation. Question Answering features over 1,000,000 queries and\nis much like the original QnA dataset but bigger and with higher quality. The Natural Language Generation dataset features 180,000 examples and\nbuilds upon the QnA dataset to deliver answers that could be spoken by a smart speaker.", "citation": "@article{DBLP:journals/corr/NguyenRSGTMD16,\n  author    = {Tri Nguyen and\n               Mir Rosenberg and\n               Xia Song and\n               Jianfeng Gao and\n               Saurabh Tiwary and\n               Rangan Majumder and\n               Li Deng},\n  title     = {{MS} {MARCO:} {A} Human Generated MAchine Reading COmprehension Dataset},\n  journal   = {CoRR},\n  volume    = {abs/1611.09268},\n  year      = {2016},\n  url       = {http://arxiv.org/abs/1611.09268},\n  archivePrefix = {arXiv},\n  eprint    = {1611.09268},\n  timestamp = {Mon, 13 Aug 2018 16:49:03 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/NguyenRSGTMD16.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ecb", "disabled": false, "gated": false, "likes": 46, "downloads": 4110, "paperswithcode_id": "ms-marco", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ms_terms", "sha": "959e003c42ba6eb7d93be482ce39c603e917888f", "lastModified": "2022-11-03T16:08:00.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:af", "language:am", "language:ar", "language:as", "language:az", "language:be", "language:bg", "language:bn", "language:bs", "language:ca", "language:chr", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fil", "language:fr", "language:ga", "language:gd", "language:gl", "language:gu", "language:guc", "language:ha", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:ig", "language:is", "language:it", "language:iu", "language:ja", "language:ka", "language:kk", "language:km", "language:kn", "language:knn", "language:ko", "language:ku", "language:ky", "language:lb", "language:lo", "language:lt", "language:lv", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:nb", "language:ne", "language:nl", "language:nn", "language:ory", "language:pa", "language:pl", "language:prs", "language:pst", "language:pt", "language:qu", "language:quc", "language:ro", "language:ru", "language:rw", "language:sd", "language:si", "language:sk", "language:sl", "language:sq", "language:sr", "language:st", "language:sv", "language:swh", "language:ta", "language:te", "language:tg", "language:th", "language:ti", "language:tk", "language:tn", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:wo", "language:xh", "language:yo", "language:zh", "language:zu", "license:ms-pl", "region:us"], "private": false, "author": null, "description": "The Microsoft Terminology Collection can be used to develop localized versions of applications that integrate with Microsoft products.\nIt can also be used to integrate Microsoft terminology into other terminology collections or serve as a base IT glossary\nfor language development in the nearly 100 languages available. Terminology is provided in .tbx format, an industry standard for terminology exchange.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ecc", "disabled": false, "gated": false, "likes": 3, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "msr_genomics_kbcomp", "sha": "4970464c9a848bb640339008050bf82063210327", "lastModified": "2023-01-25T14:40:48.000Z", "tags": ["task_categories:other", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "genomics-knowledge-base-bompletion", "region:us"], "private": false, "author": null, "description": "The database is derived from the NCI PID Pathway Interaction Database, and the textual mentions are extracted from cooccurring pairs of genes in PubMed abstracts, processed and annotated by Literome (Poon et al. 2014). This dataset was used in the paper \u201cCompositional Learning of Embeddings for Relation Paths in Knowledge Bases and Text\u201d (Toutanova, Lin, Yih, Poon, and Quirk, 2016).", "citation": "@inproceedings{toutanova-etal-2016-compositional,\n    title = \"Compositional Learning of Embeddings for Relation Paths in Knowledge Base and Text\",\n    author = \"Toutanova, Kristina  and\n      Lin, Victoria  and\n      Yih, Wen-tau  and\n      Poon, Hoifung  and\n      Quirk, Chris\",\n    booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2016\",\n    address = \"Berlin, Germany\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P16-1136\",\n    doi = \"10.18653/v1/P16-1136\",\n    pages = \"1434--1444\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ecd", "disabled": false, "gated": false, "likes": 0, "downloads": 295, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "msr_sqa", "sha": "abcf468850abe7af0734831afd199a51fde8c615", "lastModified": "2022-11-18T21:30:23.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:ms-pl", "region:us"], "private": false, "author": null, "description": "Recent work in semantic parsing for question answering has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but inter-related questions. We created SQA by asking crowdsourced workers to decompose 2,022 questions from WikiTableQuestions (WTQ), which contains highly-compositional questions about tables from Wikipedia. We had three workers decompose each WTQ question, resulting in a dataset of 6,066 sequences that contain 17,553 questions in total. Each question is also associated with answers in the form of cell locations in the tables.", "citation": "@inproceedings{iyyer2017search,\n  title={Search-based neural structured learning for sequential question answering},\n  author={Iyyer, Mohit and Yih, Wen-tau and Chang, Ming-Wei},\n  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n  pages={1821--1831},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ece", "disabled": false, "gated": false, "likes": 1, "downloads": 476, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "msr_text_compression", "sha": "c906a40d52fd002da519b86575d5a5f47ec938b9", "lastModified": "2022-11-18T21:30:29.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-Open-American-National-Corpus-(OANC1)", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "This dataset contains sentences and short paragraphs with corresponding shorter (compressed) versions. There are up to five compressions for each input text, together with quality judgements of their meaning preservation and grammaticality. The dataset is derived using source texts from the Open American National Corpus (ww.anc.org) and crowd-sourcing.", "citation": "@inproceedings{Toutanova2016ADA,\n  title={A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs},\n  author={Kristina Toutanova and Chris Brockett and Ke M. Tran and Saleema Amershi},\n  booktitle={EMNLP},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ecf", "disabled": false, "gated": false, "likes": 3, "downloads": 305, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "msr_zhen_translation_parity", "sha": "956f42d1a6d570f86ca92802f064fe9b2f61a98d", "lastModified": "2022-11-03T16:08:10.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|other-newstest2017", "language:en", "license:ms-pl", "region:us"], "private": false, "author": null, "description": "Translator Human Parity Data\n\nHuman evaluation results and translation output for the Translator Human Parity Data release,\nas described in https://blogs.microsoft.com/ai/machine-translation-news-test-set-human-parity/.\nThe Translator Human Parity Data release contains all human evaluation results and translations\nrelated to our paper \"Achieving Human Parity on Automatic Chinese to English News Translation\",\npublished on March 14, 2018.", "citation": "@misc{hassan2018achieving,\n      title={Achieving Human Parity on Automatic Chinese to English News Translation},\n      author={ Hany Hassan and Anthony Aue and Chang Chen and Vishal Chowdhary and Jonathan Clark\n               and Christian Federmann and Xuedong Huang and Marcin Junczys-Dowmunt and William Lewis\n               and Mu Li and Shujie Liu and Tie-Yan Liu and Renqian Luo and Arul Menezes and Tao Qin\n               and Frank Seide and Xu Tan and Fei Tian and Lijun Wu and Shuangzhi Wu and Yingce Xia\n               and Dongdong Zhang and Zhirui Zhang and Ming Zhou},\n      year={2018},\n      eprint={1803.05567},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed0", "disabled": false, "gated": false, "likes": 0, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "msra_ner", "sha": "34593fa1e94b1b92373d07ec13de1f5f8def7ffd", "lastModified": "2023-01-25T14:40:51.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Third International Chinese Language\nProcessing Bakeoff was held in Spring\n2006 to assess the state of the art in two\nimportant tasks: word segmentation and\nnamed entity recognition. Twenty-nine\ngroups submitted result sets in the two\ntasks across two tracks and a total of five\ncorpora. We found strong results in both\ntasks as well as continuing challenges.\n\nMSRA NER is one of the provided dataset.\nThere are three types of NE, PER (person),\nORG (organization) and LOC (location).\nThe dataset is in the BIO scheme.\n\nFor more details see https://faculty.washington.edu/levow/papers/sighan06.pdf", "citation": "@inproceedings{levow2006third,\n  author    = {Gina{-}Anne Levow},\n  title     = {The Third International Chinese Language Processing Bakeoff: Word\n               Segmentation and Named Entity Recognition},\n  booktitle = {SIGHAN@COLING/ACL},\n  pages     = {108--117},\n  publisher = {Association for Computational Linguistics},\n  year      = {2006}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed1", "disabled": false, "gated": false, "likes": 18, "downloads": 636, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mt_eng_vietnamese", "sha": "79ad5ccff8bd2f0e19cd2c75fe93ca28f1722a8c", "lastModified": "2022-11-18T21:30:45.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:vi", "license:unknown", "region:us"], "private": false, "author": null, "description": "Preprocessed Dataset from IWSLT'15 English-Vietnamese machine translation: English-Vietnamese.", "citation": "@inproceedings{Luong-Manning:iwslt15,\n        Address = {Da Nang, Vietnam}\n        Author = {Luong, Minh-Thang  and Manning, Christopher D.},\n        Booktitle = {International Workshop on Spoken Language Translation},\n        Title = {Stanford Neural Machine Translation Systems for Spoken Language Domain},\n        Year = {2015}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed2", "disabled": false, "gated": false, "likes": 16, "downloads": 1035, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "muchocine", "sha": "8ea23e8347f16d12d5958fa9a13efd38140c5cbb", "lastModified": "2023-01-25T14:40:54.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:es", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Muchocine reviews dataset contains 3,872 longform movie reviews in Spanish language,\neach with a shorter summary review, and a rating on a 1-5 scale.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed3", "disabled": false, "gated": false, "likes": 4, "downloads": 321, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_booked", "sha": "bf6176d4e6ef2643d06b872c7dc2ac82764524f1", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:ca", "language:eu", "license:cc-by-3.0", "arxiv:1803.08614", "region:us"], "private": false, "author": null, "description": "MultiBooked is a corpus of Basque and Catalan Hotel Reviews Annotated for Aspect-level Sentiment Classification.\n\nThe corpora are compiled from hotel reviews taken mainly from booking.com. The corpora are in Kaf/Naf format, which is\nan xml-style stand-off format that allows for multiple layers of annotation. Each review was sentence- and\nword-tokenized and lemmatized using Freeling for Catalan and ixa-pipes for Basque. Finally, for each language two\nannotators annotated opinion holders, opinion targets, and opinion expressions for each review, following the\nguidelines set out in the OpeNER project.", "citation": "@inproceedings{Barnes2018multibooked,\n    author={Barnes, Jeremy and Lambert, Patrik and Badia, Toni},\n    title={MultiBooked: A corpus of Basque and Catalan Hotel Reviews Annotated for Aspect-level Sentiment Classification},\n    booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC'18)},\n    year = {2018},\n    month = {May},\n    date = {7-12},\n    address = {Miyazaki, Japan},\n    publisher = {European Language Resources Association (ELRA)},\n    language = {english}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed4", "disabled": false, "gated": false, "likes": 0, "downloads": 446, "paperswithcode_id": "multibooked", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_eurlex", "sha": "fed4e4005fbc67c1abbdb8d3311561f0effd72a0", "lastModified": "2023-06-14T13:34:30.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:cc-by-sa-4.0", "arxiv:2109.00904", "region:us"], "private": false, "author": null, "description": "MultiEURLEX comprises 65k EU laws in 23 official EU languages (some low-ish resource).\nEach EU law has been annotated with EUROVOC concepts (labels) by the Publication Office of EU.\nAs with the English EURLEX, the goal is to predict the relevant EUROVOC concepts (labels);\nthis is multi-label classification task (given the text, predict multiple labels).", "citation": "@InProceedings{chalkidis-etal-2021-multieurlex,\n  author = {Chalkidis, Ilias\n                and Fergadiotis, Manos\n                and Androutsopoulos, Ion},\n  title = {MultiEURLEX -- A multi-lingual and multi-label legal document\n               classification dataset for zero-shot cross-lingual transfer},\n  booktitle = {Proceedings of the 2021 Conference on Empirical Methods\n               in Natural Language Processing},\n  year = {2021},\n  publisher = {Association for Computational Linguistics},\n  location = {Punta Cana, Dominican Republic},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed5", "disabled": false, "gated": false, "likes": 24, "downloads": 5029, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_news", "sha": "a3086b9f48da752eb39fb747d168ec129e7833a5", "lastModified": "2023-04-05T10:10:12.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "arxiv:1906.01749", "region:us"], "private": false, "author": null, "description": "Multi-News, consists of news articles and human-written summaries\nof these articles from the site newser.com.\nEach summary is professionally written by editors and\nincludes links to the original articles cited.\n\nThere are two features:\n  - document: text of news articles seperated by special token \"|||||\".\n  - summary: news summary.", "citation": "@misc{alex2019multinews,\n    title={Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},\n    author={Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},\n    year={2019},\n    eprint={1906.01749},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed6", "disabled": false, "gated": false, "likes": 39, "downloads": 4950, "paperswithcode_id": "multi-news", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_nli", "sha": "39383d403c0a2058252c6f719d3caf737abd5fb1", "lastModified": "2023-04-05T10:10:15.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-3.0", "license:cc-by-sa-3.0", "license:mit", "license:other", "region:us"], "private": false, "author": null, "description": "The Multi-Genre Natural Language Inference (MultiNLI) corpus is a\ncrowd-sourced collection of 433k sentence pairs annotated with textual\nentailment information. The corpus is modeled on the SNLI corpus, but differs in\nthat covers a range of genres of spoken and written text, and supports a\ndistinctive cross-genre generalization evaluation. The corpus served as the\nbasis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen.", "citation": "@InProceedings{N18-1101,\n  author = {Williams, Adina\n            and Nangia, Nikita\n            and Bowman, Samuel},\n  title = {A Broad-Coverage Challenge Corpus for\n           Sentence Understanding through Inference},\n  booktitle = {Proceedings of the 2018 Conference of\n               the North American Chapter of the\n               Association for Computational Linguistics:\n               Human Language Technologies, Volume 1 (Long\n               Papers)},\n  year = {2018},\n  publisher = {Association for Computational Linguistics},\n  pages = {1112--1122},\n  location = {New Orleans, Louisiana},\n  url = {http://aclweb.org/anthology/N18-1101}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed7", "disabled": false, "gated": false, "likes": 42, "downloads": 8551, "paperswithcode_id": "multinli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_para_crawl", "sha": "c3f0973b084e333f13c346f948722c8709039254", "lastModified": "2022-11-03T16:31:38.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:bg", "language:ca", "language:cs", "language:da", "language:de", "language:el", "language:es", "language:et", "language:eu", "language:fi", "language:fr", "language:ga", "language:gl", "language:ha", "language:hr", "language:hu", "language:ig", "language:is", "language:it", "language:km", "language:lt", "language:lv", "language:mt", "language:my", "language:nb", "language:ne", "language:nl", "language:nn", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:si", "language:sk", "language:sl", "language:so", "language:sv", "language:sw", "language:tl", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Parallel corpora from Web Crawls collected in the ParaCrawl project and further processed for making it a multi-parallel corpus by pivoting via English. Here we only provide the additional language pairs that came out of pivoting. The bitexts for English are available from the ParaCrawl release.\n40 languages, 669 bitexts\ntotal number of files: 40\ntotal number of tokens: 10.14G\ntotal number of sentence fragments: 505.48M\n\nPlease, acknowledge the ParaCrawl project at http://paracrawl.eu. This version is derived from the original release at their website adjusted for redistribution via the OPUS corpus collection. Please, acknowledge OPUS as well for this service.", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ed9", "disabled": false, "gated": false, "likes": 0, "downloads": 848, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_re_qa", "sha": "a164af76c2168a59fe29411ea40434b05858849f", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "annotations_creators:found", "language_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "source_datasets:extended|other-BioASQ", "source_datasets:extended|other-DuoRC", "source_datasets:extended|other-HotpotQA", "source_datasets:extended|other-Natural-Questions", "source_datasets:extended|other-Relation-Extraction", "source_datasets:extended|other-SQuAD", "source_datasets:extended|other-SearchQA", "source_datasets:extended|other-TextbookQA", "source_datasets:extended|other-TriviaQA", "language:en", "license:unknown", "arxiv:2005.02507", "region:us"], "private": false, "author": null, "description": "MultiReQA contains the sentence boundary annotation from eight publicly available QA datasets including SearchQA, TriviaQA, HotpotQA, NaturalQuestions, SQuAD, BioASQ, RelationExtraction, and TextbookQA. Five of these datasets, including SearchQA, TriviaQA, HotpotQA, NaturalQuestions, SQuAD, contain both training and test data, and three, including BioASQ, RelationExtraction, TextbookQA, contain only the test data", "citation": "@misc{m2020multireqa,\n    title={MultiReQA: A Cross-Domain Evaluation for Retrieval Question Answering Models},\n    author={Mandy Guo and Yinfei Yang and Daniel Cer and Qinlan Shen and Noah Constant},\n    year={2020},\n    eprint={2005.02507},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eda", "disabled": false, "gated": false, "likes": 0, "downloads": 1414, "paperswithcode_id": "multireqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_woz_v22", "sha": "38860b8b5062ce737a1e38c3008d7e2d13a7b3c9", "lastModified": "2023-01-25T14:41:08.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:token-classification", "task_categories:text-classification", "task_ids:dialogue-modeling", "task_ids:multi-class-classification", "task_ids:parsing", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1810.00278", "region:us"], "private": false, "author": null, "description": "Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics.\nMultiWOZ 2.1 (Eric et al., 2019) identified and fixed many erroneous annotations and user utterances in the original version, resulting in an\nimproved version of the dataset. MultiWOZ 2.2 is a yet another improved version of this dataset, which identifies and fizes dialogue state annotation errors\nacross 17.3% of the utterances on top of MultiWOZ 2.1 and redefines the ontology by disallowing vocabularies of slots with a large number of possible values\n(e.g., restaurant name, time of booking) and introducing standardized slot span annotations for these slots.", "citation": "@article{corr/abs-2007-12720,\n  author    = {Xiaoxue Zang and\n               Abhinav Rastogi and\n               Srinivas Sunkara and\n               Raghav Gupta and\n               Jianguo Zhang and\n               Jindong Chen},\n  title     = {MultiWOZ 2.2 : {A} Dialogue Dataset with Additional Annotation Corrections\n               and State Tracking Baselines},\n  journal   = {CoRR},\n  volume    = {abs/2007.12720},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2007.12720},\n  archivePrefix = {arXiv},\n  eprint    = {2007.12720}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181edb", "disabled": false, "gated": false, "likes": 15, "downloads": 6410, "paperswithcode_id": "multiwoz", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multi_x_science_sum", "sha": "c0fcac5e4bbada7372c01204200630a1a52c9a9d", "lastModified": "2022-11-18T21:31:34.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "paper-abstract-generation", "arxiv:2010.14235", "region:us"], "private": false, "author": null, "description": "Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. Multi-XScience introduces a challenging multi-document summarization task: writing the related-work section of a paper based on its abstract and the articles it references.", "citation": "@article{lu2020multi,\n  title={Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles},\n  author={Lu, Yao and Dong, Yue and Charlin, Laurent},\n  journal={arXiv preprint arXiv:2010.14235},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181edc", "disabled": false, "gated": false, "likes": 12, "downloads": 793, "paperswithcode_id": "multi-xscience", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multidoc2dial", "sha": "1108a969d076f04c7367f0c2427d1c5d6d6bdaa0", "lastModified": "2023-08-29T09:45:02.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:extended|doc2dial", "language:en", "license:apache-2.0", "arxiv:2109.12595", "region:us"], "private": false, "author": null, "description": "MultiDoc2Dial is a new task and dataset on modeling goal-oriented dialogues grounded in multiple documents. Most previous works treat document-grounded dialogue modeling as a machine reading comprehension task based on a single given document or passage. We aim to address more realistic scenarios where a goal-oriented information-seeking conversation involves multiple topics, and hence is grounded on different documents.", "citation": "@inproceedings{feng2021multidoc2dial,\n    title={MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents},\n    author={Feng, Song and Patel, Siva Sankalp and Wan, Hui and Joshi, Sachindra},\n    booktitle={EMNLP},\n    year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181edd", "disabled": false, "gated": false, "likes": 2, "downloads": 1007, "paperswithcode_id": "multidoc2dial", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "multilingual_librispeech", "sha": "581796bf5ff1fd9c8999bec3602d8fc618f7d89e", "lastModified": "2022-11-18T21:31:47.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_ids:speaker-identification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "language:es", "language:fr", "language:it", "language:nl", "language:pl", "language:pt", "license:cc-by-4.0", "arxiv:2012.03411", "region:us"], "private": false, "author": null, "description": "Multilingual LibriSpeech (MLS) dataset is a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages - English, German, Dutch, Spanish, French, Italian, Portuguese, Polish.", "citation": "@article{Pratap2020MLSAL,\n  title={MLS: A Large-Scale Multilingual Dataset for Speech Research},\n  author={Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},\n  journal={ArXiv},\n  year={2020},\n  volume={abs/2012.03411}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ede", "disabled": false, "gated": false, "likes": 7, "downloads": 1159, "paperswithcode_id": "librispeech-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mutual_friends", "sha": "be9609d48bb418ec6143c21164681e896558069c", "lastModified": "2022-11-18T21:31:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1704.07130", "region:us"], "private": false, "author": null, "description": "Our goal is to build systems that collaborate with people by exchanging\ninformation through natural language and reasoning over structured knowledge\nbase. In the MutualFriend task, two agents, A and B, each have a private\nknowledge base, which contains a list of friends with multiple attributes\n(e.g., name, school, major, etc.). The agents must chat with each other\nto find their unique mutual friend.", "citation": "@inproceedings{he-etal-2017-learning,\n    title = \"Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings\",\n    author = \"He, He  and\n      Balakrishnan, Anusha  and\n      Eric, Mihail  and\n      Liang, Percy\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1162\",\n    doi = \"10.18653/v1/P17-1162\",\n    pages = \"1766--1776\",\n    abstract = \"We study a \\textit{symmetric collaborative dialogue} setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181edf", "disabled": false, "gated": false, "likes": 2, "downloads": 290, "paperswithcode_id": "mutualfriends", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mwsc", "sha": "96226c0f66dddb547a376ff87f959c8abeffe8db", "lastModified": "2023-04-05T13:33:22.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-coreference-resolution", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:extended|winograd_wsc", "language:en", "license:cc-by-4.0", "arxiv:1806.08730", "region:us"], "private": false, "author": null, "description": "Examples taken from the Winograd Schema Challenge modified to ensure that answers are a single word from the context.\nThis modified Winograd Schema Challenge (MWSC) ensures that scores are neither inflated nor deflated by oddities in phrasing.", "citation": "@article{McCann2018decaNLP,\n  title={The Natural Language Decathlon: Multitask Learning as Question Answering},\n  author={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\n  journal={arXiv preprint arXiv:1806.08730},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee0", "disabled": false, "gated": false, "likes": 0, "downloads": 372, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "myanmar_news", "sha": "2bd243baefc73c8a42a7002dcfd707d2a37fa487", "lastModified": "2023-01-25T14:41:11.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:my", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "The Myanmar news dataset contains article snippets in four categories:\nBusiness, Entertainment, Politics, and Sport.\n\nThese were collected in October 2017 by Aye Hninn Khine", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee1", "disabled": false, "gated": false, "likes": 1, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "narrativeqa", "sha": "1dffea67bbf0ad1c493aca66f42095913a5a0dcb", "lastModified": "2022-11-18T21:32:08.000Z", "tags": ["task_categories:text2text-generation", "task_ids:abstractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1712.07040", "region:us"], "private": false, "author": null, "description": "The NarrativeQA dataset for question answering on long documents (movie scripts, books). It includes the list of documents with Wikipedia summaries, links to full stories, and questions and answers.", "citation": "@article{narrativeqa,\nauthor = {Tom\\\\'a\\\\v s Ko\\\\v cisk\\\\'y and Jonathan Schwarz and Phil Blunsom and\n          Chris Dyer and Karl Moritz Hermann and G\\\\'abor Melis and\n          Edward Grefenstette},\ntitle = {The {NarrativeQA} Reading Comprehension Challenge},\njournal = {Transactions of the Association for Computational Linguistics},\nurl = {https://TBD},\nvolume = {TBD},\nyear = {2018},\npages = {TBD},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee2", "disabled": false, "gated": false, "likes": 12, "downloads": 4195, "paperswithcode_id": "narrativeqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "narrativeqa_manual", "sha": "60b59dda681b8ad789566d3330958ef89a63025e", "lastModified": "2022-11-18T21:32:14.000Z", "tags": ["task_categories:text2text-generation", "task_ids:abstractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1712.07040", "region:us"], "private": false, "author": null, "description": "The Narrative QA Manual dataset is a reading comprehension dataset, in which the reader must answer questions about stories by reading entire books or movie scripts. The QA tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience.\\THIS DATASET REQUIRES A MANUALLY DOWNLOADED FILE! Because of a script in the original repository which downloads the stories from original URLs everytime, The links are sometimes broken or invalid.  Therefore, you need to manually download the stories for this dataset using the script provided by the authors (https://github.com/deepmind/narrativeqa/blob/master/download_stories.sh). Running the shell script creates a folder named \"tmp\" in the root directory and downloads the stories there. This folder containing the storiescan be used to load the dataset via `datasets.load_dataset(\"narrativeqa_manual\", data_dir=\"<path/to/folder>\")`.", "citation": "@article{kovcisky2018narrativeqa,\n  title={The narrativeqa reading comprehension challenge},\n  author={Ko{\\v{c}}isk{\\'y}, Tom{\\'a}{\\v{s}} and Schwarz, Jonathan and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz and Melis, G{\\'a}bor and Grefenstette, Edward},\n  journal={Transactions of the Association for Computational Linguistics},\n  volume={6},\n  pages={317--328},\n  year={2018},\n  publisher={MIT Press}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee3", "disabled": false, "gated": false, "likes": 0, "downloads": 299, "paperswithcode_id": "narrativeqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "natural_questions", "sha": "4680ede6f5f8b799606e6ecfcaaf3711c659c2ab", "lastModified": "2023-04-05T13:35:01.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The NQ corpus contains questions from real users, and it requires QA systems to\nread and comprehend an entire Wikipedia article that may or may not contain the\nanswer to the question. The inclusion of real user questions, and the\nrequirement that solutions should read an entire page to find the answer, cause\nNQ to be a more realistic and challenging task than prior QA datasets.", "citation": "@article{47761,\ntitle\t= {Natural Questions: a Benchmark for Question Answering Research},\nauthor\t= {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},\nyear\t= {2019},\njournal\t= {Transactions of the Association of Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee4", "disabled": false, "gated": false, "likes": 26, "downloads": 1047, "paperswithcode_id": "natural-questions", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ncbi_disease", "sha": "acd0e6451198d5b615c12356ab6a05fff4610920", "lastModified": "2023-01-25T14:41:18.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "This paper presents the disease name and concept annotations of the NCBI disease corpus, a collection of 793 PubMed\nabstracts fully annotated at the mention and concept level to serve as a research resource for the biomedical natural\nlanguage processing community. Each PubMed abstract was manually annotated by two annotators with disease mentions\nand their corresponding concepts in Medical Subject Headings (MeSH\u00ae) or Online Mendelian Inheritance in Man (OMIM\u00ae).\nManual curation was performed using PubTator, which allowed the use of pre-annotations as a pre-step to manual annotations.\nFourteen annotators were randomly paired and differing annotations were discussed for reaching a consensus in two\nannotation phases. In this setting, a high inter-annotator agreement was observed. Finally, all results were checked\nagainst annotations of the rest of the corpus to assure corpus-wide consistency.\n\nFor more details, see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3951655/\n\nThe original dataset can be downloaded from: https://www.ncbi.nlm.nih.gov/CBBresearch/Dogan/DISEASE/NCBI_corpus.zip\nThis dataset has been converted to CoNLL format for NER using the following tool: https://github.com/spyysalo/standoff2conll\nNote: there is a duplicate document (PMID 8528200) in the original data, and the duplicate is recreated in the converted data.", "citation": "@article{dougan2014ncbi,\n         title={NCBI disease corpus: a resource for disease name recognition and concept normalization},\n         author={Dogan, Rezarta Islamaj and Leaman, Robert and Lu, Zhiyong},\n         journal={Journal of biomedical informatics},\n         volume={47},\n         pages={1--10},\n         year={2014},\n         publisher={Elsevier}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee5", "disabled": false, "gated": false, "likes": 23, "downloads": 1774, "paperswithcode_id": "ncbi-disease-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nchlt", "sha": "4a5386301d07762e1c61af68c62d5576e7da3810", "lastModified": "2023-01-25T14:41:21.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:af", "language:nr", "language:nso", "language:ss", "language:tn", "language:ts", "language:ve", "language:xh", "language:zu", "license:cc-by-2.5", "region:us"], "private": false, "author": null, "description": "The development of linguistic resources for use in natural language processingis of utmost importance for the continued growth of research anddevelopment in the field, especially for resource-scarce languages. In this paper we describe the process and challenges of simultaneouslydevelopingmultiple linguistic resources for ten of the official languages of South Africa. The project focussed on establishing a set of foundational resources that can foster further development of both resources and technologies for the NLP industry in South Africa. The development efforts during the project included creating monolingual unannotated corpora, of which a subset of the corpora for each language was annotated on token, orthographic, morphological and morphosyntactic layers. The annotated subsetsincludes both development and test setsand were used in the creation of five core-technologies, viz. atokeniser, sentenciser,lemmatiser, part of speech tagger and morphological decomposer for each language. We report on the quality of these tools for each language and provide some more context of the importance of the resources within the South African context.", "citation": "@inproceedings{eiselen2014developing,\n  title={Developing Text Resources for Ten South African Languages.},\n  author={Eiselen, Roald and Puttkammer, Martin J},\n  booktitle={LREC},\n  pages={3698--3703},\n  year={2014}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee6", "disabled": false, "gated": false, "likes": 4, "downloads": 1565, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ncslgr", "sha": "12eef2bcf793e96b3e1ca490c4fd976f97f6f1f4", "lastModified": "2022-11-03T16:16:28.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:n<1K", "source_datasets:original", "language:ase", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "A small corpus of American Sign Language (ASL) video data from native signers, annotated with non-manual features.", "citation": "@misc{dataset:databases2007volumes,\n    title={Volumes 2--7},\n    author={Databases, NCSLGR},\n    year={2007},\n    publisher={American Sign Language Linguistic Research Project (Distributed on CD-ROM~\u2026}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee7", "disabled": false, "gated": false, "likes": 4, "downloads": 436, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nell", "sha": "f0cbdf3558d3c4858c4c77010ba8afa45b1ab9e0", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:text-retrieval", "task_ids:entity-linking-retrieval", "task_ids:fact-checking-retrieval", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100M<n<1B", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:unknown", "relation-extraction", "text-to-structured", "text-to-tabular", "region:us"], "private": false, "author": null, "description": "This dataset provides version 1115 of the belief\nextracted by CMU's Never Ending Language Learner (NELL) and version\n1110 of the candidate belief extracted by NELL. See\nhttp://rtw.ml.cmu.edu/rtw/overview.  NELL is an open information\nextraction system that attempts to read the Clueweb09 of 500 million\nweb pages (http://boston.lti.cs.cmu.edu/Data/clueweb09/) and general\nweb searches.\n\nThe dataset has 4 configurations: nell_belief, nell_candidate,\nnell_belief_sentences, and nell_candidate_sentences. nell_belief is\ncertainties of belief are lower. The two sentences config extracts the\nCPL sentence patterns filled with the applicable 'best' literal string\nfor the entities filled into the sentence patterns. And also provides\nsentences found using web searches containing the entities and\nrelationships.\n\nThere are roughly 21M entries for nell_belief_sentences, and 100M\nsentences for nell_candidate_sentences.", "citation": "@inproceedings{mitchell2015,\n  added-at = {2015-01-27T15:35:24.000+0100},\n  author = {Mitchell, T. and Cohen, W. and Hruscha, E. and Talukdar, P. and Betteridge, J. and Carlson, A. and Dalvi, B. and Gardner, M. and Kisiel, B. and Krishnamurthy, J. and Lao, N. and Mazaitis, K. and Mohammad, T. and Nakashole, N. and Platanios, E. and Ritter, A. and Samadi, M. and Settles, B. and Wang, R. and Wijaya, D. and Gupta, A. and Chen, X. and Saparov, A. and Greaves, M. and Welling, J.},\n  biburl = {https://www.bibsonomy.org/bibtex/263070703e6bb812852cca56574aed093/hotho},\n  booktitle = {AAAI},\n  description = {Papers by William W. Cohen},\n  interhash = {52d0d71f6f5b332dabc1412f18e3a93d},\n  intrahash = {63070703e6bb812852cca56574aed093},\n  keywords = {learning nell ontology semantic toread},\n  note = {: Never-Ending Learning in AAAI-2015},\n  timestamp = {2015-01-27T15:35:24.000+0100},\n  title = {Never-Ending Learning},\n  url = {http://www.cs.cmu.edu/~wcohen/pubs.html},\n  year = 2015\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee8", "disabled": false, "gated": false, "likes": 3, "downloads": 827, "paperswithcode_id": "nell", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "neural_code_search", "sha": "2b78432cc9dc03c15eb81a2b957b986f544f54f5", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "arxiv:1908.09804", "region:us"], "private": false, "author": null, "description": "Neural-Code-Search-Evaluation-Dataset presents an evaluation dataset consisting of natural language query and code snippet pairs and a search corpus consisting of code snippets collected from the most popular Android repositories on GitHub.", "citation": "@InProceedings{huggingface:dataset,\ntitle         = {Neural Code Search Evaluation Dataset},\nauthors       = {Hongyu Li, Seohyun Kim and Satish Chandra},\njournal       = {arXiv e-prints},\nyear          = 2018,\neid           = {arXiv:1908.09804 [cs.SE]},\npages         = {arXiv:1908.09804 [cs.SE]},\narchivePrefix = {arXiv},\neprint        = {1908.09804},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ee9", "disabled": false, "gated": false, "likes": 7, "downloads": 551, "paperswithcode_id": "neural-code-search-evaluation-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "news_commentary", "sha": "4a29d7fd5e025b55e9f32ff9e36a1db1640f5565", "lastModified": "2022-11-03T16:47:41.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "language:cs", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:ja", "language:nl", "language:pt", "language:ru", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus of News Commentaries provided by WMT for training SMT. The source is taken from CASMACAT: http://www.casmacat.eu/corpus/news-commentary.html\n\n12 languages, 63 bitexts\ntotal number of files: 61,928\ntotal number of tokens: 49.66M\ntotal number of sentence fragments: 1.93M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eea", "disabled": false, "gated": false, "likes": 21, "downloads": 9587, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newsgroup", "sha": "1f445fac12e8cdc145e8d9f27d9a9081d69c3e6a", "lastModified": "2023-04-05T13:35:49.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across\n20 different newsgroups. The 20 newsgroups collection has become a popular data set for experiments in text applications of\nmachine learning techniques, such as text classification and text clustering.", "citation": "@inproceedings{Lang95,\n    author = {Ken Lang},\n    title = {Newsweeder: Learning to filter netnews}\n    year = {1995}\n    booktitle = {Proceedings of the Twelfth International Conference on Machine Learning}\n    pages = {331-339}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eeb", "disabled": false, "gated": false, "likes": 7, "downloads": 9305, "paperswithcode_id": "20-newsgroups", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newsph", "sha": "6455ee930cebb321a3b5a307708f09a55a2663f2", "lastModified": "2022-11-03T16:07:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:fil", "language:tl", "license:gpl-3.0", "arxiv:2010.11574", "region:us"], "private": false, "author": null, "description": "Large-scale dataset of Filipino news articles. Sourced for the NewsPH-NLI Project (Cruz et al., 2020).", "citation": "@article{cruz2020investigating,\n  title={Investigating the True Performance of Transformers in Low-Resource Languages: A Case Study in Automatic Corpus Creation},\n  author={Jan Christian Blaise Cruz and Jose Kristian Resabal and James Lin and Dan John Velasco and Charibeth Cheng},\n  journal={arXiv preprint arXiv:2010.11574},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eec", "disabled": false, "gated": false, "likes": 2, "downloads": 290, "paperswithcode_id": "newsph-nli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newsph_nli", "sha": "70f61701753690e01ff01254007250d4101a9196", "lastModified": "2023-01-25T14:41:24.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tl", "license:unknown", "arxiv:2010.11574", "region:us"], "private": false, "author": null, "description": "First benchmark dataset for sentence entailment in the low-resource Filipino language.\nConstructed through exploting the structure of news articles. Contains 600,000 premise-hypothesis pairs,\nin 70-15-15 split for training, validation, and testing.", "citation": "@article{cruz2020investigating,\n    title={Investigating the True Performance of Transformers in Low-Resource Languages: A Case Study in Automatic Corpus Creation},\n    author={Jan Christian Blaise Cruz and Jose Kristian Resabal and James Lin and Dan John Velasco and Charibeth Cheng},\n    journal={arXiv preprint arXiv:2010.11574},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eed", "disabled": false, "gated": false, "likes": 0, "downloads": 301, "paperswithcode_id": "newsph-nli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newspop", "sha": "9b735505b3eba4b67aa8c9d0c370e8e7211c822d", "lastModified": "2022-11-03T16:31:06.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "social-media-shares-prediction", "arxiv:1801.07055", "region:us"], "private": false, "author": null, "description": "This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.\nThe collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine.\nThis data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation.", "citation": "@article{Moniz2018MultiSourceSF,\n  title={Multi-Source Social Feedback of Online News Feeds},\n  author={N. Moniz and L. Torgo},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1801.07055}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eee", "disabled": false, "gated": false, "likes": 2, "downloads": 373, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newsqa", "sha": "0d55737404bbcdbeb24bc2668c0682a7670dc1d6", "lastModified": "2023-06-01T14:59:49.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "NewsQA is a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text from the corresponding articles.", "citation": "@inproceedings{trischler2017newsqa,\n  title={NewsQA: A Machine Comprehension Dataset},\n  author={Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},\n  booktitle={Proceedings of the 2nd Workshop on Representation Learning for NLP},\n  pages={191--200},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eef", "disabled": false, "gated": false, "likes": 10, "downloads": 804, "paperswithcode_id": "newsqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "newsroom", "sha": "047c1170416947b16c5dfd351d349a844dd6cc02", "lastModified": "2023-04-05T13:35:54.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "NEWSROOM is a large dataset for training and evaluating summarization systems.\nIt contains 1.3 million articles and summaries written by authors and\neditors in the newsrooms of 38 major publications.\n\nDataset features includes:\n  - text: Input news text.\n  - summary: Summary for the news.\nAnd additional features:\n  - title: news title.\n  - url: url of the news.\n  - date: date of the article.\n  - density: extractive density.\n  - coverage: extractive coverage.\n  - compression: compression ratio.\n  - density_bin: low, medium, high.\n  - coverage_bin: extractive, abstractive.\n  - compression_bin: low, medium, high.\n\nThis dataset can be downloaded upon requests. Unzip all the contents\n\"train.jsonl, dev.josnl, test.jsonl\" to the tfds folder.", "citation": "@inproceedings{N18-1065,\n  author    = {Grusky, Max and Naaman, Mor and Artzi, Yoav},\n  title     = {NEWSROOM: A Dataset of 1.3 Million Summaries\n               with Diverse Extractive Strategies},\n  booktitle = {Proceedings of the 2018 Conference of the\n               North American Chapter of the Association for\n               Computational Linguistics: Human Language Technologies},\n  year      = {2018},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef0", "disabled": false, "gated": false, "likes": 7, "downloads": 340, "paperswithcode_id": "newsroom", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nkjp-ner", "sha": "9d69aea924449b92e1649205a8258afdbaa435f5", "lastModified": "2023-01-25T14:41:28.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "The NKJP-NER is based on a human-annotated part of National Corpus of Polish (NKJP). We extracted sentences with named entities of exactly one type. The task is to predict the type of the named entity.", "citation": "@book{przepiorkowski2012narodowy,\ntitle={Narodowy korpus jezyka polskiego},\nauthor={Przepi{\\'o}rkowski, Adam},\nyear={2012},\npublisher={Naukowe PWN}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef1", "disabled": false, "gated": false, "likes": 1, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nli_tr", "sha": "e6543a050b5c83365a4fe9afa7cdb24d2edfd261", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|snli", "source_datasets:extended|multi_nli", "language:tr", "license:cc-by-3.0", "license:cc-by-4.0", "license:cc-by-sa-3.0", "license:mit", "license:other", "region:us"], "private": false, "author": null, "description": "\\\r\nThe Natural Language Inference in Turkish (NLI-TR) is a set of two large scale datasets that were obtained by translating the foundational NLI corpora (SNLI and MNLI) using Amazon Translate.", "citation": "\\\r\n@inproceedings{budur-etal-2020-data,\r\n    title = \"Data and Representation for Turkish Natural Language Inference\",\r\n    author = \"Budur, Emrah and\r\n      \\\"{O}z\u00e7elik, R\u0131za and\r\n      G\\\"{u}ng\\\"{o}r, Tunga\",\r\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\r\n    month = nov,\r\n    year = \"2020\",\r\n    address = \"Online\",\r\n    publisher = \"Association for Computational Linguistics\",\r\n    abstract = \"Large annotated datasets in NLP are overwhelmingly in English. This is an obstacle to progress in other languages. Unfortunately, obtaining new annotated resources for each task in each language would be prohibitively expensive. At the same time, commercial machine translation systems are now robust. Can we leverage these systems to translate English-language datasets automatically? In this paper, we offer a positive response for natural language inference (NLI) in Turkish. We translated two large English NLI datasets into Turkish and had a team of experts validate their translation quality and fidelity to the original labels. Using these datasets, we address core issues of representation for Turkish NLI. We find that in-language embeddings are essential and that morphological parsing can be avoided where the training set is large. Finally, we show that models trained on our machine-translated datasets are successful on human-translated evaluation sets. We share all code, models, and data publicly.\",\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef2", "disabled": false, "gated": false, "likes": 6, "downloads": 854, "paperswithcode_id": "nli-tr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nlu_evaluation_data", "sha": "9f47b9338cf1696ea3ce726c9f67969a6da96a13", "lastModified": "2023-01-25T14:41:34.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1903.05566", "region:us"], "private": false, "author": null, "description": "Raw part of NLU Evaluation Data. It contains 25 715 non-empty examples (original dataset has 25716 examples) from 68 unique intents belonging to 18 scenarios.", "citation": "@InProceedings{XLiu.etal:IWSDS2019,\n  author    = {Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser},\n  title     = {Benchmarking Natural Language Understanding Services for building Conversational Agents},\n  booktitle = {Proceedings of the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)},\n  month     = {April},\n  year      = {2019},\n  address   = {Ortigia, Siracusa (SR), Italy},\n  publisher = {Springer},\n  pages     = {xxx--xxx},\n  url       = {http://www.xx.xx/xx/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef3", "disabled": false, "gated": false, "likes": 8, "downloads": 418, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "norec", "sha": "1ae336a016fbf7dcf6a8df6797bdac471b574772", "lastModified": "2023-01-25T14:41:38.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:nb", "language:nn", "language:no", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "NoReC was created as part of the SANT project (Sentiment Analysis for Norwegian Text), a collaboration between the Language Technology Group (LTG) at the Department of Informatics at the University of Oslo, the Norwegian Broadcasting Corporation (NRK), Schibsted Media Group and Aller Media. This first release of the corpus comprises 35,194 reviews extracted from eight different news sources: Dagbladet, VG, Aftenposten, Bergens Tidende, F\u00e6drelandsvennen, Stavanger Aftenblad, DinSide.no and P3.no. In terms of publishing date the reviews mainly cover the time span 2003\u20132017, although it also includes a handful of reviews dating back as far as 1998.", "citation": "@InProceedings{VelOvrBer18,\n  author = {Erik Velldal and Lilja Ovrelid and\n            Eivind Alexander Bergem and Cathrine Stadsnes and\n            Samia Touileb and Fredrik Jorgensen},\n  title = {{NoReC}: The {N}orwegian {R}eview {C}orpus},\n  booktitle = {Proceedings of the 11th edition of the\n               Language Resources and Evaluation Conference},\n  year = {2018},\n  address = {Miyazaki, Japan},\n  pages = {4186--4191}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef4", "disabled": false, "gated": false, "likes": 1, "downloads": 145, "paperswithcode_id": "norec", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "norne", "sha": "4e9145d8c1a2c555c60a345d26a25c6019618325", "lastModified": "2023-01-25T14:41:42.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:no", "license:other", "arxiv:1911.12146", "region:us"], "private": false, "author": null, "description": "NorNE is a manually annotated\ncorpus of named entities which extends the annotation of the existing\nNorwegian Dependency Treebank. Comprising both of the official standards of\nwritten Norwegian (Bokm\u00e5l and Nynorsk), the corpus contains around 600,000\ntokens and annotates a rich set of entity types including persons,\norganizations, locations, geo-political entities, products, and events,\nin addition to a class corresponding to nominals derived from names.", "citation": "@inproceedings{johansen2019ner,\n  title={NorNE: Annotating Named Entities for Norwegian},\n  author={Fredrik J\u00f8rgensen, Tobias Aasmoe, Anne-Stine Ruud Husev\u00e5g,\n          Lilja \u00d8vrelid, and Erik Velldal},\n  booktitle={LREC 2020},\n  year={2020},\n  url={https://arxiv.org/abs/1911.12146}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef5", "disabled": false, "gated": false, "likes": 1, "downloads": 272, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "norwegian_ner", "sha": "8f274ec7d2e5a1cb7489f8d5175c967fef866900", "lastModified": "2023-01-25T14:41:45.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:no", "license:unknown", "region:us"], "private": false, "author": null, "description": "Named entities Recognition dataset for Norwegian. It is\na version of the Universal Dependency (UD) Treebank for both Bokm\u00e5l and Nynorsk (UDN) where\nall proper nouns have been tagged with their type according to the NER tagging scheme. UDN is a converted\nversion of the Norwegian Dependency Treebank into the UD scheme.", "citation": "@inproceedings{johansen2019ner,\n  title={Named-Entity Recognition for Norwegian},\n  author={Johansen, Bjarte},\n  booktitle={Proceedings of the 22nd Nordic Conference on Computational Linguistics, NoDaLiDa},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef6", "disabled": false, "gated": false, "likes": 0, "downloads": 160, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nq_open", "sha": "d678e706856531a9f7ecf5861a54b9726ff8d837", "lastModified": "2022-11-03T16:32:11.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|natural_questions", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The NQ-Open task, introduced by Lee et.al. 2019,\nis an open domain question answering benchmark that is derived from Natural Questions.\nThe goal is to predict an English answer string for an input English question.\nAll questions can be answered using the contents of English Wikipedia.", "citation": "@article{doi:10.1162/tacl_a_00276,\n    author = {Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and Toutanova, Kristina and Jones, Llion and Kelcey, Matthew and Chang, Ming-Wei and Dai, Andrew                         M. and Uszkoreit, Jakob and Le, Quoc and Petrov, Slav},\n    title = {Natural Questions: A Benchmark for Question Answering Research},\n    journal = {Transactions of the Association for Computational Linguistics},\n    volume = {7},\n    number = {},\n    pages = {453-466},\n    year = {2019},\n    doi = {10.1162/tacl_a_00276},\n    URL = {\n            https://doi.org/10.1162/tacl_a_00276\n        },\n    eprint = {\n            https://doi.org/10.1162/tacl_a_00276\n        },\n    abstract = { We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature. }\n}\n\n@inproceedings{lee-etal-2019-latent,\n    title = \"Latent Retrieval for Weakly Supervised Open Domain Question Answering\",\n    author = \"Lee, Kenton  and\n      Chang, Ming-Wei  and\n      Toutanova, Kristina\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1612\",\n    doi = \"10.18653/v1/P19-1612\",\n    pages = \"6086--6096\",\n    abstract = \"Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef7", "disabled": false, "gated": false, "likes": 6, "downloads": 16377, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nsmc", "sha": "5c17b49e04ad8cf7ccce6d4fb6258cc6817e6fc9", "lastModified": "2023-01-25T14:41:49.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ko", "license:cc-by-2.0", "region:us"], "private": false, "author": null, "description": "This is a movie review dataset in the Korean language. Reviews were scraped from Naver movies. The dataset construction is based on the method noted in Large movie review dataset from Maas et al., 2011.", "citation": "@InProceedings{Park:2016,\n  title        = \"Naver Sentiment Movie Corpus\",\n  author       = \"Lucy Park\",\n  year         = \"2016\",\n  howpublished = {\\\\url{https://github.com/e9t/nsmc}}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef8", "disabled": false, "gated": false, "likes": 3, "downloads": 2815, "paperswithcode_id": "nsmc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "numer_sense", "sha": "35a07d3138975f33c5a6aad248999d0b44c54973", "lastModified": "2022-11-18T21:34:07.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:slot-filling", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other", "language:en", "license:mit", "arxiv:2005.00683", "region:us"], "private": false, "author": null, "description": "NumerSense is a new numerical commonsense reasoning probing task, with a diagnostic dataset consisting of 3,145 masked-word-prediction probes.\n\nWe propose to study whether numerical commonsense knowledge can be induced from pre-trained language models like BERT, and to what extent this access to knowledge robust against adversarial examples is. We hope this will be beneficial for tasks such as knowledge base completion and open-domain question answering.", "citation": "@inproceedings{lin2020numersense,\n    title={Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models},\n    author={Bill Yuchen Lin and Seyeon Lee and Rahul Khanna and Xiang Ren},\n    booktitle={Proceedings of EMNLP},\n    year={2020},\n    note={to appear}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ef9", "disabled": false, "gated": false, "likes": 1, "downloads": 449, "paperswithcode_id": "numersense", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "numeric_fused_head", "sha": "a20f1c147f161d99bcdbe369b1dbeb06ece0ed8b", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:token-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "fused-head-identification", "region:us"], "private": false, "author": null, "description": "Fused Head constructions are noun phrases in which the head noun is missing and is said to be \"fused\" with its dependent modifier. This missing information is implicit and is important for sentence understanding.The missing heads are easily filled in by humans,  but pose a challenge for computational models.\n\nFor example, in the sentence: \"I bought 5 apples but got only 4.\", 4 is a Fused-Head, and the missing head is apples, which appear earlier in the sentence.\n\nThis is a crowd-sourced dataset of 10k numerical fused head examples (1M tokens).", "citation": "@article{elazar_head,\n    author = {Elazar, Yanai and Goldberg, Yoav},\n    title = {Where\u2019s My Head? Definition, Data Set, and Models for Numeric Fused-Head Identification and Resolution},\n    journal = {Transactions of the Association for Computational Linguistics},\n    volume = {7},\n    number = {},\n    pages = {519-535},\n    year = {2019},\n    doi = {10.1162/tacl\\\\_a\\\\_00280},\n    URL = {https://doi.org/10.1162/tacl_a_00280},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181efa", "disabled": false, "gated": false, "likes": 1, "downloads": 431, "paperswithcode_id": "numeric-fused-head", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "oclar", "sha": "f5fdbc046fe78ba24b9fcbf479393c7c8fcf07e1", "lastModified": "2022-11-03T16:15:26.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "The researchers of OCLAR Marwan et al. (2019), they gathered Arabic costumer reviews from Google reviewsa and Zomato\nwebsite (https://www.zomato.com/lebanon) on wide scope of domain, including restaurants, hotels, hospitals, local shops,\netc.The corpus finally contains 3916 reviews in 5-rating scale. For this research purpose, the positive class considers\nrating stars from 5 to 3 of 3465 reviews, and the negative class is represented from values of 1 and 2 of about\n451 texts.", "citation": "@misc{Dua:2019 ,\nauthor = \"Dua, Dheeru and Graff, Casey\",\nyear = \"2017\",\ntitle = \"{UCI} Machine Learning Repository\",\nurl = \"http://archive.ics.uci.edu/ml\",\ninstitution = \"University of California, Irvine, School of Information and Computer Sciences\" }\n\n@InProceedings{AlOmari2019oclar,\ntitle = {Sentiment Classifier: Logistic Regression for Arabic Services Reviews in Lebanon},\nauthors={Al Omari, M., Al-Hajj, M., Hammami, N., & Sabra, A.},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181efb", "disabled": false, "gated": false, "likes": 1, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "offcombr", "sha": "e2653dd919d7b2a7b2162ebdf36c52df9e805bb7", "lastModified": "2023-01-25T14:41:55.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pt", "license:unknown", "hate-speech-detection", "region:us"], "private": false, "author": null, "description": "OffComBR: an annotated dataset containing for hate speech detection in Portuguese composed of news comments on the Brazilian Web.", "citation": "@article{Pelle2017,\ntitle={Offensive Comments in the Brazilian Web: a dataset and baseline results},\nauthor={Rogers P. de Pelle and Viviane P. Moreira},\nbooktitle={6th Brazilian Workshop on Social Network Analysis and Mining (BraSNAM)},\nyear={2017},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181efc", "disabled": false, "gated": false, "likes": 4, "downloads": 430, "paperswithcode_id": "offcombr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "offenseval2020_tr", "sha": "43d001ad76aeb2e64b187fe8ec0b09452b1a7af8", "lastModified": "2023-01-25T14:41:59.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:tr", "license:cc-by-2.0", "offensive-language-classification", "region:us"], "private": false, "author": null, "description": "OffensEval-TR 2020 is a Turkish offensive language corpus. The corpus consist of randomly sampled tweets and annotated in a similar way to OffensEval and GermEval.", "citation": "@InProceedings{coltekin2020lrec,\n author  = {Cagri Coltekin},\n year  = {2020},\n title  = {A Corpus of Turkish Offensive Language on Social Media},\n booktitle  = {Proceedings of The 12th Language Resources and Evaluation Conference},\n pages  = {6174--6184},\n address  = {Marseille, France},\n url  = {https://www.aclweb.org/anthology/2020.lrec-1.758},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181efd", "disabled": false, "gated": false, "likes": 3, "downloads": 302, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "offenseval_dravidian", "sha": "2e7741c956239af60c0473f0627223e6631f16b3", "lastModified": "2023-06-01T14:59:49.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:kn", "language:ml", "language:ta", "license:cc-by-4.0", "offensive-language", "region:us"], "private": false, "author": null, "description": "Offensive language identification in dravidian lanaguages dataset. The goal of this task is to identify offensive language content of the code-mixed dataset of comments/posts in Dravidian Languages ( (Tamil-English, Malayalam-English, and Kannada-English)) collected from social media.", "citation": "@inproceedings{dravidianoffensive-eacl,\ntitle={Findings of the Shared Task on {O}ffensive {L}anguage {I}dentification in {T}amil, {M}alayalam, and {K}annada},\nauthor={Chakravarthi, Bharathi Raja and\nPriyadharshini, Ruba and\nJose, Navya and\nM, Anand Kumar and\nMandl, Thomas and\nKumaresan, Prasanna Kumar and\nPonnsamy, Rahul and\nV,Hariharan and\nSherly, Elizabeth and\nMcCrae, John Philip },\nbooktitle = \"Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages\",\nmonth = April,\nyear = \"2021\",\npublisher = \"Association for Computational Linguistics\",\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181efe", "disabled": false, "gated": false, "likes": 2, "downloads": 633, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ofis_publik", "sha": "690dd439c8fdc5d0939f3f6db6ebfcf5e577f455", "lastModified": "2022-11-03T16:15:15.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:br", "language:fr", "license:unknown", "region:us"], "private": false, "author": null, "description": "Texts from the Ofis Publik ar Brezhoneg (Breton Language Board) provided by Francis Tyers\n2 languages, total number of files: 278\ntotal number of tokens: 2.12M\ntotal number of sentence fragments: 0.13M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }\n @inproceedings{tyers-2009-rule,\n    title = \"Rule-Based Augmentation of Training Data in {B}reton-{F}rench Statistical Machine Translation\",\n    author = \"Tyers, Francis M.\",\n    booktitle = \"Proceedings of the 13th Annual conference of the European Association for Machine Translation\",\n    month = may # \" 14{--}15\",\n    year = \"2009\",\n    address = \"Barcelona, Spain\",\n    publisher = \"European Association for Machine Translation\",\n    url = \"https://www.aclweb.org/anthology/2009.eamt-1.29\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181eff", "disabled": false, "gated": false, "likes": 0, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ohsumed", "sha": "a6159aa953215abfee43271ed0783e105d81de3b", "lastModified": "2022-11-18T21:34:41.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "The OHSUMED test collection is a set of 348,566 references from\nMEDLINE, the on-line medical information database, consisting of\ntitles and/or abstracts from 270 medical journals over a five-year\nperiod (1987-1991). The available fields are title, abstract, MeSH\nindexing terms, author, source, and publication type.", "citation": "@InProceedings{10.1007/978-1-4471-2099-5_20,\nauthor=\"Hersh, William\nand Buckley, Chris\nand Leone, T. J.\nand Hickam, David\",\neditor=\"Croft, Bruce W.\nand van Rijsbergen, C. J.\",\ntitle=\"OHSUMED: An Interactive Retrieval Evaluation and New Large Test Collection for Research\",\nbooktitle=\"SIGIR '94\",\nyear=\"1994\",\npublisher=\"Springer London\",\naddress=\"London\",\npages=\"192--201\",\nabstract=\"A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create a new large medical test collection, which was used in experiments with the SMART retrieval system to obtain baseline performance data as well as compare SMART with the other searchers.\",\nisbn=\"978-1-4471-2099-5\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f00", "disabled": false, "gated": false, "likes": 1, "downloads": 327, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ollie", "sha": "ffdea4edf0353c75877dff0a0e5639cb65d407af", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:other", "relation-extraction", "text-to-structured", "region:us"], "private": false, "author": null, "description": "The Ollie dataset includes two configs for the data\nused to train the Ollie informatation extraction algorithm, for 18M\nsentences and 3M sentences respectively.\n\nThis data is for academic use only. From the authors:\n\nOllie is a program that automatically identifies and extracts binary\nrelationships from English sentences. Ollie is designed for Web-scale\ninformation extraction, where target relations are not specified in\nadvance.\n\nOllie is our second-generation information extraction system . Whereas\nReVerb operates on flat sequences of tokens, Ollie works with the\ntree-like (graph with only small cycles) representation using\nStanford's compression of the dependencies. This allows Ollie to\ncapture expression that ReVerb misses, such as long-range relations.\n\nOllie also captures context that modifies a binary relation. Presently\nOllie handles attribution (He said/she believes) and enabling\nconditions (if X then).\n\nMore information is available at the Ollie homepage:\nhttps://knowitall.github.io/ollie/", "citation": "@inproceedings{ollie-emnlp12,\n  author = {Mausam and Michael Schmitz and Robert Bart and Stephen Soderland and Oren Etzioni},\n  title = {Open Language Learning for Information Extraction},\n  booktitle = {Proceedings of Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CONLL)},\n  year = {2012}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f01", "disabled": false, "gated": false, "likes": 0, "downloads": 434, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "omp", "sha": "c18d9165471d0b59a5c45e73bd9b7504e19b8786", "lastModified": "2023-01-25T14:42:05.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": "The \u201cOne Million Posts\u201d corpus is an annotated data set consisting of\nuser comments posted to an Austrian newspaper website (in German language).\n\nDER STANDARD is an Austrian daily broadsheet newspaper. On the newspaper\u2019s website,\nthere is a discussion section below each news article where readers engage in\nonline discussions. The data set contains a selection of user posts from the\n12 month time span from 2015-06-01 to 2016-05-31. There are 11,773 labeled and\n1,000,000 unlabeled posts in the data set. The labeled posts were annotated by\nprofessional forum moderators employed by the newspaper.\n\nThe data set contains the following data for each post:\n\n* Post ID\n* Article ID\n* Headline (max. 250 characters)\n* Main Body (max. 750 characters)\n* User ID (the user names used by the website have been re-mapped to new numeric IDs)\n* Time stamp\n* Parent post (replies give rise to tree-like discussion thread structures)\n* Status (online or deleted by a moderator)\n* Number of positive votes by other community members\n* Number of negative votes by other community members\n\nFor each article, the data set contains the following data:\n\n* Article ID\n* Publishing date\n* Topic Path (e.g.: Newsroom / Sports / Motorsports / Formula 1)\n* Title\n* Body\n\nDetailed descriptions of the post selection and annotation procedures are given in the paper.\n\n## Annotated Categories\n\nPotentially undesirable content:\n\n* Sentiment (negative/neutral/positive)\n    An important goal is to detect changes in the prevalent sentiment in a discussion, e.g.,\n    the location within the fora and the point in time where a turn from positive/neutral\n    sentiment to negative sentiment takes place.\n* Off-Topic (yes/no)\n    Posts which digress too far from the topic of the corresponding article.\n* Inappropriate (yes/no)\n    Swearwords, suggestive and obscene language, insults, threats etc.\n* Discriminating (yes/no)\n    Racist, sexist, misogynistic, homophobic, antisemitic and other misanthropic content.\n\nNeutral content that requires a reaction:\n\n* Feedback (yes/no)\n    Sometimes users ask questions or give feedback to the author of the article or the\n    newspaper in general, which may require a reply/reaction.\n\nPotentially desirable content:\n\n* Personal Stories (yes/no)\n    In certain fora, users are encouraged to share their personal stories, experiences,\n    anecdotes etc. regarding the respective topic.\n* Arguments Used (yes/no)\n    It is desirable for users to back their statements with rational argumentation,\n    reasoning and sources.", "citation": "@InProceedings{Schabus2017,\n  Author    = {Dietmar Schabus and Marcin Skowron and Martin Trapp},\n  Title     = {One Million Posts: A Data Set of German Online Discussions},\n  Booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)},\n  Pages     = {1241--1244},\n  Year      = {2017},\n  Address   = {Tokyo, Japan},\n  Doi       = {10.1145/3077136.3080711},\n  Month     = aug\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f02", "disabled": false, "gated": false, "likes": 1, "downloads": 624, "paperswithcode_id": "one-million-posts-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "onestop_english", "sha": "a3e5b1527f1e5080ec18cc023b61525ea3b823fb", "lastModified": "2023-01-25T14:42:09.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:text-simplification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "This dataset is a compilation of the OneStopEnglish corpus of texts written at three reading levels into one file.\nText documents are classified into three reading levels - ele, int, adv (Elementary, Intermediate and Advance).\nThis dataset demonstrates its usefulness for through two applica-tions - automatic  readability  assessment  and automatic text simplification.\nThe corpus consists of 189 texts, each in three versions/reading levels (567 in total).", "citation": "@inproceedings{vajjala-lucic-2018-onestopenglish,\n    title = {OneStopEnglish corpus: A new corpus for automatic readability assessment and text simplification},\n    author = {Sowmya Vajjala and Ivana Lu\u010di\u0107},\n    booktitle = {Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications},\n    year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f03", "disabled": false, "gated": false, "likes": 15, "downloads": 1231, "paperswithcode_id": "onestopenglish", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "onestop_qa", "sha": "2d7e346cb8c9c30980c56aad10547471777f0614", "lastModified": "2023-01-25T14:42:12.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|onestop_english", "language:en", "license:cc-by-sa-4.0", "arxiv:2004.14797", "region:us"], "private": false, "author": null, "description": "OneStopQA is a multiple choice reading comprehension dataset annotated according to the STARC (Structured Annotations for Reading Comprehension) scheme. The reading materials are Guardian articles taken from the [OneStopEnglish corpus](https://github.com/nishkalavallabhi/OneStopEnglishCorpus). Each article comes in three difficulty levels, Elementary, Intermediate and Advanced. Each paragraph is annotated with three multiple choice reading comprehension questions. The reading comprehension questions can be answered based on any of the three paragraph levels.", "citation": "@inproceedings{starc2020,\n      author    = {Berzak, Yevgeni and Malmaud, Jonathan and Levy, Roger},\n      title     = {STARC: Structured Annotations for Reading Comprehension},\n      booktitle = {ACL},\n      year      = {2020},\n      publisher = {Association for Computational Linguistics}\n      }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f04", "disabled": false, "gated": false, "likes": 4, "downloads": 295, "paperswithcode_id": "onestopqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "open_subtitles", "sha": "60f19d324367c1bc412a916b26c2f5d0cf606c3a", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:original", "language:af", "language:ar", "language:bg", "language:bn", "language:br", "language:bs", "language:ca", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:gl", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:is", "language:it", "language:ja", "language:ka", "language:kk", "language:ko", "language:lt", "language:lv", "language:mk", "language:ml", "language:ms", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:si", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:ta", "language:te", "language:th", "language:tl", "language:tr", "language:uk", "language:ur", "language:vi", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.\n\nIMPORTANT: If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/ to your website and to your reports and publications produced with the data!\n\nThis is a slightly cleaner version of the subtitle collection using improved sentence alignment and better language checking.\n\n62 languages, 1,782 bitexts\ntotal number of files: 3,735,070\ntotal number of tokens: 22.10G\ntotal number of sentence fragments: 3.35G", "citation": "P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f05", "disabled": false, "gated": false, "likes": 38, "downloads": 3487, "paperswithcode_id": "opensubtitles", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "openai_humaneval", "sha": "bd7ebee7436305b5ace9144a7357b4eb5676b417", "lastModified": "2022-11-29T16:41:19.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:mit", "code-generation", "arxiv:2107.03374", "region:us"], "private": false, "author": null, "description": "The HumanEval dataset released by OpenAI contains 164 handcrafted programming challenges together with unittests to very the viability of a proposed solution.", "citation": "@misc{chen2021evaluating,\n      title={Evaluating Large Language Models Trained on Code},\n      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},\n      year={2021},\n      eprint={2107.03374},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f06", "disabled": false, "gated": false, "likes": 105, "downloads": 54509, "paperswithcode_id": "humaneval", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "openbookqa", "sha": "1c468ff03f6647cf687096ffb895aa6e14d384c9", "lastModified": "2023-04-05T13:36:14.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "OpenBookQA aims to promote research in advanced question-answering, probing a deeper understanding of both the topic\n(with salient facts summarized as an open book, also provided with the dataset) and the language it is expressed in. In\nparticular, it contains questions that require multi-step reasoning, use of additional common and commonsense knowledge,\nand rich text comprehension.\nOpenBookQA is a new kind of question-answering dataset modeled after open book exams for assessing human understanding\nof a subject.", "citation": "@inproceedings{OpenBookQA2018,\n title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering},\n author={Todor Mihaylov and Peter Clark and Tushar Khot and Ashish Sabharwal},\n booktitle={EMNLP},\n year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f07", "disabled": false, "gated": false, "likes": 37, "downloads": 106856, "paperswithcode_id": "openbookqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "openslr", "sha": "35acb08bfa982b977bb3c80b49a9845506a39db0", "lastModified": "2023-06-01T14:59:55.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:af", "language:bn", "language:ca", "language:en", "language:es", "language:eu", "language:gl", "language:gu", "language:jv", "language:km", "language:kn", "language:ml", "language:mr", "language:my", "language:ne", "language:si", "language:st", "language:su", "language:ta", "language:te", "language:tn", "language:ve", "language:xh", "language:yo", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "OpenSLR is a site devoted to hosting speech and language resources, such as training corpora for speech recognition,\nand software related to speech recognition. We intend to be a convenient place for anyone to put resources that\nthey have created, so that they can be downloaded publicly.", "citation": "SLR32:\n@inproceedings{van-niekerk-etal-2017,\n    title = {{Rapid development of TTS corpora for four South African languages}},\n    author = {Daniel van Niekerk and Charl van Heerden and Marelie Davel and Neil Kleynhans and Oddur Kjartansson\n    and Martin Jansche and Linne Ha},\n    booktitle = {Proc. Interspeech 2017},\n    pages = {2178--2182},\n    address = {Stockholm, Sweden},\n    month = aug,\n    year  = {2017},\n    URL   = {http://dx.doi.org/10.21437/Interspeech.2017-1139}\n}\n\nSLR35, SLR36, SLR52, SLR53, SLR54:\n@inproceedings{kjartansson-etal-sltu2018,\n    title = {{Crowd-Sourced Speech Corpora for Javanese, Sundanese,  Sinhala, Nepali, and Bangladeshi Bengali}},\n    author = {Oddur Kjartansson and Supheakmungkol Sarin and Knot Pipatsrisawat and Martin Jansche and Linne Ha},\n    booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\n    year  = {2018},\n    address = {Gurugram, India},\n    month = aug,\n    pages = {52--55},\n    URL   = {https://dx.doi.org/10.21437/SLTU.2018-11},\n}\n\nSLR41, SLR42, SLR43, SLR44:\n@inproceedings{kjartansson-etal-tts-sltu2018,\n    title = {{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Framework for Bangla, Javanese,\n    Khmer, Nepali, Sinhala, and Sundanese}},\n    author = {Keshan Sodimana and Knot Pipatsrisawat and Linne Ha and Martin Jansche and Oddur Kjartansson and Pasindu\n    De Silva and Supheakmungkol Sarin},\n    booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\n    year  = {2018},\n    address = {Gurugram, India},\n    month = aug,\n    pages = {66--70},\n    URL   = {https://dx.doi.org/10.21437/SLTU.2018-14}\n}\n\nSLR63, SLR64, SLR65, SLR66, SLR78, SLR79:\n@inproceedings{he-etal-2020-open,\n  title = {{Open-source Multi-speaker Speech Corpora for Building Gujarati, Kannada, Malayalam, Marathi, Tamil and\n  Telugu Speech Synthesis Systems}},\n  author = {He, Fei and Chu, Shan-Hui Cathy and Kjartansson, Oddur and Rivera, Clara and Katanova, Anna and Gutkin,\n  Alexander and Demirsahin, Isin and Johny, Cibu and Jansche, Martin and Sarin, Supheakmungkol and Pipatsrisawat, Knot},\n  booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n  month = may,\n  year = {2020},\n  address = {Marseille, France},\n  publisher = {European Language Resources Association (ELRA)},\n  pages = {6494--6503},\n  url = {https://www.aclweb.org/anthology/2020.lrec-1.800},\n  ISBN = \"{979-10-95546-34-4},\n}\n\nSLR69, SLR76, SLR77:\n@inproceedings{kjartansson-etal-2020-open,\n    title = {{Open-Source High Quality Speech Datasets for Basque, Catalan and Galician}},\n    author = {Kjartansson, Oddur and Gutkin, Alexander and Butryna, Alena and Demirsahin, Isin and Rivera, Clara},\n    booktitle = {Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages\n    (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)},\n    year = {2020},\n    pages = {21--27},\n    month = may,\n    address = {Marseille, France},\n    publisher = {European Language Resources association (ELRA)},\n    url = {https://www.aclweb.org/anthology/2020.sltu-1.3},\n    ISBN = {979-10-95546-35-1},\n}\n\nSLR71, SLR71, SLR72, SLR73, SLR74, SLR75:\n@inproceedings{guevara-rukoz-etal-2020-crowdsourcing,\n    title = {{Crowdsourcing Latin American Spanish for Low-Resource Text-to-Speech}},\n    author = {Guevara-Rukoz, Adriana and Demirsahin, Isin and He, Fei and Chu, Shan-Hui Cathy and Sarin,\n    Supheakmungkol and Pipatsrisawat, Knot and Gutkin, Alexander and Butryna, Alena and Kjartansson, Oddur},\n    booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n    year = {2020},\n    month = may,\n    address = {Marseille, France},\n    publisher = {European Language Resources Association (ELRA)},\n    url = {https://www.aclweb.org/anthology/2020.lrec-1.801},\n    pages = {6504--6513},\n    ISBN = {979-10-95546-34-4},\n}\n\nSLR80\n@inproceedings{oo-etal-2020-burmese,\n    title = {{Burmese Speech Corpus, Finite-State Text Normalization and Pronunciation Grammars with an Application\n    to Text-to-Speech}},\n    author = {Oo, Yin May and Wattanavekin, Theeraphol and Li, Chenfang and De Silva, Pasindu and Sarin,\n    Supheakmungkol and Pipatsrisawat, Knot and Jansche, Martin and Kjartansson, Oddur and Gutkin, Alexander},\n    booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n    month = may,\n    year = {2020},\n    pages = \"6328--6339\",\n    address = {Marseille, France},\n    publisher = {European Language Resources Association (ELRA)},\n    url = {https://www.aclweb.org/anthology/2020.lrec-1.777},\n    ISBN = {979-10-95546-34-4},\n}\n\nSLR86\n@inproceedings{gutkin-et-al-yoruba2020,\n    title = {{Developing an Open-Source Corpus of Yoruba Speech}},\n    author = {Alexander Gutkin and I\u015f\u0131n Demir\u015fahin and Oddur Kjartansson and Clara Rivera and K\u00f3\u0323l\u00e1 T\u00fab\u00f2\u0323s\u00fan},\n    booktitle = {Proceedings of Interspeech 2020},\n    pages = {404--408},\n    month = {October},\n    year = {2020},\n    address = {Shanghai, China},\n    publisher = {International Speech and Communication Association (ISCA)},\n    doi = {10.21437/Interspeech.2020-1096},\n    url = {https://dx.doi.org/10.21437/Interspeech.2020-1096},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f08", "disabled": false, "gated": false, "likes": 15, "downloads": 5159, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Skylion007/openwebtext", "sha": "f2cb45cb946a0126a94a7b141b3376ceb527518f", "lastModified": "2023-04-05T13:36:17.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "Skylion007", "description": "An open-source replication of the WebText dataset from OpenAI.", "citation": "@misc{Gokaslan2019OpenWeb,\n  title={OpenWebText Corpus},\n  author={Aaron Gokaslan*, Vanya Cohen*, Ellie Pavlick, Stefanie Tellex},\n  howpublished{\\\\url{http://Skylion007.github.io/OpenWebTextCorpus}},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f09", "disabled": false, "gated": false, "likes": 213, "downloads": 7369, "paperswithcode_id": "openwebtext", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opinosis", "sha": "a726b32edc32d8ee3965037249ae9e21d8aeff18", "lastModified": "2023-04-05T13:36:20.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:apache-2.0", "abstractive-summarization", "region:us"], "private": false, "author": null, "description": "The Opinosis Opinion Dataset consists of sentences extracted from reviews for 51 topics.\nTopics and opinions are obtained from Tripadvisor, Edmunds.com and Amazon.com.", "citation": "@inproceedings{ganesan2010opinosis,\n  title={Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions},\n  author={Ganesan, Kavita and Zhai, ChengXiang and Han, Jiawei},\n  booktitle={Proceedings of the 23rd International Conference on Computational Linguistics},\n  pages={340--348},\n  year={2010},\n  organization={Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0a", "disabled": false, "gated": false, "likes": 1, "downloads": 765, "paperswithcode_id": "opinosis", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus100", "sha": "1fe1a483e69d3e6995bdf641efc364647eb158b9", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:extended", "language:af", "language:am", "language:an", "language:ar", "language:as", "language:az", "language:be", "language:bg", "language:bn", "language:br", "language:bs", "language:ca", "language:cs", "language:cy", "language:da", "language:de", "language:dz", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gu", "language:ha", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:ig", "language:is", "language:it", "language:ja", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:li", "language:lt", "language:lv", "language:mg", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:nb", "language:ne", "language:nl", "language:nn", "language:no", "language:oc", "language:or", "language:pa", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:rw", "language:se", "language:sh", "language:si", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:wa", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "license:unknown", "arxiv:2004.11867", "region:us"], "private": false, "author": null, "description": "OPUS-100 is English-centric, meaning that all training pairs include English on either the source or target side.\nThe corpus covers 100 languages (including English).OPUS-100 contains approximately 55M sentence pairs.\nOf the 99 language pairs, 44 have 1M sentence pairs of training data, 73 have at least 100k, and 95 have at least 10k.", "citation": "@misc{zhang2020improving,\n      title={Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation},\n      author={Biao Zhang and Philip Williams and Ivan Titov and Rico Sennrich},\n      year={2020},\n      eprint={2004.11867},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0b", "disabled": false, "gated": false, "likes": 60, "downloads": 30762, "paperswithcode_id": "opus-100", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_books", "sha": "717b2cb7f80cb7d63294f1f182e14b25a6bea8fb", "lastModified": "2022-11-03T16:47:07.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ca", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:fi", "language:fr", "language:hu", "language:it", "language:nl", "language:no", "language:pl", "language:pt", "language:ru", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a collection of copyright free books aligned by Andras Farkas, which are available from http://www.farkastranslations.com/bilingual_books.php\nNote that the texts are rather dated due to copyright issues and that some of them are manually reviewed (check the meta-data at the top of the corpus files in XML). The source is multilingually aligned, which is available from http://www.farkastranslations.com/bilingual_books.php. In OPUS, the alignment is formally bilingual but the multilingual alignment can be recovered from the XCES sentence alignment files. Note also that the alignment units from the original source may include multi-sentence paragraphs, which are split and sentence-aligned in OPUS.\nAll texts are freely available for personal, educational and research use. Commercial use (e.g. reselling as parallel books) and mass redistribution without explicit permission are not granted. Please acknowledge the source when using the data!\n\n16 languages, 64 bitexts\ntotal number of files: 158\ntotal number of tokens: 19.50M\ntotal number of sentence fragments: 0.91M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0c", "disabled": false, "gated": false, "likes": 24, "downloads": 22187, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_dgt", "sha": "4a22f495c4e9e779a2b3b6bc031165850551aa0d", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sh", "language:sk", "language:sl", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "A collection of translation memories provided by the JRC. Source: https://ec.europa.eu/jrc/en/language-technologies/dgt-translation-memory\n25 languages, 299 bitexts\ntotal number of files: 817,410\ntotal number of tokens: 2.13G\ntotal number of sentence fragments: 113.52M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0d", "disabled": false, "gated": false, "likes": 1, "downloads": 1536, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_dogc", "sha": "ee0b45b78d53aa646ad6430d36a9d0a742de79f1", "lastModified": "2022-11-03T16:07:43.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "language:ca", "language:es", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "This is a collection of documents from the Official Journal of the Government of Catalonia, in Catalan and Spanish languages, provided by Antoni Oliver Gonzalez from the Universitat Oberta de Catalunya.", "citation": "@inproceedings{tiedemann-2012-parallel,\n    title = \"Parallel Data, Tools and Interfaces in {OPUS}\",\n    author = {Tiedemann, J{\\\"o}rg},\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)\",\n    month = may,\n    year = \"2012\",\n    address = \"Istanbul, Turkey\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf\",\n    pages = \"2214--2218\",\n    abstract = \"This paper presents the current status of OPUS, a growing language resource of parallel corpora and related tools. The focus in OPUS is to provide freely available data sets in various formats together with basic annotation to be useful for applications in computational linguistics, translation studies and cross-linguistic corpus studies. In this paper, we report about new data sets and their features, additional annotation tools and models provided from the website and essential interfaces and on-line services included in the project.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0e", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_elhuyar", "sha": "2b1d5ab9ab358707d078cfaefec0b4df29d39aa5", "lastModified": "2022-11-03T16:07:47.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:es", "language:eu", "license:unknown", "region:us"], "private": false, "author": null, "description": "Dataset provided by the foundation Elhuyar, which is having data in languages Spanish to Basque.", "citation": "@InProceedings{opus:Elhuyar,\ntitle = {Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)},\nauthors={J. Tiedemann},\nyear={2012}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f0f", "disabled": false, "gated": false, "likes": 0, "downloads": 281, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_euconst", "sha": "8628eed6033702703a32a86d70e5000b21bf29bc", "lastModified": "2022-11-03T16:47:26.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:sk", "language:sl", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus collected from the European Constitution for 21 language.", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f10", "disabled": false, "gated": false, "likes": 7, "downloads": 29910, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_finlex", "sha": "32548153e33a8772dba9918b412fc22b0bb5a4a7", "lastModified": "2022-11-03T16:08:11.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "language:fi", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Finlex Data Base is a comprehensive collection of legislative and other judicial information of Finland, which is available in Finnish, Swedish and partially in English. This corpus is taken from the Semantic Finlex serice that provides the Finnish and Swedish data as linked open data and also raw XML files.", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f11", "disabled": false, "gated": false, "likes": 1, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_fiskmo", "sha": "8967f7ae63f063d123429e68b09f83edb545a8ce", "lastModified": "2022-11-03T16:08:01.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "language:fi", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "fiskmo, a massive parallel corpus for Finnish and Swedish.", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f12", "disabled": false, "gated": false, "likes": 0, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_gnome", "sha": "1156f67da59a5d6fa0947612f4deacfeb23b4984", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:af", "language:am", "language:an", "language:ang", "language:ar", "language:as", "language:ast", "language:az", "language:bal", "language:be", "language:bem", "language:bg", "language:bn", "language:bo", "language:br", "language:brx", "language:bs", "language:ca", "language:crh", "language:cs", "language:csb", "language:cy", "language:da", "language:de", "language:dv", "language:dz", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fo", "language:fr", "language:fur", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:gu", "language:gv", "language:ha", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:ia", "language:id", "language:ig", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:ka", "language:kg", "language:kk", "language:km", "language:kn", "language:ko", "language:kr", "language:ks", "language:ku", "language:ky", "language:la", "language:lg", "language:li", "language:lo", "language:lt", "language:lv", "language:mai", "language:mg", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:mus", "language:my", "language:nb", "language:nds", "language:ne", "language:nhn", "language:nl", "language:nn", "language:no", "language:nqo", "language:nr", "language:nso", "language:oc", "language:or", "language:os", "language:pa", "language:pl", "language:ps", "language:pt", "language:quz", "language:ro", "language:ru", "language:rw", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:st", "language:sv", "language:sw", "language:szl", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tl", "language:tr", "language:ts", "language:tt", "language:tyj", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:wa", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus of GNOME localization files. Source: https://l10n.gnome.org\n\n187 languages, 12,822 bitexts\ntotal number of files: 113,344\ntotal number of tokens: 267.27M\ntotal number of sentence fragments: 58.12M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f13", "disabled": false, "gated": false, "likes": 1, "downloads": 1556, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_infopankki", "sha": "90d8269153fb98f4a500af5a1c2fdc3c108c8483", "lastModified": "2023-06-01T14:59:57.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "language:en", "language:es", "language:et", "language:fa", "language:fi", "language:fr", "language:ru", "language:so", "language:sv", "language:tr", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus of 12 languages, 66 bitexts.", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f14", "disabled": false, "gated": false, "likes": 1, "downloads": 9758, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_memat", "sha": "f330ca446da7dddfa07c8bab6aaf45f87bb79af9", "lastModified": "2022-11-03T16:08:11.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:xh", "license:unknown", "region:us"], "private": false, "author": null, "description": "Xhosa-English parallel corpora, funded by EPSRC, the Medical Machine Translation project worked on machine translation between ixiXhosa and English, with a focus on the medical domain.", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f15", "disabled": false, "gated": false, "likes": 1, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_montenegrinsubs", "sha": "6348068fac1fafbbe14ba6456c079c48d15ad483", "lastModified": "2022-11-03T16:08:11.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:cnr", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Opus MontenegrinSubs dataset for machine translation task, for language pair en-me: english and montenegrin", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f16", "disabled": false, "gated": false, "likes": 0, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_openoffice", "sha": "b036c09097239d3163ee6725d88a385ea9a45d6e", "lastModified": "2023-06-01T14:59:55.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:ja", "language:ru", "language:sv", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A collection of documents from http://www.openoffice.org/.", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f17", "disabled": false, "gated": false, "likes": 4, "downloads": 4103, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_paracrawl", "sha": "922b0fbef09a10780020844b647a1e1e1028c5b8", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:bg", "language:ca", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fi", "language:fr", "language:ga", "language:gl", "language:hr", "language:hu", "language:is", "language:it", "language:km", "language:ko", "language:lt", "language:lv", "language:mt", "language:my", "language:nb", "language:ne", "language:nl", "language:nn", "language:pl", "language:pt", "language:ro", "language:ru", "language:si", "language:sk", "language:sl", "language:so", "language:sv", "language:sw", "language:tl", "language:uk", "language:zh", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Parallel corpora from Web Crawls collected in the ParaCrawl project.\n\n42 languages, 43 bitexts\ntotal number of files: 59,996\ntotal number of tokens: 56.11G\ntotal number of sentence fragments: 3.13G", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f18", "disabled": false, "gated": false, "likes": 5, "downloads": 1592, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_rf", "sha": "9d52206cb802bc92dd0ee480240ed72e3f6c458d", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "RF is a tiny parallel corpus of the Declarations of the Swedish Government and its translations.", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f19", "disabled": false, "gated": false, "likes": 0, "downloads": 1554, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_tedtalks", "sha": "d12ce9db2419cd92455d0178af75e55313a01ee0", "lastModified": "2022-11-03T16:15:24.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:hr", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a Croatian-English parallel corpus of transcribed and translated TED talks, originally extracted from https://wit3.fbk.eu. The corpus is compiled by \u017deljko Agi\u0107 and is taken from http://lt.ffzg.hr/zagic provided under the CC-BY-NC-SA license.\n2 languages, total number of files: 2\ntotal number of tokens: 2.81M\ntotal number of sentence fragments: 0.17M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1a", "disabled": false, "gated": false, "likes": 0, "downloads": 303, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_ubuntu", "sha": "37979be0671122540b6877962ac89cc5e4c27c6d", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:ace", "language:af", "language:ak", "language:am", "language:an", "language:ang", "language:ar", "language:ary", "language:as", "language:ast", "language:az", "language:ba", "language:bal", "language:be", "language:bem", "language:ber", "language:bg", "language:bho", "language:bn", "language:bo", "language:br", "language:brx", "language:bs", "language:bua", "language:byn", "language:ca", "language:ce", "language:ceb", "language:chr", "language:ckb", "language:co", "language:crh", "language:cs", "language:csb", "language:cv", "language:cy", "language:da", "language:de", "language:dsb", "language:dv", "language:dz", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:ff", "language:fi", "language:fil", "language:fo", "language:fr", "language:frm", "language:frp", "language:fur", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:grc", "language:gu", "language:guc", "language:gv", "language:ha", "language:haw", "language:he", "language:hi", "language:hil", "language:hne", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ig", "language:io", "language:is", "language:it", "language:iu", "language:ja", "language:jbo", "language:jv", "language:ka", "language:kab", "language:kg", "language:kk", "language:kl", "language:km", "language:kn", "language:ko", "language:kok", "language:ks", "language:ksh", "language:ku", "language:kw", "language:ky", "language:la", "language:lb", "language:lg", "language:li", "language:lij", "language:lld", "language:ln", "language:lo", "language:lt", "language:ltg", "language:lv", "language:mai", "language:mg", "language:mh", "language:mhr", "language:mi", "language:miq", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:mus", "language:my", "language:nan", "language:nap", "language:nb", "language:nds", "language:ne", "language:nhn", "language:nl", "language:nn", "language:no", "language:nso", "language:ny", "language:oc", "language:om", "language:or", "language:os", "language:pa", "language:pam", "language:pap", "language:pl", "language:pms", "language:pmy", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:rom", "language:ru", "language:rw", "language:sa", "language:sc", "language:sco", "language:sd", "language:se", "language:shn", "language:shs", "language:si", "language:sk", "language:sl", "language:sm", "language:sml", "language:sn", "language:so", "language:son", "language:sq", "language:sr", "language:st", "language:sv", "language:sw", "language:syr", "language:szl", "language:ta", "language:te", "language:tet", "language:tg", "language:th", "language:ti", "language:tk", "language:tl", "language:tlh", "language:tr", "language:trv", "language:ts", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:ve", "language:vec", "language:vi", "language:wa", "language:wae", "language:wo", "language:xal", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "language:zza", "license:bsd-3-clause", "region:us"], "private": false, "author": null, "description": "A parallel corpus of Ubuntu localization files. Source: https://translations.launchpad.net\n244 languages, 23,988 bitexts\ntotal number of files: 30,959\ntotal number of tokens: 29.84M\ntotal number of sentence fragments: 7.73M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1b", "disabled": false, "gated": false, "likes": 1, "downloads": 1555, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_wikipedia", "sha": "b18412abe9ae946e1ff4de64b269cb81d6201498", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "language:bg", "language:cs", "language:de", "language:el", "language:en", "language:es", "language:fa", "language:fr", "language:he", "language:hu", "language:it", "language:nl", "language:pl", "language:pt", "language:ro", "language:ru", "language:sl", "language:tr", "language:vi", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a corpus of parallel sentences extracted from Wikipedia by Krzysztof Wo\u0142k and Krzysztof Marasek. Please cite the following publication if you use the data: Krzysztof Wo\u0142k and Krzysztof Marasek: Building Subject-aligned Comparable Corpora and Mining it for Truly Parallel Sentence Pairs., Procedia Technology, 18, Elsevier, p.126-132, 2014\n20 languages, 36 bitexts\ntotal number of files: 114\ntotal number of tokens: 610.13M\ntotal number of sentence fragments: 25.90M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1c", "disabled": false, "gated": false, "likes": 5, "downloads": 1114, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "opus_xhosanavy", "sha": "70d285ab81b0e0cd87af8d98240ee0fe246180a9", "lastModified": "2022-11-03T16:08:13.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:xh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset is designed for machine translation from English to Xhosa.", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1d", "disabled": false, "gated": false, "likes": 3, "downloads": 349, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "orange_sum", "sha": "3a62c0414abfcd3120ab1e1cf2f340cc06a36c3a", "lastModified": "2022-11-18T21:36:52.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-headline-generation", "task_ids:news-articles-summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fr", "license:unknown", "arxiv:2010.12321", "region:us"], "private": false, "author": null, "description": "The OrangeSum dataset was inspired by the XSum dataset. It was created by scraping the \"Orange Actu\" website: https://actu.orange.fr/. Orange S.A. is a large French multinational telecommunications corporation, with 266M customers worldwide. Scraped pages cover almost a decade from Feb 2011 to Sep 2020. They belong to five main categories: France, world, politics, automotive, and society. The society category is itself divided into 8 subcategories: health, environment, people, culture, media, high-tech, unsual (\"insolite\" in French), and miscellaneous.\n\nEach article featured a single-sentence title as well as a very brief abstract, both professionally written by the author of the article. These two fields were extracted from each page, thus creating two summarization tasks: OrangeSum Title and OrangeSum Abstract.", "citation": "@article{eddine2020barthez,\n  title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model},\n  author={Eddine, Moussa Kamal and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n  journal={arXiv preprint arXiv:2010.12321},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1e", "disabled": false, "gated": false, "likes": 3, "downloads": 798, "paperswithcode_id": "orangesum", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "oscar", "sha": "9877b42e186f4bee4220a0ff14746dd7a9baca66", "lastModified": "2023-06-01T14:59:59.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:100M<n<1B", "size_categories:10K<n<100K", "size_categories:10M<n<100M", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:original", "language:af", "language:als", "language:am", "language:an", "language:ar", "language:arz", "language:as", "language:ast", "language:av", "language:az", "language:azb", "language:ba", "language:bar", "language:bcl", "language:be", "language:bg", "language:bh", "language:bn", "language:bo", "language:bpy", "language:br", "language:bs", "language:bxr", "language:ca", "language:cbk", "language:ce", "language:ceb", "language:ckb", "language:cs", "language:cv", "language:cy", "language:da", "language:de", "language:diq", "language:dsb", "language:dv", "language:el", "language:eml", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:frr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:gom", "language:gu", "language:he", "language:hi", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:ilo", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:krc", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lb", "language:lez", "language:li", "language:lmo", "language:lo", "language:lrc", "language:lt", "language:lv", "language:mai", "language:mg", "language:mhr", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:mrj", "language:ms", "language:mt", "language:mwl", "language:my", "language:myv", "language:mzn", "language:nah", "language:nap", "language:nds", "language:ne", "language:new", "language:nl", "language:nn", "language:no", "language:oc", "language:or", "language:os", "language:pa", "language:pam", "language:pl", "language:pms", "language:pnb", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:ru", "language:sa", "language:sah", "language:scn", "language:sd", "language:sh", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tl", "language:tr", "language:tt", "language:tyv", "language:ug", "language:uk", "language:ur", "language:uz", "language:vec", "language:vi", "language:vo", "language:wa", "language:war", "language:wuu", "language:xal", "language:xmf", "language:yi", "language:yo", "language:yue", "language:zh", "license:cc0-1.0", "arxiv:2010.14571", "region:us"], "private": false, "author": null, "description": "The Open Super-large Crawled ALMAnaCH coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\", "citation": "@inproceedings{ortiz-suarez-etal-2020-monolingual,\n    title = \"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages\",\n    author = \"Ortiz Su{\\'a}rez, Pedro Javier  and\n      Romary, Laurent  and\n      Sagot, Benoit\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.156\",\n    pages = \"1703--1714\",\n    abstract = \"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures.\",\n}\n\n@inproceedings{OrtizSuarezSagotRomary2019,\n  author    = {Pedro Javier {Ortiz Su{\\'a}rez} and Benoit Sagot and Laurent Romary},\n  title     = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},\n  editor    = {Piotr Ba\u0144ski and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\\\"u}ngen and Caroline Iliadi},\n  publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-9021},\n  url       = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},\n  pages     = {9 -- 16},\n  year      = {2019},\n  abstract  = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},\n  language  = {en}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f1f", "disabled": false, "gated": false, "likes": 127, "downloads": 57575, "paperswithcode_id": "oscar", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "para_pat", "sha": "95727dd3c867cb433a20308d0cf067f6abba936a", "lastModified": "2022-12-02T11:39:09.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:translation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:cs", "language:de", "language:el", "language:en", "language:es", "language:fr", "language:hu", "language:ja", "language:ko", "language:pt", "language:ro", "language:ru", "language:sk", "language:uk", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "ParaPat: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\n\nThis dataset contains the developed parallel corpus from the open access Google\nPatents dataset in 74 language pairs, comprising more than 68 million sentences\nand 800 million tokens. Sentences were automatically aligned using the Hunalign algorithm\nfor the largest 22 language pairs, while the others were abstract (i.e. paragraph) aligned.", "citation": "@inproceedings{soares-etal-2020-parapat,\n    title = \"{P}ara{P}at: The Multi-Million Sentences Parallel Corpus of Patents Abstracts\",\n    author = \"Soares, Felipe  and\n      Stevenson, Mark  and\n      Bartolome, Diego  and\n      Zaretskaya, Anna\",\n    booktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.465\",\n    pages = \"3769--3774\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f21", "disabled": false, "gated": false, "likes": 9, "downloads": 2972, "paperswithcode_id": "parapat", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "parsinlu_reading_comprehension", "sha": "1ecef505b04ed347ccc330b3e0b22face243409b", "lastModified": "2023-08-16T17:04:40.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|wikipedia|google", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": null, "description": "A Persian reading comprehenion task (generating an answer, given a question and a context paragraph).\nThe questions are mined using Google auto-complete, their answers and the corresponding evidence documents are manually annotated by native speakers.", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f22", "disabled": false, "gated": false, "likes": 1, "downloads": 304, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pass", "sha": "d2a18cc9520a07ab8061591dc1bda8e1b17d734b", "lastModified": "2022-11-03T16:15:51.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:extended|yffc100M", "language:en", "license:cc-by-4.0", "image-self-supervised pretraining", "arxiv:2109.13228", "region:us"], "private": false, "author": null, "description": "PASS (Pictures without humAns for Self-Supervision) is a large-scale dataset of 1,440,191 images that does not include any humans\nand which can be used for high-quality pretraining while significantly reducing privacy concerns.\nThe PASS images are sourced from the YFCC-100M dataset.", "citation": "@Article{asano21pass,\nauthor = \"Yuki M. Asano and Christian Rupprecht and Andrew Zisserman and Andrea Vedaldi\",\ntitle = \"PASS: An ImageNet replacement for self-supervised pretraining without humans\",\njournal = \"NeurIPS Track on Datasets and Benchmarks\",\nyear = \"2021\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f23", "disabled": false, "gated": false, "likes": 1, "downloads": 282, "paperswithcode_id": "pass", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "paws-x", "sha": "8a04d940a42cd40658986fdd8e3da561533a3646", "lastModified": "2023-01-25T14:42:16.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "task_ids:multi-input-text-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|other-paws", "language:de", "language:en", "language:es", "language:fr", "language:ja", "language:ko", "language:zh", "license:other", "paraphrase-identification", "arxiv:1908.11828", "region:us"], "private": false, "author": null, "description": "PAWS-X, a multilingual version of PAWS (Paraphrase Adversaries from Word Scrambling) for six languages.\n\nThis dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine\ntranslated training pairs in six typologically distinct languages: French, Spanish, German,\nChinese, Japanese, and Korean. English language is available by default. All translated\npairs are sourced from examples in PAWS-Wiki.\n\nFor further details, see the accompanying paper: PAWS-X: A Cross-lingual Adversarial Dataset\nfor Paraphrase Identification (https://arxiv.org/abs/1908.11828)\n\nNOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1.", "citation": "@InProceedings{pawsx2019emnlp,\n  title = {{PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification}},\n  author = {Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},\n  booktitle = {Proc. of EMNLP},\n  year = {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f24", "disabled": false, "gated": false, "likes": 17, "downloads": 26191, "paperswithcode_id": "paws-x", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "paws", "sha": "cd6b868f3d2d71e9708ed861deee4bbc4d32441e", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "task_ids:multi-input-text-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "paraphrase-identification", "arxiv:1904.01130", "region:us"], "private": false, "author": null, "description": "PAWS: Paraphrase Adversaries from Word Scrambling\n\nThis dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature\nthe importance of modeling structure, context, and word order information for the problem\nof paraphrase identification. The dataset has two subsets, one based on Wikipedia and the\nother one based on the Quora Question Pairs (QQP) dataset.\n\nFor further details, see the accompanying paper: PAWS: Paraphrase Adversaries from Word Scrambling\n(https://arxiv.org/abs/1904.01130)\n\nPAWS-QQP is not available due to license of QQP. It must be reconstructed by downloading the original\ndata and then running our scripts to produce the data and attach the labels.\n\nNOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1.", "citation": "@InProceedings{paws2019naacl,\n  title = {{PAWS: Paraphrase Adversaries from Word Scrambling}},\n  author = {Zhang, Yuan and Baldridge, Jason and He, Luheng},\n  booktitle = {Proc. of NAACL},\n  year = {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f25", "disabled": false, "gated": false, "likes": 17, "downloads": 8002, "paperswithcode_id": "paws", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pec", "sha": "6f47c6cbcabe271411c62960fe429160067f9f01", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-retrieval", "task_ids:dialogue-modeling", "task_ids:utterance-retrieval", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "\\\r\nA dataset of around 350K persona-based empathetic conversations. Each speaker is associated with a persona, which comprises multiple persona sentences. The response of each conversation is empathetic.", "citation": "\\\r\n@inproceedings{zhong2020towards,\r\n    title = \"Towards Persona-Based Empathetic Conversational Models\",\r\n    author = \"Zhong, Peixiang  and\r\n      Zhang, Chen  and\r\n      Wang, Hao  and\r\n      Liu, Yong  and\r\n      Miao, Chunyan\",\r\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\r\n    year = \"2020\",\r\n    publisher = \"Association for Computational Linguistics\",\r\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.531\",\r\n    pages = \"6556--6566\"}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f26", "disabled": false, "gated": false, "likes": 4, "downloads": 562, "paperswithcode_id": "pec", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/peer_read", "sha": "53e19322c88bb01c1b0c6a61bde68bc2b1c3028e", "lastModified": "2022-11-18T21:37:46.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "acceptability-classification", "arxiv:1804.09635", "region:us"], "private": false, "author": "allenai", "description": "PearRead is a dataset of scientific peer reviews available to help researchers study this important artifact. The dataset consists of over 14K paper drafts and the corresponding accept/reject decisions in top-tier venues including ACL, NIPS and ICLR, as well as over 10K textual peer reviews written by experts for a subset of the papers.", "citation": "@inproceedings{kang18naacl,\n  title = {A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications},\n  author = {Dongyeop Kang and Waleed Ammar and Bhavana Dalvi and Madeleine van Zuylen and Sebastian Kohlmeier and Eduard Hovy and Roy Schwartz},\n  booktitle = {Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL)},\n  address = {New Orleans, USA},\n  month = {June},\n  url = {https://arxiv.org/abs/1804.09635},\n  year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f27", "disabled": false, "gated": false, "likes": 4, "downloads": 444, "paperswithcode_id": "peerread", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "peoples_daily_ner", "sha": "5fb3484812f531f8369e90f602bf0c9c08a182b4", "lastModified": "2023-01-25T14:42:22.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "People's Daily NER Dataset is a commonly used dataset for Chinese NER, with\ntext from People's Daily (\u4eba\u6c11\u65e5\u62a5), the largest official newspaper.\n\nThe dataset is in BIO scheme. Entity types are: PER (person), ORG (organization)\nand LOC (location).", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f28", "disabled": false, "gated": false, "likes": 6, "downloads": 829, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "per_sent", "sha": "9fefc078dc803feae025342f7e98bc7c14ea52b9", "lastModified": "2023-01-25T14:42:26.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-MPQA-KBP Challenge-MediaRank", "language:en", "license:unknown", "arxiv:2011.06128", "region:us"], "private": false, "author": null, "description": "Person SenTiment (PerSenT) is a crowd-sourced dataset that captures the sentiment of an author towards the main entity in a news article. This dataset contains annotation for 5.3k documents and 38k paragraphs covering 3.2k unique entities.\n\nThe dataset consists of sentiment annotations on news articles about people. For each article, annotators judge what the author\u2019s sentiment is towards the main (target) entity of the article. The annotations also include similar judgments on paragraphs within the article.\n\nTo split the dataset, entities into 4 mutually exclusive sets. Due to the nature of news collections, some entities tend to dominate the collection. In the collection, there were four entities which were the main entity in nearly 800 articles. To avoid these entities from dominating the train or test splits, we moved them to a separate test collection. We split the remaining into a training, dev, and test sets at random. Thus our collection includes one standard test set consisting of articles drawn at random (Test Standard -- `test_random`), while the other is a test set which contains multiple articles about a small number of popular entities (Test Frequent -- `test_fixed`).", "citation": "@inproceedings{bastan2020authors,\n      title={Author's Sentiment Prediction},\n      author={Mohaddeseh Bastan and Mahnaz Koupaee and Youngseo Son and Richard Sicoli and Niranjan Balasubramanian},\n      year={2020},\n      eprint={2011.06128},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f29", "disabled": false, "gated": false, "likes": 0, "downloads": 351, "paperswithcode_id": "persent", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persian_ner", "sha": "5f8e56eb51d2eae2a0b69b3f1285c9b697742be9", "lastModified": "2023-01-25T14:42:29.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:fa", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The dataset includes 250,015 tokens and 7,682 Persian sentences in total. It is available in 3 folds to be used in turn as training and test sets. The NER tags are in IOB format.", "citation": "@inproceedings{poostchi-etal-2016-personer,\n    title = \"{P}erso{NER}: {P}ersian Named-Entity Recognition\",\n    author = \"Poostchi, Hanieh  and\n      Zare Borzeshi, Ehsan  and\n      Abdous, Mohammad  and\n      Piccardi, Massimo\",\n    booktitle = \"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers\",\n    month = dec,\n    year = \"2016\",\n    address = \"Osaka, Japan\",\n    publisher = \"The COLING 2016 Organizing Committee\",\n    url = \"https://www.aclweb.org/anthology/C16-1319\",\n    pages = \"3381--3389\",\n    abstract = \"Named-Entity Recognition (NER) is still a challenging task for languages with low digital resources. The main difficulties arise from the scarcity of annotated corpora and the consequent problematic training of an effective NER pipeline. To abridge this gap, in this paper we target the Persian language that is spoken by a population of over a hundred million people world-wide. We first present and provide ArmanPerosNERCorpus, the first manually-annotated Persian NER corpus. Then, we introduce PersoNER, an NER pipeline for Persian that leverages a word embedding and a sequential max-margin classifier. The experimental results show that the proposed approach is capable of achieving interesting MUC7 and CoNNL scores while outperforming two alternatives based on a CRF and a recurrent neural network.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2a", "disabled": false, "gated": false, "likes": 0, "downloads": 560, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pg19", "sha": "afcaeaf41d7d7a2e8d0169b44fe506cc48602ae3", "lastModified": "2023-07-28T09:21:25.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1911.05507", "region:us"], "private": false, "author": null, "description": "This repository contains the PG-19 language modeling benchmark.\nIt includes a set of books extracted from the Project Gutenberg books library, that were published before 1919.\nIt also contains metadata of book titles and publication dates.\n\nPG-19 is over double the size of the Billion Word benchmark and contains documents that are 20X longer, on average, than the WikiText long-range language modelling benchmark.\nBooks are partitioned into a train, validation, and test set. Book metadata is stored in metadata.csv which contains (book_id, short_book_title, publication_date).\n\nUnlike prior benchmarks, we do not constrain the vocabulary size --- i.e. mapping rare words to an UNK token --- but instead release the data as an open-vocabulary benchmark. The only processing of the text that has been applied is the removal of boilerplate license text, and the mapping of offensive discriminatory words as specified by Ofcom to placeholder tokens. Users are free to model the data at the character-level, subword-level, or via any mechanism that can model an arbitrary string of text.\nTo compare models we propose to continue measuring the word-level perplexity, by calculating the total likelihood of the dataset (via any chosen subword vocabulary or character-based scheme) divided by the number of tokens --- specified below in the dataset statistics table.\nOne could use this dataset for benchmarking long-range language models, or use it to pre-train for other natural language processing tasks which require long-range reasoning, such as LAMBADA or NarrativeQA. We would not recommend using this dataset to train a general-purpose language model, e.g. for applications to a production-system dialogue agent, due to the dated linguistic style of old texts and the inherent biases present in historical writing.", "citation": "@article{raecompressive2019,\n  author = {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and\n            Hillier, Chloe and Lillicrap, Timothy P},\n  title = {Compressive Transformers for Long-Range Sequence Modelling},\n  journal = {arXiv preprint},\n  url = {https://arxiv.org/abs/1911.05507},\n  year = {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2b", "disabled": false, "gated": false, "likes": 28, "downloads": 1136, "paperswithcode_id": "pg-19", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "php", "sha": "76a2574e0050f2bde35b96d6fb1e4f100355113c", "lastModified": "2022-11-03T16:31:41.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:cs", "language:de", "language:en", "language:es", "language:fi", "language:fr", "language:he", "language:hu", "language:it", "language:ja", "language:ko", "language:nl", "language:pl", "language:pt", "language:ro", "language:ru", "language:sk", "language:sl", "language:sv", "language:tr", "language:tw", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus originally extracted from http://se.php.net/download-docs.php. The original documents are written in English and have been partly translated into 21 languages. The original manuals contain about 500,000 words. The amount of actually translated texts varies for different languages between 50,000 and 380,000 words. The corpus is rather noisy and may include parts from the English original in some of the translations. The corpus is tokenized and each language pair has been sentence aligned.\n\n23 languages, 252 bitexts\ntotal number of files: 71,414\ntotal number of tokens: 3.28M\ntotal number of sentence fragments: 1.38M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2c", "disabled": false, "gated": false, "likes": 1, "downloads": 838, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "etalab-ia/piaf", "sha": "f7293b384902c44f6919d10851de0ea1b8eaf2f3", "lastModified": "2022-11-03T16:31:15.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:fr", "license:mit", "region:us"], "private": false, "author": "etalab-ia", "description": "Piaf is a reading comprehension dataset. This version, published in February 2020, contains 3835 questions on French Wikipedia.", "citation": "@InProceedings{keraron-EtAl:2020:LREC,\n  author    = {Keraron, Rachel  and  Lancrenon, Guillaume  and  Bras, Mathilde  and  Allary, Fr\u00e9d\u00e9ric  and  Moyse, Gilles  and  Scialom, Thomas  and  Soriano-Morales, Edmundo-Pavel  and  Staiano, Jacopo},\n  title     = {Project PIAF: Building a Native French Question-Answering Dataset},\n  booktitle      = {Proceedings of The 12th Language Resources and Evaluation Conference},\n  month          = {May},\n  year           = {2020},\n  address        = {Marseille, France},\n  publisher      = {European Language Resources Association},\n  pages     = {5483--5492},\n  abstract  = {Motivated by the lack of data for non-English languages, in particular for the evaluation of downstream tasks such as Question Answering, we present a participatory effort to collect a native French Question Answering Dataset. Furthermore, we describe and publicly release the annotation tool developed for our collection effort, along with the data obtained and preliminary baselines.},\n  url       = {https://www.aclweb.org/anthology/2020.lrec-1.673}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2d", "disabled": false, "gated": false, "likes": 8, "downloads": 307, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pib", "sha": "028347c1788f8dce4ff7fc25f7e62574f752ef95", "lastModified": "2023-06-01T14:59:57.000Z", "tags": ["task_categories:translation", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:translation", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:bn", "language:en", "language:gu", "language:hi", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "language:ur", "license:cc-by-4.0", "arxiv:2008.04860", "region:us"], "private": false, "author": null, "description": "Sentence aligned parallel corpus between 11 Indian Languages, crawled and extracted from the press information bureau\nwebsite.", "citation": "@inproceedings{siripragada-etal-2020-multilingual,\n    title = \"A Multilingual Parallel Corpora Collection Effort for {I}ndian Languages\",\n    author = \"Siripragada, Shashank  and\n      Philip, Jerin  and\n      Namboodiri, Vinay P.  and\n      Jawahar, C V\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.lrec-1.462\",\n    pages = \"3743--3751\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}\n@article{2020,\n   title={Revisiting Low Resource Status of Indian Languages in Machine Translation},\n   url={http://dx.doi.org/10.1145/3430984.3431026},\n   DOI={10.1145/3430984.3431026},\n   journal={8th ACM IKDD CODS and 26th COMAD},\n   publisher={ACM},\n   author={Philip, Jerin and Siripragada, Shashank and Namboodiri, Vinay P. and Jawahar, C. V.},\n   year={2020},\n   month={Dec}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2e", "disabled": false, "gated": false, "likes": 3, "downloads": 7832, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "piqa", "sha": "1105f8cbc1b38f5fa25ba4c1f6b00ae8d7e2e8d9", "lastModified": "2023-01-25T14:42:33.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1911.11641", "arxiv:1907.10641", "arxiv:1904.09728", "arxiv:1808.05326", "region:us"], "private": false, "author": null, "description": "To apply eyeshadow without a brush, should I use a cotton swab or a toothpick?\nQuestions requiring this kind of physical commonsense pose a challenge to state-of-the-art\nnatural language understanding systems. The PIQA dataset introduces the task of physical commonsense reasoning\nand a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA.\n\nPhysical commonsense knowledge is a major challenge on the road to true AI-completeness,\nincluding robots that interact with the world and understand natural language.\n\nPIQA focuses on everyday situations with a preference for atypical solutions.\nThe dataset is inspired by instructables.com, which provides users with instructions on how to build, craft,\nbake, or manipulate objects using everyday materials.\n\nThe underlying task is formualted as multiple choice question answering:\ngiven a question `q` and two possible solutions `s1`, `s2`, a model or\na human must choose the most appropriate solution, of which exactly one is correct.\nThe dataset is further cleaned of basic artifacts using the AFLite algorithm which is an improvement of\nadversarial filtering. The dataset contains 16,000 examples for training, 2,000 for development and 3,000 for testing.", "citation": "@inproceedings{Bisk2020,\n  author = {Yonatan Bisk and Rowan Zellers and\n            Ronan Le Bras and Jianfeng Gao\n            and Yejin Choi},\n  title = {PIQA: Reasoning about Physical Commonsense in\n           Natural Language},\n  booktitle = {Thirty-Fourth AAAI Conference on\n               Artificial Intelligence},\n  year = {2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f2f", "disabled": false, "gated": false, "likes": 45, "downloads": 180546, "paperswithcode_id": "piqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pn_summary", "sha": "c7a6ba306a2341366bca94668b54b2de1eb40a67", "lastModified": "2023-01-25T14:42:36.000Z", "tags": ["task_categories:summarization", "task_categories:text-classification", "task_ids:news-articles-summarization", "task_ids:news-articles-headline-generation", "task_ids:text-simplification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fa", "license:mit", "arxiv:2012.11204", "region:us"], "private": false, "author": null, "description": "A well-structured summarization dataset for the Persian language consists of 93,207 records. It is prepared for Abstractive/Extractive tasks (like cnn_dailymail for English). It can also be used in other scopes like Text Generation, Title Generation, and News Category Classification.\nIt is imperative to consider that the newlines were replaced with the `[n]` symbol. Please interpret them into normal newlines (for ex. `t.replace(\"[n]\", \"\\n\")`) and then use them for your purposes.", "citation": "@article{pnSummary, title={Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text Summarization},\nauthor={Mehrdad Farahani, Mohammad Gharachorloo, Mohammad Manthouri},\nyear={2020},\neprint={2012.11204},\narchivePrefix={arXiv},\nprimaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f30", "disabled": false, "gated": false, "likes": 4, "downloads": 434, "paperswithcode_id": "pn-summary", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "poem_sentiment", "sha": "7cc73652bac880d26d49c28129af97ef81e59acb", "lastModified": "2023-01-25T14:42:40.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2011.02686", "region:us"], "private": false, "author": null, "description": "Poem Sentiment is a sentiment dataset of poem verses from Project Gutenberg. This dataset can be used for tasks such as sentiment classification or style transfer for poems.", "citation": "@misc{sheng2020investigating,\n      title={Investigating Societal Biases in a Poetry Composition System},\n      author={Emily Sheng and David Uthus},\n      year={2020},\n      eprint={2011.02686},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f31", "disabled": false, "gated": false, "likes": 9, "downloads": 1856, "paperswithcode_id": "gutenberg-poem-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "polemo2", "sha": "ae1773ef57d09b099d9223b08007fc81a33d55a7", "lastModified": "2023-01-25T14:42:43.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:bsd-3-clause", "region:us"], "private": false, "author": null, "description": "The PolEmo2.0 is a set of online reviews from medicine and hotels domains. The task is to predict the sentiment of a review. There are two separate test sets, to allow for in-domain (medicine and hotels) as well as out-of-domain (products and university) validation.", "citation": "@inproceedings{kocon-etal-2019-multi,\ntitle = \"Multi-Level Sentiment Analysis of {P}ol{E}mo 2.0: Extended Corpus of Multi-Domain Consumer Reviews\",\nauthor = \"Koco{\\'n}, Jan and\nMilkowski, Piotr and\nZa{\\'s}ko-Zieli{\\'n}ska, Monika\",\nbooktitle = \"Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)\",\nmonth = nov,\nyear = \"2019\",\naddress = \"Hong Kong, China\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://www.aclweb.org/anthology/K19-1092\",\ndoi = \"10.18653/v1/K19-1092\",\npages = \"980--991\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f32", "disabled": false, "gated": false, "likes": 0, "downloads": 436, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "poleval2019_cyberbullying", "sha": "b4bd6f1360e3f29b9f2f3c852c6380dba171991b", "lastModified": "2023-01-25T14:42:46.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:unknown", "region:us"], "private": false, "author": null, "description": "    In Task 6-1, the participants are to distinguish between normal/non-harmful tweets (class: 0) and tweets\n    that contain any kind of harmful information (class: 1). This includes cyberbullying, hate speech and\n    related phenomena.\n\n    In Task 6-2, the participants shall distinguish between three classes of tweets: 0 (non-harmful),\n    1 (cyberbullying), 2 (hate-speech). There are various definitions of both cyberbullying and hate-speech,\n    some of them even putting those two phenomena in the same group. The specific conditions on which we based\n    our annotations for both cyberbullying and hate-speech, which have been worked out during ten years of research\n    will be summarized in an introductory paper for the task, however, the main and definitive condition to 1\n    distinguish the two is whether the harmful action is addressed towards a private person(s) (cyberbullying),\n    or a public person/entity/large group (hate-speech).", "citation": "@proceedings{ogr:kob:19:poleval,\n  editor    = {Maciej Ogrodniczuk and \u0141ukasz Kobyli\u0144ski},\n  title     = {{Proceedings of the PolEval 2019 Workshop}},\n  year      = {2019},\n  address   = {Warsaw, Poland},\n  publisher = {Institute of Computer Science, Polish Academy of Sciences},\n  url       = {http://2019.poleval.pl/files/poleval2019.pdf},\n  isbn      = \"978-83-63159-28-3\"}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f33", "disabled": false, "gated": false, "likes": 1, "downloads": 469, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "poleval2019_mt", "sha": "f6bafacc603c294f95e0abcd7ed21e1665ce8abe", "lastModified": "2022-11-18T21:39:08.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:expert-generated", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:pl", "language:ru", "license:unknown", "region:us"], "private": false, "author": null, "description": "PolEval is a SemEval-inspired evaluation campaign for natural language processing tools for Polish.Submitted solutions compete against one another within certain tasks selected by organizers, using available data and are evaluated according topre-established procedures. One of the tasks in PolEval-2019 was Machine Translation (Task-4).\nThe task is to train as good as possible machine translation system, using any technology,with limited textual resources.The competition will be done for 2 language pairs, more popular English-Polish (into Polish direction) and pair that can be called low resourcedRussian-Polish (in both directions).\n\nHere, Polish-English is also made available to allow for training in both directions. However, the test data is ONLY available for English-Polish.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f34", "disabled": false, "gated": false, "likes": 0, "downloads": 714, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "polsum", "sha": "ccee60de431d1bbc3a2a0fb3e1fc67217d7bcaaa", "lastModified": "2022-11-03T16:07:56.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:pl", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "Polish Summaries Corpus: the corpus of Polish news summaries.", "citation": "@inproceedings{\n    ogro:kop:14:lrec,\n    author = \"Ogrodniczuk, Maciej and Kope\u0107, Mateusz\",\n    pdf = \"http://nlp.ipipan.waw.pl/Bib/ogro:kop:14:lrec.pdf\",\n    title = \"The {P}olish {S}ummaries {C}orpus\",\n    pages = \"3712--3715\",\n    crossref = \"lrec:14\"\n}\n@proceedings{\n    lrec:14,\n    editor = \"Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Loftsson, Hrafn and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Piperidis, Stelios\",\n    isbn = \"978-2-9517408-8-4\",\n    title = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\n    url = \"http://www.lrec-conf.org/proceedings/lrec2014/index.html\",\n    booktitle = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\n    address = \"Reykjav\u00edk, Iceland\",\n    key = \"LREC\",\n    year = \"2014\",\n    organization = \"European Language Resources Association (ELRA)\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f35", "disabled": false, "gated": false, "likes": 1, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "polyglot_ner", "sha": "4eebd107243873922c5ce6df9737093a1db83b77", "lastModified": "2023-04-05T13:36:52.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:original", "language:ar", "language:bg", "language:ca", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fa", "language:fi", "language:fr", "language:he", "language:hi", "language:hr", "language:hu", "language:id", "language:it", "language:ja", "language:ko", "language:lt", "language:lv", "language:ms", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:sk", "language:sl", "language:sr", "language:sv", "language:th", "language:tl", "language:tr", "language:uk", "language:vi", "language:zh", "license:unknown", "arxiv:1410.3791", "region:us"], "private": false, "author": null, "description": "Polyglot-NER\nA training dataset automatically generated from Wikipedia and Freebase the task\nof named entity recognition. The dataset contains the basic Wikipedia based\ntraining data for 40 languages we have (with coreference resolution) for the task of\nnamed entity recognition. The details of the procedure of generating them is outlined in\nSection 3 of the paper (https://arxiv.org/abs/1410.3791). Each config contains the data\ncorresponding to a different language. For example, \"es\" includes only spanish examples.", "citation": "@article{polyglotner,\n         author = {Al-Rfou, Rami and Kulkarni, Vivek and Perozzi, Bryan and Skiena, Steven},\n         title = {{Polyglot-NER}: Massive Multilingual Named Entity Recognition},\n         journal = {{Proceedings of the 2015 {SIAM} International Conference on Data Mining, Vancouver, British Columbia, Canada, April 30- May 2, 2015}},\n         month     = {April},\n         year      = {2015},\n         publisher = {SIAM},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f36", "disabled": false, "gated": false, "likes": 23, "downloads": 6386, "paperswithcode_id": "polyglot-ner", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "prachathai67k", "sha": "5a53014b5d16ab28a874aa5734cb63b33c5fa6d5", "lastModified": "2023-01-25T14:42:50.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "`prachathai-67k`: News Article Corpus and Multi-label Text Classificdation from Prachathai.com\nThe prachathai-67k dataset was scraped from the news site Prachathai.\nWe filtered out those articles with less than 500 characters of body text, mostly images and cartoons.\nIt contains 67,889 articles wtih 12 curated tags from August 24, 2004 to November 15, 2018.\nThe dataset was originally scraped by @lukkiddd and cleaned by @cstorm125.\nYou can also see preliminary exploration at https://github.com/PyThaiNLP/prachathai-67k/blob/master/exploration.ipynb", "citation": "@misc{prachathai67k,\n  author = {cstorm125, lukkiddd },\n  title = {prachathai67k},\n  year = {2019},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished={\\\\url{https://github.com/PyThaiNLP/prachathai-67k}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f37", "disabled": false, "gated": false, "likes": 3, "downloads": 358, "paperswithcode_id": "prachathai-67k", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pragmeval", "sha": "a288ce79f5c34681fee7cd199a1c989896ef27f9", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Evaluation of language understanding with a 11 datasets benchmark focusing on discourse and pragmatics", "citation": "@misc{sileo2019discoursebased,\n      title={Discourse-Based Evaluation of Language Understanding},\n      author={Damien Sileo and Tim Van-de-Cruys and Camille Pradel and Philippe Muller},\n      year={2019},\n      eprint={1907.08672},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f38", "disabled": false, "gated": false, "likes": 3, "downloads": 3135, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "proto_qa", "sha": "9e2ae9fd1c28f55859e79eb8f4dbfc5a54e71245", "lastModified": "2022-11-03T16:31:01.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2005.00771", "region:us"], "private": false, "author": null, "description": "This dataset is for studying computational models trained to reason about prototypical situations. Using deterministic filtering a sampling from a larger set of all transcriptions was built. It contains 9789 instances where each instance represents a survey question from Family Feud game. Each instance exactly is a question, a set of answers, and a count associated with each answer.\nEach line is a json dictionary, in which:\n1. question - contains the question (in original and a normalized form)\n2. answerstrings - contains the original answers provided by survey respondents (when available), along with the counts for each string. Because the FamilyFeud data has only cluster names rather than strings, those cluster names are included with 0 weight.\n3. answer-clusters - lists clusters, with the count of each cluster and the strings included in that cluster. Each cluster is given a unique ID that can be linked to in the assessment files.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning},\nauthors={Michael Boratko, Xiang Lorraine Li, Tim O\u2019Gorman, Rajarshi Das, Dan Le, Andrew McCallum},\nyear={2020},\npublisher = {GitHub},\njournal = {GitHub repository},\nhowpublished={\\\\url{https://github.com/iesl/protoqa-data}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f39", "disabled": false, "gated": false, "likes": 1, "downloads": 566, "paperswithcode_id": "protoqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "psc", "sha": "4f3985371db2d872e9514e218a2ec12d31d4a305", "lastModified": "2023-01-25T14:42:57.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The Polish Summaries Corpus contains news articles and their summaries. We used summaries of the same article as positive pairs and sampled the most similar summaries of different articles as negatives.", "citation": "@inproceedings{ogro:kop:14:lrec,\ntitle={The {P}olish {S}ummaries {C}orpus},\nauthor={Ogrodniczuk, Maciej and Kope{\\'c}, Mateusz},\nbooktitle = \"Proceedings of the Ninth International {C}onference on {L}anguage {R}esources and {E}valuation, {LREC}~2014\",\nyear = \"2014\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3a", "disabled": false, "gated": false, "likes": 1, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ptb_text_only", "sha": "a904f03a0206f421d10f98fa7c5996176faae2ac", "lastModified": "2022-11-18T21:39:46.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "This is the Penn Treebank Project: Release 2 CDROM, featuring a million words of 1989 Wall Street Journal material. This corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure.", "citation": "@article{marcus-etal-1993-building,\n    title = \"Building a Large Annotated Corpus of {E}nglish: The {P}enn {T}reebank\",\n    author = \"Marcus, Mitchell P.  and\n      Santorini, Beatrice  and\n      Marcinkiewicz, Mary Ann\",\n    journal = \"Computational Linguistics\",\n    volume = \"19\",\n    number = \"2\",\n    year = \"1993\",\n    url = \"https://www.aclweb.org/anthology/J93-2004\",\n    pages = \"313--330\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3b", "disabled": false, "gated": false, "likes": 11, "downloads": 37075, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pubmed", "sha": "c525c7c6f98163c10ed10bd7b4ee57e779241fe7", "lastModified": "2022-12-22T07:57:43.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:text-scoring", "task_ids:topic-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:other", "citation-estimation", "region:us"], "private": false, "author": null, "description": "NLM produces a baseline set of MEDLINE/PubMed citation records in XML format for download on an annual basis. The annual baseline is released in December of each year. Each day, NLM produces update files that include new, revised and deleted citations. See our documentation page for more information.", "citation": "Courtesy of the U.S. National Library of Medicine.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3c", "disabled": false, "gated": false, "likes": 36, "downloads": 691, "paperswithcode_id": "pubmed", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pubmed_qa", "sha": "62ba0829abb599fdb61b73cebfa1cf49bbb8a345", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "arxiv:1909.06146", "region:us"], "private": false, "author": null, "description": "PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\nThe task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative\nstatins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts.\nPubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances.\nEach PubMedQA instance is composed of (1) a question which is either an existing research article\ntitle or derived from one, (2) a context which is the corresponding abstract without its conclusion,\n(3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question,\nand (4) a yes/no/maybe answer which summarizes the conclusion.\nPubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their\nquantitative contents, is required to answer the questions.", "citation": "@inproceedings{jin2019pubmedqa,\n  title={PubMedQA: A Dataset for Biomedical Research Question Answering},\n  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},\n  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n  pages={2567--2577},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3d", "disabled": false, "gated": false, "likes": 73, "downloads": 13305, "paperswithcode_id": "pubmedqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "py_ast", "sha": "34e3cdcc0762df45b5ebec8b3f86ba5abc184ece", "lastModified": "2022-11-18T21:40:05.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "task_categories:fill-mask", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:code", "license:bsd-2-clause", "license:mit", "code-modeling", "code-generation", "region:us"], "private": false, "author": null, "description": "Dataset consisting of parsed ASTs that were used to train and\nevaluate the DeepSyn tool.\nThe Python programs are collected from GitHub repositories\nby removing duplicate files, removing project forks (copy of another existing repository)\n,keeping only programs that parse and have at most 30'000 nodes in the AST and\nwe aim to remove obfuscated files", "citation": "@InProceedings{OOPSLA \u201916, ACM,\ntitle = {Probabilistic Model for Code with Decision Trees.},\nauthors={Raychev, V., Bielik, P., and Vechev, M.},\nyear={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3e", "disabled": false, "gated": false, "likes": 3, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qa4mre", "sha": "8ced0691b55b9874f3f60a42123ec6801410aed1", "lastModified": "2023-04-05T13:36:59.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:other", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "language:bg", "language:de", "language:en", "language:es", "language:it", "language:ro", "license:unknown", "region:us"], "private": false, "author": null, "description": "QA4MRE dataset was created for the CLEF 2011/2012/2013 shared tasks to promote research in\nquestion answering and reading comprehension. The dataset contains a supporting\npassage and a set of questions corresponding to the passage. Multiple options\nfor answers are provided for each question, of which only one is correct. The\ntraining and test datasets are available for the main track.\nAdditional gold standard documents are available for two pilot studies: one on\nalzheimers data, and the other on entrance exams data.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f3f", "disabled": false, "gated": false, "likes": 2, "downloads": 3650, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qa_srl", "sha": "3069753b648c250f986ac24fad32081aa378c3a8", "lastModified": "2022-11-18T21:40:16.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The dataset contains question-answer pairs to model verbal predicate-argument structure. The questions start with wh-words (Who, What, Where, What, etc.) and contain a verb predicate in the sentence; the answers are phrases in the sentence.\nThere were 2 datsets used in the paper, newswire and wikipedia. Unfortunately the newswiredataset is built from CoNLL-2009 English training set that is covered under license\nThus, we are providing only Wikipedia training set here. Please check README.md for more details on newswire dataset.\nFor the Wikipedia domain, randomly sampled sentences from the English Wikipedia (excluding questions and sentences with fewer than 10 or more than 60 words) were taken.\nThis new dataset is designed to solve this great NLP task and is crafted with a lot of care.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {QA-SRL: Question-Answer Driven Semantic Role Labeling},\nauthors={Luheng He, Mike Lewis, Luke Zettlemoyer},\nyear={2015}\npublisher = {cs.washington.edu},\nhowpublished={\\\\url{https://dada.cs.washington.edu/qasrl/#page-top}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f40", "disabled": false, "gated": false, "likes": 1, "downloads": 507, "paperswithcode_id": "qa-srl", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qa_zre", "sha": "943fd2e7e663694a04b658417b955b4685161925", "lastModified": "2023-04-05T13:37:03.000Z", "tags": ["task_categories:question-answering", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:unknown", "zero-shot-relation-extraction", "region:us"], "private": false, "author": null, "description": "A dataset reducing relation extraction to simple reading comprehension questions", "citation": "@inproceedings{levy-etal-2017-zero,\n    title = \"Zero-Shot Relation Extraction via Reading Comprehension\",\n    author = \"Levy, Omer  and\n      Seo, Minjoon  and\n      Choi, Eunsol  and\n      Zettlemoyer, Luke\",\n    booktitle = \"Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)\",\n    month = aug,\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/K17-1034\",\n    doi = \"10.18653/v1/K17-1034\",\n    pages = \"333--342\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f41", "disabled": false, "gated": false, "likes": 2, "downloads": 384, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qangaroo", "sha": "ea12d8ca305ff28b931cee9f5bd45ce57a1421e5", "lastModified": "2023-04-05T13:37:06.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "  We have created two new Reading Comprehension datasets focussing on multi-hop (alias multi-step) inference.\n\nSeveral pieces of information often jointly imply another fact. In multi-hop inference, a new fact is derived by combining facts via a chain of multiple steps.\n\nOur aim is to build Reading Comprehension methods that perform multi-hop inference on text, where individual facts are spread out across different documents.\n\nThe two QAngaroo datasets provide a training and evaluation resource for such methods.", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f42", "disabled": false, "gated": false, "likes": 0, "downloads": 760, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qanta", "sha": "5fe8cf6bb26ee0b6cc2975b1ec3c85391f22ef84", "lastModified": "2023-04-05T13:37:09.000Z", "tags": ["task_categories:question-answering", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "quizbowl", "arxiv:1904.04792", "region:us"], "private": false, "author": null, "description": "The Qanta dataset is a question answering dataset based on the academic trivia game Quizbowl.", "citation": "@article{Rodriguez2019QuizbowlTC,\n  title={Quizbowl: The Case for Incremental Question Answering},\n  author={Pedro Rodriguez and Shi Feng and Mohit Iyyer and He He and Jordan L. Boyd-Graber},\n  journal={ArXiv},\n  year={2019},\n  volume={abs/1904.04792}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f43", "disabled": false, "gated": false, "likes": 3, "downloads": 707, "paperswithcode_id": "quizbowl", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qasc", "sha": "3dfa861b842adcec206a3a7b56e8c4a03fbf2e22", "lastModified": "2023-04-05T13:37:12.000Z", "tags": ["task_categories:question-answering", "task_categories:multiple-choice", "task_ids:extractive-qa", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1910.11473", "region:us"], "private": false, "author": null, "description": "QASC is a question-answering dataset with a focus on sentence composition. It consists of 9,980 8-way multiple-choice\nquestions about grade school science (8,134 train, 926 dev, 920 test), and comes with a corpus of 17M sentences.", "citation": "@article{allenai:qasc,\n      author    = {Tushar Khot and Peter Clark and Michal Guerquin and Peter Jansen and Ashish Sabharwal},\n      title     = {QASC: A Dataset for Question Answering via Sentence Composition},\n      journal   = {arXiv:1910.11473v2},\n      year      = {2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f44", "disabled": false, "gated": false, "likes": 6, "downloads": 3900, "paperswithcode_id": "qasc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/qasper", "sha": "fdc9d8214fbab5dd782958601db4d678e6934a54", "lastModified": "2022-10-07T22:04:11.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|s2orc", "language:en", "license:cc-by-4.0", "arxiv:2105.03011", "region:us"], "private": false, "author": "allenai", "description": "A dataset containing 1585 papers with 5049 information-seeking questions asked by regular readers of NLP papers, and answered by a separate set of NLP practitioners.", "citation": "@inproceedings{Dasigi2021ADO,\n  title={A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers},\n  author={Pradeep Dasigi and Kyle Lo and Iz Beltagy and Arman Cohan and Noah A. Smith and Matt Gardner},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f45", "disabled": false, "gated": false, "likes": 38, "downloads": 2748, "paperswithcode_id": "qasper", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qed", "sha": "088afcb25437751257e04ad1e36768b1e8bedcfb", "lastModified": "2022-11-03T16:31:09.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|natural_questions", "language:en", "license:unknown", "explanations-in-question-answering", "arxiv:2009.06354", "region:us"], "private": false, "author": null, "description": "QED, is a linguistically informed, extensible framework for explanations in question answering. A QED explanation specifies the relationship between a question and answer according to formal semantic notions such as referential equality, sentencehood, and entailment. It is an expertannotated dataset of QED explanations built upon a subset of the Google Natural Questions dataset.", "citation": "@misc{lamm2020qed,\n    title={QED: A Framework and Dataset for Explanations in Question Answering},\n    author={Matthew Lamm and Jennimaria Palomaki and Chris Alberti and Daniel Andor and Eunsol Choi and Livio Baldini Soares and Michael Collins},\n    year={2020},\n    eprint={2009.06354},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f46", "disabled": false, "gated": false, "likes": 2, "downloads": 511, "paperswithcode_id": "qed", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qed_amara", "sha": "38ca16750265b1af70fbe98b7f8b6a296c1c816f", "lastModified": "2022-11-03T16:31:42.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:aa", "language:ab", "language:ae", "language:aeb", "language:af", "language:ak", "language:am", "language:an", "language:ar", "language:arq", "language:arz", "language:as", "language:ase", "language:ast", "language:av", "language:ay", "language:az", "language:ba", "language:be", "language:ber", "language:bg", "language:bh", "language:bi", "language:bm", "language:bn", "language:bnt", "language:bo", "language:br", "language:bs", "language:bug", "language:ca", "language:ce", "language:ceb", "language:ch", "language:cho", "language:cku", "language:cnh", "language:co", "language:cr", "language:cs", "language:cu", "language:cv", "language:cy", "language:da", "language:de", "language:dv", "language:dz", "language:ee", "language:efi", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:ff", "language:fi", "language:fil", "language:fj", "language:fo", "language:fr", "language:ga", "language:gd", "language:gl", "language:gn", "language:gu", "language:ha", "language:hai", "language:haw", "language:haz", "language:hch", "language:he", "language:hi", "language:ho", "language:hr", "language:ht", "language:hu", "language:hup", "language:hus", "language:hy", "language:hz", "language:ia", "language:id", "language:ie", "language:ig", "language:ik", "language:inh", "language:io", "language:iro", "language:is", "language:it", "language:iu", "language:ja", "language:jv", "language:ka", "language:kar", "language:ki", "language:kj", "language:kk", "language:kl", "language:km", "language:kn", "language:ko", "language:kr", "language:ksh", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lb", "language:lg", "language:li", "language:lkt", "language:lld", "language:ln", "language:lo", "language:lt", "language:ltg", "language:lu", "language:luo", "language:luy", "language:lv", "language:mad", "language:mfe", "language:mg", "language:mi", "language:mk", "language:ml", "language:mn", "language:mni", "language:moh", "language:mos", "language:mr", "language:ms", "language:mt", "language:mus", "language:my", "language:nb", "language:nci", "language:nd", "language:ne", "language:nl", "language:nn", "language:nso", "language:nv", "language:ny", "language:oc", "language:om", "language:or", "language:pa", "language:pam", "language:pap", "language:pi", "language:pl", "language:pnb", "language:prs", "language:ps", "language:pt", "language:qu", "language:rm", "language:rn", "language:ro", "language:ru", "language:rup", "language:rw", "language:sa", "language:sc", "language:scn", "language:sco", "language:sd", "language:sg", "language:sgn", "language:sh", "language:si", "language:sk", "language:sl", "language:sm", "language:sn", "language:so", "language:sq", "language:sr", "language:st", "language:sv", "language:sw", "language:szl", "language:ta", "language:te", "language:tet", "language:tg", "language:th", "language:ti", "language:tk", "language:tl", "language:tlh", "language:to", "language:tr", "language:ts", "language:tt", "language:tw", "language:ug", "language:uk", "language:umb", "language:ur", "language:uz", "language:ve", "language:vi", "language:vls", "language:vo", "language:wa", "language:wo", "language:xh", "language:yaq", "language:yi", "language:yo", "language:za", "language:zam", "language:zh", "language:zu", "license:unknown", "region:us"], "private": false, "author": null, "description": "The QCRI Educational Domain Corpus (formerly QCRI AMARA Corpus) is an open multilingual collection of subtitles for educational videos and lectures collaboratively transcribed and translated over the AMARA web-based platform.\nDeveloped by: Qatar Computing Research Institute, Arabic Language Technologies Group\nThe QED Corpus is made public for RESEARCH purpose only.\nThe corpus is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. Copyright Qatar Computing Research Institute. All rights reserved.\n225 languages, 9,291 bitexts\ntotal number of files: 271,558\ntotal number of tokens: 371.76M\ntotal number of sentence fragments: 30.93M", "citation": "A. Abdelali, F. Guzman, H. Sajjad and S. Vogel, \"The AMARA Corpus: Building parallel language resources for the educational domain\", The Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC'14). Reykjavik, Iceland, 2014. Pp. 1856-1862. Isbn. 978-2-9517408-8-4.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f47", "disabled": false, "gated": false, "likes": 4, "downloads": 845, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "quac", "sha": "a2a4f46f4a6ad02897cc098d0b6c70cafa2b8ae2", "lastModified": "2023-01-25T14:43:01.000Z", "tags": ["task_categories:question-answering", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|wikipedia", "language:en", "license:mit", "arxiv:1808.07036", "region:us"], "private": false, "author": null, "description": "Question Answering in Context is a dataset for modeling, understanding,\nand participating in information seeking dialog. Data instances consist\nof an interactive dialog between two crowd workers: (1) a student who\nposes a sequence of freeform questions to learn as much as possible\nabout a hidden Wikipedia text, and (2) a teacher who answers the questions\nby providing short excerpts (spans) from the text. QuAC introduces\nchallenges not found in existing machine comprehension datasets: its\nquestions are often more open-ended, unanswerable, or only meaningful\nwithin the dialog context.", "citation": "@inproceedings{choi-etal-2018-quac,\ntitle = \"QUAC: Question answering in context\",\nabstract = \"We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.\",\nauthor = \"Eunsol Choi and He He and Mohit Iyyer and Mark Yatskar and Yih, {Wen Tau} and Yejin Choi and Percy Liang and Luke Zettlemoyer\",\nyear = \"2018\",\nlanguage = \"English (US)\",\nseries = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\npublisher = \"Association for Computational Linguistics\",\npages = \"2174--2184\",\neditor = \"Ellen Riloff and David Chiang and Julia Hockenmaier and Jun'ichi Tsujii\",\nbooktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\nnote = \"2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018 ; Conference date: 31-10-2018 Through 04-11-2018\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f48", "disabled": false, "gated": false, "likes": 15, "downloads": 859, "paperswithcode_id": "quac", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "quail", "sha": "4e1ae2f7abec085a44643e33888ca520c5d2b304", "lastModified": "2023-04-05T13:37:16.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": "QuAIL is a  reading comprehension dataset. QuAIL contains 15K multi-choice questions in texts 300-350 tokens long 4 domains (news, user stories, fiction, blogs).QuAIL is balanced and annotated for question types.\\", "citation": "@inproceedings{DBLP:conf/aaai/RogersKDR20,\n  author    = {Anna Rogers and\n               Olga Kovaleva and\n               Matthew Downey and\n               Anna Rumshisky},\n  title     = {Getting Closer to {AI} Complete Question Answering: {A} Set of Prerequisite\n               Real Tasks},\n  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}\n               2020, The Thirty-Second Innovative Applications of Artificial Intelligence\n               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational\n               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,\n               February 7-12, 2020},\n  pages     = {8722--8731},\n  publisher = {{AAAI} Press},\n  year      = {2020},\n  url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6398},\n  timestamp = {Thu, 04 Jun 2020 13:18:48 +0200},\n  biburl    = {https://dblp.org/rec/conf/aaai/RogersKDR20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f49", "disabled": false, "gated": false, "likes": 3, "downloads": 11896, "paperswithcode_id": "quail", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "quarel", "sha": "cbee717347c584e2cceaf00967ff83f9348790f9", "lastModified": "2023-04-05T13:37:19.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "QuaRel is a crowdsourced dataset of 2771 multiple-choice story questions, including their logical forms.", "citation": "@inproceedings{quarel_v1,\n    title={QuaRel: A Dataset and Models for Answering Questions about Qualitative Relationships},\n    author={Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, Ashish Sabharwal},\n    year={2018},\n    journal={arXiv:1805.05377v1}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f4a", "disabled": false, "gated": false, "likes": 2, "downloads": 2268, "paperswithcode_id": "quarel", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "quartz", "sha": "d09d2e1e12c2c44c001da9cfa83ca6192a51f71d", "lastModified": "2023-04-05T13:37:22.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "QuaRTz is a crowdsourced dataset of 3864 multiple-choice questions about open domain qualitative relationships. Each\nquestion is paired with one of 405 different background sentences (sometimes short paragraphs).\nThe QuaRTz dataset V1 contains 3864 questions about open domain qualitative relationships. Each question is paired with\none of 405 different background sentences (sometimes short paragraphs).\nThe dataset is split into train (2696), dev (384) and test (784). A background sentence will only appear in a single split.", "citation": "@InProceedings{quartz,\n  author = {Oyvind Tafjord and Matt Gardner and Kevin Lin and Peter Clark},\n  title = {\"QUARTZ: An Open-Domain Dataset of Qualitative Relationship\nQuestions\"},\n  year = {\"2019\"},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f4b", "disabled": false, "gated": false, "likes": 4, "downloads": 4950, "paperswithcode_id": "quartz", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "quoref", "sha": "da390d8480386f85908bd894b0001e2b78525667", "lastModified": "2023-04-05T13:37:27.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "coreference-resolution", "region:us"], "private": false, "author": null, "description": "Quoref is a QA dataset which tests the coreferential reasoning capability of reading comprehension systems. In this\nspan-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard\ncoreferences before selecting the appropriate span(s) in the paragraphs for answering questions.", "citation": "@article{allenai:quoref,\n      author    = {Pradeep Dasigi and Nelson F. Liu and Ana Marasovic and Noah A. Smith and  Matt Gardner},\n      title     = {Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning},\n      journal   = {arXiv:1908.05803v2 },\n      year      = {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f4d", "disabled": false, "gated": false, "likes": 4, "downloads": 3454, "paperswithcode_id": "quoref", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "race", "sha": "27c1690f6b9a2cc98e624883d8642a23bdaf65e3", "lastModified": "2023-04-05T13:37:29.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "arxiv:1704.04683", "region:us"], "private": false, "author": null, "description": "Race is a large-scale reading comprehension dataset with more than 28,000 passages and nearly 100,000 questions. The\n dataset is collected from English examinations in China, which are designed for middle school and high school students.\nThe dataset can be served as the training and test sets for machine comprehension.", "citation": "@article{lai2017large,\n    title={RACE: Large-scale ReAding Comprehension Dataset From Examinations},\n    author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},\n    journal={arXiv preprint arXiv:1704.04683},\n    year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f4e", "disabled": false, "gated": false, "likes": 26, "downloads": 40492, "paperswithcode_id": "race", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "re_dial", "sha": "f905f21740fb20c01165cd9d364c3f21975a2fdf", "lastModified": "2022-11-18T21:41:23.000Z", "tags": ["task_categories:other", "task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "dialogue-sentiment-classification", "region:us"], "private": false, "author": null, "description": "ReDial (Recommendation Dialogues) is an annotated dataset of dialogues, where users\nrecommend movies to each other. The dataset was collected by a team of researchers working at\nPolytechnique Montr\u00e9al, MILA \u2013 Quebec AI Institute, Microsoft Research Montr\u00e9al, HEC Montreal, and Element AI.\n\nThe dataset allows research at the intersection of goal-directed dialogue systems\n(such as restaurant recommendation) and free-form (also called \u201cchit-chat\u201d) dialogue systems.", "citation": "@inproceedings{li2018conversational,\n  title={Towards Deep Conversational Recommendations},\n  author={Li, Raymond and Kahou, Samira Ebrahimi and Schulz, Hannes and Michalski, Vincent and Charlin, Laurent and Pal, Chris},\n  booktitle={Advances in Neural Information Processing Systems 31 (NIPS 2018)},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f4f", "disabled": false, "gated": false, "likes": 0, "downloads": 321, "paperswithcode_id": "redial", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "reasoning_bg", "sha": "255c1d7a993c50c729bf1293e1a236c629d63cd2", "lastModified": "2022-11-03T16:31:39.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:bg", "license:apache-2.0", "arxiv:1908.01519", "region:us"], "private": false, "author": null, "description": "This new dataset is designed to do reading comprehension in Bulgarian language.", "citation": "@article{hardalov2019beyond,\n  title={Beyond english-only reading comprehension: Experiments in zero-shot multilingual transfer for bulgarian},\n  author={Hardalov, Momchil and Koychev, Ivan and Nakov, Preslav},\n  journal={arXiv preprint arXiv:1908.01519},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f50", "disabled": false, "gated": false, "likes": 0, "downloads": 857, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "recipe_nlg", "sha": "b177140471b2b282f809247a61928f5b0bb7e14f", "lastModified": "2023-01-25T14:43:04.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-retrieval", "task_categories:summarization", "task_ids:document-retrieval", "task_ids:entity-linking-retrieval", "task_ids:explanation-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The dataset contains 2231142 cooking recipes (>2 millions). It's processed in more careful way and provides more samples than any other dataset in the area.", "citation": "@inproceedings{bien-etal-2020-recipenlg,\ntitle = \"{R}ecipe{NLG}: A Cooking Recipes Dataset for Semi-Structured Text Generation\",\nauthor = \"Bie{'n}, Micha{l}  and\n  Gilski, Micha{l}  and\n  Maciejewska, Martyna  and\n  Taisner, Wojciech  and\n  Wisniewski, Dawid  and\n  Lawrynowicz, Agnieszka\",\nbooktitle = \"Proceedings of the 13th International Conference on Natural Language Generation\",\nmonth = dec,\nyear = \"2020\",\naddress = \"Dublin, Ireland\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"https://www.aclweb.org/anthology/2020.inlg-1.4\",\npages = \"22--28\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f51", "disabled": false, "gated": false, "likes": 24, "downloads": 541, "paperswithcode_id": "recipenlg", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "reclor", "sha": "93c0ffc0b14136ced473ffdd1cab57e2d6905040", "lastModified": "2022-11-18T21:41:37.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "Logical reasoning is an important ability to examine, analyze, and critically evaluate arguments as they occur in ordinary\nlanguage as the definition from LSAC. ReClor is a dataset extracted from logical reasoning questions of standardized graduate\nadmission examinations. Empirical results show that the state-of-the-art models struggle on ReClor with poor performance\nindicating more research is needed to essentially enhance the logical reasoning ability of current models. We hope this\ndataset could help push Machine Reading Comprehension (MRC) towards more complicated reasonin", "citation": "@inproceedings{yu2020reclor,\n        author = {Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},\n        title = {ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning},\n        booktitle = {International Conference on Learning Representations (ICLR)},\n        month = {April},\n        year = {2020}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f52", "disabled": false, "gated": false, "likes": 1, "downloads": 294, "paperswithcode_id": "reclor", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "red_caps", "sha": "a745ef7e779f60083b7478db5d85ab62a174eb9d", "lastModified": "2023-01-25T14:43:07.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2111.11431", "region:us"], "private": false, "author": null, "description": "RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\nImages and captions from Reddit depict and describe a wide variety of objects and scenes.\nThe data is collected from a manually curated set of subreddits (350 total),\nwhich give coarse image labels and allow steering of the dataset composition\nwithout labeling individual instances.", "citation": "@misc{desai2021redcaps,\n      title={RedCaps: web-curated image-text data created by the people, for the people},\n      author={Karan Desai and Gaurav Kaul and Zubin Aysola and Justin Johnson},\n      year={2021},\n      eprint={2111.11431},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f53", "disabled": false, "gated": false, "likes": 44, "downloads": 246622, "paperswithcode_id": "redcaps", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "webis/tldr-17", "sha": "fa7f50e62d35aff41aa165ddbe6c10dfa01ff49c", "lastModified": "2023-06-05T12:48:30.000Z", "tags": ["task_categories:summarization", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "reddit-posts-summarization", "region:us"], "private": false, "author": "webis", "description": "This corpus contains preprocessed posts from the Reddit dataset.\nThe dataset consists of 3,848,330 posts with an average length of 270 words for content,\nand 28 words for the summary.\n\nFeatures includes strings: author, body, normalizedBody, content, summary, subreddit, subreddit_id.\nContent is used as document and summary is used as summary.", "citation": "@inproceedings{volske-etal-2017-tl,\n    title = {TL;DR: Mining {R}eddit to Learn Automatic Summarization},\n    author = {V{\\\"o}lske, Michael  and Potthast, Martin  and Syed, Shahbaz  and Stein, Benno},\n    booktitle = {Proceedings of the Workshop on New Frontiers in Summarization},\n    month = {sep},\n    year = {2017},\n    address = {Copenhagen, Denmark},\n    publisher = {Association for Computational Linguistics},\n    url = {https://www.aclweb.org/anthology/W17-4508},\n    doi = {10.18653/v1/W17-4508},\n    pages = {59--63},\n    abstract = {Recent advances in automatic text summarization have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining social media for author-provided summaries, taking advantage of the common practice of appending a {``}TL;DR{''} to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the news genre. Our technique is likely applicable to other social media sites and general web crawls.},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f54", "disabled": false, "gated": false, "likes": 26, "downloads": 651, "paperswithcode_id": "webis-tldr-17-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "reddit_tifu", "sha": "68cc1f53a9e340ece8664e5f2cdf59f2929ad2a1", "lastModified": "2023-06-15T21:21:20.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:mit", "reddit-posts-summarization", "arxiv:1811.00783", "region:us"], "private": false, "author": null, "description": "Reddit dataset, where TIFU denotes the name of subbreddit /r/tifu.\nAs defined in the publication, styel \"short\" uses title as summary and\n\"long\" uses tldr as summary.\n\nFeatures includes:\n  - document: post text without tldr.\n  - tldr: tldr line.\n  - title: trimmed title without tldr.\n  - ups: upvotes.\n  - score: score.\n  - num_comments: number of comments.\n  - upvote_ratio: upvote ratio.", "citation": "@misc{kim2018abstractive,\n    title={Abstractive Summarization of Reddit Posts with Multi-level Memory Networks},\n    author={Byeongchang Kim and Hyunwoo Kim and Gunhee Kim},\n    year={2018},\n    eprint={1811.00783},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f55", "disabled": false, "gated": false, "likes": 5, "downloads": 942, "paperswithcode_id": "reddit-tifu", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "refresd", "sha": "40cd64166105dc4410c9ee23948704a42ca3bfb2", "lastModified": "2023-01-25T14:43:11.000Z", "tags": ["task_categories:text-classification", "task_categories:translation", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|other-wikimatrix", "language:en", "language:fr", "license:mit", "arxiv:1907.05791", "region:us"], "private": false, "author": null, "description": "The Rationalized English-French Semantic Divergences (REFreSD) dataset consists of 1,039\n English-French sentence-pairs annotated with sentence-level divergence judgments and token-level\n rationales. For any questions, write to ebriakou@cs.umd.edu.", "citation": "@inproceedings{briakou-carpuat-2020-detecting,\n    title = \"Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank\",\n    author = \"Briakou, Eleftheria and Carpuat, Marine\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.121\",\n    pages = \"1563--1580\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f56", "disabled": false, "gated": false, "likes": 0, "downloads": 303, "paperswithcode_id": "refresd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "reuters21578", "sha": "28838256a1eb63d578641ac9e6c2916006c8b549", "lastModified": "2023-08-30T17:35:01.000Z", "tags": ["language:en", "license:other", "region:us"], "private": false, "author": null, "description": "The Reuters-21578 dataset  is one of the most widely used data collections for text\ncategorization research. It is collected from the Reuters financial newswire service in 1987.", "citation": "@article{APTE94,\nauthor = {Chidanand Apt{\\'{e}} and Fred Damerau and Sholom M. Weiss},\ntitle = {Automated Learning of Decision Rules for Text Categorization},\njournal = {ACM Transactions on Information Systems},\nyear = {1994},\nnote = {To appear.}\n}\n\n@inproceedings{APTE94b,\nauthor = {Chidanand Apt{\\'{e}} and Fred Damerau and Sholom M. Weiss},\ntitle = {Toward Language Independent Automated Learning of Text Categorization Models},\nbooktitle = {sigir94},\nyear = {1994},\nnote = {To appear.}\n}\n\n@inproceedings{HAYES8},\nauthor = {Philip J. Hayes and Peggy M. Anderson and Irene B. Nirenburg and\nLinda M. Schmandt},\ntitle = {{TCS}: A Shell for Content-Based Text Categorization},\nbooktitle = {IEEE Conference on Artificial Intelligence Applications},\nyear = {1990}\n}\n\n@inproceedings{HAYES90b,\nauthor = {Philip J. Hayes and Steven P. Weinstein},\ntitle = {{CONSTRUE/TIS:} A System for Content-Based Indexing of a\nDatabase of News Stories},\nbooktitle = {Second Annual Conference on Innovative Applications of\nArtificial Intelligence},\nyear = {1990}\n}\n\n@incollection{HAYES92 ,\nauthor = {Philip J. Hayes},\ntitle = {Intelligent High-Volume Text Processing using Shallow,\nDomain-Specific Techniques},\nbooktitle = {Text-Based Intelligent Systems},\npublisher = {Lawrence Erlbaum},\naddress =  {Hillsdale, NJ},\nyear = {1992},\neditor = {Paul S. Jacobs}\n}\n\n@inproceedings{LEWIS91c ,\nauthor = {David D. Lewis},\ntitle = {Evaluating Text Categorization},\nbooktitle = {Proceedings of Speech and Natural Language Workshop},\nyear = {1991},\nmonth = {feb},\norganization = {Defense Advanced Research Projects Agency},\npublisher = {Morgan Kaufmann},\npages = {312--318}\n\n}\n\n@phdthesis{LEWIS91d,\nauthor = {David Dolan Lewis},\ntitle = {Representation and Learning in Information Retrieval},\nschool = {Computer Science Dept.; Univ. of Massachusetts; Amherst, MA 01003},\nyear = 1992},\nnote = {Technical Report 91--93.}\n}\n\n@inproceedings{LEWIS91e,\nauthor = {David D. Lewis},\ntitle = {Data Extraction as Text Categorization: An Experiment with\nthe {MUC-3} Corpus},\nbooktitle = {Proceedings of the Third Message Understanding Evaluation\nand Conference},\nyear = {1991},\nmonth = {may},\norganization = {Defense Advanced Research Projects Agency},\npublisher = {Morgan Kaufmann},\naddress = {Los Altos, CA}\n\n}\n\n@inproceedings{LEWIS92b,\nauthor = {David D. Lewis},\ntitle = {An Evaluation of Phrasal and Clustered Representations on a Text\nCategorization Task},\nbooktitle = {Fifteenth Annual International ACM SIGIR Conference on\nResearch and Development in Information Retrieval},\nyear = {1992},\npages = {37--50}\n}\n\n@inproceedings{LEWIS92d ,\nauthor = {David D. Lewis and Richard M. Tong},\ntitle = {Text Filtering in {MUC-3} and {MUC-4}},\nbooktitle = {Proceedings of the Fourth Message Understanding Conference ({MUC-4})},\nyear = {1992},\nmonth = {jun},\norganization = {Defense Advanced Research Projects Agency},\npublisher = {Morgan Kaufmann},\naddress = {Los Altos, CA}\n}\n\n@inproceedings{LEWIS92e,\nauthor = {David D. Lewis},\ntitle = {Feature Selection and Feature Extraction for Text Categorization},\nbooktitle = {Proceedings of Speech and Natural Language Workshop},\nyear = {1992},\nmonth = {feb} ,\norganization = {Defense Advanced Research Projects Agency},\npublisher = {Morgan Kaufmann},\npages = {212--217}\n}\n\n@inproceedings{LEWIS94b,\nauthor = {David D. Lewis and Marc Ringuette},\ntitle = {A Comparison of Two Learning Algorithms for Text Categorization},\nbooktitle = {Symposium on Document Analysis and Information Retrieval},\nyear = {1994},\norganization = {ISRI; Univ. of Nevada, Las Vegas},\naddress = {Las Vegas, NV},\nmonth = {apr},\npages = {81--93}\n}\n\n@article{LEWIS94d,\nauthor = {David D. Lewis and Philip J. Hayes},\ntitle = {Guest Editorial},\njournal = {ACM Transactions on Information Systems},\nyear = {1994},\nvolume  = {12},\nnumber  = {3},\npages = {231},\nmonth = {jul}\n}\n\n@article{SPARCKJONES76,\nauthor = {K. {Sparck Jones} and  C. J. {van Rijsbergen}},\ntitle =  {Information Retrieval Test Collections},\njournal = {Journal of Documentation},\nyear = {1976},\nvolume = {32},\nnumber = {1},\npages = {59--75}\n}\n\n@book{WEISS91,\nauthor = {Sholom M. Weiss and Casimir A. Kulikowski},\ntitle = {Computer Systems That Learn},\npublisher = {Morgan Kaufmann},\nyear = {1991},\naddress = {San Mateo, CA}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f57", "disabled": false, "gated": false, "likes": 9, "downloads": 1646, "paperswithcode_id": "reuters-21578", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "riddle_sense", "sha": "41afed52a8e4249e9b3bfc7f45bb10c1c578386f", "lastModified": "2022-11-18T21:42:04.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Answering such a riddle-style question is a challenging cognitive process, in that it requires\ncomplex commonsense reasoning abilities, an understanding of figurative language, and counterfactual reasoning\nskills, which are all important abilities for advanced natural language understanding (NLU). However,\nthere is currently no dedicated datasets aiming to test these abilities. Herein, we present RiddleSense,\na new multiple-choice question answering task, which comes with the first large dataset (5.7k examples) for answering\nriddle-style commonsense questions. We systematically evaluate a wide range of models over the challenge,\nand point out that there is a large gap between the best-supervised model and human performance \u2014 suggesting\nintriguing future research in the direction of higher-order commonsense reasoning and linguistic creativity towards\nbuilding advanced NLU systems.", "citation": "@InProceedings{lin-etal-2021-riddlesense,\ntitle={RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge},\nauthor={Lin, Bill Yuchen and Wu, Ziyi and Yang, Yichi and Lee, Dong-Ho and Ren, Xiang},\njournal={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP 2021): Findings},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f58", "disabled": false, "gated": false, "likes": 15, "downloads": 879, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ro_sent", "sha": "30fe6d65e1cc395f95b9be1cb46ad26670a9cab8", "lastModified": "2023-01-25T14:43:14.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ro", "license:unknown", "arxiv:2009.08712", "region:us"], "private": false, "author": null, "description": "This dataset is a Romanian Sentiment Analysis dataset.\nIt is present in a processed form, as used by the authors of `Romanian Transformers`\nin their examples and based on the original data present in\n`https://github.com/katakonst/sentiment-analysis-tensorflow`. The original dataset is collected\nfrom product and movie reviews in Romanian.", "citation": "@article{dumitrescu2020birth,\n  title={The birth of Romanian BERT},\n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius and Pyysalo, Sampo},\n  journal={arXiv preprint arXiv:2009.08712},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f59", "disabled": false, "gated": false, "likes": 0, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ro_sts", "sha": "f6d02a2ee6f703633935795ca47d873f65dc801c", "lastModified": "2022-11-18T21:42:20.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-sts-b", "language:ro", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The RO-STS (Romanian Semantic Textual Similarity) dataset contains 8628 pairs of sentences with their similarity score. It is a high-quality translation of the STS benchmark dataset.", "citation": "@inproceedings{dumitrescu2021liro,\n  title={Liro: Benchmark and leaderboard for romanian language tasks},\n  author={Dumitrescu, Stefan Daniel and Rebeja, Petru and Lorincz, Beata and Gaman, Mihaela and Avram, Andrei and Ilie, Mihai and Pruteanu, Andrei and Stan, Adriana and Rosia, Lorena and Iacobescu, Cristina and others},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5a", "disabled": false, "gated": false, "likes": 0, "downloads": 298, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ro_sts_parallel", "sha": "76ce53e6a31a6891265ba6a1626d7f1b027a4480", "lastModified": "2022-11-18T21:42:26.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|other-sts-b", "language:en", "language:ro", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The RO-STS-Parallel (a Parallel Romanian English dataset - translation of the Semantic Textual Similarity) contains 17256 sentences in Romanian and English. It is a high-quality translation of the English STS benchmark dataset into Romanian.", "citation": "@inproceedings{dumitrescu2021liro,\n  title={Liro: Benchmark and leaderboard for romanian language tasks},\n  author={Dumitrescu, Stefan Daniel and Rebeja, Petru and Lorincz, Beata and Gaman, Mihaela and Avram, Andrei and Ilie, Mihai and Pruteanu, Andrei and Stan, Adriana and Rosia, Lorena and Iacobescu, Cristina and others},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5b", "disabled": false, "gated": false, "likes": 0, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "roman_urdu", "sha": "b28fc9ac5730894061b7591b61297945bf0eb7ec", "lastModified": "2023-01-25T14:43:17.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ur", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is an extensive compilation of Roman Urdu Dataset (Urdu written in Latin/Roman script) tagged for sentiment analysis.", "citation": "@InProceedings{Sharf:2018,\ntitle = \"Performing Natural Language Processing on Roman Urdu Datasets\",\nauthors = \"Zareen Sharf and Saif Ur Rahman\",\nbooktitle = \"International Journal of Computer Science and Network Security\",\nvolume = \"18\",\nnumber = \"1\",\npages = \"141-148\",\nyear = \"2018\"\n}\n\n@misc{Dua:2019,\nauthor = \"Dua, Dheeru and Graff, Casey\",\nyear = \"2017\",\ntitle = \"{UCI} Machine Learning Repository\",\nurl = \"http://archive.ics.uci.edu/ml\",\ninstitution = \"University of California, Irvine, School of Information and Computer Sciences\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5c", "disabled": false, "gated": false, "likes": 2, "downloads": 325, "paperswithcode_id": "roman-urdu-data-set", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ronec", "sha": "40ba37c5327a620ed2683f19f820c698050f8148", "lastModified": "2023-01-25T14:43:21.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ro", "license:mit", "arxiv:1909.01247", "region:us"], "private": false, "author": null, "description": "RONEC - the Romanian Named Entity Corpus, at version 2.0, holds 12330 sentences with over 0.5M tokens, annotated with 15 classes, to a total of 80.283 distinctly annotated entities. It is used for named entity recognition and represents the largest Romanian NER corpus to date.", "citation": "@article{dumitrescu2019introducing,\n  title={Introducing RONEC--the Romanian Named Entity Corpus},\n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},\n  journal={arXiv preprint arXiv:1909.01247},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5d", "disabled": false, "gated": false, "likes": 1, "downloads": 317, "paperswithcode_id": "ronec", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ropes", "sha": "f952e07f6fd78d17499644cbe698bae223560284", "lastModified": "2022-11-18T21:42:43.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|wikipedia", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1908.05852", "region:us"], "private": false, "author": null, "description": "ROPES (Reasoning Over Paragraph Effects in Situations) is a QA dataset\nwhich tests a system's ability to apply knowledge from a passage\nof text to a new situation. A system is presented a background\npassage containing a causal or qualitative relation(s) (e.g.,\n\"animal pollinators increase efficiency of fertilization in flowers\"),\na novel situation that uses this background, and questions that require\nreasoning about effects of the relationships in the background\npassage in the background of the situation.", "citation": "@inproceedings{Lin2019ReasoningOP,\n  title={Reasoning Over Paragraph Effects in Situations},\n  author={Kevin Lin and Oyvind Tafjord and Peter Clark and Matt Gardner},\n  booktitle={MRQA@EMNLP},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5e", "disabled": false, "gated": false, "likes": 11, "downloads": 3978, "paperswithcode_id": "ropes", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "rotten_tomatoes", "sha": "c9f4562ef4a6c84f0098f7845944a5472cb52cad", "lastModified": "2023-04-05T13:39:30.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Movie Review Dataset.\nThis is a dataset of containing 5,331 positive and 5,331 negative processed\nsentences from Rotten Tomatoes movie reviews. This data was first used in Bo\nPang and Lillian Lee, ``Seeing stars: Exploiting class relationships for\nsentiment categorization with respect to rating scales.'', Proceedings of the\nACL, 2005.", "citation": "@InProceedings{Pang+Lee:05a,\n  author =       {Bo Pang and Lillian Lee},\n  title =        {Seeing stars: Exploiting class relationships for sentiment\n                  categorization with respect to rating scales},\n  booktitle =    {Proceedings of the ACL},\n  year =         2005\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f5f", "disabled": false, "gated": false, "likes": 30, "downloads": 61359, "paperswithcode_id": "mr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "RussianNLP/russian_super_glue", "sha": "53cb9d7f38b34c308a2eea3f4797f9edc7947d8b", "lastModified": "2023-06-19T12:23:49.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:zero-shot-classification", "task_categories:text-generation", "task_ids:natural-language-inference", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "size_categories:100M<n<1B", "source_datasets:original", "language:ru", "license:mit", "glue", "qa", "superGLUE", "NLI", "reasoning", "arxiv:2202.07791", "region:us"], "private": false, "author": "RussianNLP", "description": "Recent advances in the field of universal language models and transformers require the development of a methodology for\ntheir broad diagnostics and testing for general intellectual skills - detection of natural language inference,\ncommonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first\ntime, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from\nscratch for the Russian language. We provide baselines, human level evaluation, an open-source framework for evaluating\nmodels and an overall leaderboard of transformer models for the Russian language.", "citation": "@article{shavrina2020russiansuperglue,\n                  title={RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark},\n                  author={Shavrina, Tatiana and Fenogenova, Alena and Emelyanov, Anton and Shevelev, Denis and Artemova,\n                  Ekaterina and Malykh, Valentin and Mikhailov, Vladislav and Tikhonova, Maria and Chertok, Andrey and\n                  Evlampiev, Andrey},\n                  journal={arXiv preprint arXiv:2010.15925},\n                  year={2020}\n                  }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f60", "disabled": false, "gated": false, "likes": 17, "downloads": 2977, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "samsum", "sha": "500cefec3a5ea3af77cdda904af60cd21c93f08e", "lastModified": "2022-12-27T11:03:09.000Z", "tags": ["task_categories:summarization", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-nd-4.0", "conversations-summarization", "arxiv:1911.12237", "region:us"], "private": false, "author": null, "description": "SAMSum Corpus contains over 16k chat dialogues with manually annotated\nsummaries.\nThere are two features:\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - id: id of a example.", "citation": "@article{gliwa2019samsum,\n  title={SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization},\n  author={Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},\n  journal={arXiv preprint arXiv:1911.12237},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f62", "disabled": false, "gated": false, "likes": 180, "downloads": 232833, "paperswithcode_id": "samsum-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sanskrit_classic", "sha": "b1d601f145c84d035ec1a67e78c4cddee1fa98f4", "lastModified": "2022-11-03T16:07:56.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:sa", "license:other", "region:us"], "private": false, "author": null, "description": "This dataset combines some of the classical Sanskrit texts.", "citation": "@Misc{johnsonetal2014,\n author = {Johnson, Kyle P. and Patrick Burns and John Stewart and Todd Cook},\n title = {CLTK: The Classical Language Toolkit},\n url = {https://github.com/cltk/cltk},\n year = {2014--2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f63", "disabled": false, "gated": false, "likes": 2, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "saudinewsnet", "sha": "15904d7a8e39d6aacae2d4a3076c260b0a766c0d", "lastModified": "2023-07-17T08:18:44.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "The dataset contains a set of 31,030 Arabic newspaper articles alongwith metadata, extracted from various online Saudi newspapers and written in MSA.", "citation": "@misc{hagrima2015,\nauthor = \"M. Alhagri\",\ntitle = \"Saudi Newspapers Arabic Corpus (SaudiNewsNet)\",\nyear = 2015,\nurl = \"http://github.com/ParallelMazen/SaudiNewsNet\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f64", "disabled": false, "gated": false, "likes": 2, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sberquad", "sha": "92d74b272206a76fb3fec1f0355acab370a4de3a", "lastModified": "2023-08-29T12:35:15.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ru", "license:unknown", "arxiv:1912.09723", "region:us"], "private": false, "author": null, "description": "Sber Question Answering Dataset (SberQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. Russian original analogue presented in Sberbank Data Science Journey 2017.", "citation": "@article{Efimov_2020,\n   title={SberQuAD \u2013 Russian Reading Comprehension Dataset: Description and Analysis},\n   ISBN={9783030582197},\n   ISSN={1611-3349},\n   url={http://dx.doi.org/10.1007/978-3-030-58219-7_1},\n   DOI={10.1007/978-3-030-58219-7_1},\n   journal={Experimental IR Meets Multilinguality, Multimodality, and Interaction},\n   publisher={Springer International Publishing},\n   author={Efimov, Pavel and Chertok, Andrey and Boytsov, Leonid and Braslavski, Pavel},\n   year={2020},\n   pages={3\u201315}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f65", "disabled": false, "gated": false, "likes": 10, "downloads": 1818, "paperswithcode_id": "sberquad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scan", "sha": "00b3f6ce04b0387cbc54eaefd32a8eb9414e2b9b", "lastModified": "2023-06-01T14:59:55.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:bsd", "multi-turn", "arxiv:1711.00350", "region:us"], "private": false, "author": null, "description": "SCAN tasks with various splits.\n\nSCAN is a set of simple language-driven navigation tasks for studying\ncompositional learning and zero-shot generalization.\n\nSee https://github.com/brendenlake/SCAN for a description of the splits.\n\nExample usage:\ndata = datasets.load_dataset('scan/length')", "citation": "@inproceedings{Lake2018GeneralizationWS,\n  title={Generalization without Systematicity: On the Compositional Skills of\n         Sequence-to-Sequence Recurrent Networks},\n  author={Brenden M. Lake and Marco Baroni},\n  booktitle={ICML},\n  year={2018},\n  url={https://arxiv.org/pdf/1711.00350.pdf},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f66", "disabled": false, "gated": false, "likes": 3, "downloads": 2775, "paperswithcode_id": "scan", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scb_mt_enth_2020", "sha": "b104b0993ff36d2747a3d75ed40ba0d5fe8b51cd", "lastModified": "2022-11-18T21:43:37.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:found", "annotations_creators:machine-generated", "language_creators:expert-generated", "language_creators:found", "language_creators:machine-generated", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "language:th", "license:cc-by-sa-4.0", "arxiv:2007.03541", "arxiv:1909.05858", "region:us"], "private": false, "author": null, "description": "scb-mt-en-th-2020: A Large English-Thai Parallel Corpus\nThe primary objective of our work is to build a large-scale English-Thai dataset for machine translation.\nWe construct an English-Thai machine translation dataset with over 1 million segment pairs, curated from various sources,\nnamely news, Wikipedia articles, SMS messages, task-based dialogs, web-crawled data and government documents.\nMethodology for gathering data, building parallel texts and removing noisy sentence pairs are presented in a reproducible manner.\nWe train machine translation models based on this dataset. Our models' performance are comparable to that of\nGoogle Translation API (as of May 2020) for Thai-English and outperform Google when the Open Parallel Corpus (OPUS) is\nincluded in the training data for both Thai-English and English-Thai translation.\nThe dataset, pre-trained models, and source code to reproduce our work are available for public use.", "citation": "@article{lowphansirikul2020scb,\n  title={scb-mt-en-th-2020: A Large English-Thai Parallel Corpus},\n  author={Lowphansirikul, Lalita and Polpanumas, Charin and Rutherford, Attapol T and Nutanong, Sarana},\n  journal={arXiv preprint arXiv:2007.03541},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f67", "disabled": false, "gated": false, "likes": 3, "downloads": 471, "paperswithcode_id": "scb-mt-en-th-2020", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scene_parse_150", "sha": "f600e74bb03900e2a511061da4e4821a664bbc4b", "lastModified": "2023-01-25T14:43:32.000Z", "tags": ["task_categories:image-segmentation", "task_ids:instance-segmentation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|ade20k", "language:en", "license:bsd-3-clause", "scene-parsing", "arxiv:1608.05442", "region:us"], "private": false, "author": null, "description": "Scene parsing is to segment and parse an image into different image regions associated with semantic categories, such as sky, road, person, and bed.\nMIT Scene Parsing Benchmark (SceneParse150) provides a standard training and evaluation platform for the algorithms of scene parsing.\nThe data for this benchmark comes from ADE20K Dataset which contains more than 20K scene-centric images exhaustively annotated with objects and object parts.\nSpecifically, the benchmark is divided into 20K images for training, 2K images for validation, and another batch of held-out images for testing.\nThere are totally 150 semantic categories included for evaluation, which include stuffs like sky, road, grass, and discrete objects like person, car, bed.\nNote that there are non-uniform distribution of objects occuring in the images, mimicking a more natural object occurrence in daily scene.", "citation": "@inproceedings{zhou2017scene,\n    title={Scene Parsing through ADE20K Dataset},\n    author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},\n    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n    year={2017}\n}\n\n@article{zhou2016semantic,\n  title={Semantic understanding of scenes through the ade20k dataset},\n  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},\n  journal={arXiv preprint arXiv:1608.05442},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f68", "disabled": false, "gated": false, "likes": 14, "downloads": 2496, "paperswithcode_id": "ade20k", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "schema_guided_dstc8", "sha": "d61831f6822cc4c3e765489da9a5f99359b5db7e", "lastModified": "2023-01-25T14:43:36.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:token-classification", "task_categories:text-classification", "task_ids:dialogue-modeling", "task_ids:multi-class-classification", "task_ids:parsing", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:1909.05855", "arxiv:2002.01359", "region:us"], "private": false, "author": null, "description": "The Schema-Guided Dialogue dataset (SGD) was developed for the Dialogue State Tracking task of the Eights Dialogue Systems Technology Challenge (dstc8).\nThe SGD dataset consists of over 18k annotated multi-domain, task-oriented conversations between a human and a virtual assistant.\nThese conversations involve interactions with services and APIs spanning 17 domains, ranging from banks and events to media, calendar, travel, and weather.\nFor most of these domains, the SGD dataset contains multiple different APIs, many of which have overlapping functionalities but different interfaces,\nwhich reflects common real-world scenarios.", "citation": "@inproceedings{aaai/RastogiZSGK20,\n  author    = {Abhinav Rastogi and\n               Xiaoxue Zang and\n               Srinivas Sunkara and\n               Raghav Gupta and\n               Pranav Khaitan},\n  title     = {Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided\n               Dialogue Dataset},\n  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}\n               2020, The Thirty-Second Innovative Applications of Artificial Intelligence\n               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational\n               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,\n               February 7-12, 2020},\n  pages     = {8689--8696},\n  publisher = {{AAAI} Press},\n  year      = {2020},\n  url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6394}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f69", "disabled": false, "gated": false, "likes": 7, "downloads": 608, "paperswithcode_id": "sgd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/scicite", "sha": "a73e7a3c980fcedaff1076fddce9d2a24fa0a4d2", "lastModified": "2023-01-25T14:43:39.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "arxiv:1904.01608", "region:us"], "private": false, "author": "allenai", "description": "This is a dataset for classifying citation intents in academic papers.\nThe main citation intent label for each Json object is specified with the label\nkey while the citation context is specified in with a context key. Example:\n{\n 'string': 'In chacma baboons, male-infant relationships can be linked to both\n    formation of friendships and paternity success [30,31].'\n 'sectionName': 'Introduction',\n 'label': 'background',\n 'citingPaperId': '7a6b2d4b405439',\n 'citedPaperId': '9d1abadc55b5e0',\n ...\n }\nYou may obtain the full information about the paper using the provided paper ids\nwith the Semantic Scholar API (https://api.semanticscholar.org/).\nThe labels are:\nMethod, Background, Result", "citation": "@InProceedings{Cohan2019Structural,\n  author={Arman Cohan and Waleed Ammar and Madeleine Van Zuylen and Field Cady},\n  title={Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n  booktitle={NAACL},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6a", "disabled": false, "gated": false, "likes": 4, "downloads": 547, "paperswithcode_id": "scicite", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scielo", "sha": "d017d39fe9971663b9b69abbf41fd3662dbab4f0", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:es", "language:pt", "license:unknown", "arxiv:1905.01852", "region:us"], "private": false, "author": null, "description": "A parallel corpus of full-text scientific articles collected from Scielo database in the following languages: English, Portuguese and Spanish. The corpus is sentence aligned for all language pairs, as well as trilingual aligned for a small subset of sentences. Alignment was carried out using the Hunalign algorithm.", "citation": "@inproceedings{soares2018large,\n  title={A Large Parallel Corpus of Full-Text Scientific Articles},\n  author={Soares, Felipe and Moreira, Viviane and Becker, Karin},\n  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018)},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6b", "disabled": false, "gated": false, "likes": 1, "downloads": 568, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scientific_papers", "sha": "14c5296f2d707630f5835c9da59dcaddeea19b20", "lastModified": "2023-04-05T13:39:46.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "abstractive-summarization", "arxiv:1804.05685", "region:us"], "private": false, "author": null, "description": "Scientific papers datasets contains two sets of long and structured documents.\nThe datasets are obtained from ArXiv and PubMed OpenAccess repositories.\n\nBoth \"arxiv\" and \"pubmed\" have two features:\n  - article: the body of the document, pagragraphs seperated by \"/n\".\n  - abstract: the abstract of the document, pagragraphs seperated by \"/n\".\n  - section_names: titles of sections, seperated by \"/n\".", "citation": "@article{Cohan_2018,\n   title={A Discourse-Aware Attention Model for Abstractive Summarization of\n            Long Documents},\n   url={http://dx.doi.org/10.18653/v1/n18-2097},\n   DOI={10.18653/v1/n18-2097},\n   journal={Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 2 (Short Papers)},\n   publisher={Association for Computational Linguistics},\n   author={Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},\n   year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6c", "disabled": false, "gated": false, "likes": 80, "downloads": 5730, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/scifact", "sha": "97fdeac7dc84a9d9731f259348300685f2df9b68", "lastModified": "2022-11-18T21:44:10.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-2.0", "region:us"], "private": false, "author": "allenai", "description": "SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts, and annotated with labels and rationales.", "citation": "@inproceedings{Wadden2020FactOF,\n  title={Fact or Fiction: Verifying Scientific Claims},\n  author={David Wadden and Shanchuan Lin and Kyle Lo and Lucy Lu Wang and Madeleine van Zuylen and Arman Cohan and Hannaneh Hajishirzi},\n  booktitle={EMNLP},\n  year={2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6d", "disabled": false, "gated": false, "likes": 7, "downloads": 872, "paperswithcode_id": "scifact", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sciq", "sha": "2781d6158899d6ba2edc0c7777bb11af57e78252", "lastModified": "2023-06-06T07:16:34.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-3.0", "region:us"], "private": false, "author": null, "description": "The SciQ dataset contains 13,679 crowdsourced science exam questions about Physics, Chemistry and Biology, among others. The questions are in multiple-choice format with 4 answer options each. For the majority of the questions, an additional paragraph with supporting evidence for the correct answer is provided.", "citation": "@inproceedings{SciQ,\n    title={Crowdsourcing Multiple Choice Science Questions},\n    author={Johannes Welbl, Nelson F. Liu, Matt Gardner},\n    year={2017},\n    journal={arXiv:1707.06209v1}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6e", "disabled": false, "gated": false, "likes": 66, "downloads": 90721, "paperswithcode_id": "sciq", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "scitail", "sha": "12ecea924f3c6ade6955cac4951f1c8ca5d96383", "lastModified": "2023-04-05T13:39:52.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "The SciTail dataset is an entailment dataset created from multiple-choice science exams and web sentences. Each question\nand the correct answer choice are converted into an assertive statement to form the hypothesis. We use information\nretrieval to obtain relevant text from a large text corpus of web sentences, and use these sentences as a premise P. We\ncrowdsource the annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order to create\nthe SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with entails label and 16,925 examples\nwith neutral label", "citation": "inproceedings{scitail,\n     Author = {Tushar Khot and Ashish Sabharwal and Peter Clark},\n     Booktitle = {AAAI},\n     Title = {{SciTail}: A Textual Entailment Dataset from Science Question Answering},\n     Year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f6f", "disabled": false, "gated": false, "likes": 5, "downloads": 3394, "paperswithcode_id": "scitail", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/scitldr", "sha": "1d4bfe28051ac4074d22a938b913f303aa3402b0", "lastModified": "2023-01-25T14:43:42.000Z", "tags": ["task_categories:summarization", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "scientific-documents-summarization", "arxiv:2004.15011", "region:us"], "private": false, "author": "allenai", "description": "A new multi-target dataset of 5.4K TLDRs over 3.2K papers.\nSCITLDR contains both author-written and expert-derived TLDRs,\nwhere the latter are collected using a novel annotation protocol\nthat produces high-quality summaries while minimizing annotation burden.", "citation": "@article{cachola2020tldr,\n  title={{TLDR}: Extreme Summarization of Scientific Documents},\n  author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\n  journal={arXiv:2004.15011},\n  year={2020},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f70", "disabled": false, "gated": false, "likes": 17, "downloads": 1066, "paperswithcode_id": "scitldr", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "search_qa", "sha": "06907e45883b7cae435453b65d598447039fde79", "lastModified": "2023-06-16T09:03:21.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1704.05179", "region:us"], "private": false, "author": null, "description": "We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind\nCNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article\nand generate a question-answer pair, but start from an existing question-answer pair, crawled from J! Archive, and augment it with text snippets retrieved by Google.\nFollowing this approach, we built SearchQA, which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context\n tuple of the SearchQA comes with additional meta-data such as the snippet's URL, which we believe will be valuable resources for future research. We conduct human evaluation\n as well as test two baseline methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a meaningful gap between the human\n and machine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f71", "disabled": false, "gated": false, "likes": 11, "downloads": 596, "paperswithcode_id": "searchqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sede", "sha": "93a57424ff4063876390b90de7728912b0a91e67", "lastModified": "2022-11-18T21:44:41.000Z", "tags": ["task_categories:token-classification", "task_ids:parsing", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2106.05006", "arxiv:2005.02539", "region:us"], "private": false, "author": null, "description": "SEDE (Stack Exchange Data Explorer) is new dataset for Text-to-SQL tasks with more than 12,000 SQL queries and their\nnatural language description. It's based on a real usage of users from the Stack Exchange Data Explorer platform,\nwhich brings complexities and challenges never seen before in any other semantic parsing dataset like\nincluding complex nesting, dates manipulation, numeric and text manipulation, parameters, and most\nimportantly: under-specification and hidden-assumptions.\n\nPaper (NLP4Prog workshop at ACL2021): https://arxiv.org/abs/2106.05006", "citation": "@misc{hazoom2021texttosql,\n      title={Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data},\n      author={Moshe Hazoom and Vibhor Malik and Ben Bogin},\n      year={2021},\n      eprint={2106.05006},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f72", "disabled": false, "gated": false, "likes": 5, "downloads": 291, "paperswithcode_id": "sede", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "selqa", "sha": "debe34d183d3ffee466895f2808257ac6fbd05ec", "lastModified": "2023-01-25T14:43:46.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:1606.00851", "region:us"], "private": false, "author": null, "description": "The SelQA dataset provides crowdsourced annotation for two selection-based question answer tasks,\nanswer sentence selection and answer triggering.", "citation": "@InProceedings{7814688,\n  author={T. {Jurczyk} and M. {Zhai} and J. D. {Choi}},\n  booktitle={2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)},\n  title={SelQA: A New Benchmark for Selection-Based Question Answering},\n  year={2016},\n  volume={},\n  number={},\n  pages={820-827},\n  doi={10.1109/ICTAI.2016.0128}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f73", "disabled": false, "gated": false, "likes": 0, "downloads": 876, "paperswithcode_id": "selqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sem_eval_2010_task_8", "sha": "8772d5e6dc26d4aa35e82bfd820b1ac46b383055", "lastModified": "2023-04-05T13:39:59.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "The SemEval-2010 Task 8 focuses on Multi-way classification of semantic relations between pairs of nominals.\nThe task was designed to compare different approaches to semantic relation classification\nand to provide a standard testbed for future research.", "citation": "@inproceedings{hendrickx-etal-2010-semeval,\n    title = \"{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals\",\n    author = \"Hendrickx, Iris  and\n      Kim, Su Nam  and\n      Kozareva, Zornitsa  and\n      Nakov, Preslav  and\n      {\\'O} S{\\'e}aghdha, Diarmuid  and\n      Pad{\\'o}, Sebastian  and\n      Pennacchiotti, Marco  and\n      Romano, Lorenza  and\n      Szpakowicz, Stan\",\n    booktitle = \"Proceedings of the 5th International Workshop on Semantic Evaluation\",\n    month = jul,\n    year = \"2010\",\n    address = \"Uppsala, Sweden\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/S10-1006\",\n    pages = \"33--38\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f74", "disabled": false, "gated": false, "likes": 5, "downloads": 582, "paperswithcode_id": "semeval-2010-task-8", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sem_eval_2014_task_1", "sha": "bb97f4b80533aab20282f93784db3430fbb530f5", "lastModified": "2023-01-25T14:43:53.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-ImageFlickr and SemEval-2012 STS MSR-Video Descriptions", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The SemEval-2014 Task 1 focuses on Evaluation of Compositional Distributional Semantic Models\non Full Sentences through Semantic Relatedness and Entailment. The task was designed to\npredict the degree of relatedness between two sentences and to detect the entailment\nrelation holding between them.", "citation": "@inproceedings{inproceedings,\nauthor = {Marelli, Marco and Bentivogli, Luisa and Baroni, Marco and Bernardi, Raffaella and Menini, Stefano and Zamparelli, Roberto},\nyear = {2014},\nmonth = {08},\npages = {},\ntitle = {SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment},\ndoi = {10.3115/v1/S14-2001}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f75", "disabled": false, "gated": false, "likes": 1, "downloads": 369, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sem_eval_2018_task_1", "sha": "a13b167553f4218591cf8c67d6f37713bee2d0e0", "lastModified": "2022-11-18T21:45:06.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "language:en", "language:es", "license:unknown", "emotion-classification", "region:us"], "private": false, "author": null, "description": " SemEval-2018 Task 1: Affect in Tweets: SubTask 5: Emotion Classification.\n This is a dataset for multilabel emotion classification for tweets.\n 'Given a tweet, classify it as 'neutral or no emotion' or as one, or more, of eleven given emotions that best represent the mental state of the tweeter.'\n It contains 22467 tweets in three languages manually annotated by crowdworkers using Best\u2013Worst Scaling.", "citation": "@InProceedings{SemEval2018Task1,\n author = {Mohammad, Saif M. and Bravo-Marquez, Felipe and Salameh, Mohammad and Kiritchenko, Svetlana},\n title = {SemEval-2018 {T}ask 1: {A}ffect in Tweets},\n booktitle = {Proceedings of International Workshop on Semantic Evaluation (SemEval-2018)},\n address = {New Orleans, LA, USA},\n year = {2018}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f76", "disabled": false, "gated": false, "likes": 9, "downloads": 2380, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sem_eval_2020_task_11", "sha": "f1cb339c4b8554c264004512e462f2216084792b", "lastModified": "2023-01-25T14:43:56.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:unknown", "propaganda-span-identification", "propaganda-technique-classification", "arxiv:2009.02696", "region:us"], "private": false, "author": null, "description": "Propagandistic news articles use specific techniques to convey their message,\nsuch as whataboutism, red Herring, and name calling, among many others.\nThe Propaganda Techniques Corpus (PTC) allows to study automatic algorithms to\ndetect them. We provide a permanent leaderboard to allow researchers both to\nadvertise their progress and to be up-to-speed with the state of the art on the\ntasks offered (see below for a definition).", "citation": "@misc{martino2020semeval2020,\n      title={SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles},\n      author={G. Da San Martino and A. Barr\u00f3n-Cede\u00f1o and H. Wachsmuth and R. Petrov and P. Nakov},\n      year={2020},\n      eprint={2009.02696},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f77", "disabled": false, "gated": false, "likes": 5, "downloads": 325, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sent_comp", "sha": "2bfbdf687eb8f84f08656e8c9455f82396a41dad", "lastModified": "2022-11-18T21:45:18.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "sentence-compression", "region:us"], "private": false, "author": null, "description": "Large corpus of uncompressed and compressed sentences from news articles.", "citation": "@inproceedings{filippova-altun-2013-overcoming,\n    title = \"Overcoming the Lack of Parallel Data in Sentence Compression\",\n    author = \"Filippova, Katja  and\n      Altun, Yasemin\",\n    booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct,\n    year = \"2013\",\n    address = \"Seattle, Washington, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D13-1155\",\n    pages = \"1481--1491\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f78", "disabled": false, "gated": false, "likes": 1, "downloads": 351, "paperswithcode_id": "sentence-compression", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "senti_lex", "sha": "fef91cf506c726fd0fc4e45baa73b8b7bdbc985e", "lastModified": "2023-06-08T12:24:00.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:af", "language:an", "language:ar", "language:az", "language:be", "language:bg", "language:bn", "language:br", "language:bs", "language:ca", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fo", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gu", "language:he", "language:hi", "language:hr", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:io", "language:is", "language:it", "language:ja", "language:ka", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lb", "language:lt", "language:lv", "language:mk", "language:mr", "language:ms", "language:mt", "language:nl", "language:nn", "language:no", "language:pl", "language:pt", "language:rm", "language:ro", "language:ru", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:sw", "language:ta", "language:te", "language:th", "language:tk", "language:tl", "language:tr", "language:uk", "language:ur", "language:uz", "language:vi", "language:vo", "language:wa", "language:yi", "language:zh", "language:zhw", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "This dataset add sentiment lexicons for 81 languages generated via graph propagation based on a knowledge graph--a graphical representation of real-world entities and the links between them.", "citation": "@inproceedings{inproceedings,\nauthor = {Chen, Yanqing and Skiena, Steven},\nyear = {2014},\nmonth = {06},\npages = {383-389},\ntitle = {Building Sentiment Lexicons for All Major Languages},\nvolume = {2},\njournal = {52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014 - Proceedings of the Conference},\ndoi = {10.3115/v1/P14-2063}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f79", "disabled": false, "gated": false, "likes": 5, "downloads": 12633, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "senti_ws", "sha": "eff382b9098f75e0298da4bfb6071dfcfa4df3be", "lastModified": "2023-01-25T14:44:03.000Z", "tags": ["task_categories:token-classification", "task_categories:text-classification", "task_ids:text-scoring", "task_ids:sentiment-scoring", "task_ids:part-of-speech", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:de", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, and pos-tagging. The POS tags are [\"NN\", \"VVINF\", \"ADJX\", \"ADV\"] -> [\"noun\", \"verb\", \"adjective\", \"adverb\"], and positive and negative polarity bearing words are weighted within the interval of [-1, 1].", "citation": "@INPROCEEDINGS{remquahey2010,\ntitle = {SentiWS -- a Publicly Available German-language Resource for Sentiment Analysis},\nbooktitle = {Proceedings of the 7th International Language Resources and Evaluation (LREC'10)},\nauthor = {Remus, R. and Quasthoff, U. and Heyer, G.},\nyear = {2010}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f7a", "disabled": false, "gated": false, "likes": 1, "downloads": 430, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sentiment140", "sha": "278a135620069e3122e0a054ba45250bd1b98085", "lastModified": "2023-10-20T12:55:00.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "Sentiment140 consists of Twitter messages with emoticons, which are used as noisy labels for\nsentiment classification. For more detailed information please refer to the paper.", "citation": "@article{go2009twitter,\n  title={Twitter sentiment classification using distant supervision},\n  author={Go, Alec and Bhayani, Richa and Huang, Lei},\n  journal={CS224N project report, Stanford},\n  volume={1},\n  number={12},\n  pages={2009},\n  year={2009}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f7b", "disabled": false, "gated": false, "likes": 11, "downloads": 1278, "paperswithcode_id": "sentiment140", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "setimes", "sha": "30a12206f5d30fa87fc692acd62c0f17de11a060", "lastModified": "2022-11-03T16:47:00.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:bg", "language:bs", "language:el", "language:en", "language:hr", "language:mk", "language:ro", "language:sq", "language:sr", "language:tr", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "SETimes \u2013 A Parallel Corpus of English and South-East European Languages\nThe corpus is based on the content published on the SETimes.com news portal. The news portal publishes \u201cnews and views from Southeast Europe\u201d in ten languages: Bulgarian, Bosnian, Greek, English, Croatian, Macedonian, Romanian, Albanian and Serbian. This version of the corpus tries to solve the issues present in an older version of the corpus (published inside OPUS, described in the LREC 2010 paper by Francis M. Tyers and Murat Serdar Alperen). The following procedures were applied to resolve existing issues:\n\n- stricter extraction process \u2013 no HTML residues present\n- language identification on every non-English document \u2013 non-English online documents contain English material in case the article was not translated into that language\n- resolving encoding issues in Croatian and Serbian \u2013 diacritics were partially lost due to encoding errors \u2013 text was rediacritized.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f7e", "disabled": false, "gated": false, "likes": 0, "downloads": 6420, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sharc", "sha": "b5656cbc3b55e35e831ac9d14a05c1e939aca1c3", "lastModified": "2022-11-03T16:16:40.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "conversational-qa", "arxiv:1809.01494", "region:us"], "private": false, "author": null, "description": "ShARC is a Conversational Question Answering dataset focussing on question answering from texts containing rules. The goal is to answer questions by possibly asking follow-up questions first. It is assumed assume that the question is often underspecified, in the sense that the question does not provide enough information to be answered directly. However, an agent can use the supporting rule text to infer what needs to be asked in order to determine the final answer.", "citation": "@misc{saeidi2018interpretation,\n      title={Interpretation of Natural Language Rules in Conversational Machine Reading},\n      author={Marzieh Saeidi and Max Bartolo and Patrick Lewis and Sameer Singh and Tim Rockt\u00e4schel and Mike Sheldon and Guillaume Bouchard and Sebastian Riedel},\n      year={2018},\n      eprint={1809.01494},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f80", "disabled": false, "gated": false, "likes": 1, "downloads": 617, "paperswithcode_id": "sharc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sharc_modified", "sha": "3cd2386ee875c038d8d40b6a665d1e9ad6ece6fc", "lastModified": "2022-11-03T16:31:23.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|sharc", "language:en", "license:unknown", "conversational-qa", "arxiv:1909.03759", "arxiv:2009.06354", "region:us"], "private": false, "author": null, "description": "ShARC, a conversational QA task, requires a system to answer user questions based on rules expressed in natural language text. However, it is found that in the ShARC dataset there are multiple spurious patterns that could be exploited by neural models. SharcModified is a new dataset which reduces the patterns identified in the original dataset. To reduce the sensitivity of neural models, for each occurence of an instance conforming to any of the patterns, we automatically construct alternatives where we choose to either replace the current instance with an alternative instance which does not exhibit the pattern; or retain the original instance. The modified ShARC has two versions sharc-mod and history-shuffled. For morre details refer to Appendix A.3 .", "citation": "@inproceedings{verma-etal-2020-neural,\n    title = \"Neural Conversational {QA}: Learning to Reason vs Exploiting Patterns\",\n    author = \"Verma, Nikhil  and\n      Sharma, Abhishek  and\n      Madan, Dhiraj  and\n      Contractor, Danish  and\n      Kumar, Harshit  and\n      Joshi, Sachindra\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.589\",\n    pages = \"7263--7269\",\n    abstract = \"Neural Conversational QA tasks such as ShARC require systems to answer questions based on the contents of a given passage. On studying recent state-of-the-art models on the ShARC QA task, we found indications that the model(s) learn spurious clues/patterns in the data-set. Further, a heuristic-based program, built to exploit these patterns, had comparative performance to that of the neural models. In this paper we share our findings about the four types of patterns in the ShARC corpus and how the neural models exploit them. Motivated by the above findings, we create and share a modified data-set that has fewer spurious patterns than the original data-set, consequently allowing models to learn better.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f81", "disabled": false, "gated": false, "likes": 0, "downloads": 698, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sick", "sha": "05e83234fb10dd676ce8b35ad94d00b731d0ab92", "lastModified": "2023-01-25T14:44:16.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|image-flickr-8k", "source_datasets:extended|semeval2012-sts-msr-video", "language:en", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": null, "description": "Shared and internationally recognized benchmarks are fundamental for the development of any computational system.\nWe aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them.\nSICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs.\nBy means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral).\nThe SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes.", "citation": "@inproceedings{marelli-etal-2014-sick,\n    title = \"A {SICK} cure for the evaluation of compositional distributional semantic models\",\n    author = \"Marelli, Marco  and\n      Menini, Stefano  and\n      Baroni, Marco  and\n      Bentivogli, Luisa  and\n      Bernardi, Raffaella  and\n      Zamparelli, Roberto\",\n    booktitle = \"Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)\",\n    month = may,\n    year = \"2014\",\n    address = \"Reykjavik, Iceland\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf\",\n    pages = \"216--223\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f82", "disabled": false, "gated": false, "likes": 5, "downloads": 3212, "paperswithcode_id": "sick", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "silicone", "sha": "f171f67d95c426897a95c437c5650b7cccf8591b", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:dialogue-modeling", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:sentiment-classification", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "emotion-classification", "dialogue-act-classification", "arxiv:2009.11152", "region:us"], "private": false, "author": null, "description": "The Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE (SILICONE) benchmark is a collection\n of resources for training, evaluating, and analyzing natural language understanding systems\n specifically designed for spoken language. All datasets are in the English language and cover a\n variety of domains including daily life, scripted scenarios, joint task completion, phone call\n conversations, and televsion dialogue. Some datasets additionally include emotion and/or sentimant\n labels.", "citation": "@inproceedings{chapuis-etal-2020-hierarchical,\n    title = \"Hierarchical Pre-training for Sequence Labelling in Spoken Dialog\",\n    author = \"Chapuis, Emile  and\n      Colombo, Pierre  and\n      Manica, Matteo  and\n      Labeau, Matthieu  and\n      Clavel, Chlo{\\'e}\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.239\",\n    doi = \"10.18653/v1/2020.findings-emnlp.239\",\n    pages = \"2636--2648\",\n    abstract = \"Sequence labelling tasks like Dialog Act and Emotion/Sentiment identification are a\n        key component of spoken dialog systems. In this work, we propose a new approach to learn\n        generic representations adapted to spoken dialog, which we evaluate on a new benchmark we\n        call Sequence labellIng evaLuatIon benChmark fOr spoken laNguagE benchmark (SILICONE).\n        SILICONE is model-agnostic and contains 10 different datasets of various sizes.\n        We obtain our representations with a hierarchical encoder based on transformer architectures,\n        for which we extend two well-known pre-training objectives. Pre-training is performed on\n        OpenSubtitles: a large corpus of spoken dialog containing over 2.3 billion of tokens. We\n        demonstrate how hierarchical encoders achieve competitive results with consistently fewer\n        parameters compared to state-of-the-art models and we show their importance for both\n        pre-training and fine-tuning.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f83", "disabled": false, "gated": false, "likes": 8, "downloads": 1798, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "simple_questions_v2", "sha": "245aa0eb121bbfc01980e04746ab48cc5c71c792", "lastModified": "2022-11-18T21:46:14.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "SimpleQuestions is a dataset for simple QA, which consists\nof a total of 108,442 questions written in natural language by human\nEnglish-speaking annotators each paired with a corresponding fact,\nformatted as (subject, relationship, object), that provides the answer\nbut also a complete explanation.  Fast have been extracted from the\nKnowledge Base Freebase (freebase.com).  We randomly shuffle these\nquestions and use 70% of them (75910) as training set, 10% as\nvalidation set (10845), and the remaining 20% as test set.", "citation": "@misc{bordes2015largescale,\n      title={Large-scale Simple Question Answering with Memory Networks},\n      author={Antoine Bordes and Nicolas Usunier and Sumit Chopra and Jason Weston},\n      year={2015},\n      eprint={1506.02075},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f84", "disabled": false, "gated": false, "likes": 2, "downloads": 632, "paperswithcode_id": "simplequestions", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "smartdata", "sha": "3e591221ba4d0fc0fe104c05272fe2f5e7f6a130", "lastModified": "2023-01-25T14:44:26.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:de", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "DFKI SmartData Corpus is a dataset of 2598 German-language documents\nwhich has been annotated with fine-grained geo-entities, such as streets,\nstops and routes, as well as standard named entity types. It has also\nbeen annotated with a set of 15 traffic- and industry-related n-ary\nrelations and events, such as Accidents, Traffic jams, Acquisitions,\nand Strikes. The corpus consists of newswire texts, Twitter messages,\nand traffic reports from radio stations, police and railway companies.\nIt allows for training and evaluating both named entity recognition\nalgorithms that aim for fine-grained typing of geo-entities, as well\nas n-ary relation extraction systems.", "citation": "@InProceedings{SCHIERSCH18.85,\n  author = {Martin Schiersch and Veselina Mironova and Maximilian Schmitt and Philippe Thomas and Aleksandra Gabryszak and Leonhard Hennig},\n  title = \"{A German Corpus for Fine-Grained Named Entity Recognition and Relation Extraction of Traffic and Industry Events}\",\n  booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},\n  year = {2018},\n  month = {May 7-12, 2018},\n  address = {Miyazaki, Japan},\n  editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and H\u00e9l\u00e8ne Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {979-10-95546-00-9},\n  language = {english}\n  }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f86", "disabled": false, "gated": false, "likes": 1, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sms_spam", "sha": "078db3b12d3f1ee0c4ff6f4348fcf5a090f1b9d0", "lastModified": "2023-01-25T14:44:29.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:crowdsourced", "annotations_creators:found", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-nus-sms-corpus", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The SMS Spam Collection v.1 is a public set of SMS labeled messages that have been collected for mobile phone spam research.\nIt has one collection composed by 5,574 English, real and non-enconded messages, tagged according being legitimate (ham) or spam.", "citation": "@inproceedings{Almeida2011SpamFiltering,\n  title={Contributions to the Study of SMS Spam Filtering: New Collection and Results},\n  author={Tiago A. Almeida and Jose Maria Gomez Hidalgo and Akebo Yamakami},\n  year={2011},\n  booktitle = \"Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11)\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f87", "disabled": false, "gated": false, "likes": 15, "downloads": 1572, "paperswithcode_id": "sms-spam-collection-data-set", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "snips_built_in_intents", "sha": "9b8ff05bd82a8c484dae4ce0a139c570d0feefab", "lastModified": "2023-01-25T14:44:32.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc0-1.0", "arxiv:1805.10190", "region:us"], "private": false, "author": null, "description": "Snips' built in intents dataset was initially used to compare different voice assistants and released as a public dataset hosted at\nhttps://github.com/sonos/nlu-benchmark 2016-12-built-in-intents. The dataset contains 328 utterances over 10 intent classes. The\nrelated paper mentioned on the github page is https://arxiv.org/abs/1805.10190 and a related Medium post is\nhttps://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d .", "citation": "@article{DBLP:journals/corr/abs-1805-10190,\n  author    = {Alice Coucke and\n               Alaa Saade and\n               Adrien Ball and\n               Th{\\'{e}}odore Bluche and\n               Alexandre Caulier and\n               David Leroy and\n               Cl{\\'{e}}ment Doumouro and\n               Thibault Gisselbrecht and\n               Francesco Caltagirone and\n               Thibaut Lavril and\n               Ma{\\\"{e}}l Primet and\n               Joseph Dureau},\n  title     = {Snips Voice Platform: an embedded Spoken Language Understanding system\n               for private-by-design voice interfaces},\n  journal   = {CoRR},\n  volume    = {abs/1805.10190},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1805.10190},\n  archivePrefix = {arXiv},\n  eprint    = {1805.10190},\n  timestamp = {Mon, 13 Aug 2018 16:46:59 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-10190.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f88", "disabled": false, "gated": false, "likes": 5, "downloads": 1498, "paperswithcode_id": "snips", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "snli", "sha": "28d6eeaaec6b6c764041ddc461144bd0b272d1f5", "lastModified": "2023-01-25T14:44:35.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other-flicker-30k", "source_datasets:extended|other-visual-genome", "language:en", "license:cc-by-4.0", "arxiv:1909.02209", "region:us"], "private": false, "author": null, "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English\nsentence pairs manually labeled for balanced classification with the labels\nentailment, contradiction, and neutral, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).", "citation": "@inproceedings{snli:emnlp2015,\n    Author = {Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher, and Manning, Christopher D.},\n    Booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n    Publisher = {Association for Computational Linguistics},\n    Title = {A large annotated corpus for learning natural language inference},\n    Year = {2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f89", "disabled": false, "gated": false, "likes": 32, "downloads": 38464, "paperswithcode_id": "snli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "snow_simplified_japanese_corpus", "sha": "4a127f87d5781443678ec44b694cbaf9a205a3a1", "lastModified": "2022-11-03T16:31:17.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "annotations_creators:other", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:ja", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "About SNOW T15: The simplified corpus for the Japanese language. The corpus has 50,000 manually simplified and aligned sentences. This corpus contains the original sentences, simplified sentences and English translation of the original sentences. It can be used for automatic text simplification as well as translating simple Japanese into English and vice-versa. The core vocabulary is restricted to 2,000 words where it is selected by accounting for several factors such as meaning preservation, variation, simplicity and the UniDic word segmentation criterion.\nFor details, refer to the explanation page of Japanese simplification (http://www.jnlp.org/research/Japanese_simplification). The original texts are from \"small_parallel_enja: 50k En/Ja Parallel Corpus for Testing SMT Methods\", which is a bilingual corpus for machine translation. About SNOW T23: An expansion corpus of 35,000 sentences rewritten in easy Japanese (simple Japanese vocabulary) based on SNOW T15. The original texts are from \"Tanaka Corpus\" (http://www.edrdg.org/wiki/index.php/Tanaka_Corpus).", "citation": "@inproceedings{maruyama-yamamoto-2018-simplified,\n    title = \"Simplified Corpus with Core Vocabulary\",\n    author = \"Maruyama, Takumi  and\n      Yamamoto, Kazuhide\",\n    booktitle = \"Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)\",\n    month = may,\n    year = \"2018\",\n    address = \"Miyazaki, Japan\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"https://www.aclweb.org/anthology/L18-1185\",\n}\n\n@inproceedings{yamamoto-2017-simplified-japanese,\n    title = \"\u3084\u3055\u3057\u3044\u2f47\u672c\u8a9e\u5bfe\u8a33\u30b3\u30fc\u30d1\u30b9\u306e\u69cb\u7bc9\",\n    author = \"\u2f2d\u672c \u548c\u82f1  and\n      \u4e38\u2f2d \u62d3\u6d77  and\n      \u2f93\u5f35 \u2eef\u6674  and\n      \u7a32\u5ca1 \u5922\u2f08  and\n      \u2f29\u5ddd \u8000\u2f00\u6717  and\n      \u52dd\u2f65 \u54f2\u5f18  and\n      \u9ad9\u6a4b \u5bdb\u6cbb\",\n    booktitle = \"\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a\u7b2c23\u56de\u5e74\u6b21\u5927\u4f1a\",\n    month = 3\u6708,\n    year = \"2017\",\n    address = \"\u8328\u57ce, \u65e5\u672c\",\n    publisher = \"\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a\",\n    url = \"https://www.anlp.jp/proceedings/annual_meeting/2017/pdf_dir/B5-1.pdf\",\n}\n\n@inproceedings{katsuta-yamamoto-2018-crowdsourced,\n    title = \"Crowdsourced Corpus of Sentence Simplification with Core Vocabulary\",\n    author = \"Katsuta, Akihiro  and\n      Yamamoto, Kazuhide\",\n    booktitle = \"Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)\",\n    month = may,\n    year = \"2018\",\n    address = \"Miyazaki, Japan\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"https://www.aclweb.org/anthology/L18-1072\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8a", "disabled": false, "gated": false, "likes": 15, "downloads": 447, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "so_stacksample", "sha": "dfdf39f9b7fbc3afbd31591a18c232067918cd91", "lastModified": "2022-11-03T16:30:57.000Z", "tags": ["task_categories:text2text-generation", "task_ids:abstractive-qa", "task_ids:open-domain-abstractive-qa", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "Dataset with the text of 10% of questions and answers from the Stack Overflow programming Q&A website.\n\nThis is organized as three tables:\n\nQuestions contains the title, body, creation date, closed date (if applicable), score, and owner ID for all non-deleted Stack Overflow questions whose Id is a multiple of 10.\nAnswers contains the body, creation date, score, and owner ID for each of the answers to these questions. The ParentId column links back to the Questions table.\nTags contains the tags on each of these questions.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8b", "disabled": false, "gated": false, "likes": 3, "downloads": 574, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "social_bias_frames", "sha": "f70086ce2be609b4e80fa3cdabef901bbe333712", "lastModified": "2023-04-05T13:40:19.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "explanation-generation", "region:us"], "private": false, "author": null, "description": "Social Bias Frames is a new way of representing the biases and offensiveness that are implied in language.\nFor example, these frames are meant to distill the implication that \"women (candidates) are less qualified\"\nbehind the statement \"we shouldn\u2019t lower our standards to hire more women.\"", "citation": "@inproceedings{sap2020socialbiasframes,\n   title={Social Bias Frames: Reasoning about Social and Power Implications of Language},\n   author={Sap, Maarten and Gabriel, Saadia and Qin, Lianhui and Jurafsky, Dan and Smith, Noah A and Choi, Yejin},\n   year={2020},\n   booktitle={ACL},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8c", "disabled": false, "gated": false, "likes": 8, "downloads": 947, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "social_i_qa", "sha": "54e4776dd86d0a52f6a96b034456107cbe8cad1f", "lastModified": "2023-04-05T13:40:21.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "We introduce Social IQa: Social Interaction QA, a new question-answering benchmark for testing social commonsense intelligence. Contrary to many prior benchmarks that focus on physical or taxonomic knowledge, Social IQa focuses on reasoning about people\u2019s actions and their social implications. For example, given an action like \"Jesse saw a concert\" and a question like \"Why did Jesse do this?\", humans can easily infer that Jesse wanted \"to see their favorite performer\" or \"to enjoy the music\", and not \"to see what's happening inside\" or \"to see if it works\". The actions in Social IQa span a wide variety of social situations, and answer candidates contain both human-curated answers and adversarially-filtered machine-generated candidates. Social IQa contains over 37,000 QA pairs for evaluating models\u2019 abilities to reason about the social implications of everyday events and situations. (Less)", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8d", "disabled": false, "gated": false, "likes": 4, "downloads": 31273, "paperswithcode_id": "social-iqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sofc_materials_articles", "sha": "98d425e85eda954f58ad8435c924a85db40e968a", "lastModified": "2023-03-09T10:44:46.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:token-classification", "task_categories:text-classification", "task_ids:named-entity-recognition", "task_ids:slot-filling", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2006.03039", "region:us"], "private": false, "author": null, "description": "The SOFC-Exp corpus consists of 45 open-access scholarly articles annotated by domain experts.\nA corpus and an inter-annotator agreement study demonstrate the complexity of the suggested\nnamed entity recognition and slot filling tasks as well as high annotation quality is presented\nin the accompanying paper.", "citation": "@misc{friedrich2020sofcexp,\n      title={The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain},\n      author={Annemarie Friedrich and Heike Adel and Federico Tomazic and Johannes Hingerl and Renou Benteau and Anika Maruscyk and Lukas Lange},\n      year={2020},\n      eprint={2006.03039},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8e", "disabled": false, "gated": false, "likes": 7, "downloads": 298, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sogou_news", "sha": "52964e5626b518bb564ff0419a5c6bb78fa888fb", "lastModified": "2023-04-05T13:40:25.000Z", "tags": ["arxiv:1509.01626", "region:us"], "private": false, "author": null, "description": "The Sogou News dataset is a mixture of 2,909,551 news articles from the SogouCA and SogouCS news corpora, in 5 categories.\nThe number of training samples selected for each class is 90,000 and testing 12,000. Note that the Chinese characters have been converted to Pinyin.\nclassification labels of the news are determined by their domain names in the URL. For example, the news with\nURL http://sports.sohu.com is categorized as a sport class.", "citation": "@misc{zhang2015characterlevel,\n    title={Character-level Convolutional Networks for Text Classification},\n    author={Xiang Zhang and Junbo Zhao and Yann LeCun},\n    year={2015},\n    eprint={1509.01626},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f8f", "disabled": false, "gated": false, "likes": 0, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "spanish_billion_words", "sha": "b8387424f6cf2923e110df19b1e1934124c63f58", "lastModified": "2022-11-03T16:16:07.000Z", "tags": ["task_categories:other", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:es", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "An unannotated Spanish corpus of nearly 1.5 billion words, compiled from different resources from the web.\nThis resources include the spanish portions of SenSem, the Ancora Corpus, some OPUS Project Corpora and the Europarl,\nthe Tibidabo Treebank, the IULA Spanish LSP Treebank, and dumps from the Spanish Wikipedia, Wikisource and Wikibooks.\nThis corpus is a compilation of 100 text files. Each line of these files represents one of the 50 million sentences from the corpus.", "citation": "@misc{cardellinoSBWCE,\n     author = {Cardellino, Cristian},\n     title = {Spanish {B}illion {W}ords {C}orpus and {E}mbeddings},\n     url = {https://crscardellino.github.io/SBWCE/},\n     month = {August},\n     year = {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f90", "disabled": false, "gated": false, "likes": 9, "downloads": 317, "paperswithcode_id": "sbwce", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "spc", "sha": "fd6ca489a0be5117c21e4cd85b721e417dc7157e", "lastModified": "2023-06-01T14:59:49.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:af", "language:el", "language:en", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a collection of parallel corpora collected by Hercules Dalianis and his research group for bilingual dictionary construction.\nMore information in: Hercules Dalianis, Hao-chun Xing, Xin Zhang: Creating a Reusable English-Chinese Parallel Corpus for Bilingual Dictionary Construction, In Proceedings of LREC2010 (source: http://people.dsv.su.se/~hercules/SEC/) and Konstantinos Charitakis (2007): Using Parallel Corpora to Create a Greek-English Dictionary with UPLUG, In Proceedings of NODALIDA 2007. Afrikaans-English: Aldin Draghoender and Mattias Kanhov: Creating a reusable English \u2013 Afrikaans parallel corpora for bilingual dictionary construction\n\n4 languages, 3 bitexts\ntotal number of files: 6\ntotal number of tokens: 1.32M\ntotal number of sentence fragments: 0.15M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f91", "disabled": false, "gated": false, "likes": 0, "downloads": 556, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "species_800", "sha": "7ec89c51018b845f7507f14cf1903d6d80bd8359", "lastModified": "2023-06-16T11:33:29.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "We have developed an efficient algorithm and implementation of a dictionary-based approach to named entity recognition,\nwhich we here use to identifynames of species and other taxa in text. The tool, SPECIES, is more than an order of\nmagnitude faster and as accurate as existing tools. The precision and recall was assessed both on an existing gold-standard\ncorpus and on a new corpus of 800 abstracts, which were manually annotated after the development of the tool. The corpus\ncomprises abstracts from journals selected to represent many taxonomic groups, which gives insights into which types of\norganism names are hard to detect and which are easy. Finally, we have tagged organism names in the entire Medline database\nand developed a web resource, ORGANISMS, that makes the results accessible to the broad community of biologists.", "citation": "@article{pafilis2013species,\n         title={The SPECIES and ORGANISMS resources for fast and accurate identification of taxonomic names in text},\n         author={Pafilis, Evangelos and Frankild, Sune P and Fanini, Lucia and Faulwetter, Sarah and Pavloudi, Christina and Vasileiadou, Aikaterini and Arvanitidis, Christos and Jensen, Lars Juhl},\n         journal={PloS one},\n         volume={8},\n         number={6},\n         pages={e65390},\n         year={2013},\n         publisher={Public Library of Science}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f92", "disabled": false, "gated": false, "likes": 2, "downloads": 344, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "speech_commands", "sha": "e2ba1bc645a16080588d2f92c96f84a3030b3aa3", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:audio-classification", "task_ids:keyword-spotting", "annotations_creators:other", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1804.03209", "region:us"], "private": false, "author": null, "description": "This is a set of one-second .wav audio files, each containing a single spoken\nEnglish word or background noise. These words are from a small set of commands, and are spoken by a\nvariety of different speakers. This data set is designed to help train simple\nmachine learning models. This dataset is covered in more detail at\n[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n\nVersion 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n64,727 audio files.\n\nIn version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n\n\nIn version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n\nIn both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\nit is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\nfrom unrecognized ones.\n\nThe `_silence_` class contains a set of longer audio clips that are either recordings or\na mathematical simulation of noise.", "citation": "@article{speechcommandsv2,\n   author = { {Warden}, P.},\n    title = \"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}\",\n  journal = {ArXiv e-prints},\n  archivePrefix = \"arXiv\",\n  eprint = {1804.03209},\n  primaryClass = \"cs.CL\",\n  keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n    year = 2018,\n    month = apr,\n    url = {https://arxiv.org/abs/1804.03209},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f93", "disabled": false, "gated": false, "likes": 14, "downloads": 3170, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "spider", "sha": "6232cc3fad6d54c62b3ba23a364083a98ff36a17", "lastModified": "2022-11-03T16:31:49.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "text-to-sql", "region:us"], "private": false, "author": null, "description": "Spider is a large-scale complex and cross-domain semantic parsing and text-toSQL dataset annotated by 11 college students", "citation": "@article{yu2018spider,\n  title={Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task},\n  author={Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and others},\n  journal={arXiv preprint arXiv:1809.08887},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f94", "disabled": false, "gated": false, "likes": 61, "downloads": 2096, "paperswithcode_id": "spider-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad", "sha": "5fe18c4c680f9922d794e3f4dd673a751c74ee37", "lastModified": "2023-04-05T13:40:31.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|wikipedia", "language:en", "license:cc-by-4.0", "arxiv:1606.05250", "region:us"], "private": false, "author": null, "description": "Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.", "citation": "@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f95", "disabled": false, "gated": false, "likes": 147, "downloads": 155401, "paperswithcode_id": "squad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_adversarial", "sha": "1a1f68e92164c8326214e43923f69092025e7e09", "lastModified": "2022-11-18T21:47:43.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|squad", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "Here are two different adversaries, each of which uses a different procedure to pick the sentence it adds to the paragraph:\nAddSent: Generates up to five candidate adversarial sentences that don't answer the question, but have a lot of words in common with the question. Picks the one that most confuses the model.\nAddOneSent: Similar to AddSent, but just picks one of the candidate sentences at random. This adversary is does not query the model in any way.", "citation": "@inproceedings{jia-liang-2017-adversarial,\n    title = \"Adversarial Examples for Evaluating Reading Comprehension Systems\",\n    author = \"Jia, Robin  and\n      Liang, Percy\",\n    booktitle = \"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing\",\n    month = sep,\n    year = \"2017\",\n    address = \"Copenhagen, Denmark\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D17-1215\",\n    doi = \"10.18653/v1/D17-1215\",\n    pages = \"2021--2031\",\n    abstract = \"Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f96", "disabled": false, "gated": false, "likes": 6, "downloads": 1777, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_es", "sha": "392af020d80ee511834b04d169943f53389f1453", "lastModified": "2023-04-05T13:40:35.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|squad", "language:es", "license:cc-by-4.0", "arxiv:1912.05200", "region:us"], "private": false, "author": null, "description": "automatic translation of the Stanford Question Answering Dataset (SQuAD) v2 into Spanish", "citation": "@article{2016arXiv160605250R,\n       author = {Casimiro Pio , Carrino and  Marta R. , Costa-jussa and  Jose A. R. , Fonollosa},\n        title = \"{Automatic Spanish Translation of the SQuAD Dataset for Multilingual\nQuestion Answering}\",\n      journal = {arXiv e-prints},\n         year = 2019,\n          eid = {arXiv:1912.05200v1},\n        pages = {arXiv:1912.05200v1},\narchivePrefix = {arXiv},\n       eprint = {1912.05200v2},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f97", "disabled": false, "gated": false, "likes": 7, "downloads": 763, "paperswithcode_id": "squad-es", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_it", "sha": "dbbfce7465606e8534e0cbced9ac042531661dd3", "lastModified": "2023-04-05T13:40:37.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:extended|squad", "language:it", "license:unknown", "region:us"], "private": false, "author": null, "description": "SQuAD-it is derived from the SQuAD dataset and it is obtained through semi-automatic translation of the SQuAD dataset\ninto Italian. It represents a large-scale dataset for open question answering processes on factoid questions in Italian.\n The dataset contains more than 60,000 question/answer pairs derived from the original English dataset. The dataset is\n split into training and test sets to support the replicability of the benchmarking of QA systems:", "citation": "@InProceedings{10.1007/978-3-030-03840-3_29,\n    author={Croce, Danilo and Zelenanska, Alexandra and Basili, Roberto},\n    editor={Ghidini, Chiara and Magnini, Bernardo and Passerini, Andrea and Traverso, Paolo\",\n    title={Neural Learning for Question Answering in Italian},\n    booktitle={AI*IA 2018 -- Advances in Artificial Intelligence},\n    year={2018},\n    publisher={Springer International Publishing},\n    address={Cham},\n    pages={389--402},\n    isbn={978-3-030-03840-3}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f98", "disabled": false, "gated": false, "likes": 2, "downloads": 455, "paperswithcode_id": "squad-it", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_kor_v1", "sha": "0ec395f44b60476e99b6214113dd6110689c8928", "lastModified": "2023-06-15T15:25:29.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "license:cc-by-nd-4.0", "arxiv:1909.07005", "region:us"], "private": false, "author": null, "description": "KorQuAD 1.0 is a large-scale Korean dataset for machine reading comprehension task consisting of human generated questions for Wikipedia articles. We benchmark the data collecting process of SQuADv1.0 and crowdsourced 70,000+ question-answer pairs. 1,637 articles and 70,079 pairs of question answers were collected. 1,420 articles are used for the training set, 140 for the dev set, and 77 for the test set. 60,407 question-answer pairs are for the training set, 5,774 for the dev set, and 3,898 for the test set.", "citation": "@article{lim2019korquad1,\n  title={Korquad1. 0: Korean qa dataset for machine reading comprehension},\n  author={Lim, Seungyoung and Kim, Myungji and Lee, Jooyoul},\n  journal={arXiv preprint arXiv:1909.07005},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f99", "disabled": false, "gated": false, "likes": 10, "downloads": 1489, "paperswithcode_id": "korquad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_kor_v2", "sha": "211913322097d2f0a850816f5d913e29c3bd3165", "lastModified": "2023-02-07T14:40:49.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|squad_kor_v1", "source_datasets:original", "language:ko", "license:cc-by-nd-4.0", "region:us"], "private": false, "author": null, "description": "KorQuAD 2.0 is a Korean question and answering dataset consisting of a total of 100,000+ pairs. There are three major differences from KorQuAD 1.0, which is the standard Korean Q & A data. The first is that a given document is a whole Wikipedia page, not just one or two paragraphs. Second, because the document also contains tables and lists, it is necessary to understand the document structured with HTML tags. Finally, the answer can be a long text covering not only word or phrase units, but paragraphs, tables, and lists. As a baseline model, BERT Multilingual is used, released by Google as an open source. It shows 46.0% F1 score, a very low score compared to 85.7% of the human F1 score. It indicates that this data is a challenging task. Additionally, we increased the performance by no-answer data augmentation. Through the distribution of this data, we intend to extend the limit of MRC that was limited to plain text to real world tasks of various lengths and formats.", "citation": "@article{NODE09353166,\n    author={Youngmin Kim,Seungyoung Lim;Hyunjeong Lee;Soyoon Park;Myungji Kim},\n    title={{KorQuAD 2.0: Korean QA Dataset for Web Document Machine Comprehension}},\n    booltitle={{Journal of KIISE \uc81c47\uad8c \uc81c6\ud638}},\n    journal={{Journal of KIISE}},\n    volume={{47}},\n    issue={{6}},\n    publisher={The Korean Institute of Information Scientists and Engineers},\n    year={2020},\n    ISSN={{2383-630X}},\n    pages={577-586},\n    url={http://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE09353166}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f9a", "disabled": false, "gated": false, "likes": 3, "downloads": 621, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_v1_pt", "sha": "cdb82982c27d0f8810e7389702729b2cb084880d", "lastModified": "2023-04-05T13:40:41.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pt", "license:mit", "arxiv:1606.05250", "region:us"], "private": false, "author": null, "description": "Portuguese translation of the SQuAD dataset. The translation was performed automatically using the Google Cloud API.", "citation": "@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f9b", "disabled": false, "gated": false, "likes": 7, "downloads": 521, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "squad_v2", "sha": "e4d7191788b08fde3cbd09bd8fe1fcd827ee1715", "lastModified": "2023-04-05T13:40:44.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:1606.05250", "region:us"], "private": false, "author": null, "description": "combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers\n to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but\n also determine when no answer is supported by the paragraph and abstain from answering.", "citation": "@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f9c", "disabled": false, "gated": false, "likes": 98, "downloads": 50759, "paperswithcode_id": "squad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "srwac", "sha": "6393d9bd04354dfad543163b9f592e2ed993baa6", "lastModified": "2022-11-03T16:08:14.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100M<n<1B", "source_datasets:original", "language:sr", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "The Serbian web corpus srWaC was built by crawling the .rs top-level domain in 2014. The corpus was near-deduplicated on paragraph level, normalised via diacritic restoration, morphosyntactically annotated and lemmatised. The corpus is shuffled by paragraphs. Each paragraph contains metadata on the URL, domain and language identification (Serbian vs. Croatian).\nVersion 1.0 of this corpus is described in http://www.aclweb.org/anthology/W14-0405. Version 1.1 contains newer and better linguistic annotations.", "citation": "@misc{11356/1063,\n title = {Serbian web corpus {srWaC} 1.1},\n author = {Ljube{\\v s}i{\\'c}, Nikola and Klubi{\\v c}ka, Filip},\n url = {http://hdl.handle.net/11356/1063},\n note = {Slovenian language resource repository {CLARIN}.{SI}},\n copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n year = {2016} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f9e", "disabled": false, "gated": false, "likes": 1, "downloads": 308, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sst", "sha": "6b03ff1094bd06fd3556ad53215b90361a7dee11", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Stanford Sentiment Treebank, the first corpus with fully labeled parse trees that allows for a\ncomplete analysis of the compositional effects of sentiment in language.", "citation": "@inproceedings{socher-etal-2013-recursive,\n    title = \"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\",\n    author = \"Socher, Richard and Perelygin, Alex and Wu, Jean and\n      Chuang, Jason and Manning, Christopher D. and Ng, Andrew and Potts, Christopher\",\n    booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct,\n    year = \"2013\",\n    address = \"Seattle, Washington, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D13-1170\",\n    pages = \"1631--1642\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181f9f", "disabled": false, "gated": false, "likes": 11, "downloads": 3615, "paperswithcode_id": "sst", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "stereoset", "sha": "b6c3f62364c797870dc8743982b5e820088e676f", "lastModified": "2023-01-25T14:44:52.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "stereotype-detection", "arxiv:2004.09456", "region:us"], "private": false, "author": null, "description": "Stereoset is a dataset that measures stereotype bias in language models. Stereoset consists of 17,000 sentences that\nmeasures model preferences across gender, race, religion, and profession.", "citation": "@article{nadeem2020Stereoset,\n  title={Stereoset: Measuring stereotypical bias in pretrained language models},\n  author={Nadeem, Moin and Bethke, Anna and Reddy, Siva},\n  journal={arXiv preprint arXiv:2004.09456},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa0", "disabled": false, "gated": false, "likes": 12, "downloads": 968, "paperswithcode_id": "stereoset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "story_cloze", "sha": "b68028bf0c5441d1b82274d461a005195e863483", "lastModified": "2023-04-05T13:40:54.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Story Cloze Test' is a commonsense reasoning framework for evaluating story understanding,\nstory generation, and script learning.This test requires a system to choose the correct ending\nto a four-sentence story.", "citation": "@inproceedings{mostafazadeh2017lsdsem,\n  title={Lsdsem 2017 shared task: The story cloze test},\n  author={Mostafazadeh, Nasrin and Roth, Michael and Louis, Annie and Chambers, Nathanael and Allen, James},\n  booktitle={Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics},\n  pages={46--51},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa1", "disabled": false, "gated": false, "likes": 7, "downloads": 3216, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "stsb_multi_mt", "sha": "93d57ef91790589e3ce9c365164337a8a78b7632", "lastModified": "2022-11-18T21:48:48.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|other-sts-b", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:nl", "language:pl", "language:pt", "language:ru", "language:zh", "license:other", "arxiv:1708.00055", "region:us"], "private": false, "author": null, "description": "These are different multilingual translations and the English original of the STSbenchmark dataset. Translation has been done with deepl.com.", "citation": "@InProceedings{huggingface:dataset:stsb_multi_mt,\ntitle = {Machine translated multilingual STS benchmark dataset.},\nauthor={Philip May},\nyear={2021},\nurl={https://github.com/PhilipMay/stsb-multi-mt}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa3", "disabled": false, "gated": false, "likes": 34, "downloads": 5838, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "style_change_detection", "sha": "974a60eccac3073b7ddb3cbf39a329c4bdf994b3", "lastModified": "2023-04-05T13:41:00.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "The goal of the style change detection task is to identify text positions within a given multi-author document at which the author switches. Detecting these positions is a crucial part of the authorship identification process, and for multi-author document analysis in general.\n\nAccess to the dataset needs to be requested from zenodo.", "citation": "@inproceedings{bevendorff2020shared,\n  title={Shared Tasks on Authorship Analysis at PAN 2020},\n  author={Bevendorff, Janek and Ghanem, Bilal and Giachanou, Anastasia and Kestemont, Mike and Manjavacas, Enrique and Potthast, Martin and Rangel, Francisco and Rosso, Paolo and Specht, G{\\\"u}nther and Stamatatos, Efstathios and others},\n  booktitle={European Conference on Information Retrieval},\n  pages={508--516},\n  year={2020},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa4", "disabled": false, "gated": false, "likes": 0, "downloads": 431, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "subjqa", "sha": "3d1b2f29120182ba0e934d2842c09db636a8979f", "lastModified": "2023-03-16T13:27:54.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|yelp_review_full", "source_datasets:extended|other-amazon_reviews_ucsd", "source_datasets:extended|other-tripadvisor_reviews", "language:en", "license:unknown", "arxiv:2004.14283", "region:us"], "private": false, "author": null, "description": "SubjQA is a question answering dataset that focuses on subjective questions and answers.\nThe dataset consists of roughly 10,000 questions over reviews from 6 different domains: books, movies, grocery,\nelectronics, TripAdvisor (i.e. hotels), and restaurants.", "citation": "@inproceedings{bjerva20subjqa,\n    title = \"SubjQA: A Dataset for Subjectivity and Review Comprehension\",\n    author = \"Bjerva, Johannes  and\n      Bhutani, Nikita  and\n      Golahn, Behzad  and\n      Tan, Wang-Chiew  and\n      Augenstein, Isabelle\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing\",\n    month = November,\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa5", "disabled": false, "gated": false, "likes": 7, "downloads": 2411, "paperswithcode_id": "subjqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "super_glue", "sha": "d05df0885fb0a37b9a05ae5a6cf7084fc2b309c4", "lastModified": "2023-04-05T13:41:04.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_categories:question-answering", "task_ids:natural-language-inference", "task_ids:word-sense-disambiguation", "task_ids:coreference-resolution", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other", "language:en", "license:unknown", "superglue", "NLU", "natural language understanding", "region:us"], "private": false, "author": null, "description": "SuperGLUE (https://super.gluebenchmark.com/) is a new benchmark styled after\nGLUE with a new set of more difficult language understanding tasks, improved\nresources, and a new public leaderboard.", "citation": "@article{wang2019superglue,\n  title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},\n  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1905.00537},\n  year={2019}\n}\n\nNote that each SuperGLUE dataset has its own citation. Please see the source to\nget the correct citation for each contained dataset.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa6", "disabled": false, "gated": false, "likes": 119, "downloads": 499642, "paperswithcode_id": "superglue", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "superb", "sha": "dd75bbc58a2af7b8413b7685e02217a64ce45e41", "lastModified": "2023-01-25T14:45:01.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_ids:keyword-spotting", "task_ids:speaker-identification", "task_ids:audio-intent-classification", "task_ids:audio-emotion-recognition", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "source_datasets:extended|librispeech_asr", "source_datasets:extended|other-librimix", "source_datasets:extended|other-speech_commands", "language:en", "license:unknown", "query-by-example-spoken-term-detection", "audio-slot-filling", "speaker-diarization", "automatic-speaker-verification", "arxiv:2105.01051", "region:us"], "private": false, "author": null, "description": "Self-supervised learning (SSL) has proven vital for advancing research in\nnatural language processing (NLP) and computer vision (CV). The paradigm\npretrains a shared model on large volumes of unlabeled data and achieves\nstate-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\nspeech processing community lacks a similar setup to systematically explore the\nparadigm. To bridge this gap, we introduce Speech processing Universal\nPERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\nperformance of a shared model across a wide range of speech processing tasks\nwith minimal architecture changes and labeled data. Among multiple usages of the\nshared model, we especially focus on extracting the representation learned from\nSSL due to its preferable re-usability. We present a simple framework to solve\nSUPERB tasks by learning task-specialized lightweight prediction heads on top of\nthe frozen shared model. Our results demonstrate that the framework is promising\nas SSL representations show competitive generalizability and accessibility\nacross SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a\nbenchmark toolkit to fuel the research in representation learning and general\nspeech processing.\n\nNote that in order to limit the required storage for preparing this dataset, the\naudio is stored in the .wav format and is not converted to a float32 array. To\nconvert the audio file to a float32 array, please make use of the `.map()`\nfunction as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@article{DBLP:journals/corr/abs-2105-01051,\n  author    = {Shu{-}Wen Yang and\n               Po{-}Han Chi and\n               Yung{-}Sung Chuang and\n               Cheng{-}I Jeff Lai and\n               Kushal Lakhotia and\n               Yist Y. Lin and\n               Andy T. Liu and\n               Jiatong Shi and\n               Xuankai Chang and\n               Guan{-}Ting Lin and\n               Tzu{-}Hsien Huang and\n               Wei{-}Cheng Tseng and\n               Ko{-}tik Lee and\n               Da{-}Rong Liu and\n               Zili Huang and\n               Shuyan Dong and\n               Shang{-}Wen Li and\n               Shinji Watanabe and\n               Abdelrahman Mohamed and\n               Hung{-}yi Lee},\n  title     = {{SUPERB:} Speech processing Universal PERformance Benchmark},\n  journal   = {CoRR},\n  volume    = {abs/2105.01051},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2105.01051},\n  archivePrefix = {arXiv},\n  eprint    = {2105.01051},\n  timestamp = {Thu, 01 Jul 2021 13:30:22 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-01051.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa7", "disabled": false, "gated": false, "likes": 22, "downloads": 4619, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "svhn", "sha": "26ff89e61368e04525be2431396efef3555977b6", "lastModified": "2023-01-25T14:45:04.000Z", "tags": ["task_categories:image-classification", "task_categories:object-detection", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting.\nIt can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images)\nand comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.", "citation": "@article{netzer2011reading,\n  title={Reading digits in natural images with unsupervised feature learning},\n  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},\n  year={2011}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa8", "disabled": false, "gated": false, "likes": 9, "downloads": 1394, "paperswithcode_id": "svhn", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swag", "sha": "bd6552834ed1f37a2d23b91dbc989d91e8379658", "lastModified": "2023-01-25T14:45:08.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1808.05326", "region:us"], "private": false, "author": null, "description": "Given a partial description like \"she opened the hood of the car,\"\nhumans can reason about the situation and anticipate what might come\nnext (\"then, she examined the engine\"). SWAG (Situations With Adversarial Generations)\nis a large-scale dataset for this task of grounded commonsense\ninference, unifying natural language inference and physically grounded reasoning.\n\nThe dataset consists of 113k multiple choice questions about grounded situations\n(73k training, 20k validation, 20k test).\nEach question is a video caption from LSMDC or ActivityNet Captions,\nwith four answer choices about what might happen next in the scene.\nThe correct answer is the (real) video caption for the next event in the video;\nthe three incorrect answers are adversarially generated and human verified,\nso as to fool machines but not humans. SWAG aims to be a benchmark for\nevaluating grounded commonsense NLI and for learning representations.\n\nThe full data contain more information,\nbut the regular configuration will be more interesting for modeling\n(note that the regular data are shuffled). The test set for leaderboard submission\nis under the regular configuration.", "citation": "@inproceedings{zellers2018swagaf,\n    title={SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference},\n    author={Zellers, Rowan and Bisk, Yonatan and Schwartz, Roy and Choi, Yejin},\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fa9", "disabled": false, "gated": false, "likes": 12, "downloads": 4967, "paperswithcode_id": "swag", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swahili", "sha": "922b06ea158f42d9cbe7973a3f4793a14c0fd139", "lastModified": "2022-11-18T21:49:35.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:sw", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The Swahili dataset developed specifically for language modeling task.\nThe dataset contains 28,000 unique words with 6.84M, 970k, and 2M words for the train,\nvalid and test partitions respectively which represent the ratio 80:10:10.\nThe entire dataset is lowercased, has no punctuation marks and,\nthe start and end of sentence markers have been incorporated to facilitate easy tokenization during language modeling.", "citation": "@InProceedings{huggingface:dataset,\ntitle = Language modeling data for Swahili (Version 1),\nauthors={Shivachi Casper Shikali, & Mokhosi Refuoe.\n},\nyear={2019},\nlink = http://doi.org/10.5281/zenodo.3553423\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181faa", "disabled": false, "gated": false, "likes": 7, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swahili_news", "sha": "89125258ffbfeea6e33b5f8b02ddfad8d364339b", "lastModified": "2023-01-25T14:45:11.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:sw", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Swahili is spoken by 100-150 million people across East Africa. In Tanzania, it is one of two national languages (the other is English) and it is the official language of instruction in all schools. News in Swahili is an important part of the media sphere in Tanzania.\n\nNews contributes to education, technology, and the economic growth of a country, and news in local languages plays an important cultural role in many Africa countries. In the modern age, African languages in news and other spheres are at risk of being lost as English becomes the dominant language in online spaces.\n\nThe Swahili news dataset was created to reduce the gap of using the Swahili language to create NLP technologies and help AI practitioners in Tanzania and across Africa continent to practice their NLP skills to solve different problems in organizations or societies related to Swahili language. Swahili News were collected from different websites that provide news in the Swahili language. I was able to find some websites that provide news in Swahili only and others in different languages including Swahili.\n\nThe dataset was created for a specific task of text classification, this means each news content can be categorized into six different topics (Local news, International news , Finance news, Health news, Sports news, and Entertainment news). The dataset comes with a specified train/test split. The train set contains 75% of the dataset and test set contains 25% of the dataset.", "citation": "@dataset{davis_david_2020_5514203,\n  author       = {Davis David},\n  title        = {Swahili : News Classification Dataset},\n  month        = dec,\n  year         = 2020,\n  note         = {{The news version contains both train and test sets.}},\n  publisher    = {Zenodo},\n  version      = {0.2},\n  doi          = {10.5281/zenodo.5514203},\n  url          = {https://doi.org/10.5281/zenodo.5514203}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fab", "disabled": false, "gated": false, "likes": 2, "downloads": 1046, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swda", "sha": "cdb700c0ef6a13ef1ec35cec2bb38fe683ffddf9", "lastModified": "2023-01-25T14:45:15.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other-Switchboard-1 Telephone Speech Corpus, Release 2", "language:en", "license:cc-by-nc-sa-3.0", "arxiv:1811.05021", "arxiv:1711.05568", "arxiv:1709.04250", "arxiv:1805.06280", "region:us"], "private": false, "author": null, "description": "The Switchboard Dialog Act Corpus (SwDA) extends the Switchboard-1 Telephone Speech Corpus, Release 2 with\nturn/utterance-level dialog-act tags. The tags summarize syntactic, semantic, and pragmatic information about the\nassociated turn. The SwDA project was undertaken at UC Boulder in the late 1990s.\nThe SwDA is not inherently linked to the Penn Treebank 3 parses of Switchboard, and it is far from straightforward to\nalign the two resources. In addition, the SwDA is not distributed with the Switchboard's tables of metadata about the\nconversations and their participants.", "citation": "@techreport{Jurafsky-etal:1997,\n    Address = {Boulder, CO},\n    Author = {Jurafsky, Daniel and Shriberg, Elizabeth and Biasca, Debra},\n    Institution = {University of Colorado, Boulder Institute of Cognitive Science},\n    Number = {97-02},\n    Title = {Switchboard {SWBD}-{DAMSL} Shallow-Discourse-Function Annotation Coders Manual, Draft 13},\n    Year = {1997}}\n\n@article{Shriberg-etal:1998,\n    Author = {Shriberg, Elizabeth and Bates, Rebecca and Taylor, Paul and Stolcke, Andreas and Jurafsky, Daniel and Ries, Klaus and Coccaro, Noah and Martin, Rachel and Meteer, Marie and Van Ess-Dykema, Carol},\n    Journal = {Language and Speech},\n    Number = {3--4},\n    Pages = {439--487},\n    Title = {Can Prosody Aid the Automatic Classification of Dialog Acts in Conversational Speech?},\n    Volume = {41},\n    Year = {1998}}\n\n@article{Stolcke-etal:2000,\n    Author = {Stolcke, Andreas and Ries, Klaus and Coccaro, Noah and Shriberg, Elizabeth and Bates, Rebecca and Jurafsky, Daniel and Taylor, Paul and Martin, Rachel and Meteer, Marie and Van Ess-Dykema, Carol},\n    Journal = {Computational Linguistics},\n    Number = {3},\n    Pages = {339--371},\n    Title = {Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech},\n    Volume = {26},\n    Year = {2000}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fac", "disabled": false, "gated": false, "likes": 8, "downloads": 476, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swedish_medical_ner", "sha": "678294cd577eff4968ad13afd2ed353d90062857", "lastModified": "2023-01-25T14:45:18.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:sv", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "SwedMedNER is a dataset for training and evaluating Named Entity Recognition systems on medical texts in Swedish.\nIt is derived from medical articles on the Swedish Wikipedia, L\u00e4kartidningen, and 1177 V\u00e5rdguiden.", "citation": "@inproceedings{almgrenpavlovmogren2016bioner,\n  title={Named Entity Recognition in Swedish Medical Journals with Deep Bidirectional Character-Based LSTMs},\n  author={Simon Almgren, Sean Pavlov, Olof Mogren},\n  booktitle={Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM 2016)},\n  pages={1},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fad", "disabled": false, "gated": false, "likes": 2, "downloads": 800, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "swedish_ner_corpus", "sha": "372b6a10b210de1b89046da145a3e336fb85f7db", "lastModified": "2023-01-25T14:45:21.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:sv", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Webbnyheter 2012 from Spraakbanken, semi-manually annotated and adapted for CoreNLP Swedish NER. Semi-manually defined in this case as: Bootstrapped from Swedish Gazetters then manually correcte/reviewed by two independent native speaking swedish annotators. No annotator agreement calculated.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fae", "disabled": false, "gated": false, "likes": 1, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "rcds/swiss_judgment_prediction", "sha": "29806f87bba4f23d0707d3b6d9ea5432afefbe2f", "lastModified": "2023-06-14T11:59:24.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "language:fr", "language:it", "language:en", "license:cc-by-sa-4.0", "judgement-prediction", "arxiv:2110.00806", "arxiv:2209.12325", "region:us"], "private": false, "author": "rcds", "description": "Swiss-Judgment-Prediction is a multilingual, diachronic dataset of 85K Swiss Federal Supreme Court (FSCS) cases annotated with the respective binarized judgment outcome (approval/dismissal), posing a challenging text classification task. We also provide additional metadata, i.e., the publication year, the legal area and the canton of origin per case, to promote robustness and fairness studies on the critical area of legal NLP.", "citation": "@InProceedings{niklaus-etal-2021-swiss,\n  author = {Niklaus, Joel\n                and Chalkidis, Ilias\n                and St\u00fcrmer, Matthias},\n  title = {Swiss-Court-Predict: A Multilingual Legal Judgment Prediction Benchmark},\n  booktitle = {Proceedings of the 2021 Natural Legal Language Processing Workshop},\n  year = {2021},\n  location = {Punta Cana, Dominican Republic},\n}\n@misc{niklaus2022empirical,\n    title={An Empirical Study on Cross-X Transfer for Legal Judgment Prediction},\n    author={Joel Niklaus and Matthias St\u00fcrmer and Ilias Chalkidis},\n    year={2022},\n    eprint={2209.12325},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb0", "disabled": false, "gated": false, "likes": 11, "downloads": 1494, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tab_fact", "sha": "00281d7d7fa574c58df8246c82d88a53b332f2b9", "lastModified": "2023-01-25T14:45:28.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1909.02164", "region:us"], "private": false, "author": null, "description": "The problem of verifying whether a textual hypothesis holds the truth based on the given evidence, also known as fact verification, plays an important role in the study of natural language understanding and semantic representation. However, existing studies are restricted to dealing with unstructured textual evidence (e.g., sentences and passages, a pool of passages), while verification using structured forms of evidence, such as tables, graphs, and databases, remains unexplored. TABFACT is large scale dataset with 16k Wikipedia tables as evidence for 118k human annotated statements designed for fact verification with semi-structured evidence. The statements are labeled as either ENTAILED or REFUTED. TABFACT is challenging since it involves both soft linguistic reasoning and hard symbolic reasoning.", "citation": "@inproceedings{2019TabFactA,\n  title={TabFact : A Large-scale Dataset for Table-based Fact Verification},\n  author={Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou and William Yang Wang},\n  booktitle = {International Conference on Learning Representations (ICLR)},\n  address = {Addis Ababa, Ethiopia},\n  month = {April},\n  year = {2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb1", "disabled": false, "gated": false, "likes": 7, "downloads": 738, "paperswithcode_id": "tabfact", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tamilmixsentiment", "sha": "2f417fcf209e7c5fbe223ebf2a49be5822680391", "lastModified": "2023-06-16T13:07:45.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:ta", "license:unknown", "region:us"], "private": false, "author": null, "description": "The first gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. Train: 11,335 Validation: 1,260 and Test: 3,149.  This makes the largest general domain sentiment dataset for this relatively low-resource language with code-mixing phenomenon.  The dataset contains all the three types of code-mixed sentences - Inter-Sentential switch, Intra-Sentential switch and Tag switching. Most comments were written in Roman script with either Tamil grammar with English lexicon or English grammar with Tamil lexicon. Some comments were written in Tamil script with English expressions in between.", "citation": "@inproceedings{chakravarthi-etal-2020-corpus,\n    title = \"Corpus Creation for Sentiment Analysis in Code-Mixed {T}amil-{E}nglish Text\",\n    author = \"Chakravarthi, Bharathi Raja  and\n      Muralidaran, Vigneshwaran  and\n      Priyadharshini, Ruba  and\n      McCrae, John Philip\",\n    booktitle = \"Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources association\",\n    url = \"https://www.aclweb.org/anthology/2020.sltu-1.28\",\n    pages = \"202--210\",\n    abstract = \"Understanding the sentiment of a comment from a video or an image is an essential task in many applications. Sentiment analysis of a text can be useful for various decision-making processes. One such application is to analyse the popular sentiments of videos on social media based on viewer comments. However, comments from social media do not follow strict rules of grammar, and they contain mixing of more than one language, often written in non-native scripts. Non-availability of annotated code-mixed data for a low-resourced language like Tamil also adds difficulty to this problem. To overcome this, we created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. In this paper, we describe the process of creating the corpus and assigning polarities. We present inter-annotator agreement and show the results of sentiment analysis trained on this corpus as a benchmark.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-35-1\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb2", "disabled": false, "gated": false, "likes": 0, "downloads": 322, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tanzil", "sha": "cf80f7db5d8b09252ff7c01c856acfa5a13c8822", "lastModified": "2022-11-03T16:31:41.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:am", "language:ar", "language:az", "language:bg", "language:bn", "language:bs", "language:cs", "language:de", "language:dv", "language:en", "language:es", "language:fa", "language:fr", "language:ha", "language:hi", "language:id", "language:it", "language:ja", "language:ko", "language:ku", "language:ml", "language:ms", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:sd", "language:so", "language:sq", "language:sv", "language:sw", "language:ta", "language:tg", "language:th", "language:tr", "language:tt", "language:ug", "language:ur", "language:uz", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a collection of Quran translations compiled by the Tanzil project\nThe translations provided at this page are for non-commercial purposes only. If used otherwise, you need to obtain necessary permission from the translator or the publisher.\n\nIf you are using more than three of the following translations in a website or application, we require you to put a link back to this page to make sure that subsequent users have access to the latest updates.\n\n42 languages, 878 bitexts\ntotal number of files: 105\ntotal number of tokens: 22.33M\ntotal number of sentence fragments: 1.01M", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb3", "disabled": false, "gated": false, "likes": 4, "downloads": 847, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tapaco", "sha": "58b71ecd5016350847357ad7de52bf19b5d4aa6f", "lastModified": "2023-06-08T13:14:46.000Z", "tags": ["task_categories:text2text-generation", "task_categories:translation", "task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:1M<n<10M", "size_categories:n<1K", "source_datasets:extended|other-tatoeba", "language:af", "language:ar", "language:az", "language:be", "language:ber", "language:bg", "language:bn", "language:br", "language:ca", "language:cbk", "language:cmn", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fi", "language:fr", "language:gl", "language:gos", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:kab", "language:ko", "language:kw", "language:la", "language:lfn", "language:lt", "language:mk", "language:mr", "language:nb", "language:nds", "language:nl", "language:orv", "language:ota", "language:pes", "language:pl", "language:pt", "language:rn", "language:ro", "language:ru", "language:sl", "language:sr", "language:sv", "language:tk", "language:tl", "language:tlh", "language:tok", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:vi", "language:vo", "language:war", "language:wuu", "language:yue", "license:cc-by-2.0", "paraphrase-generation", "region:us"], "private": false, "author": null, "description": "A freely available paraphrase corpus for 73 languages extracted from the Tatoeba database. Tatoeba is a crowdsourcing project mainly geared towards language learners. Its aim is to provide example sentences and translations for particular linguistic constructions and words. The paraphrase corpus is created by populating a graph with Tatoeba sentences and equivalence links between sentences \u201cmeaning the same thing\u201d. This graph is then traversed to extract sets of paraphrases. Several language-independent filters and pruning steps are applied to remove uninteresting sentences. A manual evaluation performed on three languages shows that between half and three quarters of inferred paraphrases are correct and that most remaining ones are either correct but trivial, or near-paraphrases that neutralize a morphological distinction. The corpus contains a total of 1.9 million sentences, with 200 \u2013 250 000 sentences per language. It covers a range of languages for which, to our knowledge,no other paraphrase dataset exists.", "citation": "@dataset{scherrer_yves_2020_3707949,\n  author       = {Scherrer, Yves},\n  title        = {{TaPaCo: A Corpus of Sentential Paraphrases for 73 Languages}},\n  month        = mar,\n  year         = 2020,\n  publisher    = {Zenodo},\n  version      = {1.0},\n  doi          = {10.5281/zenodo.3707949},\n  url          = {https://doi.org/10.5281/zenodo.3707949}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb4", "disabled": false, "gated": false, "likes": 32, "downloads": 11119, "paperswithcode_id": "tapaco", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tashkeela", "sha": "8c3a388dcbcff57e0949d8dde6ddc4c566f63672", "lastModified": "2022-11-03T16:07:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:ar", "license:gpl-2.0", "diacritics-prediction", "region:us"], "private": false, "author": null, "description": "Arabic vocalized texts.\nit contains 75 million of fully vocalized words mainly97 books from classical and modern Arabic language.", "citation": "@article{zerrouki2017tashkeela,\n  title={Tashkeela: Novel corpus of Arabic vocalized texts, data for auto-diacritization systems},\n  author={Zerrouki, Taha and Balla, Amar},\n  journal={Data in brief},\n  volume={11},\n  pages={147},\n  year={2017},\n  publisher={Elsevier}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb5", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "taskmaster1", "sha": "4d99295707c87b5f989b8802a9a4f37366733b72", "lastModified": "2022-11-18T21:50:41.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1909.05358", "region:us"], "private": false, "author": null, "description": "Taskmaster-1 is a  goal-oriented conversational dataset. It includes 13,215 task-based dialogs comprising six domains. Two procedures were used to create this collection, each with unique advantages. The first involves a two-person, spoken \"Wizard of Oz\" (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is \"self-dialog\" in which crowdsourced workers write the entire dialog themselves.", "citation": "@inproceedings{48484,\ntitle\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\nauthor\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\nyear\t= {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb6", "disabled": false, "gated": false, "likes": 1, "downloads": 554, "paperswithcode_id": "taskmaster-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "taskmaster2", "sha": "b794b7305f86b98fc2772a3368eaf30ec3135b74", "lastModified": "2022-12-01T16:31:12.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1909.05358", "region:us"], "private": false, "author": null, "description": "Taskmaster is dataset for goal oriented conversations. The Taskmaster-2 dataset consists of 17,289 dialogs in the seven domains which include restaurants, food ordering, movies, hotels, flights, music and sports. Unlike Taskmaster-1, which includes both written \"self-dialogs\" and spoken two-person dialogs, Taskmaster-2 consists entirely of spoken two-person dialogs. In addition, while Taskmaster-1 is almost exclusively task-based, Taskmaster-2 contains a good number of search- and recommendation-oriented dialogs. All dialogs in this release were created using a Wizard of Oz (WOz) methodology in which crowdsourced workers played the role of a 'user' and trained call center operators played the role of the 'assistant'. In this way, users were led to believe they were interacting with an automated system that \u201cspoke\u201d using text-to-speech (TTS) even though it was in fact a human behind the scenes. As a result, users could express themselves however they chose in the context of an automated interface.", "citation": "@inproceedings{48484,\ntitle\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\nauthor\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\nyear\t= {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb7", "disabled": false, "gated": false, "likes": 4, "downloads": 1183, "paperswithcode_id": "taskmaster-2", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "taskmaster3", "sha": "55b57b262cb27d3ed7a90ac98c1c7301946ec2fe", "lastModified": "2022-11-03T16:30:39.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1909.05358", "region:us"], "private": false, "author": null, "description": "Taskmaster is dataset for goal oriented conversations. The Taskmaster-3 dataset consists of 23,757 movie ticketing dialogs. By \"movie ticketing\" we mean conversations where the customer's goal is to purchase tickets after deciding on theater, time, movie name, number of tickets, and date, or opt out of the transaction. This collection was created using the \"self-dialog\" method. This means a single, crowd-sourced worker is paid to create a conversation writing turns for both speakers, i.e. the customer and the ticketing agent.", "citation": "@inproceedings{48484,\ntitle\t= {Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset},\nauthor\t= {Bill Byrne and Karthik Krishnamoorthi and Chinnadhurai Sankar and Arvind Neelakantan and Daniel Duckworth and Semih Yavuz and Ben Goodrich and Amit Dubey and Kyu-Young Kim and Andy Cedilnik},\nyear\t= {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb8", "disabled": false, "gated": false, "likes": 0, "downloads": 299, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tatoeba", "sha": "f0b1d791cdd3b9439a9221c9fab50ed8841538f4", "lastModified": "2022-11-03T16:32:34.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ab", "language:acm", "language:ady", "language:af", "language:afb", "language:afh", "language:aii", "language:ain", "language:ajp", "language:akl", "language:aln", "language:am", "language:an", "language:ang", "language:aoz", "language:apc", "language:ar", "language:arq", "language:ary", "language:arz", "language:as", "language:ast", "language:avk", "language:awa", "language:ayl", "language:az", "language:ba", "language:bal", "language:bar", "language:be", "language:ber", "language:bg", "language:bho", "language:bjn", "language:bm", "language:bn", "language:bo", "language:br", "language:brx", "language:bs", "language:bua", "language:bvy", "language:bzt", "language:ca", "language:cay", "language:cbk", "language:ce", "language:ceb", "language:ch", "language:chg", "language:chn", "language:cho", "language:chr", "language:cjy", "language:ckb", "language:ckt", "language:cmn", "language:co", "language:code", "language:cpi", "language:crh", "language:crk", "language:cs", "language:csb", "language:cv", "language:cy", "language:da", "language:de", "language:dng", "language:drt", "language:dsb", "language:dtp", "language:dv", "language:dws", "language:ee", "language:egl", "language:el", "language:emx", "language:en", "language:enm", "language:eo", "language:es", "language:et", "language:eu", "language:ext", "language:fi", "language:fj", "language:fkv", "language:fo", "language:fr", "language:frm", "language:fro", "language:frr", "language:fuc", "language:fur", "language:fuv", "language:fy", "language:ga", "language:gag", "language:gan", "language:gbm", "language:gcf", "language:gd", "language:gil", "language:gl", "language:gn", "language:gom", "language:gos", "language:got", "language:grc", "language:gsw", "language:gu", "language:gv", "language:ha", "language:hak", "language:haw", "language:hbo", "language:he", "language:hi", "language:hif", "language:hil", "language:hnj", "language:hoc", "language:hr", "language:hrx", "language:hsb", "language:hsn", "language:ht", "language:hu", "language:hy", "language:ia", "language:iba", "language:id", "language:ie", "language:ig", "language:ii", "language:ike", "language:ilo", "language:io", "language:is", "language:it", "language:izh", "language:ja", "language:jam", "language:jbo", "language:jdt", "language:jpa", "language:jv", "language:ka", "language:kaa", "language:kab", "language:kam", "language:kek", "language:kha", "language:kjh", "language:kk", "language:kl", "language:km", "language:kmr", "language:kn", "language:ko", "language:koi", "language:kpv", "language:krc", "language:krl", "language:ksh", "language:ku", "language:kum", "language:kw", "language:kxi", "language:ky", "language:la", "language:laa", "language:lad", "language:lb", "language:ldn", "language:lfn", "language:lg", "language:lij", "language:liv", "language:lkt", "language:lld", "language:lmo", "language:ln", "language:lo", "language:lt", "language:ltg", "language:lut", "language:lv", "language:lzh", "language:lzz", "language:mad", "language:mai", "language:max", "language:mdf", "language:mfe", "language:mg", "language:mgm", "language:mh", "language:mhr", "language:mi", "language:mic", "language:min", "language:mk", "language:ml", "language:mn", "language:mni", "language:mnw", "language:moh", "language:mr", "language:mt", "language:mvv", "language:mwl", "language:mww", "language:my", "language:myv", "language:na", "language:nah", "language:nan", "language:nb", "language:nch", "language:nds", "language:ngt", "language:ngu", "language:niu", "language:nl", "language:nlv", "language:nn", "language:nog", "language:non", "language:nov", "language:npi", "language:nst", "language:nus", "language:nv", "language:ny", "language:nys", "language:oar", "language:oc", "language:ofs", "language:ood", "language:or", "language:orv", "language:os", "language:osp", "language:ota", "language:otk", "language:pa", "language:pag", "language:pal", "language:pam", "language:pap", "language:pau", "language:pcd", "language:pdc", "language:pes", "language:phn", "language:pi", "language:pl", "language:pms", "language:pnb", "language:ppl", "language:prg", "language:ps", "language:pt", "language:qu", "language:quc", "language:qya", "language:rap", "language:rif", "language:rm", "language:rn", "language:ro", "language:rom", "language:ru", "language:rue", "language:rw", "language:sa", "language:sah", "language:sc", "language:scn", "language:sco", "language:sd", "language:sdh", "language:se", "language:sg", "language:sgs", "language:shs", "language:shy", "language:si", "language:sjn", "language:sl", "language:sm", "language:sma", "language:sn", "language:so", "language:sq", "language:sr", "language:stq", "language:su", "language:sux", "language:sv", "language:swg", "language:swh", "language:syc", "language:ta", "language:te", "language:tet", "language:tg", "language:th", "language:thv", "language:ti", "language:tig", "language:tk", "language:tl", "language:tlh", "language:tly", "language:tmr", "language:tmw", "language:tn", "language:to", "language:toi", "language:tok", "language:tpi", "language:tpw", "language:tr", "language:ts", "language:tt", "language:tts", "language:tvl", "language:ty", "language:tyv", "language:tzl", "language:udm", "language:ug", "language:uk", "language:umb", "language:ur", "language:uz", "language:vec", "language:vep", "language:vi", "language:vo", "language:vro", "language:wa", "language:war", "language:wo", "language:wuu", "language:xal", "language:xh", "language:xqa", "language:yi", "language:yo", "language:yue", "language:zlm", "language:zsm", "language:zu", "language:zza", "license:cc-by-2.0", "region:us"], "private": false, "author": null, "description": "This is a collection of translated sentences from Tatoeba\n359 languages, 3,403 bitexts\ntotal number of files: 750\ntotal number of tokens: 65.54M\ntotal number of sentence fragments: 8.96M", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fb9", "disabled": false, "gated": false, "likes": 20, "downloads": 3842, "paperswithcode_id": "tatoeba", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ted_hrlr", "sha": "3a54bebc275e0aa4b503c6005425e2881364bc21", "lastModified": "2023-04-05T13:41:24.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:extended|ted_talks_iwslt", "language:az", "language:be", "language:en", "language:es", "language:fr", "language:gl", "language:he", "language:it", "language:pt", "language:ru", "language:tr", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": null, "description": "Data sets derived from TED talk transcripts for comparing similar language pairs\nwhere one is high resource and the other is low resource.", "citation": "@inproceedings{Ye2018WordEmbeddings,\n  author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n  title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n  booktitle = {HLT-NAACL},\n  year    = {2018},\n  }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fba", "disabled": false, "gated": false, "likes": 0, "downloads": 2202, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ted_iwlst2013", "sha": "604d3ac0c54873fdd005b230148e3f92f1e34fb4", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "language:de", "language:en", "language:es", "language:fa", "language:fr", "language:it", "language:nl", "language:pl", "language:pt", "language:ro", "language:ru", "language:sl", "language:tr", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "A parallel corpus of TED talk subtitles provided by CASMACAT: http://www.casmacat.eu/corpus/ted2013.html. The files are originally provided by https://wit3.fbk.eu.\n\n15 languages, 14 bitexts\ntotal number of files: 28\ntotal number of tokens: 67.67M\ntotal number of sentence fragments: 3.81M", "citation": "J. Tiedemann, 2012, Parallel Data, Tools and Interfaces in OPUS. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fbb", "disabled": false, "gated": false, "likes": 0, "downloads": 2087, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ted_multi", "sha": "e0f0bda8278ac5dd5af8f37afdb935dfd388bf21", "lastModified": "2023-04-05T13:42:14.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "Massively multilingual (60 language) data set derived from TED Talk transcripts.\nEach record consists of parallel arrays of language and text. Missing and\nincomplete translations will be filtered out.", "citation": "@InProceedings{qi-EtAl:2018:N18-2,\n  author    = {Qi, Ye  and  Sachan, Devendra  and  Felix, Matthieu  and  Padmanabhan, Sarguna  and  Neubig, Graham},\n  title     = {When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\n  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\n  month     = {June},\n  year      = {2018},\n  address   = {New Orleans, Louisiana},\n  publisher = {Association for Computational Linguistics},\n  pages     = {529--535},\n  abstract  = {The performance of Neural Machine Translation (NMT) systems often suffers in low-resource scenarios where sufficiently large-scale parallel corpora cannot be obtained. Pre-trained word embeddings have proven to be invaluable for improving performance in natural language analysis tasks, which often suffer from paucity of data. However, their utility for NMT has not been extensively explored. In this work, we perform five sets of experiments that analyze when we can expect pre-trained word embeddings to help in NMT tasks. We show that such embeddings can be surprisingly effective in some cases -- providing gains of up to 20 BLEU points in the most favorable setting.},\n  url       = {http://www.aclweb.org/anthology/N18-2084}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fbc", "disabled": false, "gated": false, "likes": 2, "downloads": 342, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ted_talks_iwslt", "sha": "784097b9a7eb8321220dcc0d77668d4127f1e0be", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:af", "language:am", "language:ar", "language:arq", "language:art", "language:as", "language:ast", "language:az", "language:be", "language:bg", "language:bi", "language:bn", "language:bo", "language:bs", "language:ca", "language:ceb", "language:cnh", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fil", "language:fr", "language:ga", "language:gl", "language:gu", "language:ha", "language:he", "language:hi", "language:hr", "language:ht", "language:hu", "language:hup", "language:hy", "language:id", "language:ig", "language:inh", "language:is", "language:it", "language:ja", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lb", "language:lo", "language:lt", "language:ltg", "language:lv", "language:mg", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:nb", "language:ne", "language:nl", "language:nn", "language:oc", "language:pa", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:rup", "language:sh", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:sv", "language:sw", "language:szl", "language:ta", "language:te", "language:tg", "language:th", "language:tl", "language:tlh", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:zh", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": null, "description": "The core of WIT3 is the TED Talks corpus, that basically redistributes the original content published by the TED Conference website (http://www.ted.com). Since 2007,\nthe TED Conference, based in California, has been posting all video recordings of its talks together with subtitles in English\nand their translations in more than 80 languages. Aside from its cultural and social relevance, this content, which is published under the Creative Commons BYNC-ND license, also represents a precious\nlanguage resource for the machine translation research community, thanks to its size, variety of topics, and covered languages.\nThis effort repurposes the original content in a way which is more convenient for machine translation researchers.", "citation": "@inproceedings{cettolo-etal-2012-wit3,\n    title = \"{WIT}3: Web Inventory of Transcribed and Translated Talks\",\n    author = \"Cettolo, Mauro  and\n      Girardi, Christian  and\n      Federico, Marcello\",\n    booktitle = \"Proceedings of the 16th Annual conference of the European Association for Machine Translation\",\n    month = may # \" 28{--}30\",\n    year = \"2012\",\n    address = \"Trento, Italy\",\n    publisher = \"European Association for Machine Translation\",\n    url = \"https://www.aclweb.org/anthology/2012.eamt-1.60\",\n    pages = \"261--268\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fbd", "disabled": false, "gated": false, "likes": 11, "downloads": 96419, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "telugu_books", "sha": "5692fa3357c49771fc35f2770e2743fcff968b89", "lastModified": "2022-11-03T16:07:57.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:te", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset is created by scraping telugu novels from teluguone.com this dataset can be used for nlp tasks like topic modeling, word embeddings, transfer learning etc", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Indic NLP - Natural Language Processing for Indian Languages},\nauthors = {Sudalai Rajkumar, Anusha Motamarri},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fbe", "disabled": false, "gated": false, "likes": 2, "downloads": 293, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "telugu_news", "sha": "810a34adb8601823f9685b2de777f2467bd74075", "lastModified": "2023-01-25T14:45:35.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:multi-class-classification", "task_ids:topic-classification", "annotations_creators:machine-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:te", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset contains Telugu language news articles along with respective\ntopic labels (business, editorial, entertainment, nation, sport) extracted from\nthe daily Andhra Jyoti. This dataset could be used to build Classification and Language Models.", "citation": "@InProceedings{kaggle:dataset,\ntitle = {Telugu News - Natural Language Processing for Indian Languages},\nauthors={Sudalai Rajkumar, Anusha Motamarri},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fbf", "disabled": false, "gated": false, "likes": 0, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tep_en_fa_para", "sha": "06ddfcbac5ce6b9a990ce113070a90fda83b46cc", "lastModified": "2022-11-03T16:08:03.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:fa", "license:unknown", "region:us"], "private": false, "author": null, "description": "TEP: Tehran English-Persian parallel corpus. The first free Eng-Per corpus, provided by the Natural Language and Text Processing Laboratory, University of Tehran.", "citation": "@InProceedings{\u201cTEP: Tehran English-Persian Parallel Corpus\u201d,\ntitle = {TEP: Tehran English-Persian Parallel Corpus\u201d, in proceedings of 12th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2011)},\nauthors={M. T. Pilevar, H. Faili, and A. H. Pilevar, },\nyear={2011}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc0", "disabled": false, "gated": false, "likes": 1, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "text2log", "sha": "bfa1a013d61207ed97e9f393a66f2578ca3076b2", "lastModified": "2022-11-03T16:15:15.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The dataset contains about 100,000 simple English sentences selected and filtered from enTenTen15 and their translation into First Order Logic (FOL) Lambda Dependency-based Compositional Semantics using ccg2lambda.", "citation": "@INPROCEEDINGS{9401852,  author={Levkovskyi, Oleksii and Li, Wei},  booktitle={SoutheastCon 2021},   title={Generating Predicate Logic Expressions from Natural Language},   year={2021},  volume={},  number={},  pages={1-8},  doi={10.1109/SoutheastCon45413.2021.9401852}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc1", "disabled": false, "gated": false, "likes": 3, "downloads": 417, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "thai_toxicity_tweet", "sha": "8c8cf6dd175f6bc356baa62ee0ae7ebd32fe0eff", "lastModified": "2023-01-25T14:45:38.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:th", "license:cc-by-nc-3.0", "region:us"], "private": false, "author": null, "description": "Thai Toxicity Tweet Corpus contains 3,300 tweets annotated by humans with guidelines including a 44-word dictionary.\nThe author obtained 2,027 and 1,273 toxic and non-toxic tweets, respectively; these were labeled by three annotators. The result of corpus\nanalysis indicates that tweets that include toxic words are not always toxic. Further, it is more likely that a tweet is toxic, if it contains\ntoxic words indicating their original meaning. Moreover, disagreements in annotation are primarily because of sarcasm, unclear existing\ntarget, and word sense ambiguity.\n\nNotes from data cleaner: The data is included into [huggingface/datasets](https://www.github.com/huggingface/datasets) in Dec 2020.\nBy this time, 506 of the tweets are not available publicly anymore. We denote these by `TWEET_NOT_FOUND` in `tweet_text`.\nProcessing can be found at [this PR](https://github.com/tmu-nlp/ThaiToxicityTweetCorpus/pull/1).", "citation": "@article{sirihattasak2019annotation,\n  title={Annotation and Classification of Toxicity for Thai Twitter},\n  author={Sirihattasak, Sugan and Komachi, Mamoru and Ishikawa, Hiroshi},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc2", "disabled": false, "gated": false, "likes": 2, "downloads": 312, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "thainer", "sha": "3ad85ac8d59a21f345656d6d1776604683ab4a5c", "lastModified": "2023-01-25T14:45:41.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-tirasaroj-aroonmanakun", "language:th", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "ThaiNER (v1.3) is a 6,456-sentence named entity recognition dataset created from expanding the 2,258-sentence\n[unnamed dataset](http://pioneer.chula.ac.th/~awirote/Data-Nutcha.zip) by\n[Tirasaroj and Aroonmanakun (2012)](http://pioneer.chula.ac.th/~awirote/publications/).\nIt is used to train NER taggers in [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp).\nThe NER tags are annotated by [Tirasaroj and Aroonmanakun (2012)]((http://pioneer.chula.ac.th/~awirote/publications/))\nfor 2,258 sentences and the rest by [@wannaphong](https://github.com/wannaphong/).\nThe POS tags are done by [PyThaiNLP](https://github.com/PyThaiNLP/pythainlp)'s `perceptron` engine trained on `orchid_ud`.\n[@wannaphong](https://github.com/wannaphong/) is now the only maintainer of this dataset.", "citation": "@misc{Wannaphong Phatthiyaphaibun_2019,\n    title={wannaphongcom/thai-ner: ThaiNER 1.3},\n    url={https://zenodo.org/record/3550546},\n    DOI={10.5281/ZENODO.3550546},\n    abstractNote={Thai Named Entity Recognition},\n    publisher={Zenodo},\n    author={Wannaphong Phatthiyaphaibun},\n    year={2019},\n    month={Nov}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc3", "disabled": false, "gated": false, "likes": 1, "downloads": 380, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "thaiqa_squad", "sha": "cb2e0deca5a0ec4e3adbdf6f96aa12ecaaea57da", "lastModified": "2022-11-03T16:15:52.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-thaiqa", "language:th", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": null, "description": "`thaiqa_squad` is an open-domain, extractive question answering dataset (4,000 questions in `train` and 74 questions in `dev`) in\n[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format, originally created by [NECTEC](https://www.nectec.or.th/en/) from\nWikipedia articles and adapted to [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) format by [PyThaiNLP](https://github.com/PyThaiNLP/).", "citation": "No clear citation guidelines from source:\nhttps://aiforthai.in.th/corpus.php\nSQuAD version:\nhttps://github.com/PyThaiNLP/thaiqa_squad", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc4", "disabled": false, "gated": false, "likes": 5, "downloads": 345, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "thaisum", "sha": "593ced77641bcfbc23fbf96eaeac0167e3881395", "lastModified": "2022-11-18T21:51:46.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:th", "license:mit", "region:us"], "private": false, "author": null, "description": "ThaiSum is a large-scale corpus for Thai text summarization obtained from several online news websites namely Thairath,\nThaiPBS, Prachathai, and The Standard. This dataset consists of over 350,000 article and summary pairs\nwritten by journalists.", "citation": "@mastersthesis{chumpolsathien_2020,\n    title={Using Knowledge Distillation from Keyword Extraction to Improve the Informativeness of Neural Cross-lingual Summarization},\n    author={Chumpolsathien, Nakhun},\n    year={2020},\n    school={Beijing Institute of Technology}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc5", "disabled": false, "gated": false, "likes": 7, "downloads": 499, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "EleutherAI/pile", "sha": "148e1d5e8349977c76f673190424a2faf6980a1d", "lastModified": "2023-05-03T15:58:14.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100B<n<1T", "source_datasets:original", "language:en", "license:other", "arxiv:2201.07311", "arxiv:2101.00027", "region:us"], "private": false, "author": "EleutherAI", "description": "The Pile is a 825 GiB diverse, open source language modelling data set that consists of 22 smaller, high-quality\ndatasets combined together.", "citation": "@misc{gao2020pile,\n      title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling},\n      author={Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy},\n      year={2020},\n      eprint={2101.00027},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc6", "disabled": false, "gated": false, "likes": 247, "downloads": 50219, "paperswithcode_id": "the-pile", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "the_pile_books3", "sha": "f8b5a8bc4606c0e5b508f599d072230081c8f364", "lastModified": "2023-11-02T15:05:12.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:mit", "arxiv:2101.00027", "region:us"], "private": false, "author": null, "description": "This dataset is Shawn Presser's work and is part of EleutherAi/The Pile dataset. This dataset contains all of bibliotik in plain .txt form, aka 197,000 books processed in exactly the same way as did for bookcorpusopen (a.k.a. books1). seems to be similar to OpenAI's mysterious \"books2\" dataset referenced in their papers. Unfortunately OpenAI will not give details, so we know very little about any differences. People suspect it's \"all of libgen\", but it's purely conjecture.", "citation": "@article{pile,\n    title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n    author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n    journal={arXiv preprint arXiv:2101.00027},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc7", "disabled": false, "gated": false, "likes": 126, "downloads": 334, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "the_pile_openwebtext2", "sha": "4e947ff1114ca59ffb82c840db640fe72beaa65e", "lastModified": "2023-02-24T13:58:16.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:text-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:text-scoring", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:mit", "arxiv:2101.00027", "region:us"], "private": false, "author": null, "description": "OpenWebText2 is part of EleutherAi/The Pile dataset and is an enhanced version of the original OpenWebTextCorpus covering all Reddit submissions from 2005 up until April 2020, with further months becoming available after the corresponding PushShift dump files are released.", "citation": "@article{pile,\n    title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n    author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n    journal={arXiv preprint arXiv:2101.00027},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc8", "disabled": false, "gated": false, "likes": 12, "downloads": 465, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "the_pile_stack_exchange", "sha": "a2ff852b5a140036dd06a370ccae722d0d00373f", "lastModified": "2023-02-20T15:10:44.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:2101.00027", "region:us"], "private": false, "author": null, "description": "This dataset is part of EleutherAI/The Pile dataset and is a dataset for Language Models from processing stackexchange data dump, which is an anonymized dump of all user-contributed content on the Stack Exchange network.", "citation": "@article{pile,\n    title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n    author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n    journal={arXiv preprint arXiv:2101.00027},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fc9", "disabled": false, "gated": false, "likes": 9, "downloads": 299, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tilde_model", "sha": "acc5759086bd8f4b341d50d0d8a256397ae25c83", "lastModified": "2022-11-03T16:31:39.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hr", "language:hu", "language:is", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:tr", "language:uk", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "This is the Tilde MODEL Corpus \u2013 Multilingual Open Data for European Languages.\n\nThe data has been collected from sites allowing free use and reuse of its content, as well as from Public Sector web sites. The activities have been undertaken as part of the ODINE Open Data Incubator for Europe, which aims to support the next generation of digital businesses and fast-track the development of new products and services. The corpus includes the following parts:\nTilde MODEL - EESC is a multilingual corpus compiled from document texts of European Economic and Social Committee document portal. Source: http://dm.eesc.europa.eu/\nTilde MODEL - RAPID multilingual parallel corpus is compiled from all press releases of Press Release Database of European Commission released between 1975 and end of 2016 as available from http://europa.eu/rapid/\nTilde MODEL - ECB multilingual parallel corpus is compiled from the multilingual pages of European Central Bank web site http://ebc.europa.eu/\nTilde MODEL - EMA is a corpus compiled from texts of European Medicines Agency document portal as available in http://www.ema.europa.eu/ at the end of 2016\nTilde MODEL - World Bank is a corpus compiled from texts of World Bank as available in http://www.worldbank.org/ in 2017\nTilde MODEL - AirBaltic.com Travel Destinations is a multilingual parallel corpus compiled from description texts of AirBaltic.com travel destinations as available in https://www.airbaltic.com/en/destinations/ in 2017\nTilde MODEL - LiveRiga.com is a multilingual parallel corpus compiled from Riga tourist attractions description texts of http://liveriga.com/ web site in 2017\nTilde MODEL - Lithuanian National Philharmonic Society is a parallel corpus compiled from texts of Lithuanian National Philharmonic Society web site http://www.filharmonija.lt/ in 2017\nTilde MODEL - mupa.hu is a parallel corpus from texts of M\u00fcpa Budapest - web site of Hungarian national culture house and concert venue https://www.mupa.hu/en/ compiled in spring of 2017\nTilde MODEL - fold.lv is a parallel corpus from texts of fold.lv portal http://www.fold.lv/en/ of the best of Latvian and foreign creative industries as compiled in spring of 2017\nTilde MODEL - czechtourism.com is a multilingual parallel corpus from texts of http://czechtourism.com/ portal compiled in spring of 2017\n30 languages, 274 bitexts\ntotal number of files: 125\ntotal number of tokens: 1.43G\ntotal number of sentence fragments: 62.44M", "citation": "Roberts Rozis, Raivis Skadins, 2017, Tilde MODEL - Multilingual Open Data for EU Languages. Proceedings of the 21th Nordic Conference of Computational Linguistics NODALIDA 2017", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fca", "disabled": false, "gated": false, "likes": 1, "downloads": 846, "paperswithcode_id": "tilde-model-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "time_dial", "sha": "c78882c22fe0de8f19220bd01e679b5e8f7d2c5c", "lastModified": "2022-11-03T16:07:53.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "dialog-act-classification", "arxiv:2106.04571", "region:us"], "private": false, "author": null, "description": "TimeDial presents a crowdsourced English challenge set, for temporal commonsense reasoning, formulated\nas a multiple choice cloze task with around 1.5k carefully curated dialogs. The dataset is derived from\nthe DailyDialog (Li et al., 2017), which is a multi-turn dialog corpus.\n\nIn order to establish strong baselines and provide information on future model development, we\nconducted extensive experiments with state-of-the-art LMs. While humans can easily answer these\nquestions (97.8%), the best T5 model variant struggles on this challenge set (73%). Moreover, our\nqualitative error analyses show that the models often rely on shallow, spurious features (particularly text\nmatching), instead of truly doing reasoning over the context.", "citation": "@inproceedings{qin-etal-2021-timedial,\n    title = \"{TimeDial: Temporal Commonsense Reasoning in Dialog}\",\n    author = \"Qin, Lianhui and Gupta, Aditya and Upadhyay, Shyam and He, Luheng and Choi, Yejin and Faruqui, Manaal\",\n    booktitle = \"Proc. of ACL\",\n    year = \"2021\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fcb", "disabled": false, "gated": false, "likes": 4, "downloads": 315, "paperswithcode_id": "timedial", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "times_of_india_news_headlines", "sha": "3c5f34fa047bc69d278345997c9170bd2648cc91", "lastModified": "2022-11-03T16:15:42.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-retrieval", "task_ids:document-retrieval", "task_ids:fact-checking-retrieval", "task_ids:text-simplification", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "This news dataset is a persistent historical archive of noteable events in the Indian subcontinent from start-2001 to mid-2020, recorded in realtime by the journalists of India. It contains approximately 3.3 million events published by Times of India. Times Group as a news agency, reaches out a very wide audience across Asia and drawfs every other agency in the quantity of english articles published per day. Due to the heavy daily volume over multiple years, this data offers a deep insight into Indian society, its priorities, events, issues and talking points and how they have unfolded over time. It is possible to chop this dataset into a smaller piece for a more focused analysis, based on one or more facets.", "citation": "@data{DVN/DPQMQH_2020,\nauthor = {Kulkarni, Rohit},\npublisher = {Harvard Dataverse},\ntitle = {{Times of India News Headlines}},\nyear = {2020},\nversion = {V1},\ndoi = {10.7910/DVN/DPQMQH},\nurl = {https://doi.org/10.7910/DVN/DPQMQH}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fcc", "disabled": false, "gated": false, "likes": 0, "downloads": 297, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "timit_asr", "sha": "1d0cd09f9ca7c40158e7e5377f45c9c718e53c68", "lastModified": "2022-10-28T16:41:41.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "The TIMIT corpus of reading speech has been developed to provide speech data for acoustic-phonetic research studies\nand for the evaluation of automatic speech recognition systems.\n\nTIMIT contains high quality recordings of 630 individuals/speakers with 8 different American English dialects,\nwith each individual reading upto 10 phonetically rich sentences.\n\nMore info on TIMIT dataset can be understood from the \"README\" which can be found here:\nhttps://catalog.ldc.upenn.edu/docs/LDC93S1/readme.txt", "citation": "@inproceedings{\n  title={TIMIT Acoustic-Phonetic Continuous Speech Corpus},\n  author={Garofolo, John S., et al},\n  ldc_catalog_no={LDC93S1},\n  DOI={https://doi.org/10.35111/17gk-bn40},\n  journal={Linguistic Data Consortium, Philadelphia},\n  year={1983}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fcd", "disabled": false, "gated": false, "likes": 16, "downloads": 2303, "paperswithcode_id": "timit", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tiny_shakespeare", "sha": "89e866dc6dd0ba9693404ab5aa90429a748101c8", "lastModified": "2023-04-05T13:42:24.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "40,000 lines of Shakespeare from a variety of Shakespeare's plays. Featured in Andrej Karpathy's blog post 'The Unreasonable Effectiveness of Recurrent Neural Networks': http://karpathy.github.io/2015/05/21/rnn-effectiveness/.\n\nTo use for e.g. character modelling:\n\n```\nd = datasets.load_dataset(name='tiny_shakespeare')['train']\nd = d.map(lambda x: datasets.Value('strings').unicode_split(x['text'], 'UTF-8'))\n# train split includes vocabulary for other splits\nvocabulary = sorted(set(next(iter(d)).numpy()))\nd = d.map(lambda x: {'cur_char': x[:-1], 'next_char': x[1:]})\nd = d.unbatch()\nseq_len = 100\nbatch_size = 2\nd = d.batch(seq_len)\nd = d.batch(batch_size)\n```", "citation": "@misc{\n  author={Karpathy, Andrej},\n  title={char-rnn},\n  year={2015},\n  howpublished={\\\\url{https://github.com/karpathy/char-rnn}}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fce", "disabled": false, "gated": false, "likes": 19, "downloads": 2850, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tlc", "sha": "df6c6030d67228b03b8db55c25073f4e036da83d", "lastModified": "2022-11-03T16:31:06.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:th", "license:unknown", "region:us"], "private": false, "author": null, "description": "Thai Literature Corpora (TLC): Corpora of machine-ingestible Thai classical literature texts.\n\nRelease: 6/25/19\n\nIt consists of two datasets:\n\n## TLC set\nIt is texts from [Vajirayana Digital Library](https://vajirayana.org/), stored by chapters and stanzas (non-tokenized).\n\ntlc v.2.0 (6/17/19 : a total of 34 documents, 292,270 lines, 31,790,734 characters)\ntlc v.1.0 (6/11/19 : a total of 25 documents, 113,981 lines, 28,775,761 characters)\n\n## TNHC set\nIt is texts from Thai National Historical Corpus, stored by lines (manually tokenized).\n\ntnhc v.1.0 (6/25/19 : a total of 47 documents, 756,478 lines, 13,361,142 characters)", "citation": "@misc{\n  author={Sawatphol, Jitkapat},\n  title={Thai Literature Corpora},\n  year={2019},\n  howpublished={\\\\url{https://attapol.github.io/tlc.html}}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fcf", "disabled": false, "gated": false, "likes": 0, "downloads": 581, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tmu_gfm_dataset", "sha": "0d777608043c765380778305df41387c763b0d49", "lastModified": "2022-11-03T16:30:48.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "grammatical-error-correction", "region:us"], "private": false, "author": null, "description": "A dataset for GEC metrics with manual evaluations of grammaticality, fluency, and meaning preservation for system outputs. More detail about the creation of the dataset can be found in Yoshimura et al. (2020).", "citation": "@inproceedings{yoshimura-etal-2020-reference,\n    title = \"{SOME}: Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction\",\n    author = \"Yoshimura, Ryoma  and\n      Kaneko, Masahiro  and\n      Kajiwara, Tomoyuki  and\n      Komachi, Mamoru\",\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\n    month = dec,\n    year = \"2020\",\n    address = \"Barcelona, Spain (Online)\",\n    publisher = \"International Committee on Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.coling-main.573\",\n    pages = \"6516--6522\",\n    abstract = \"We propose a reference-less metric trained on manual evaluations of system outputs for grammatical error correction (GEC). Previous studies have shown that reference-less metrics are promising; however, existing metrics are not optimized for manual evaluations of the system outputs because no dataset of the system output exists with manual evaluation. This study manually evaluates outputs of GEC systems to optimize the metrics. Experimental results show that the proposed metric improves correlation with the manual evaluation in both system- and sentence-level meta-evaluation. Our dataset and metric will be made publicly available.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd0", "disabled": false, "gated": false, "likes": 2, "downloads": 364, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "told-br", "sha": "1ad35f1bc628685d0dc476855a0d717b6322def9", "lastModified": "2023-01-25T14:54:23.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pt", "license:cc-by-sa-4.0", "hate-speech-detection", "arxiv:2010.04543", "region:us"], "private": false, "author": null, "description": "ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced\nby 42 annotators selected from a pool of 129 volunteers. Annotators were selected aiming\nto create a plural group in terms of demographics (ethnicity, sexual orientation, age, gender).\nEach tweet was labeled by three annotators in 6 possible categories:\nLGBTQ+phobia,Xenophobia, Obscene, Insult, Misogyny and Racism.", "citation": "@article{DBLP:journals/corr/abs-2010-04543,\n  author    = {Joao Augusto Leite and\n               Diego F. Silva and\n               Kalina Bontcheva and\n               Carolina Scarton},\n  title     = {Toxic Language Detection in Social Media for Brazilian Portuguese:\n               New Dataset and Multilingual Analysis},\n  journal   = {CoRR},\n  volume    = {abs/2010.04543},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2010.04543},\n  eprinttype = {arXiv},\n  eprint    = {2010.04543},\n  timestamp = {Tue, 15 Dec 2020 16:10:16 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04543.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd1", "disabled": false, "gated": false, "likes": 5, "downloads": 465, "paperswithcode_id": "told-br", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "totto", "sha": "5982ae9b21885a1f67f79fe5f24c097e4103481d", "lastModified": "2023-02-23T09:49:19.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "arxiv:2004.14373", "region:us"], "private": false, "author": null, "description": "ToTTo is an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description.", "citation": "@inproceedings{parikh2020totto,\n  title={{ToTTo}: A Controlled Table-To-Text Generation Dataset},\n  author={Parikh, Ankur P and Wang, Xuezhi and Gehrmann, Sebastian and Faruqui, Manaal and Dhingra, Bhuwan and Yang, Diyi and Das, Dipanjan},\n  booktitle={Proceedings of EMNLP},\n  year={2020}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd2", "disabled": false, "gated": false, "likes": 6, "downloads": 759, "paperswithcode_id": "totto", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "trec", "sha": "6dc47d2cef06ccd4cc777cf7c460411c50ee58ca", "lastModified": "2023-04-05T13:42:29.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Text REtrieval Conference (TREC) Question Classification dataset contains 5500 labeled questions in training set and another 500 for test set.\n\nThe dataset has 6 coarse class labels and 50 fine class labels. Average length of each sentence is 10, vocabulary size of 8700.\n\nData are collected from four sources: 4,500 English questions published by USC (Hovy et al., 2001), about 500 manually constructed questions for a few rare classes, 894 TREC 8 and TREC 9 questions, and also 500 questions from TREC 10 which serves as the test set. These questions were manually labeled.", "citation": "@inproceedings{li-roth-2002-learning,\n    title = \"Learning Question Classifiers\",\n    author = \"Li, Xin  and\n      Roth, Dan\",\n    booktitle = \"{COLING} 2002: The 19th International Conference on Computational Linguistics\",\n    year = \"2002\",\n    url = \"https://www.aclweb.org/anthology/C02-1150\",\n}\n@inproceedings{hovy-etal-2001-toward,\n    title = \"Toward Semantics-Based Answer Pinpointing\",\n    author = \"Hovy, Eduard  and\n      Gerber, Laurie  and\n      Hermjakob, Ulf  and\n      Lin, Chin-Yew  and\n      Ravichandran, Deepak\",\n    booktitle = \"Proceedings of the First International Conference on Human Language Technology Research\",\n    year = \"2001\",\n    url = \"https://www.aclweb.org/anthology/H01-1069\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd3", "disabled": false, "gated": false, "likes": 30, "downloads": 45347, "paperswithcode_id": "trecqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "trivia_qa", "sha": "d63a76f01c8226449f76b437dd512cf8b17adf5d", "lastModified": "2023-06-09T15:34:16.000Z", "tags": ["task_categories:question-answering", "task_categories:text2text-generation", "task_ids:open-domain-qa", "task_ids:open-domain-abstractive-qa", "task_ids:extractive-qa", "task_ids:abstractive-qa", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1705.03551", "region:us"], "private": false, "author": null, "description": "TriviaqQA is a reading comprehension dataset containing over 650K\nquestion-answer-evidence triples. TriviaqQA includes 95K question-answer\npairs authored by trivia enthusiasts and independently gathered evidence\ndocuments, six per question on average, that provide high quality distant\nsupervision for answering the questions.", "citation": "@article{2017arXivtriviaqa,\n       author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},\n                 Daniel and {Zettlemoyer}, Luke},\n        title = \"{triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}\",\n      journal = {arXiv e-prints},\n         year = 2017,\n          eid = {arXiv:1705.03551},\n        pages = {arXiv:1705.03551},\narchivePrefix = {arXiv},\n       eprint = {1705.03551},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd4", "disabled": false, "gated": false, "likes": 30, "downloads": 32433, "paperswithcode_id": "triviaqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tsac", "sha": "766c4acb36b86236ab183c1325d7532e610ef989", "lastModified": "2023-01-25T14:54:29.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:aeb", "license:lgpl-3.0", "region:us"], "private": false, "author": null, "description": "Tunisian Sentiment Analysis Corpus.\n\nAbout 17k user comments manually annotated to positive and negative polarities. This corpus is collected from Facebook users comments written on official pages of Tunisian radios and TV channels namely Mosaique FM, JawhraFM, Shemes FM, HiwarElttounsi TV and Nessma TV. The corpus is collected from a period spanning January 2015 until June 2016.", "citation": "@inproceedings{medhaffar-etal-2017-sentiment,\n    title = \"Sentiment Analysis of {T}unisian Dialects: Linguistic Ressources and Experiments\",\n    author = \"Medhaffar, Salima  and\n      Bougares, Fethi  and\n      Est{`e}ve, Yannick  and\n      Hadrich-Belguith, Lamia\",\n    booktitle = \"Proceedings of the Third {A}rabic Natural Language Processing Workshop\",\n    month = apr,\n    year = \"2017\",\n    address = \"Valencia, Spain\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/W17-1307\",\n    doi = \"10.18653/v1/W17-1307\",\n    pages = \"55--61\",\n    abstract = \"Dialectal Arabic (DA) is significantly different from the Arabic language taught in schools and used in written communication and formal speech (broadcast news, religion, politics, etc.). There are many existing researches in the field of Arabic language Sentiment Analysis (SA); however, they are generally restricted to Modern Standard Arabic (MSA) or some dialects of economic or political interest. In this paper we are interested in the SA of the Tunisian Dialect. We utilize Machine Learning techniques to determine the polarity of comments written in Tunisian Dialect. First, we evaluate the SA systems performances with models trained using freely available MSA and Multi-dialectal data sets. We then collect and annotate a Tunisian Dialect corpus of 17.000 comments from Facebook. This corpus allows us a significant accuracy improvement compared to the best model trained on other Arabic dialects or MSA data. We believe that this first freely available corpus will be valuable to researchers working in the field of Tunisian Sentiment Analysis and similar areas.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd5", "disabled": false, "gated": false, "likes": 0, "downloads": 295, "paperswithcode_id": "tsac", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ttc4900", "sha": "d601fdc05be2ba9c381c4ee459179a9c5fe63d0d", "lastModified": "2023-01-25T14:54:33.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:tr", "license:unknown", "news-category-classification", "region:us"], "private": false, "author": null, "description": "The data set is taken from kemik group\nhttp://www.kemik.yildiz.edu.tr/\nThe data are pre-processed for the text categorization, collocations are found, character set is corrected, and so forth.\nWe named TTC4900 by mimicking the name convention of TTC 3600 dataset shared by the study http://journals.sagepub.com/doi/abs/10.1177/0165551515620551\n\nIf you use the dataset in a paper, please refer https://www.kaggle.com/savasy/ttc4900 as footnote and cite one of the papers as follows:\n\n- A Comparison of Different Approaches to Document Representation in Turkish Language, SDU Journal of Natural and Applied Science, Vol 22, Issue 2, 2018\n- A comparative analysis of text classification for Turkish language, Pamukkale University Journal of Engineering Science Volume 25 Issue 5, 2018\n- A Knowledge-poor Approach to Turkish Text Categorization with a Comparative Analysis, Proceedings of CICLING 2014, Springer LNCS, Nepal, 2014.", "citation": "@article{doi:10.5505/pajes.2018.15931,\nauthor = {Y\u0131ld\u0131r\u0131m, Sava\u015f and Y\u0131ld\u0131z, Tu\u011fba},\ntitle = {A comparative analysis of text classification for Turkish language},\njournal = {Pamukkale Univ Muh Bilim Derg},\nvolume = {24},\nnumber = {5},\npages = {879-886},\nyear = {2018},\ndoi = {10.5505/pajes.2018.15931},\nnote ={doi: 10.5505/pajes.2018.15931},\n\nURL = {https://dx.doi.org/10.5505/pajes.2018.15931},\neprint = {https://dx.doi.org/10.5505/pajes.2018.15931}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd6", "disabled": false, "gated": false, "likes": 2, "downloads": 293, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tunizi", "sha": "8d76babc9736f1902ab13be75627a60b6e716dcc", "lastModified": "2023-01-25T14:54:36.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:aeb", "license:unknown", "arxiv:2004.14303", "region:us"], "private": false, "author": null, "description": "On social media, Arabic speakers tend to express themselves in their own local dialect. To do so, Tunisians use \"Tunisian Arabizi\", which consists in supplementing numerals to the Latin script rather than the Arabic alphabet. TUNIZI is the first Tunisian Arabizi Dataset including 3K sentences, balanced, covering different topics, preprocessed and annotated as positive and negative.", "citation": "@inproceedings{Chayma2020,\ntitle={TUNIZI: a Tunisian Arabizi sentiment analysis Dataset},\nauthor={Fourati, Chayma and Messaoudi, Abir and Haddad, Hatem},\nbooktitle={AfricaNLP Workshop, Putting Africa on the NLP Map. ICLR 2020, Virtual Event},\nvolume = {arXiv:3091079},\nyear = {2020},\nurl = {https://arxiv.org/submit/3091079},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd7", "disabled": false, "gated": false, "likes": 0, "downloads": 297, "paperswithcode_id": "tunizi", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tuple_ie", "sha": "3dfe2c3c76c6365261b38762a9a9da0fc68c6ca0", "lastModified": "2022-11-03T16:31:04.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "open-information-extraction", "region:us"], "private": false, "author": null, "description": "The TupleInf Open IE dataset contains Open IE tuples extracted from 263K sentences that were used by the solver in \u201cAnswering Complex Questions Using Open Information Extraction\u201d (referred as Tuple KB, T). These sentences were collected from a large Web corpus using training questions from 4th and 8th grade as queries. This dataset contains 156K sentences collected for 4th grade questions and 107K sentences for 8th grade questions. Each sentence is followed by the Open IE v4 tuples using their simple format.", "citation": "@article{Khot2017AnsweringCQ,\n  title={Answering Complex Questions Using Open Information Extraction},\n  author={Tushar Khot and A. Sabharwal and Peter Clark},\n  journal={ArXiv},\n  year={2017},\n  volume={abs/1704.05572}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd8", "disabled": false, "gated": false, "likes": 1, "downloads": 562, "paperswithcode_id": "tupleinf-open-ie-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turk", "sha": "2dd947af8561295c2d3d0d56758bf5686d5c82f5", "lastModified": "2022-11-18T21:56:55.000Z", "tags": ["task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "TURKCorpus is a dataset for evaluating sentence simplification systems that focus on lexical paraphrasing,\nas described in \"Optimizing Statistical Machine Translation for Text Simplification\". The corpus is composed of 2000 validation and 359 test original sentences that were each simplified 8 times by different annotators.", "citation": " @article{Xu-EtAl:2016:TACL,\n author = {Wei Xu and Courtney Napoles and Ellie Pavlick and Quanze Chen and Chris Callison-Burch},\n title = {Optimizing Statistical Machine Translation for Text Simplification},\n journal = {Transactions of the Association for Computational Linguistics},\n volume = {4},\n year = {2016},\n url = {https://cocoxu.github.io/publications/tacl2016-smt-simplification.pdf},\n pages = {401--415}\n }\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fd9", "disabled": false, "gated": false, "likes": 3, "downloads": 384, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turkic_xwmt", "sha": "e9c33673f427206bb33755f0d82736d9d722c0a5", "lastModified": "2023-06-01T14:59:57.000Z", "tags": ["task_categories:translation", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:translation", "size_categories:n<1K", "source_datasets:extended|WMT 2020 News Translation Task", "language:az", "language:ba", "language:en", "language:kaa", "language:kk", "language:ky", "language:ru", "language:sah", "language:tr", "language:uz", "license:mit", "arxiv:2109.04593", "region:us"], "private": false, "author": null, "description": "A Large-Scale Study of Machine Translation in Turkic Languages", "citation": "@inproceedings{mirzakhalov2021large,\n  title={A Large-Scale Study of Machine Translation in Turkic Languages},\n  author={Mirzakhalov, Jamshidbek and Babu, Anoop and Ataman, Duygu and Kariev, Sherzod and Tyers, Francis and Abduraufov, Otabek and Hajili, Mammad and Ivanova, Sardana and Khaytbaev, Abror and Laverghetta Jr, Antonio and others},\n  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},\n  pages={5876--5890},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fda", "disabled": false, "gated": false, "likes": 11, "downloads": 12993, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turkish_movie_sentiment", "sha": "e5cf0b256fbeda1b9b1c04ddf9f24d9108dc93c4", "lastModified": "2022-11-03T16:07:48.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:tr", "license:unknown", "region:us"], "private": false, "author": null, "description": "This data set is a dataset from kaggle consisting of Turkish movie reviews and scored between 0-5.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fdb", "disabled": false, "gated": false, "likes": 3, "downloads": 295, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turkish_ner", "sha": "4f96e681ecf219a0c635a107f094f530140fc6c9", "lastModified": "2023-01-25T14:54:39.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tr", "license:cc-by-4.0", "arxiv:1702.02363", "region:us"], "private": false, "author": null, "description": "Turkish Wikipedia Named-Entity Recognition and Text Categorization\n(TWNERTC) dataset is a collection of automatically categorized and annotated\nsentences obtained from Wikipedia. The authors constructed large-scale\ngazetteers by using a graph crawler algorithm to extract\nrelevant entity and domain information\nfrom a semantic knowledge base, Freebase.\nThe constructed gazetteers contains approximately\n300K entities with thousands of fine-grained entity types\nunder 77 different domains.", "citation": "@InProceedings@article{DBLP:journals/corr/SahinTYES17,\n  author    = {H. Bahadir Sahin and\n               Caglar Tirkaz and\n               Eray Yildiz and\n               Mustafa Tolga Eren and\n               Omer Ozan Sonmez},\n  title     = {Automatically Annotated Turkish Corpus for Named Entity Recognition\n               and Text Categorization using Large-Scale Gazetteers},\n  journal   = {CoRR},\n  volume    = {abs/1702.02363},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1702.02363},\n  archivePrefix = {arXiv},\n  eprint    = {1702.02363},\n  timestamp = {Mon, 13 Aug 2018 16:46:36 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/SahinTYES17.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fdc", "disabled": false, "gated": false, "likes": 5, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turkish_product_reviews", "sha": "966cbe841c67cf340740548df638210b4eab7c83", "lastModified": "2023-01-25T14:54:42.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tr", "license:unknown", "region:us"], "private": false, "author": null, "description": "Turkish Product Reviews.\nThis repository contains 235.165 product reviews collected online. There are 220.284 positive, 14881 negative reviews.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fdd", "disabled": false, "gated": false, "likes": 3, "downloads": 340, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turkish_shrinked_ner", "sha": "fced99e0ce32ff29ed4f2c0ef97916165d35a861", "lastModified": "2023-01-25T14:54:44.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other-turkish_ner", "language:tr", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Shrinked version (48 entity type) of the turkish_ner.\n\nOriginal turkish_ner dataset: Automatically annotated Turkish corpus for named entity recognition and text categorization using large-scale gazetteers. The constructed gazetteers contains approximately 300K entities with thousands of fine-grained entity types under 25 different domains.\n\nShrinked entity types are: academic, academic_person, aircraft, album_person, anatomy, animal, architect_person, capital, chemical, clothes, country, culture, currency, date, food, genre, government, government_person, language, location, material, measure, medical, military, military_person, nation, newspaper, organization, organization_person, person, production_art_music, production_art_music_person, quantity, religion, science, shape, ship, software, space, space_person, sport, sport_name, sport_person, structure, subject, tech, train, vehicle", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fde", "disabled": false, "gated": false, "likes": 1, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turku_ner_corpus", "sha": "0c220bb2ce60b2b7a6a55d3df16899ed1a10dbd0", "lastModified": "2023-01-25T14:54:48.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fi", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": "An open, broad-coverage corpus for Finnish named entity recognition presented in Luoma et al. (2020) A Broad-coverage Corpus for Finnish Named Entity Recognition.", "citation": "@inproceedings{luoma-etal-2020-broad,\ntitle = \"A Broad-coverage Corpus for {F}innish Named Entity Recognition\",\nauthor = {Luoma, Jouni and Oinonen, Miika and Pyyk{\\\"o}nen, Maria and Laippala, Veronika and Pyysalo, Sampo},\nbooktitle = \"Proceedings of The 12th Language Resources and Evaluation Conference\",\nyear = \"2020\",\nurl = \"https://www.aclweb.org/anthology/2020.lrec-1.567\",\npages = \"4615--4624\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fdf", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tweet_eval", "sha": "675a13f04b51b72ccb66915dd5ca2bb13aee8412", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:extended|other-tweet-datasets", "language:en", "license:unknown", "arxiv:2010.12421", "region:us"], "private": false, "author": null, "description": "TweetEval consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. All tasks have been unified into the same benchmark, with each dataset presented in the same format and with fixed training, validation and test splits.", "citation": "@inproceedings{barbieri2020tweeteval,\n  title={{TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification}},\n  author={Barbieri, Francesco and Camacho-Collados, Jose and Espinosa-Anke, Luis and Neves, Leonardo},\n  booktitle={Proceedings of Findings of EMNLP},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe0", "disabled": false, "gated": false, "likes": 84, "downloads": 59165, "paperswithcode_id": "tweeteval", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tweet_qa", "sha": "0e7fbdf34fd739c6108655fcc8fc218acd6f9e70", "lastModified": "2022-11-18T21:57:35.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:1907.06292", "region:us"], "private": false, "author": null, "description": "TweetQA is the first dataset for QA on social media data by leveraging news media and crowdsourcing.", "citation": "@inproceedings{xiong2019tweetqa,\n  title={TweetQA: A Social Media Focused Question Answering Dataset},\n  author={Xiong, Wenhan and Wu, Jiawei and Wang, Hong and Kulkarni, Vivek and Yu, Mo and Guo, Xiaoxiao and Chang, Shiyu and Wang, William Yang},\n  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe1", "disabled": false, "gated": false, "likes": 3, "downloads": 751, "paperswithcode_id": "tweetqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tweets_ar_en_parallel", "sha": "f3b9a68569a51171e7aa627b229736e48958bb9b", "lastModified": "2023-01-25T14:54:55.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "language:en", "license:apache-2.0", "tweets-translation", "region:us"], "private": false, "author": null, "description": "    Twitter users often post parallel tweets\u2014tweets that contain the same content but are\n    written in different languages. Parallel tweets can be an important resource for developing\n    machine translation (MT) systems among other natural language processing (NLP) tasks. This\n    resource is a result of a generic method for collecting parallel tweets. Using the method,\n    we compiled a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts\n    who post English-Arabic tweets regularly. Additionally, we annotate a subset of Twitter accounts\n    with their countries of origin and topic of interest, which provides insights about the population\n    who post parallel tweets.", "citation": "@inproceedings{Mubarak2020bilingualtweets,\ntitle={Constructing a Bilingual Corpus of Parallel Tweets},\nauthor={Mubarak, Hamdy and Hassan, Sabit and Abdelali, Ahmed},\nbooktitle={Proceedings of 13th Workshop on Building and Using Comparable Corpora (BUCC)},\naddress={Marseille, France},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe2", "disabled": false, "gated": false, "likes": 3, "downloads": 562, "paperswithcode_id": "bilingual-corpus-of-arabic-english-parallel", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tweets_hate_speech_detection", "sha": "21a716f9b472ddb26d23a0c145dce794086229f6", "lastModified": "2023-01-25T14:54:59.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": null, "description": "The objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n\nFormally, given a training sample of tweets and labels, where label \u20181\u2019 denotes the tweet is racist/sexist and label \u20180\u2019 denotes the tweet is not racist/sexist, your objective is to predict the labels on the given test dataset.", "citation": "@InProceedings{Z\nRoshan Sharma:dataset,\ntitle = {Sentimental Analysis of Tweets for Detecting Hate/Racist Speeches},\nauthors={Roshan Sharma},\nyear={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe3", "disabled": false, "gated": false, "likes": 15, "downloads": 1963, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "twi_text_c3", "sha": "abfb984f7cd500f89c9bc620cdbcd00e56e01496", "lastModified": "2022-11-03T16:15:20.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tw", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "Twi Text C3 is the largest Twi texts collected and used to train FastText embeddings in the\nYorubaTwi Embedding paper: https://www.aclweb.org/anthology/2020.lrec-1.335/", "citation": "@inproceedings{alabi-etal-2020-massive,\n    title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of Yoruba and {T}wi\",\n    author = \"Alabi, Jesujoba  and\n      Amponsah-Kaakyire, Kwabena  and\n      Adelani, David  and\n      Espa{\\\\~n}a-Bonet, Cristina\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n    pages = \"2754--2762\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe4", "disabled": false, "gated": false, "likes": 1, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "twi_wordsim353", "sha": "b21f0144299b74934915e2e22d52a969a1b075ed", "lastModified": "2022-11-03T16:07:57.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:en", "language:tw", "license:unknown", "region:us"], "private": false, "author": null, "description": "A translation of the word pair similarity dataset wordsim-353 to Twi.\n\nThe dataset was presented in the paper\nAlabi et al.: Massive vs. Curated Embeddings for Low-Resourced\nLanguages: the Case of Yor\u00f9b\u00e1 and Twi (LREC 2020).", "citation": "@inproceedings{alabi-etal-2020-massive,\n    title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Y}or{\\\\`u}b{\\\\'a} and {T}wi\",\n    author = \"Alabi, Jesujoba  and\n      Amponsah-Kaakyire, Kwabena  and\n      Adelani, David  and\n      Espa{\\\\~n}a-Bonet, Cristina\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n    pages = \"2754--2762\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe5", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tydiqa", "sha": "9fb85e997f05a63b2a3ae0e7bde64fd8ef52250b", "lastModified": "2023-04-05T13:42:46.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:extended|wikipedia", "language:ar", "language:bn", "language:en", "language:fi", "language:id", "language:ja", "language:ko", "language:ru", "language:sw", "language:te", "language:th", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\ndon\u2019t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\nthe use of translation (unlike MLQA and XQuAD).", "citation": "@article{tydiqa,\ntitle   = {TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},\nauthor  = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki}\nyear    = {2020},\njournal = {Transactions of the Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe6", "disabled": false, "gated": false, "likes": 15, "downloads": 4731, "paperswithcode_id": "tydi-qa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ubuntu_dialogs_corpus", "sha": "6aab564e4e1b31a91d3204db5473cf145d7ebf53", "lastModified": "2023-04-05T13:42:49.000Z", "tags": ["task_categories:conversational", "task_ids:dialogue-generation", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1506.08909", "region:us"], "private": false, "author": null, "description": "Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter.", "citation": "@article{DBLP:journals/corr/LowePSP15,\n  author    = {Ryan Lowe and\n               Nissan Pow and\n               Iulian Serban and\n               Joelle Pineau},\n  title     = {The Ubuntu Dialogue Corpus: {A} Large Dataset for Research in Unstructured\n               Multi-Turn Dialogue Systems},\n  journal   = {CoRR},\n  volume    = {abs/1506.08909},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1506.08909},\n  archivePrefix = {arXiv},\n  eprint    = {1506.08909},\n  timestamp = {Mon, 13 Aug 2018 16:48:23 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/LowePSP15.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe7", "disabled": false, "gated": false, "likes": 15, "downloads": 467, "paperswithcode_id": "ubuntu-dialogue-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "udhr", "sha": "36a71b270bf3a7fa355fc656c8b96b7094350a3c", "lastModified": "2022-11-03T16:16:11.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:aa", "language:ab", "language:ace", "language:acu", "language:ada", "language:ady", "language:af", "language:agr", "language:aii", "language:ajg", "language:als", "language:alt", "language:am", "language:amc", "language:ame", "language:ami", "language:amr", "language:ar", "language:arl", "language:arn", "language:ast", "language:auc", "language:ay", "language:az", "language:ban", "language:bax", "language:bba", "language:bci", "language:be", "language:bem", "language:bfa", "language:bg", "language:bho", "language:bi", "language:bik", "language:bin", "language:blt", "language:bm", "language:bn", "language:bo", "language:boa", "language:br", "language:bs", "language:buc", "language:bug", "language:bum", "language:ca", "language:cab", "language:cak", "language:cbi", "language:cbr", "language:cbs", "language:cbt", "language:cbu", "language:ccp", "language:ceb", "language:cfm", "language:ch", "language:chj", "language:chk", "language:chr", "language:cic", "language:cjk", "language:cjs", "language:cjy", "language:ckb", "language:cnh", "language:cni", "language:cnr", "language:co", "language:cof", "language:cot", "language:cpu", "language:crh", "language:cri", "language:crs", "language:cs", "language:csa", "language:csw", "language:ctd", "language:cy", "language:da", "language:dag", "language:ddn", "language:de", "language:dga", "language:dip", "language:duu", "language:dv", "language:dyo", "language:dyu", "language:dz", "language:ee", "language:el", "language:en", "language:eo", "language:es", "language:ese", "language:et", "language:eu", "language:eve", "language:evn", "language:fa", "language:fat", "language:fi", "language:fj", "language:fkv", "language:fo", "language:fon", "language:fr", "language:fuf", "language:fur", "language:fuv", "language:fvr", "language:fy", "language:ga", "language:gaa", "language:gag", "language:gan", "language:gd", "language:gjn", "language:gkp", "language:gl", "language:gld", "language:gn", "language:gsw", "language:gu", "language:guc", "language:guu", "language:gv", "language:gyr", "language:ha", "language:hak", "language:haw", "language:he", "language:hi", "language:hil", "language:hlt", "language:hmn", "language:hms", "language:hna", "language:hni", "language:hnj", "language:hns", "language:hr", "language:hsb", "language:hsn", "language:ht", "language:hu", "language:hus", "language:huu", "language:hy", "language:ia", "language:ibb", "language:id", "language:idu", "language:ig", "language:ii", "language:ijs", "language:ilo", "language:io", "language:is", "language:it", "language:iu", "language:ja", "language:jiv", "language:jv", "language:ka", "language:kaa", "language:kbd", "language:kbp", "language:kde", "language:kdh", "language:kea", "language:kek", "language:kg", "language:kha", "language:kjh", "language:kk", "language:kkh", "language:kl", "language:km", "language:kmb", "language:kn", "language:ko", "language:koi", "language:koo", "language:kqn", "language:kqs", "language:kr", "language:kri", "language:krl", "language:ktu", "language:ku", "language:kwi", "language:ky", "language:la", "language:lad", "language:lah", "language:lb", "language:lg", "language:lia", "language:lij", "language:lld", "language:ln", "language:lns", "language:lo", "language:lob", "language:lot", "language:loz", "language:lt", "language:lua", "language:lue", "language:lun", "language:lus", "language:lv", "language:mad", "language:mag", "language:mai", "language:mam", "language:man", "language:maz", "language:mcd", "language:mcf", "language:men", "language:mfq", "language:mg", "language:mh", "language:mi", "language:mic", "language:min", "language:miq", "language:mk", "language:ml", "language:mn", "language:mnw", "language:mor", "language:mos", "language:mr", "language:mt", "language:mto", "language:mxi", "language:mxv", "language:my", "language:mzi", "language:nan", "language:nb", "language:nba", "language:nds", "language:ne", "language:ng", "language:nhn", "language:nio", "language:niu", "language:niv", "language:njo", "language:nku", "language:nl", "language:nn", "language:not", "language:nr", "language:nso", "language:nv", "language:ny", "language:nym", "language:nyn", "language:nzi", "language:oaa", "language:oc", "language:ojb", "language:oki", "language:om", "language:orh", "language:os", "language:ote", "language:pa", "language:pam", "language:pap", "language:pau", "language:pbb", "language:pcd", "language:pcm", "language:pis", "language:piu", "language:pl", "language:pon", "language:pov", "language:ppl", "language:prq", "language:ps", "language:pt", "language:qu", "language:quc", "language:qug", "language:quh", "language:quy", "language:qva", "language:qvc", "language:qvh", "language:qvm", "language:qvn", "language:qwh", "language:qxn", "language:qxu", "language:rar", "language:rgn", "language:rm", "language:rmn", "language:rn", "language:ro", "language:ru", "language:rup", "language:rw", "language:sa", "language:sah", "language:sc", "language:sco", "language:se", "language:sey", "language:sg", "language:shk", "language:shn", "language:shp", "language:si", "language:sk", "language:skr", "language:sl", "language:slr", "language:sm", "language:sn", "language:snk", "language:snn", "language:so", "language:sr", "language:srr", "language:ss", "language:st", "language:su", "language:suk", "language:sus", "language:sv", "language:sw", "language:swb", "language:ta", "language:taj", "language:tbz", "language:tca", "language:tdt", "language:te", "language:tem", "language:tet", "language:tg", "language:th", "language:ti", "language:tiv", "language:tk", "language:tl", "language:tly", "language:tn", "language:to", "language:tob", "language:toi", "language:toj", "language:top", "language:tpi", "language:tr", "language:ts", "language:tsz", "language:tt", "language:tw", "language:ty", "language:tyv", "language:tzh", "language:tzm", "language:tzo", "language:udu", "language:ug", "language:uk", "language:umb", "language:und", "language:ur", "language:ura", "language:uz", "language:vai", "language:ve", "language:vec", "language:vep", "language:vi", "language:vmw", "language:wa", "language:war", "language:wo", "language:wuu", "language:wwa", "language:xh", "language:xsm", "language:yad", "language:yao", "language:yap", "language:yi", "language:ykg", "language:yo", "language:yrk", "language:yua", "language:yue", "language:za", "language:zam", "language:zdj", "language:zgh", "language:zh", "language:zlm", "language:zro", "language:ztu", "language:zu", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Universal Declaration of Human Rights (UDHR) is a milestone document in the history of human rights. Drafted by\nrepresentatives with different legal and cultural backgrounds from all regions of the world, it set out, for the\nfirst time, fundamental human rights to be universally protected. The Declaration was adopted by the UN General\nAssembly in Paris on 10 December 1948 during its 183rd plenary meeting. The dataset includes translations of the\ndocument in 464+ languages and dialects.\n\n\u00a9 1996 \u2013 2009 The Office of the High Commissioner for Human Rights\n\nThis plain text version prepared by the \u201cUDHR in Unicode\u201d project, https://www.unicode.org/udhr.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe8", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "um005", "sha": "5b82b2f25cd93da6c8f25d998c88c9c140dc46fb", "lastModified": "2022-11-18T21:58:09.000Z", "tags": ["task_categories:translation", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:ur", "license:unknown", "region:us"], "private": false, "author": null, "description": "UMC005 English-Urdu is a parallel corpus of texts in English and Urdu language with sentence alignments. The corpus can be used for experiments with statistical machine translation.\n\nThe texts come from four different sources:\n- Quran\n- Bible\n- Penn Treebank (Wall Street Journal)\n- Emille corpus\n\nThe authors provide the religious texts of Quran and Bible for direct download. Because of licensing reasons, Penn and Emille texts cannot be redistributed freely. However, if you already hold a license for the original corpora, we are able to provide scripts that will recreate our data on your disk. Our modifications include but are not limited to the following:\n\n- Correction of Urdu translations and manual sentence alignment of the Emille texts.\n- Manually corrected sentence alignment of the other corpora.\n- Our data split (training-development-test) so that our published experiments can be reproduced.\n- Tokenization (optional, but needed to reproduce our experiments).\n- Normalization (optional) of e.g. European vs. Urdu numerals, European vs. Urdu punctuation, removal of Urdu diacritics.", "citation": "@unpublished{JaZeWordOrderIssues2011,\nauthor      = {Bushra Jawaid and Daniel Zeman},\ntitle       = {Word-Order Issues in {English}-to-{Urdu} Statistical Machine Translation},\nyear        = {2011},\njournal     = {The Prague Bulletin of Mathematical Linguistics},\nnumber      = {95},\ninstitution = {Univerzita Karlova},\naddress     = {Praha, Czechia},\nissn        = {0032-6585},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fe9", "disabled": false, "gated": false, "likes": 0, "downloads": 573, "paperswithcode_id": "umc005-english-urdu", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "un_ga", "sha": "66f9ffb815cfe134cfbab5996369f41f21e29ded", "lastModified": "2023-06-01T14:59:53.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "language:en", "language:es", "language:fr", "language:ru", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "United nations general assembly resolutions: A six-language parallel corpus.\nThis is a collection of translated documents from the United Nations originally compiled into a translation memory by Alexandre Rafalovitch, Robert Dale (see http://uncorpora.org).\n6 languages, 15 bitexts\ntotal number of files: 6\ntotal number of tokens: 18.87M\ntotal number of sentence fragments: 0.44M", "citation": "@inproceedings{title = \"United Nations General Assembly Resolutions: a six-language parallel corpus\",\nabstract = \"In this paper we describe a six-ways parallel public-domain corpus consisting of 2100 United Nations General Assembly Resolutions with translations in the six official languages of the United Nations, with an average of around 3 million tokens per language. The corpus is available in a preprocessed, formatting-normalized TMX format with paragraphs aligned across multiple languages. We describe the background to the corpus and its content, the process of its construction, and some of its interesting properties.\",\nauthor = \"Alexandre Rafalovitch and Robert Dale\",\nyear = \"2009\",\nlanguage = \"English\",\nbooktitle = \"MT Summit XII proceedings\",\npublisher = \"International Association of Machine Translation\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fea", "disabled": false, "gated": false, "likes": 0, "downloads": 2235, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "un_multi", "sha": "7174145b62f3b80ca1d1eb5c6ed8bcfe6d4b7398", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "language:de", "language:en", "language:es", "language:fr", "language:ru", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This is a collection of translated documents from the United Nations. This corpus is available in all 6 official languages of the UN, consisting of around 300 million words per language", "citation": "@inproceedings{eisele-chen-2010-multiun,\n    title = \"{M}ulti{UN}: A Multilingual Corpus from United Nation Documents\",\n    author = \"Eisele, Andreas  and\n      Chen, Yu\",\n    booktitle = \"Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)\",\n    month = may,\n    year = \"2010\",\n    address = \"Valletta, Malta\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"http://www.lrec-conf.org/proceedings/lrec2010/pdf/686_Paper.pdf\",\n    abstract = \"This paper describes the acquisition, preparation and properties of a corpus extracted from the official documents of the United Nations (UN). This corpus is available in all 6 official languages of the UN, consisting of around 300 million words per language. We describe the methods we used for crawling, document formatting, and sentence alignment. This corpus also includes a common test set for machine translation. We present the results of a French-Chinese machine translation experiment performed on this corpus.\",\n}\n\n@InProceedings{TIEDEMANN12.463,\n  author = {J\ufffdrg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181feb", "disabled": false, "gated": false, "likes": 3, "downloads": 3276, "paperswithcode_id": "multiun", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "un_pc", "sha": "1e592b6a0792682e78007f2c54888a58db9cb2eb", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "language:ar", "language:en", "language:es", "language:fr", "language:ru", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This parallel corpus consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish.", "citation": "@inproceedings{ziemski-etal-2016-united,\n    title = \"The {U}nited {N}ations Parallel Corpus v1.0\",\n    author = \"Ziemski, Micha{\\\\l}  and\n      Junczys-Dowmunt, Marcin  and\n      Pouliquen, Bruno\",\n    booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n    month = may,\n    year = \"2016\",\n    address = \"Portoro{\\v{z}}, Slovenia\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"https://www.aclweb.org/anthology/L16-1561\",\n    pages = \"3530--3534\",\n    abstract = \"This paper describes the creation process and statistics of the official United Nations Parallel Corpus, the first parallel corpus composed from United Nations documents published by the original data creator. The parallel corpus presented consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish. The corpus is freely available for download under a liberal license. Apart from the pairwise aligned documents, a fully aligned subcorpus for the six official UN languages is distributed. We provide baseline BLEU scores of our Moses-based SMT systems trained with the full data of language pairs involving English and for all possible translation directions of the six-way subcorpus.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fec", "disabled": false, "gated": false, "likes": 3, "downloads": 2315, "paperswithcode_id": "united-nations-parallel-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "universal_dependencies", "sha": "e0a1d916e3346af8460b71a18491313c5cbdfb41", "lastModified": "2023-06-01T14:59:56.000Z", "tags": ["task_categories:token-classification", "task_ids:parsing", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:af", "language:aii", "language:ajp", "language:akk", "language:am", "language:apu", "language:aqz", "language:ar", "language:be", "language:bg", "language:bho", "language:bm", "language:br", "language:bxr", "language:ca", "language:ckt", "language:cop", "language:cs", "language:cu", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fo", "language:fr", "language:fro", "language:ga", "language:gd", "language:gl", "language:got", "language:grc", "language:gsw", "language:gun", "language:gv", "language:he", "language:hi", "language:hr", "language:hsb", "language:hu", "language:hy", "language:id", "language:is", "language:it", "language:ja", "language:kfm", "language:kk", "language:kmr", "language:ko", "language:koi", "language:kpv", "language:krl", "language:la", "language:lt", "language:lv", "language:lzh", "language:mdf", "language:mr", "language:mt", "language:myu", "language:myv", "language:nl", "language:no", "language:nyq", "language:olo", "language:orv", "language:otk", "language:pcm", "language:pl", "language:pt", "language:ro", "language:ru", "language:sa", "language:sk", "language:sl", "language:sme", "language:sms", "language:soj", "language:sq", "language:sr", "language:sv", "language:swl", "language:ta", "language:te", "language:th", "language:tl", "language:tpn", "language:tr", "language:ug", "language:uk", "language:ur", "language:vi", "language:wbp", "language:wo", "language:yo", "language:yue", "language:zh", "license:unknown", "constituency-parsing", "dependency-parsing", "region:us"], "private": false, "author": null, "description": "Universal Dependencies is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective. The annotation scheme is based on (universal) Stanford dependencies (de Marneffe et al., 2006, 2008, 2014), Google universal part-of-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tagsets (Zeman, 2008).", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fed", "disabled": false, "gated": false, "likes": 14, "downloads": 28469, "paperswithcode_id": "universal-dependencies", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "universal_morphologies", "sha": "20d4829303a5b853db00a3b82116fcdc1ff3d070", "lastModified": "2023-06-08T09:28:28.000Z", "tags": ["task_categories:token-classification", "task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "size_categories:n<1K", "source_datasets:original", "language:ady", "language:ang", "language:ar", "language:arn", "language:ast", "language:az", "language:ba", "language:be", "language:bg", "language:bn", "language:bo", "language:br", "language:ca", "language:ckb", "language:crh", "language:cs", "language:csb", "language:cu", "language:cy", "language:da", "language:de", "language:dsb", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fo", "language:fr", "language:frm", "language:fro", "language:frr", "language:fur", "language:fy", "language:ga", "language:gal", "language:gd", "language:gmh", "language:gml", "language:got", "language:grc", "language:gv", "language:hai", "language:he", "language:hi", "language:hu", "language:hy", "language:is", "language:it", "language:izh", "language:ka", "language:kbd", "language:kjh", "language:kk", "language:kl", "language:klr", "language:kmr", "language:kn", "language:krl", "language:kw", "language:la", "language:liv", "language:lld", "language:lt", "language:lud", "language:lv", "language:mk", "language:mt", "language:mwf", "language:nap", "language:nb", "language:nds", "language:nl", "language:nn", "language:nv", "language:oc", "language:olo", "language:osx", "language:pl", "language:ps", "language:pt", "language:qu", "language:ro", "language:ru", "language:sa", "language:sga", "language:sh", "language:sl", "language:sme", "language:sq", "language:sv", "language:swc", "language:syc", "language:te", "language:tg", "language:tk", "language:tr", "language:tt", "language:uk", "language:ur", "language:uz", "language:vec", "language:vep", "language:vot", "language:xcl", "language:xno", "language:yi", "language:zu", "license:cc-by-sa-3.0", "morphology", "region:us"], "private": false, "author": null, "description": "The Universal Morphology (UniMorph) project is a collaborative effort to improve how NLP handles complex morphology in the world\u2019s languages.\nThe goal of UniMorph is to annotate morphological data in a universal schema that allows an inflected word from any language to be defined by its lexical meaning,\ntypically carried by the lemma, and by a rendering of its inflectional form in terms of a bundle of morphological features from our schema.\nThe specification of the schema is described in Sylak-Glassman (2016).", "citation": "@article{sylak2016composition,\n  title={The composition and use of the universal morphological feature schema (unimorph schema)},\n  author={Sylak-Glassman, John},\n  journal={Johns Hopkins University},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fee", "disabled": false, "gated": false, "likes": 14, "downloads": 15267, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "urdu_fake_news", "sha": "ba316146ca94bb358a0db7c77bf62e93f8a7765f", "lastModified": "2023-01-25T15:01:58.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:ur", "license:unknown", "region:us"], "private": false, "author": null, "description": "Urdu fake news datasets that contain news of 5 different news domains.\nThese domains are Sports, Health, Technology, Entertainment, and Business.\nThe real news are collected by combining manual approaches.", "citation": "@article{MaazUrdufake2020,\nauthor = {Amjad, Maaz and Sidorov, Grigori and Zhila, Alisa and  G\u2019{o}mez-Adorno, Helena and Voronkov, Ilia  and Gelbukh, Alexander},\ntitle = {Bend the Truth: A Benchmark Dataset for Fake News Detection in Urdu and Its Evaluation},\njournal={Journal of Intelligent & Fuzzy Systems},\nvolume={39},\nnumber={2},\npages={2457-2469},\ndoi = {10.3233/JIFS-179905},\nyear={2020},\npublisher={IOS Press}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fef", "disabled": false, "gated": false, "likes": 0, "downloads": 304, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "urdu_sentiment_corpus", "sha": "0291ae46a28ea6b84a9f258d0c70356134c2f596", "lastModified": "2023-01-25T15:02:01.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ur", "license:unknown", "region:us"], "private": false, "author": null, "description": "\u201cUrdu Sentiment Corpus\u201d (USC) shares the dat of Urdu tweets for the sentiment analysis and polarity detection.\nThe dataset is consisting of tweets and overall, the dataset is comprising over 17, 185 tokens\nwith 52% records as positive, and 48 % records as negative.", "citation": "@inproceedings{khan2020usc,\n  title={Urdu Sentiment Corpus (v1.0): Linguistic Exploration and Visualization of Labeled Datasetfor Urdu Sentiment Analysis.},\n  author={Khan, Muhammad Yaseen and Nizami, Muhammad Suffian},\n  booktitle={2020 IEEE 2nd International Conference On Information Science & Communication Technology (ICISCT)},\n  pages={},\n  year={2020},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff0", "disabled": false, "gated": false, "likes": 1, "downloads": 285, "paperswithcode_id": "urdu-sentiment-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "vctk", "sha": "bb50fbe0ac4a39c7837dd613a6a6acd8e501b419", "lastModified": "2023-11-23T14:05:24.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "task_categories:text-to-audio", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "The CSTR VCTK Corpus includes speech data uttered by 110 English speakers with various accents.", "citation": "@inproceedings{Veaux2017CSTRVC,\n    title        = {CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit},\n    author       = {Christophe Veaux and Junichi Yamagishi and Kirsten MacDonald},\n    year         = 2017\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff1", "disabled": false, "gated": false, "likes": 9, "downloads": 354, "paperswithcode_id": "vctk", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "vivos", "sha": "3cbfb2502e5e84776b4b778b020a09759f723f52", "lastModified": "2023-06-14T08:29:21.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:vi", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": null, "description": "\\\r\nVIVOS is a free Vietnamese speech corpus consisting of 15 hours of recording speech prepared for\r\nVietnamese Automatic Speech Recognition task.\r\nThe corpus was prepared by AILAB, a computer science lab of VNUHCM - University of Science, with Prof. Vu Hai Quan is the head of.\r\nWe publish this corpus in hope to attract more scientists to solve Vietnamese speech recognition problems.", "citation": "\\\r\n@inproceedings{luong-vu-2016-non,\r\n    title = \"A non-expert {K}aldi recipe for {V}ietnamese Speech Recognition System\",\r\n    author = \"Luong, Hieu-Thi  and\r\n      Vu, Hai-Quan\",\r\n    booktitle = \"Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016)\",\r\n    month = dec,\r\n    year = \"2016\",\r\n    address = \"Osaka, Japan\",\r\n    publisher = \"The COLING 2016 Organizing Committee\",\r\n    url = \"https://aclanthology.org/W16-5207\",\r\n    pages = \"51--55\",\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff2", "disabled": false, "gated": false, "likes": 5, "downloads": 581, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "web_nlg", "sha": "ba4405a1091c767bfcb0f4c28474429db5f1851d", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:tabular-to-text", "task_ids:rdf-to-text", "annotations_creators:found", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-db_pedia", "source_datasets:original", "language:en", "language:ru", "license:cc-by-sa-3.0", "license:cc-by-nc-sa-4.0", "license:gfdl", "region:us"], "private": false, "author": null, "description": "The WebNLG challenge consists in mapping data to text. The training data consists\nof Data/Text pairs where the data is a set of triples extracted from DBpedia and the text is a verbalisation\nof these triples. For instance, given the 3 DBpedia triples shown in (a), the aim is to generate a text such as (b).\n\na. (John_E_Blaha birthDate 1942_08_26) (John_E_Blaha birthPlace San_Antonio) (John_E_Blaha occupation Fighter_pilot)\nb. John E Blaha, born in San Antonio on 1942-08-26, worked as a fighter pilot\n\nAs the example illustrates, the task involves specific NLG subtasks such as sentence segmentation\n(how to chunk the input data into sentences), lexicalisation (of the DBpedia properties),\naggregation (how to avoid repetitions) and surface realisation\n(how to build a syntactically correct and natural sounding text).", "citation": "@inproceedings{web_nlg,\n  author    = {Claire Gardent and\n               Anastasia Shimorina and\n               Shashi Narayan and\n               Laura Perez{-}Beltrachini},\n  editor    = {Regina Barzilay and\n               Min{-}Yen Kan},\n  title     = {Creating Training Corpora for {NLG} Micro-Planners},\n  booktitle = {Proceedings of the 55th Annual Meeting of the\n               Association for Computational Linguistics,\n               {ACL} 2017, Vancouver, Canada, July 30 - August 4,\n               Volume 1: Long Papers},\n  pages     = {179--188},\n  publisher = {Association for Computational Linguistics},\n  year      = {2017},\n  url       = {https://doi.org/10.18653/v1/P17-1017},\n  doi       = {10.18653/v1/P17-1017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff3", "disabled": false, "gated": false, "likes": 14, "downloads": 8220, "paperswithcode_id": "webnlg", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "web_of_science", "sha": "8928966f84c2d531c09c52f9e22578c1162f2041", "lastModified": "2023-04-05T13:42:58.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "The Web Of Science (WOS) dataset is a collection of data  of published papers\navailable from the Web of Science. WOS has been released in three versions: WOS-46985, WOS-11967 and WOS-5736. WOS-46985 is the\nfull dataset. WOS-11967 and WOS-5736 are two subsets of WOS-46985.", "citation": "@inproceedings{kowsari2017HDLTex,\ntitle={HDLTex: Hierarchical Deep Learning for Text Classification},\nauthor={Kowsari, Kamran and Brown, Donald E and Heidarysafa, Mojtaba and Jafari Meimandi, Kiana and and Gerber, Matthew S and Barnes, Laura E},\nbooktitle={Machine Learning and Applications (ICMLA), 2017 16th IEEE International Conference on},\nyear={2017},\norganization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff4", "disabled": false, "gated": false, "likes": 3, "downloads": 699, "paperswithcode_id": "web-of-science-dataset", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "web_questions", "sha": "9ee1d599148668b092b3715e58451f139688dfd1", "lastModified": "2023-04-05T13:43:02.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "This dataset consists of 6,642 question/answer pairs.\nThe questions are supposed to be answerable by Freebase, a large knowledge graph.\nThe questions are mostly centered around a single named entity.\nThe questions are popular ones asked on the web (at least in 2013).", "citation": "@inproceedings{berant-etal-2013-semantic,\n    title = \"Semantic Parsing on {F}reebase from Question-Answer Pairs\",\n    author = \"Berant, Jonathan  and\n      Chou, Andrew  and\n      Frostig, Roy  and\n      Liang, Percy\",\n    booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct,\n    year = \"2013\",\n    address = \"Seattle, Washington, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D13-1160\",\n    pages = \"1533--1544\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff5", "disabled": false, "gated": false, "likes": 15, "downloads": 39155, "paperswithcode_id": "webquestions", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "weibo_ner", "sha": "4cef8e84e1a5f61d0437ecb473b1a91c40b674ef", "lastModified": "2023-01-25T15:02:04.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "Tags: PER(\u4eba\u540d), LOC(\u5730\u70b9\u540d), GPE(\u884c\u653f\u533a\u540d), ORG(\u673a\u6784\u540d)\nLabel\tTag\tMeaning\nPER\tPER.NAM\t\u540d\u5b57\uff08\u5f20\u4e09\uff09\nPER.NOM\t\u4ee3\u79f0\u3001\u7c7b\u522b\u540d\uff08\u7a77\u4eba\uff09\nLOC\tLOC.NAM\t\u7279\u6307\u540d\u79f0\uff08\u7d2b\u7389\u5c71\u5e84\uff09\nLOC.NOM\t\u6cdb\u79f0\uff08\u5927\u5ce1\u8c37\u3001\u5bbe\u9986\uff09\nGPE\tGPE.NAM\t\u884c\u653f\u533a\u7684\u540d\u79f0\uff08\u5317\u4eac\uff09\nORG\tORG.NAM\t\u7279\u5b9a\u673a\u6784\u540d\u79f0\uff08\u901a\u60e0\u533b\u9662\uff09\nORG.NOM\t\u6cdb\u6307\u540d\u79f0\u3001\u7edf\u79f0\uff08\u6587\u827a\u516c\u53f8\uff09", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff6", "disabled": false, "gated": false, "likes": 6, "downloads": 326, "paperswithcode_id": "weibo-ner", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wi_locness", "sha": "b2c355af423ed63043a1ecded46348910c29029a", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "multilinguality:other-language-learner", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "grammatical-error-correction", "region:us"], "private": false, "author": null, "description": "Write & Improve (Yannakoudakis et al., 2018) is an online web platform that assists non-native\nEnglish students with their writing. Specifically, students from around the world submit letters,\nstories, articles and essays in response to various prompts, and the W&I system provides instant\nfeedback. Since W&I went live in 2014, W&I annotators have manually annotated some of these\nsubmissions and assigned them a CEFR level.", "citation": "@inproceedings{bryant-etal-2019-bea,\n    title = \"The {BEA}-2019 Shared Task on Grammatical Error Correction\",\n    author = \"Bryant, Christopher  and\n        Felice, Mariano  and\n        Andersen, {\\\\O}istein E.  and\n        Briscoe, Ted\",\n    booktitle = \"Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications\",\n    month = aug,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/W19-4406\",\n    doi = \"10.18653/v1/W19-4406\",\n    pages = \"52--75\",\n    abstract = \"This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC). As with the CoNLL-2014 shared task, participants are required to correct all types of errors in test data. One of the main contributions of the BEA-2019 shared task is the introduction of a new dataset, the Write{\\\\&}Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities. Another contribution is the introduction of tracks, which control the amount of annotated data available to participants. Systems are evaluated in terms of ERRANT F{\\\\_}0.5, which allows us to report a much wider range of performance statistics. The competition was hosted on Codalab and remains open for further submissions on the blind test set.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff7", "disabled": false, "gated": false, "likes": 7, "downloads": 536, "paperswithcode_id": "locness-corpus", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wider_face", "sha": "4260d38b0259afacef5166a56fcf94345e66241c", "lastModified": "2023-01-25T15:02:08.000Z", "tags": ["task_categories:object-detection", "task_ids:face-detection", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-wider", "language:en", "license:cc-by-nc-nd-4.0", "arxiv:1511.06523", "region:us"], "private": false, "author": null, "description": "WIDER FACE dataset is a face detection benchmark dataset, of which images are\nselected from the publicly available WIDER dataset. We choose 32,203 images and\nlabel 393,703 faces with a high degree of variability in scale, pose and\nocclusion as depicted in the sample images. WIDER FACE dataset is organized\nbased on 61 event classes. For each event class, we randomly select 40%/10%/50%\ndata as training, validation and testing sets. We adopt the same evaluation\nmetric employed in the PASCAL VOC dataset. Similar to MALF and Caltech datasets,\nwe do not release bounding box ground truth for the test images. Users are\nrequired to submit final prediction files, which we shall proceed to evaluate.", "citation": "@inproceedings{yang2016wider,\n    Author = {Yang, Shuo and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},\n    Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n    Title = {WIDER FACE: A Face Detection Benchmark},\n    Year = {2016}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff8", "disabled": false, "gated": false, "likes": 15, "downloads": 669, "paperswithcode_id": "wider-face-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki40b", "sha": "11251230da18df3301dee2de415cd00714d310ca", "lastModified": "2023-04-05T13:43:07.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "Clean-up text for 40+ Wikipedia languages editions of pages\ncorrespond to entities. The datasets have train/dev/test splits per language.\nThe dataset is cleaned up by page filtering to remove disambiguation pages,\nredirect pages, deleted pages, and non-entity pages. Each example contains the\nwikidata id of the entity, and the full Wikipedia article after page processing\nthat removes non-content sections and structured objects.", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ff9", "disabled": false, "gated": false, "likes": 9, "downloads": 7104, "paperswithcode_id": "wiki-40b", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_asp", "sha": "8acc6756e0de17a62c51b0fa0d20160d75fe44ce", "lastModified": "2022-11-18T21:59:51.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "aspect-based-summarization", "arxiv:2011.07832", "region:us"], "private": false, "author": null, "description": "WikiAsp is a multi-domain, aspect-based summarization dataset in the encyclopedic\ndomain. In this task, models are asked to summarize cited reference documents of a\nWikipedia article into aspect-based summaries. Each of the 20 domains include 10\ndomain-specific pre-defined aspects.", "citation": "@article{hayashi20tacl,\n  title   = {WikiAsp: A Dataset for Multi-domain Aspect-based Summarization},\n  authors = {Hiroaki Hayashi and Prashant Budania and Peng Wang and Chris Ackerson and Raj Neervannan and Graham Neubig},\n  journal = {Transactions of the Association for Computational Linguistics (TACL)},\n  year    = {2020},\n  url     = {https://arxiv.org/abs/2011.07832}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ffa", "disabled": false, "gated": false, "likes": 3, "downloads": 2905, "paperswithcode_id": "wikiasp", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_atomic_edits", "sha": "d7d2395cd1de18f7faea67da8d65a960387f92d6", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:ja", "language:ru", "language:zh", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": null, "description": "A dataset of atomic wikipedia edits containing insertions and deletions of a contiguous chunk of text in a sentence. This dataset contains ~43 million edits across 8 languages.\n\nAn atomic edit is defined as an edit e applied to a natural language expression S as the insertion, deletion, or substitution of a sub-expression P such that both the original expression S and the resulting expression e(S) are well-formed semantic constituents (MacCartney, 2009). In this corpus, we release such atomic insertions and deletions made to sentences in wikipedia.", "citation": "@InProceedings{WikiAtomicEdits,\n  title = {{WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse}},\n  author = {Faruqui, Manaal and Pavlick, Ellie and Tenney, Ian and Das, Dipanjan},\n  booktitle = {Proc. of EMNLP},\n  year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ffb", "disabled": false, "gated": false, "likes": 10, "downloads": 2430, "paperswithcode_id": "wikiatomicedits", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_auto", "sha": "2b51c81bbfaef52bc66e9727d01fc006b3df86f3", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other-wikipedia", "language:en", "license:cc-by-sa-3.0", "arxiv:2005.02324", "region:us"], "private": false, "author": null, "description": "WikiAuto provides a set of aligned sentences from English Wikipedia and Simple English Wikipedia\nas a resource to train sentence simplification systems. The authors first crowd-sourced a set of manual alignments\nbetween sentences in a subset of the Simple English Wikipedia and their corresponding versions in English Wikipedia\n(this corresponds to the `manual` config), then trained a neural CRF system to predict these alignments.\nThe trained model was then applied to the other articles in Simple English Wikipedia with an English counterpart to\ncreate a larger corpus of aligned sentences (corresponding to the `auto`, `auto_acl`, `auto_full_no_split`, and `auto_full_with_split`  configs here).", "citation": "@inproceedings{acl/JiangMLZX20,\n  author    = {Chao Jiang and\n               Mounica Maddela and\n               Wuwei Lan and\n               Yang Zhong and\n               Wei Xu},\n  editor    = {Dan Jurafsky and\n               Joyce Chai and\n               Natalie Schluter and\n               Joel R. Tetreault},\n  title     = {Neural {CRF} Model for Sentence Alignment in Text Simplification},\n  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational\n               Linguistics, {ACL} 2020, Online, July 5-10, 2020},\n  pages     = {7943--7960},\n  publisher = {Association for Computational Linguistics},\n  year      = {2020},\n  url       = {https://www.aclweb.org/anthology/2020.acl-main.709/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ffc", "disabled": false, "gated": false, "likes": 7, "downloads": 955, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_bio", "sha": "78d8f38167e7c497ba71c2b76322763691dcd0b3", "lastModified": "2022-11-18T22:00:08.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "arxiv:1603.07771", "region:us"], "private": false, "author": null, "description": "This dataset gathers 728,321 biographies from wikipedia. It aims at evaluating text generation\nalgorithms. For each article, we provide the first paragraph and the infobox (both tokenized).\nFor each article, we extracted the first paragraph (text), the infobox (structured data). Each\ninfobox is encoded as a list of (field name, field value) pairs. We used Stanford CoreNLP\n(http://stanfordnlp.github.io/CoreNLP/) to preprocess the data, i.e. we broke the text into\nsentences and tokenized both the text and the field values. The dataset was randomly split in\nthree subsets train (80%), valid (10%), test (10%).", "citation": "@article{DBLP:journals/corr/LebretGA16,\n  author    = {R{\\'{e}}mi Lebret and\n               David Grangier and\n               Michael Auli},\n  title     = {Generating Text from Structured Data with Application to the Biography\n               Domain},\n  journal   = {CoRR},\n  volume    = {abs/1603.07771},\n  year      = {2016},\n  url       = {http://arxiv.org/abs/1603.07771},\n  archivePrefix = {arXiv},\n  eprint    = {1603.07771},\n  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/LebretGA16.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ffd", "disabled": false, "gated": false, "likes": 14, "downloads": 2280, "paperswithcode_id": "wikibio", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_dpr", "sha": "caf027cbb8740cae558cacb7e926fd5202f50f83", "lastModified": "2023-04-05T13:43:12.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "license:gfdl", "text-search", "arxiv:2004.04906", "region:us"], "private": false, "author": null, "description": "This is the wikipedia split used to evaluate the Dense Passage Retrieval (DPR) model.\nIt contains 21M passages from wikipedia along with their DPR embeddings.\nThe wikipedia articles were split into multiple, disjoint text blocks of 100 words as passages.", "citation": "@misc{karpukhin2020dense,\n    title={Dense Passage Retrieval for Open-Domain Question Answering},\n    author={Vladimir Karpukhin and Barlas O\u011fuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},\n    year={2020},\n    eprint={2004.04906},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181ffe", "disabled": false, "gated": false, "likes": 19, "downloads": 9640, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_hop", "sha": "08050e62000fa615cea79e1da8828c827e0fdce0", "lastModified": "2022-11-03T16:47:35.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "multi-hop", "arxiv:1710.06481", "region:us"], "private": false, "author": null, "description": "WikiHop is open-domain and based on Wikipedia articles; the goal is to recover Wikidata information by hopping through documents. The goal is to answer text understanding queries by combining multiple facts that are spread across different documents.", "citation": "@misc{welbl2018constructing,\n      title={Constructing Datasets for Multi-hop Reading Comprehension Across Documents},\n      author={Johannes Welbl and Pontus Stenetorp and Sebastian Riedel},\n      year={2018},\n      eprint={1710.06481},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f181fff", "disabled": false, "gated": false, "likes": 1, "downloads": 2930, "paperswithcode_id": "wikihop", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_lingua", "sha": "700647c975386e82e711d45ee801d9385af000b1", "lastModified": "2023-06-16T14:39:41.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "language:cs", "language:de", "language:en", "language:es", "language:fr", "language:hi", "language:id", "language:it", "language:ja", "language:ko", "language:nl", "language:pt", "language:ru", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-3.0", "arxiv:2010.03093", "region:us"], "private": false, "author": null, "description": "WikiLingua is a large-scale multilingual dataset for the evaluation of\ncross-lingual abstractive summarization systems. The dataset includes ~770k\narticle and summary pairs in 18 languages from WikiHow. The gold-standard\narticle-summary alignments across languages was done by aligning the images\nthat are used to describe each how-to step in an article.", "citation": "@inproceedings{ladhak-etal-2020-wikilingua,\n    title = \"{W}iki{L}ingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization\",\n    author = \"Ladhak, Faisal  and\n      Durmus, Esin  and\n      Cardie, Claire  and\n      McKeown, Kathleen\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.findings-emnlp.360\",\n    doi = \"10.18653/v1/2020.findings-emnlp.360\",\n    pages = \"4034--4048\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182000", "disabled": false, "gated": false, "likes": 29, "downloads": 11521, "paperswithcode_id": "wikilingua", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_movies", "sha": "f50e01dce46b553e01d2db64a4aac1271af141ce", "lastModified": "2022-11-18T22:00:27.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-3.0", "arxiv:1606.03126", "region:us"], "private": false, "author": null, "description": "The WikiMovies dataset consists of roughly 100k (templated) questions over 75k entities based on questions with answers in the open movie database (OMDb).", "citation": "@misc{miller2016keyvalue,\n      title={Key-Value Memory Networks for Directly Reading Documents},\n      author={Alexander Miller and Adam Fisch and Jesse Dodge and Amir-Hossein Karimi and Antoine Bordes and Jason Weston},\n      year={2016},\n      eprint={1606.03126},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182001", "disabled": false, "gated": false, "likes": 4, "downloads": 330, "paperswithcode_id": "wikimovies", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_qa", "sha": "4cdcefa3617bf52a562b1c423fd992859b031ee4", "lastModified": "2023-04-05T13:43:16.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Wiki Question Answering corpus from Microsoft", "citation": "@InProceedings{YangYihMeek:EMNLP2015:WikiQA,\n       author = {{Yi}, Yang and {Wen-tau},  Yih and {Christopher} Meek},\n        title = \"{WikiQA: A Challenge Dataset for Open-Domain Question Answering}\",\n      journal = {Association for Computational Linguistics},\n         year = 2015,\n          doi = {10.18653/v1/D15-1237},\n        pages = {2013\u20132018},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182002", "disabled": false, "gated": false, "likes": 17, "downloads": 33127, "paperswithcode_id": "wikiqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_qa_ar", "sha": "90f1673b95f7ca68ffc7d8bd1451f8e304819f49", "lastModified": "2023-01-25T15:02:18.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "license:unknown", "region:us"], "private": false, "author": null, "description": "Arabic Version of WikiQA by automatic automatic machine translators and crowdsourced the selection of the best one to be incorporated into the corpus", "citation": "@InProceedings{YangYihMeek:EMNLP2015:WikiQA,\n       author = {{Yi}, Yang and {Wen-tau},  Yih and {Christopher} Meek},\n        title = \"{WikiQA: A Challenge Dataset for Open-Domain Question Answering}\",\n      journal = {Association for Computational Linguistics},\n         year = 2015,\n          doi = {10.18653/v1/D15-1237},\n        pages = {2013\u20132018},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182003", "disabled": false, "gated": false, "likes": 2, "downloads": 311, "paperswithcode_id": "wikiqaar", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_snippets", "sha": "f24024a6c4677ce83b8e48d72ebe46edd211d26f", "lastModified": "2023-04-05T13:43:20.000Z", "tags": ["task_categories:text-generation", "task_categories:other", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:extended|wiki40b", "source_datasets:extended|wikipedia", "language:en", "license:unknown", "text-search", "region:us"], "private": false, "author": null, "description": "Wikipedia version split into plain text snippets for dense semantic indexing.", "citation": "@ONLINE {wikidump,\n    author = {Wikimedia Foundation},\n    title  = {Wikimedia Downloads},\n    url    = {https://dumps.wikimedia.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182004", "disabled": false, "gated": false, "likes": 0, "downloads": 875, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_source", "sha": "ed3c7ab60f400e36c1f4699ca194229557c710dd", "lastModified": "2022-11-03T16:07:54.000Z", "tags": ["task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:sv", "license:unknown", "region:us"], "private": false, "author": null, "description": "2 languages, total number of files: 132\ntotal number of tokens: 1.80M\ntotal number of sentence fragments: 78.36k", "citation": "@InProceedings{TIEDEMANN12.463,\n  author = {J{\\\"o}rg Tiedemann},\n  title = {Parallel Data, Tools and Interfaces in OPUS},\n  booktitle = {Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12)},\n  year = {2012},\n  month = {may},\n  date = {23-25},\n  address = {Istanbul, Turkey},\n  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {978-2-9517408-7-7},\n  language = {english}\n }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182005", "disabled": false, "gated": false, "likes": 0, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_split", "sha": "2cdf4fe1d512ee12911e9a0afc02a5ac8cb13635", "lastModified": "2023-04-05T13:43:23.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "split-and-rephrase", "arxiv:1808.09468", "region:us"], "private": false, "author": null, "description": "One million English sentences, each split into two sentences that together preserve the original meaning, extracted from Wikipedia\nGoogle's WikiSplit dataset was constructed automatically from the publicly available Wikipedia revision history. Although\nthe dataset contains some inherent noise, it can serve as valuable training data for models that split or merge sentences.", "citation": "@InProceedings{BothaEtAl2018,\n  title = {{Learning To Split and Rephrase From Wikipedia Edit History}},\n  author = {Botha, Jan A and Faruqui, Manaal and Alex, John and Baldridge, Jason and Das, Dipanjan},\n  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},\n  pages = {to appear},\n  note = {arXiv preprint arXiv:1808.09468},\n  year = {2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182006", "disabled": false, "gated": false, "likes": 3, "downloads": 469, "paperswithcode_id": "wikisplit", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiki_summary", "sha": "9ff0f3a6cdddae09887aa54ff6e1879c4664afde", "lastModified": "2022-11-18T22:00:55.000Z", "tags": ["task_categories:text2text-generation", "task_categories:translation", "task_categories:question-answering", "task_categories:summarization", "task_ids:abstractive-qa", "task_ids:explanation-generation", "task_ids:extractive-qa", "task_ids:open-domain-qa", "task_ids:open-domain-abstractive-qa", "task_ids:text-simplification", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fa", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "\\\r\nThe dataset extracted from Persian Wikipedia into the form of articles and highlights and cleaned the dataset into pairs of articles and highlights and reduced the articles' length (only version 1.0.0) and highlights' length to a maximum of 512 and 128, respectively, suitable for parsBERT.", "citation": "\\\r\n@misc{Bert2BertWikiSummaryPersian,\r\n  author = {Mehrdad Farahani},\r\n  title = {Summarization using Bert2Bert model on WikiSummary dataset},\r\n  year = {2020},\r\n  publisher = {GitHub},\r\n  journal = {GitHub repository},\r\n  howpublished = {https://github.com/m3hrdadfi/wiki-summary},\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182007", "disabled": false, "gated": false, "likes": 6, "downloads": 414, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikiann", "sha": "dc3daffcf9b8ec42a91ae90876a07cd6fc110312", "lastModified": "2023-06-01T14:59:59.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:ace", "language:af", "language:als", "language:am", "language:an", "language:ang", "language:ar", "language:arc", "language:arz", "language:as", "language:ast", "language:ay", "language:az", "language:ba", "language:bar", "language:be", "language:bg", "language:bh", "language:bn", "language:bo", "language:br", "language:bs", "language:ca", "language:cbk", "language:cdo", "language:ce", "language:ceb", "language:ckb", "language:co", "language:crh", "language:cs", "language:csb", "language:cv", "language:cy", "language:da", "language:de", "language:diq", "language:dv", "language:el", "language:eml", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:ext", "language:fa", "language:fi", "language:fo", "language:fr", "language:frr", "language:fur", "language:fy", "language:ga", "language:gan", "language:gd", "language:gl", "language:gn", "language:gu", "language:hak", "language:he", "language:hi", "language:hr", "language:hsb", "language:hu", "language:hy", "language:ia", "language:id", "language:ig", "language:ilo", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ksh", "language:ku", "language:ky", "language:la", "language:lb", "language:li", "language:lij", "language:lmo", "language:ln", "language:lt", "language:lv", "language:lzh", "language:mg", "language:mhr", "language:mi", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:mwl", "language:my", "language:mzn", "language:nan", "language:nap", "language:nds", "language:ne", "language:nl", "language:nn", "language:no", "language:nov", "language:oc", "language:or", "language:os", "language:pa", "language:pdc", "language:pl", "language:pms", "language:pnb", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:ru", "language:rw", "language:sa", "language:sah", "language:scn", "language:sco", "language:sd", "language:sgs", "language:sh", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:su", "language:sv", "language:sw", "language:szl", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tl", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:vec", "language:vep", "language:vi", "language:vls", "language:vo", "language:vro", "language:wa", "language:war", "language:wuu", "language:xmf", "language:yi", "language:yo", "language:yue", "language:zea", "language:zh", "license:unknown", "arxiv:1902.00193", "region:us"], "private": false, "author": null, "description": "WikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles annotated with LOC (location), PER (person), and ORG (organisation) tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of Rahimi et al. (2019), which supports 176 of the 282 languages from the original WikiANN corpus.", "citation": "@inproceedings{pan-etal-2017-cross,\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\n    author = \"Pan, Xiaoman  and\n      Zhang, Boliang  and\n      May, Jonathan  and\n      Nothman, Joel  and\n      Knight, Kevin  and\n      Ji, Heng\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\n    doi = \"10.18653/v1/P17-1178\",\n    pages = \"1946--1958\",\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of new KB mining methods: generating {``}silver-standard{''} annotations by transferring annotations from English to other languages through cross-lingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from cross-lingual links. Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182008", "disabled": false, "gated": false, "likes": 63, "downloads": 37175, "paperswithcode_id": "wikiann-1", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikicorpus", "sha": "4a83cabd0f0e6eefebddf8627b3113f2fdaaf89b", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-classification", "task_categories:text-generation", "task_categories:token-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "task_ids:part-of-speech", "annotations_creators:machine-generated", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10M<n<100M", "size_categories:1M<n<10M", "source_datasets:original", "language:ca", "language:en", "language:es", "license:gfdl", "word-sense-disambiguation", "lemmatization", "region:us"], "private": false, "author": null, "description": "The Wikicorpus is a trilingual corpus (Catalan, Spanish, English) that contains large portions of the Wikipedia (based on a 2006 dump) and has been automatically enriched with linguistic information. In its present version, it contains over 750 million words.", "citation": "@inproceedings{reese-etal-2010-wikicorpus,\n    title = \"{W}ikicorpus: A Word-Sense Disambiguated Multilingual {W}ikipedia Corpus\",\n    author = \"Reese, Samuel  and\n      Boleda, Gemma  and\n      Cuadros, Montse  and\n      Padr{\\'o}, Llu{\\'i}s  and\n      Rigau, German\",\n    booktitle = \"Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)\",\n    month = may,\n    year = \"2010\",\n    address = \"Valletta, Malta\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"http://www.lrec-conf.org/proceedings/lrec2010/pdf/222_Paper.pdf\",\n    abstract = \"This article presents a new freely available trilingual corpus (Catalan, Spanish, English) that contains large portions of the Wikipedia and has been automatically enriched with linguistic information. To our knowledge, this is the largest such corpus that is freely available to the community: In its present version, it contains over 750 million words. The corpora have been annotated with lemma and part of speech information using the open source library FreeLing. Also, they have been sense annotated with the state of the art Word Sense Disambiguation algorithm UKB. As UKB assigns WordNet senses, and WordNet has been aligned across languages via the InterLingual Index, this sort of annotation opens the way to massive explorations in lexical semantics that were not possible before. We present a first attempt at creating a trilingual lexical resource from the sense-tagged Wikipedia corpora, namely, WikiNet. Moreover, we present two by-products of the project that are of use for the NLP community: An open source Java-based parser for Wikipedia pages developed for the construction of the corpus, and the integration of the WSD algorithm UKB in FreeLing.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182009", "disabled": false, "gated": false, "likes": 5, "downloads": 1295, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikihow", "sha": "68115f58ceb7af01a452017567ca9ca964467bcf", "lastModified": "2022-11-18T22:01:14.000Z", "tags": ["region:us"], "private": false, "author": null, "description": "WikiHow is a new large-scale dataset using the online WikiHow\n(http://www.wikihow.com/) knowledge base.\n\nThere are two features:\n  - text: wikihow answers texts.\n  - headline: bold lines as summary.\n\nThere are two separate versions:\n  - all: consisting of the concatenation of all paragraphs as the articles and\n         the bold lines as the reference summaries.\n  - sep: consisting of each paragraph and its summary.\n\nDownload \"wikihowAll.csv\" and \"wikihowSep.csv\" from\nhttps://github.com/mahnazkoupaee/WikiHow-Dataset and place them in manual folder\nhttps://www.tensorflow.org/datasets/api_docs/python/tfds/download/DownloadConfig.\nTrain/validation/test splits are provided by the authors.\nPreprocessing is applied to remove short articles\n(abstract length < 0.75 article length) and clean up extra commas.", "citation": "@misc{koupaee2018wikihow,\n    title={WikiHow: A Large Scale Text Summarization Dataset},\n    author={Mahnaz Koupaee and William Yang Wang},\n    year={2018},\n    eprint={1810.09305},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200a", "disabled": false, "gated": false, "likes": 4, "downloads": 3823, "paperswithcode_id": "wikihow", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikipedia", "sha": "3a84779681ce7efad7334ba0e0c25f7336d6a912", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "source_datasets:original", "language:aa", "language:ab", "language:ace", "language:af", "language:ak", "language:als", "language:am", "language:an", "language:ang", "language:ar", "language:arc", "language:arz", "language:as", "language:ast", "language:atj", "language:av", "language:ay", "language:az", "language:azb", "language:ba", "language:bar", "language:bcl", "language:be", "language:bg", "language:bh", "language:bi", "language:bjn", "language:bm", "language:bn", "language:bo", "language:bpy", "language:br", "language:bs", "language:bug", "language:bxr", "language:ca", "language:cbk", "language:cdo", "language:ce", "language:ceb", "language:ch", "language:cho", "language:chr", "language:chy", "language:ckb", "language:co", "language:cr", "language:crh", "language:cs", "language:csb", "language:cu", "language:cv", "language:cy", "language:da", "language:de", "language:din", "language:diq", "language:dsb", "language:dty", "language:dv", "language:dz", "language:ee", "language:el", "language:eml", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:ext", "language:fa", "language:ff", "language:fi", "language:fj", "language:fo", "language:fr", "language:frp", "language:frr", "language:fur", "language:fy", "language:ga", "language:gag", "language:gan", "language:gd", "language:gl", "language:glk", "language:gn", "language:gom", "language:gor", "language:got", "language:gu", "language:gv", "language:ha", "language:hak", "language:haw", "language:he", "language:hi", "language:hif", "language:ho", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:ig", "language:ii", "language:ik", "language:ilo", "language:inh", "language:io", "language:is", "language:it", "language:iu", "language:ja", "language:jam", "language:jbo", "language:jv", "language:ka", "language:kaa", "language:kab", "language:kbd", "language:kbp", "language:kg", "language:ki", "language:kj", "language:kk", "language:kl", "language:km", "language:kn", "language:ko", "language:koi", "language:krc", "language:ks", "language:ksh", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lad", "language:lb", "language:lbe", "language:lez", "language:lfn", "language:lg", "language:li", "language:lij", "language:lmo", "language:ln", "language:lo", "language:lrc", "language:lt", "language:ltg", "language:lv", "language:lzh", "language:mai", "language:mdf", "language:mg", "language:mh", "language:mhr", "language:mi", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:mrj", "language:ms", "language:mt", "language:mus", "language:mwl", "language:my", "language:myv", "language:mzn", "language:na", "language:nah", "language:nan", "language:nap", "language:nds", "language:ne", "language:new", "language:ng", "language:nl", "language:nn", "language:no", "language:nov", "language:nrf", "language:nso", "language:nv", "language:ny", "language:oc", "language:olo", "language:om", "language:or", "language:os", "language:pa", "language:pag", "language:pam", "language:pap", "language:pcd", "language:pdc", "language:pfl", "language:pi", "language:pih", "language:pl", "language:pms", "language:pnb", "language:pnt", "language:ps", "language:pt", "language:qu", "language:rm", "language:rmy", "language:rn", "language:ro", "language:ru", "language:rue", "language:rup", "language:rw", "language:sa", "language:sah", "language:sat", "language:sc", "language:scn", "language:sco", "language:sd", "language:se", "language:sg", "language:sgs", "language:sh", "language:si", "language:sk", "language:sl", "language:sm", "language:sn", "language:so", "language:sq", "language:sr", "language:srn", "language:ss", "language:st", "language:stq", "language:su", "language:sv", "language:sw", "language:szl", "language:ta", "language:tcy", "language:tdt", "language:te", "language:tg", "language:th", "language:ti", "language:tk", "language:tl", "language:tn", "language:to", "language:tpi", "language:tr", "language:ts", "language:tt", "language:tum", "language:tw", "language:ty", "language:tyv", "language:udm", "language:ug", "language:uk", "language:ur", "language:uz", "language:ve", "language:vec", "language:vep", "language:vi", "language:vls", "language:vo", "language:vro", "language:wa", "language:war", "language:wo", "language:wuu", "language:xal", "language:xh", "language:xmf", "language:yi", "language:yo", "language:yue", "language:za", "language:zea", "language:zh", "language:zu", "license:cc-by-sa-3.0", "license:gfdl", "region:us"], "private": false, "author": null, "description": "Wikipedia dataset containing cleaned articles of all languages.\nThe datasets are built from the Wikipedia dump\n(https://dumps.wikimedia.org/) with one split per language. Each example\ncontains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).", "citation": "@ONLINE {wikidump,\n    author = {Wikimedia Foundation},\n    title  = {Wikimedia Downloads},\n    url    = {https://dumps.wikimedia.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200b", "disabled": false, "gated": false, "likes": 355, "downloads": 42057, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikisql", "sha": "829510ce473d56a119a2a86ebf9875c8360fcde2", "lastModified": "2023-04-05T13:43:31.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "text-to-sql", "arxiv:1709.00103", "region:us"], "private": false, "author": null, "description": "A large crowd-sourced dataset for developing natural language interfaces for relational databases", "citation": "@article{zhongSeq2SQL2017,\n  author    = {Victor Zhong and\n               Caiming Xiong and\n               Richard Socher},\n  title     = {Seq2SQL: Generating Structured Queries from Natural Language using\n               Reinforcement Learning},\n  journal   = {CoRR},\n  volume    = {abs/1709.00103},\n  year      = {2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200c", "disabled": false, "gated": false, "likes": 60, "downloads": 3907, "paperswithcode_id": "wikisql", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikitext", "sha": "f5562967961a45407fa15044c5535a607200983f", "lastModified": "2023-06-20T07:52:10.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "license:gfdl", "arxiv:1609.07843", "region:us"], "private": false, "author": null, "description": " The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\n Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike\n License.", "citation": "@misc{merity2016pointer,\n      title={Pointer Sentinel Mixture Models},\n      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},\n      year={2016},\n      eprint={1609.07843},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200d", "disabled": false, "gated": false, "likes": 208, "downloads": 553327, "paperswithcode_id": "wikitext-2", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wikitext_tl39", "sha": "94967b92a094be4822b40540dedd17cda6892dde", "lastModified": "2022-11-03T16:15:46.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:fil", "language:tl", "license:gpl-3.0", "arxiv:1907.00409", "region:us"], "private": false, "author": null, "description": "Large scale, unlabeled text dataset with 39 Million tokens in the training set. Inspired by the original WikiText Long Term Dependency dataset (Merity et al., 2016). TL means \"Tagalog.\" Originally published in Cruz & Cheng (2019).", "citation": "@article{cruz2019evaluating,\n  title={Evaluating Language Model Finetuning Techniques for Low-resource Languages},\n  author={Cruz, Jan Christian Blaise and Cheng, Charibeth},\n  journal={arXiv preprint arXiv:1907.00409},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200e", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "paperswithcode_id": "wikitext-tl-39", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wili_2018", "sha": "4c285f8d46ef506b334b34a542c66f6f9257d27e", "lastModified": "2023-01-25T15:02:28.000Z", "tags": ["task_categories:text-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ace", "language:af", "language:als", "language:am", "language:an", "language:ang", "language:ar", "language:arz", "language:as", "language:ast", "language:av", "language:ay", "language:az", "language:azb", "language:ba", "language:bar", "language:bcl", "language:be", "language:bg", "language:bho", "language:bjn", "language:bn", "language:bo", "language:bpy", "language:br", "language:bs", "language:bxr", "language:ca", "language:cbk", "language:cdo", "language:ce", "language:ceb", "language:chr", "language:ckb", "language:co", "language:crh", "language:cs", "language:csb", "language:cv", "language:cy", "language:da", "language:de", "language:diq", "language:dsb", "language:dty", "language:dv", "language:egl", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:ext", "language:fa", "language:fi", "language:fo", "language:fr", "language:frp", "language:fur", "language:fy", "language:ga", "language:gag", "language:gd", "language:gl", "language:glk", "language:gn", "language:gu", "language:gv", "language:ha", "language:hak", "language:he", "language:hi", "language:hif", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:ig", "language:ilo", "language:io", "language:is", "language:it", "language:ja", "language:jam", "language:jbo", "language:jv", "language:ka", "language:kaa", "language:kab", "language:kbd", "language:kk", "language:km", "language:kn", "language:ko", "language:koi", "language:kok", "language:krc", "language:ksh", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lad", "language:lb", "language:lez", "language:lg", "language:li", "language:lij", "language:lmo", "language:ln", "language:lo", "language:lrc", "language:lt", "language:ltg", "language:lv", "language:lzh", "language:mai", "language:map", "language:mdf", "language:mg", "language:mhr", "language:mi", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:mrj", "language:ms", "language:mt", "language:mwl", "language:my", "language:myv", "language:mzn", "language:nan", "language:nap", "language:nb", "language:nci", "language:nds", "language:ne", "language:new", "language:nl", "language:nn", "language:nrm", "language:nso", "language:nv", "language:oc", "language:olo", "language:om", "language:or", "language:os", "language:pa", "language:pag", "language:pam", "language:pap", "language:pcd", "language:pdc", "language:pfl", "language:pl", "language:pnb", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:roa", "language:ru", "language:rue", "language:rup", "language:rw", "language:sa", "language:sah", "language:sc", "language:scn", "language:sco", "language:sd", "language:sgs", "language:sh", "language:si", "language:sk", "language:sl", "language:sme", "language:sn", "language:so", "language:sq", "language:sr", "language:srn", "language:stq", "language:su", "language:sv", "language:sw", "language:szl", "language:ta", "language:tcy", "language:te", "language:tet", "language:tg", "language:th", "language:tk", "language:tl", "language:tn", "language:to", "language:tr", "language:tt", "language:tyv", "language:udm", "language:ug", "language:uk", "language:ur", "language:uz", "language:vec", "language:vep", "language:vi", "language:vls", "language:vo", "language:vro", "language:wa", "language:war", "language:wo", "language:wuu", "language:xh", "language:xmf", "language:yi", "language:yo", "language:zea", "language:zh", "license:odbl", "language-identification", "arxiv:1801.07779", "region:us"], "private": false, "author": null, "description": "It is a benchmark dataset for language identification and contains 235000 paragraphs of 235 languages", "citation": "@dataset{thoma_martin_2018_841984,\n  author       = {Thoma, Martin},\n  title        = {{WiLI-2018 - Wikipedia Language Identification database}},\n  month        = jan,\n  year         = 2018,\n  publisher    = {Zenodo},\n  version      = {1.0.0},\n  doi          = {10.5281/zenodo.841984},\n  url          = {https://doi.org/10.5281/zenodo.841984}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18200f", "disabled": false, "gated": false, "likes": 3, "downloads": 351, "paperswithcode_id": "wili-2018", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wino_bias", "sha": "4f1647960c145806d36ee7657434af8102e465fa", "lastModified": "2023-01-25T15:02:31.000Z", "tags": ["task_categories:token-classification", "task_ids:coreference-resolution", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "arxiv:1804.06876", "region:us"], "private": false, "author": null, "description": "WinoBias, a Winograd-schema dataset for coreference resolution focused on gender bias.\nThe corpus contains Winograd-schema style sentences with entities corresponding to people\nreferred by their occupation (e.g. the nurse, the doctor, the carpenter).", "citation": "@article{DBLP:journals/corr/abs-1804-06876,\n  author    = {Jieyu Zhao and\n               Tianlu Wang and\n               Mark Yatskar and\n               Vicente Ordonez and\n               Kai{-}Wei Chang},\n  title     = {Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods},\n  journal   = {CoRR},\n  volume    = {abs/1804.06876},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1804.06876},\n  archivePrefix = {arXiv},\n  eprint    = {1804.06876},\n  timestamp = {Mon, 13 Aug 2018 16:47:01 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-06876.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182010", "disabled": false, "gated": false, "likes": 11, "downloads": 9341, "paperswithcode_id": "winobias", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "winograd_wsc", "sha": "ea5923c7e76e862df7d7283a9907e7dc49a876da", "lastModified": "2023-01-25T15:02:35.000Z", "tags": ["task_categories:multiple-choice", "task_ids:multiple-choice-coreference-resolution", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "A Winograd schema is a pair of sentences that differ in only one or two words and that contain an ambiguity that is\nresolved in opposite ways in the two sentences and requires the use of world knowledge and reasoning for its\nresolution. The schema takes its name from a well-known example by Terry Winograd:\n\n> The city councilmen refused the demonstrators a permit because they [feared/advocated] violence.\n\nIf the word is ``feared'', then ``they'' presumably refers to the city council; if it is ``advocated'' then ``they''\npresumably refers to the demonstrators.", "citation": "@inproceedings{levesque2012winograd,\n  title={The winograd schema challenge},\n  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},\n  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},\n  year={2012},\n  organization={Citeseer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182011", "disabled": false, "gated": false, "likes": 5, "downloads": 1940, "paperswithcode_id": "wsc", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "winogrande", "sha": "ca173793e6fb0a4486c21df9f105a319a6c7d42b", "lastModified": "2023-06-05T11:49:56.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "WinoGrande is a new collection of 44k problems, inspired by Winograd Schema Challenge (Levesque, Davis, and Morgenstern\n 2011), but adjusted to improve the scale and robustness against the dataset-specific bias. Formulated as a\nfill-in-a-blank task with binary options, the goal is to choose the right option for a given sentence which requires\ncommonsense reasoning.", "citation": "@InProceedings{ai2:winogrande,\ntitle = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},\nauthors={Keisuke, Sakaguchi and Ronan, Le Bras and Chandra, Bhagavatula and Yejin, Choi\n},\nyear={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182012", "disabled": false, "gated": false, "likes": 25, "downloads": 197109, "paperswithcode_id": "winogrande", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wiqa", "sha": "6a82038b5cb704d0527c7023000d3b5c28071edd", "lastModified": "2023-04-05T13:43:43.000Z", "tags": ["language:en", "region:us"], "private": false, "author": null, "description": "The WIQA dataset V1 has 39705 questions containing a perturbation and a possible effect in the context of a paragraph.\nThe dataset is split into 29808 train questions, 6894 dev questions and 3003 test questions.", "citation": "@article{wiqa,\n      author    = {Niket Tandon and Bhavana Dalvi Mishra and Keisuke Sakaguchi and Antoine Bosselut and Peter Clark}\n      title     = {WIQA: A dataset for \"What if...\" reasoning over procedural text},\n      journal   = {arXiv:1909.04739v1},\n      year      = {2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182013", "disabled": false, "gated": false, "likes": 2, "downloads": 2845, "paperswithcode_id": "wiqa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wisesight1000", "sha": "c6f339a893fddc7fcb2bda6b9dfea04843d12e3b", "lastModified": "2023-06-14T08:20:50.000Z", "tags": ["task_categories:token-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:extended|wisesight_sentiment", "language:th", "license:cc0-1.0", "word-tokenization", "region:us"], "private": false, "author": null, "description": "`wisesight1000` contains Thai social media texts randomly drawn from the full `wisesight-sentiment`, tokenized by human annotators.\nOut of the labels `neg` (negative), `neu` (neutral), `pos` (positive), `q` (question), 250 samples each. Some texts are removed because\nthey look like spam.Because these samples are representative of real world content, we believe having these annotaed samples will allow\nthe community to robustly evaluate tokenization algorithms.", "citation": "@software{bact_2019_3457447,\n  author       = {Suriyawongkul, Arthit and\n                  Chuangsuwanich, Ekapol and\n                  Chormai, Pattarawat and\n                  Polpanumas, Charin},\n  title        = {PyThaiNLP/wisesight-sentiment: First release},\n  month        = sep,\n  year         = 2019,\n  publisher    = {Zenodo},\n  version      = {v1.0},\n  doi          = {10.5281/zenodo.3457447},\n  url          = {https://doi.org/10.5281/zenodo.3457447}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182014", "disabled": false, "gated": false, "likes": 0, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wisesight_sentiment", "sha": "8830d6905b83502080b99d5a1cc16ccd67a651db", "lastModified": "2023-01-25T15:02:42.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:th", "license:cc0-1.0", "region:us"], "private": false, "author": null, "description": "Wisesight Sentiment Corpus: Social media messages in Thai language with sentiment category (positive, neutral, negative, question)\n* Released to public domain under Creative Commons Zero v1.0 Universal license.\n* Category (Labels): {\"pos\": 0, \"neu\": 1, \"neg\": 2, \"q\": 3}\n* Size: 26,737 messages\n* Language: Central Thai\n* Style: Informal and conversational. With some news headlines and advertisement.\n* Time period: Around 2016 to early 2019. With small amount from other period.\n* Domains: Mixed. Majority are consumer products and services (restaurants, cosmetics, drinks, car, hotels), with some current affairs.\n* Privacy:\n    * Only messages that made available to the public on the internet (websites, blogs, social network sites).\n    * For Facebook, this means the public comments (everyone can see) that made on a public page.\n    * Private/protected messages and messages in groups, chat, and inbox are not included.\n* Alternations and modifications:\n    * Keep in mind that this corpus does not statistically represent anything in the language register.\n    * Large amount of messages are not in their original form. Personal data are removed or masked.\n    * Duplicated, leading, and trailing whitespaces are removed. Other punctuations, symbols, and emojis are kept intact.\n    (Mis)spellings are kept intact.\n    * Messages longer than 2,000 characters are removed.\n    * Long non-Thai messages are removed. Duplicated message (exact match) are removed.\n* More characteristics of the data can be explore: https://github.com/PyThaiNLP/wisesight-sentiment/blob/master/exploration.ipynb", "citation": "@software{bact_2019_3457447,\n  author       = {Suriyawongkul, Arthit and\n                  Chuangsuwanich, Ekapol and\n                  Chormai, Pattarawat and\n                  Polpanumas, Charin},\n  title        = {PyThaiNLP/wisesight-sentiment: First release},\n  month        = sep,\n  year         = 2019,\n  publisher    = {Zenodo},\n  version      = {v1.0},\n  doi          = {10.5281/zenodo.3457447},\n  url          = {https://doi.org/10.5281/zenodo.3457447}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182015", "disabled": false, "gated": false, "likes": 6, "downloads": 973, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wmt20_mlqe_task1", "sha": "b681ea54c9900b1f968472e12604a00f3bd14327", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|reddit", "source_datasets:extended|wikipedia", "language:de", "language:en", "language:et", "language:ne", "language:ro", "language:ru", "language:si", "language:zh", "license:unknown", "region:us"], "private": false, "author": null, "description": "This shared task (part of WMT20) will build on its previous editions\nto further examine automatic methods for estimating the quality\nof neural machine translation output at run-time, without relying\non reference translations. As in previous years, we cover estimation\nat various levels. Important elements introduced this year include: a new\ntask where sentences are annotated with Direct Assessment (DA)\nscores instead of labels based on post-editing; a new multilingual\nsentence-level dataset mainly from Wikipedia articles, where the\nsource articles can be retrieved for document-wide context; the\navailability of NMT models to explore system-internal information for the task.\n\nTask 1 uses Wikipedia data for 6 language pairs that includes high-resource\nEnglish--German (En-De) and English--Chinese (En-Zh), medium-resource\nRomanian--English (Ro-En) and Estonian--English (Et-En), and low-resource\nSinhalese--English (Si-En) and Nepalese--English (Ne-En), as well as a\ndataset with a combination of Wikipedia articles and Reddit articles\nfor Russian-English (En-Ru). The datasets were collected by translating\nsentences sampled from source language articles using state-of-the-art NMT\nmodels built using the fairseq toolkit and annotated with Direct Assessment (DA)\nscores by professional translators. Each sentence was annotated following the\nFLORES setup, which presents a form of DA, where at least three professional\ntranslators rate each sentence from 0-100 according to the perceived translation\nquality. DA scores are standardised using the z-score by rater. Participating systems\nare required to score sentences according to z-standardised DA scores.", "citation": "Not available.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18201c", "disabled": false, "gated": false, "likes": 1, "downloads": 1492, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wmt20_mlqe_task2", "sha": "05c23fb491ceb2713c7e5aa1cc8f914bef2c8e87", "lastModified": "2023-06-01T14:59:47.000Z", "tags": ["task_categories:translation", "task_categories:text-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|wikipedia", "language:de", "language:en", "language:zh", "license:unknown", "translation-quality-estimation", "arxiv:1902.08646", "region:us"], "private": false, "author": null, "description": "This shared task (part of WMT20) will build on its previous editions\nto further examine automatic methods for estimating the quality\nof neural machine translation output at run-time, without relying\non reference translations. As in previous years, we cover estimation\nat various levels. Important elements introduced this year include: a new\ntask where sentences are annotated with Direct Assessment (DA)\nscores instead of labels based on post-editing; a new multilingual\nsentence-level dataset mainly from Wikipedia articles, where the\nsource articles can be retrieved for document-wide context; the\navailability of NMT models to explore system-internal information for the task.\n\nTask 2 evaluates the application of QE for post-editing purposes. It consists of predicting:\n- A/ Word-level tags. This is done both on source side (to detect which words caused errors)\nand target side (to detect mistranslated or missing words).\n  - A1/ Each token is tagged as either `OK` or `BAD`. Additionally,\n  each gap between two words is tagged as `BAD` if one or more\n  missing words should have been there, and `OK` otherwise. Note\n  that number of tags for each target sentence is 2*N+1, where\n  N is the number of tokens in the sentence.\n  - A2/ Tokens are tagged as `OK` if they were correctly\n  translated, and `BAD` otherwise. Gaps are not tagged.\n- B/ Sentence-level HTER scores. HTER (Human Translation Error Rate)\nis the ratio between the number of edits (insertions/deletions/replacements)\nneeded and the reference translation length.", "citation": "Not available.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18201d", "disabled": false, "gated": false, "likes": 2, "downloads": 429, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wmt20_mlqe_task3", "sha": "94289cdb1abddff08f357ad00ad4f226e196fa55", "lastModified": "2023-01-25T15:02:49.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:extended|amazon_us_reviews", "language:en", "language:fr", "license:unknown", "region:us"], "private": false, "author": null, "description": "This shared task (part of WMT20) will build on its previous editions\nto further examine automatic methods for estimating the quality\nof neural machine translation output at run-time, without relying\non reference translations. As in previous years, we cover estimation\nat various levels. Important elements introduced this year include: a new\ntask where sentences are annotated with Direct Assessment (DA)\nscores instead of labels based on post-editing; a new multilingual\nsentence-level dataset mainly from Wikipedia articles, where the\nsource articles can be retrieved for document-wide context; the\navailability of NMT models to explore system-internal information for the task.\n\nThe goal of this task 3 is to predict document-level quality scores as well as fine-grained annotations.", "citation": "Not available.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18201e", "disabled": false, "gated": false, "likes": 0, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wnut_17", "sha": "9a631b654e7ed17a61ab0aaf6901ca1654b99a88", "lastModified": "2023-04-05T13:45:05.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "WNUT 17: Emerging and Rare entity recognition\n\nThis shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\nNamed entities form the basis of many modern approaches to other tasks (like event clustering and summarisation),\nbut recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms.\nTake for example the tweet \u201cso.. kktny in 30 mins?\u201d - even human experts find entity kktny hard to detect and resolve.\nThis task will evaluate the ability to detect and classify novel, emerging, singleton named entities in noisy text.\n\nThe goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities.", "citation": "@inproceedings{derczynski-etal-2017-results,\n    title = \"Results of the {WNUT}2017 Shared Task on Novel and Emerging Entity Recognition\",\n    author = \"Derczynski, Leon  and\n      Nichols, Eric  and\n      van Erp, Marieke  and\n      Limsopatham, Nut\",\n    booktitle = \"Proceedings of the 3rd Workshop on Noisy User-generated Text\",\n    month = sep,\n    year = \"2017\",\n    address = \"Copenhagen, Denmark\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/W17-4418\",\n    doi = \"10.18653/v1/W17-4418\",\n    pages = \"140--147\",\n    abstract = \"This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions.\n                Named entities form the basis of many modern approaches to other tasks (like event clustering and summarization),\n                but recall on them is a real problem in noisy text - even among annotators.\n                This drop tends to be due to novel entities and surface forms.\n                Take for example the tweet {``}so.. kktny in 30 mins?!{''} {--} even human experts find the entity {`}kktny{'}\n                hard to detect and resolve. The goal of this task is to provide a definition of emerging and of rare entities,\n                and based on that, also datasets for detecting these entities. The task as described in this paper evaluated the\n                ability of participating entries to detect and classify novel and emerging named entities in noisy text.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182020", "disabled": false, "gated": false, "likes": 10, "downloads": 9126, "paperswithcode_id": "wnut-2017-emerging-and-rare-entity", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wongnai_reviews", "sha": "146e30d6a0deb445608fd058e3170b6d91c7eaff", "lastModified": "2023-01-25T15:02:56.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:th", "license:lgpl-3.0", "region:us"], "private": false, "author": null, "description": "Wongnai's review dataset contains restaurant reviews and ratings, mainly in Thai language.\nThe reviews are in 5 classes ranging from 1 to 5 stars.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182021", "disabled": false, "gated": false, "likes": 2, "downloads": 466, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "woz_dialogue", "sha": "5db69108647ba28c0f9fd1528617caf0b1ec9f60", "lastModified": "2023-06-01T14:59:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_categories:token-classification", "task_categories:text-classification", "task_ids:dialogue-modeling", "task_ids:multi-class-classification", "task_ids:parsing", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:de", "language:en", "language:it", "license:unknown", "arxiv:1604.04562", "region:us"], "private": false, "author": null, "description": "Wizard-of-Oz (WOZ) is a dataset for training task-oriented dialogue systems. The dataset is designed around the task of finding a restaurant in the Cambridge, UK area. There are three informable slots (food, pricerange,area) that users can use to constrain the search and six requestable slots (address, phone, postcode plus the three informable slots) that the user can ask a value for once a restaurant has been offered.", "citation": "@misc{wen2017networkbased,\n      title={A Network-based End-to-End Trainable Task-oriented Dialogue System},\n      author={Tsung-Hsien Wen and David Vandyke and Nikola Mrksic and Milica Gasic and Lina M. Rojas-Barahona and Pei-Hao Su and Stefan Ultes and Steve Young},\n      year={2017},\n      eprint={1604.04562},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182022", "disabled": false, "gated": false, "likes": 3, "downloads": 862, "paperswithcode_id": "wizard-of-oz", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wrbsc", "sha": "96110424c9aeff40512aff49d44eb068487af072", "lastModified": "2023-01-25T15:02:59.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": null, "description": "WUT Relations Between Sentences Corpus contains 2827 pairs of related sentences.\nRelationships are derived from Cross-document Structure Theory (CST), which enables multi-document summarization through identification of cross-document rhetorical relationships within a cluster of related documents.\nEvery relation was marked by at least 3 annotators.", "citation": "@misc{11321/305,\n title = {{WUT} Relations Between Sentences Corpus},\n author = {Oleksy, Marcin and Fikus, Dominika and Wolski, Michal and Podbielska, Malgorzata and Turek, Agnieszka and K\u0119dzia, Pawel},\n url = {http://hdl.handle.net/11321/305},\n note = {{CLARIN}-{PL} digital repository},\n copyright = {Attribution-{ShareAlike} 3.0 Unported ({CC} {BY}-{SA} 3.0)},\n year = {2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182023", "disabled": false, "gated": false, "likes": 0, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "x_stance", "sha": "addb0a0487f1fbb89869f64d75e90827183e4af5", "lastModified": "2023-04-05T13:45:10.000Z", "tags": ["task_categories:text-classification", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "language:en", "language:fr", "language:it", "license:cc-by-nc-4.0", "stance-detection", "arxiv:2003.08385", "region:us"], "private": false, "author": null, "description": "The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions.\n\nIt can be used to train and evaluate stance detection systems.", "citation": "@inproceedings{vamvas2020xstance,\n    author    = \"Vamvas, Jannis and Sennrich, Rico\",\n    title     = \"{X-Stance}: A Multilingual Multi-Target Dataset for Stance Detection\",\n    booktitle = \"Proceedings of the 5th Swiss Text Analytics Conference (SwissText) \\\\& 16th Conference on Natural Language Processing (KONVENS)\",\n    address   = \"Zurich, Switzerland\",\n    year      = \"2020\",\n    month     = \"jun\",\n    url       = \"http://ceur-ws.org/Vol-2624/paper9.pdf\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182024", "disabled": false, "gated": false, "likes": 4, "downloads": 481, "paperswithcode_id": "x-stance", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xcopa", "sha": "778f59340d3840381b54b40d885b1ac47cdfc2c6", "lastModified": "2023-04-05T13:45:13.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:extended|copa", "language:et", "language:ht", "language:id", "language:it", "language:qu", "language:sw", "language:ta", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\nthe globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages. All the details about the\ncreation of XCOPA and the implementation of the baselines are available in the paper.\\n", "citation": "  @article{ponti2020xcopa,\n  title={{XCOPA: A} Multilingual Dataset for Causal Commonsense Reasoning},\n  author={Edoardo M. Ponti, Goran Glava\\v{s}, Olga Majewska, Qianchu Liu, Ivan Vuli\\'{c} and Anna Korhonen},\n  journal={arXiv preprint},\n  year={2020},\n  url={https://ducdauge.github.io/files/xcopa.pdf}\n}\n\n@inproceedings{roemmele2011choice,\n  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},\n  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},\n  booktitle={2011 AAAI Spring Symposium Series},\n  year={2011},\n  url={https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182025", "disabled": false, "gated": false, "likes": 6, "downloads": 24955, "paperswithcode_id": "xcopa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xcsr", "sha": "512c2be6284195636331305ea30caf3086f7befe", "lastModified": "2022-11-03T16:46:53.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|codah", "source_datasets:extended|commonsense_qa", "language:ar", "language:de", "language:en", "language:es", "language:fr", "language:hi", "language:it", "language:ja", "language:nl", "language:pl", "language:pt", "language:ru", "language:sw", "language:ur", "language:vi", "language:zh", "license:mit", "arxiv:2106.06937", "region:us"], "private": false, "author": null, "description": "To evaluate multi-lingual language models (ML-LMs) for commonsense reasoning in a cross-lingual zero-shot transfer setting (X-CSR), i.e., training in English and test in other languages, we create two benchmark datasets, namely X-CSQA and X-CODAH. Specifically, we automatically translate the original CSQA and CODAH datasets, which only have English versions, to 15 other languages, forming development and test sets for studying X-CSR. As our goal is to evaluate different ML-LMs in a unified evaluation protocol for X-CSR, we argue that such translated examples, although might contain noise, can serve as a starting benchmark for us to obtain meaningful analysis, before more human-translated datasets will be available in the future.", "citation": "# X-CSR\n@inproceedings{lin-etal-2021-common,\n    title = \"Common Sense Beyond {E}nglish: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Lee, Seyeon  and\n      Qiao, Xiaoyang  and\n      Ren, Xiang\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.102\",\n    doi = \"10.18653/v1/2021.acl-long.102\",\n    pages = \"1274--1287\",\n}\n\n# CSQA\n@inproceedings{Talmor2019commonsenseqaaq,\n    address = {Minneapolis, Minnesota},\n    author = {Talmor, Alon  and Herzig, Jonathan  and Lourie, Nicholas and Berant, Jonathan},\n    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n    doi = {10.18653/v1/N19-1421},\n    pages = {4149--4158},\n    publisher = {Association for Computational Linguistics},\n    title = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},\n    url = {https://www.aclweb.org/anthology/N19-1421},\n    year = {2019}\n}\n\n# CODAH\n@inproceedings{Chen2019CODAHAA,\n    address = {Minneapolis, USA},\n    author = {Chen, Michael  and D{'}Arcy, Mike  and Liu, Alisa  and Fernandez, Jared  and Downey, Doug},\n    booktitle = {Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP}},\n    doi = {10.18653/v1/W19-2008},\n    pages = {63--69},\n    publisher = {Association for Computational Linguistics},\n    title = {CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense},\n    url = {https://www.aclweb.org/anthology/W19-2008},\n    year = {2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182026", "disabled": false, "gated": false, "likes": 4, "downloads": 56481, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xed_en_fi", "sha": "8d0e5e9839674b75148a9b20ff6d0384227c61f9", "lastModified": "2023-06-01T14:59:50.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:extended|other-OpenSubtitles2016", "language:en", "language:fi", "license:cc-by-4.0", "arxiv:2011.01612", "region:us"], "private": false, "author": null, "description": "A multilingual fine-grained emotion dataset. The dataset consists of human annotated Finnish (25k) and English sentences (30k). Plutchik\u2019s\ncore emotions are used to annotate the dataset with the addition of neutral to create a multilabel multiclass\ndataset. The dataset is carefully evaluated using language-specific BERT models and SVMs to\nshow that XED performs on par with other similar datasets and is therefore a useful tool for\nsentiment analysis and emotion detection.", "citation": "@inproceedings{ohman2020xed,\n  title={XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection},\n  author={{\\\"O}hman, Emily and P{\\\"a}mies, Marc and Kajava, Kaisla and Tiedemann, J{\\\"o}rg},\n  booktitle={The 28th International Conference on Computational Linguistics (COLING 2020)},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182027", "disabled": false, "gated": false, "likes": 6, "downloads": 774, "paperswithcode_id": "xed", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xglue", "sha": "11926279ebd121c823cb5511ede5c1789764870b", "lastModified": "2023-06-30T09:06:30.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-classification", "task_categories:text2text-generation", "task_categories:token-classification", "task_ids:acceptability-classification", "task_ids:extractive-qa", "task_ids:named-entity-recognition", "task_ids:natural-language-inference", "task_ids:news-articles-headline-generation", "task_ids:open-domain-qa", "task_ids:parsing", "task_ids:topic-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:found", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:found", "language_creators:machine-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "source_datasets:extended|conll2003", "source_datasets:extended|squad", "source_datasets:extended|xnli", "source_datasets:original", "language:ar", "language:bg", "language:de", "language:el", "language:en", "language:es", "language:fr", "language:hi", "language:it", "language:nl", "language:pl", "language:pt", "language:ru", "language:sw", "language:th", "language:tr", "language:ur", "language:vi", "language:zh", "license:other", "paraphrase-identification", "question-answering", "arxiv:2004.01401", "region:us"], "private": false, "author": null, "description": "XGLUE is a new benchmark dataset to evaluate the performance of cross-lingual pre-trained\nmodels with respect to cross-lingual natural language understanding and generation.\nThe benchmark is composed of the following 11 tasks:\n- NER\n- POS Tagging (POS)\n- News Classification (NC)\n- MLQA\n- XNLI\n- PAWS-X\n- Query-Ad Matching (QADSM)\n- Web Page Ranking (WPR)\n- QA Matching (QAM)\n- Question Generation (QG)\n- News Title Generation (NTG)\n\nFor more information, please take a look at https://microsoft.github.io/XGLUE/.", "citation": "@article{Liang2020XGLUEAN,\n  title={XGLUE: A New Benchmark Dataset for Cross-lingual Pre-training, Understanding and Generation},\n  author={Yaobo Liang and Nan Duan and Yeyun Gong and Ning Wu and Fenfei Guo and Weizhen Qi\n  and Ming Gong and Linjun Shou and Daxin Jiang and Guihong Cao and Xiaodong Fan and Ruofei\n  Zhang and Rahul Agrawal and Edward Cui and Sining Wei and Taroon Bharti and Ying Qiao\n  and Jiun-Hung Chen and Winnie Wu and Shuguang Liu and Fan Yang and Daniel Campos\n  and Rangan Majumder and Ming Zhou},\n  journal={arXiv},\n  year={2020},\n  volume={abs/2004.01401}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182028", "disabled": false, "gated": false, "likes": 21, "downloads": 1975, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xnli", "sha": "1cdcf07be24d81f3d782038a5a0b9c8d62f76e60", "lastModified": "2023-04-05T13:45:18.000Z", "tags": ["language:ar", "language:bg", "language:de", "language:el", "language:en", "language:es", "language:fr", "language:hi", "language:ru", "language:sw", "language:th", "language:tr", "language:ur", "language:vi", "language:zh", "region:us"], "private": false, "author": null, "description": "XNLI is a subset of a few thousand examples from MNLI which has been translated\ninto a 14 different languages (some low-ish resource). As with MNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).", "citation": "@InProceedings{conneau2018xnli,\n  author = {Conneau, Alexis\n                 and Rinott, Ruty\n                 and Lample, Guillaume\n                 and Williams, Adina\n                 and Bowman, Samuel R.\n                 and Schwenk, Holger\n                 and Stoyanov, Veselin},\n  title = {XNLI: Evaluating Cross-lingual Sentence Representations},\n  booktitle = {Proceedings of the 2018 Conference on Empirical Methods\n               in Natural Language Processing},\n  year = {2018},\n  publisher = {Association for Computational Linguistics},\n  location = {Brussels, Belgium},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182029", "disabled": false, "gated": false, "likes": 34, "downloads": 77716, "paperswithcode_id": "xnli", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xor_tydi_qa", "sha": "91e85a524cd8f584d8c7e7a7324104f5f2c6b3a7", "lastModified": "2023-01-25T15:03:13.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "source_datasets:extended|tydiqa", "language:ar", "language:bn", "language:fi", "language:ja", "language:ko", "language:ru", "language:te", "license:mit", "arxiv:2010.11856", "region:us"], "private": false, "author": null, "description": "    XOR-TyDi QA brings together for the first time information-seeking questions,\n    open-retrieval QA, and multilingual QA to create a multilingual open-retrieval\n    QA dataset that enables cross-lingual answer retrieval. It consists of questions\n    written by information-seeking native speakers in 7 typologically diverse languages\n    and answer annotations that are retrieved from multilingual document collections.\n    There are three sub-tasks: XOR-Retrieve, XOR-EnglishSpan, and XOR-Full.", "citation": "    @misc{asai2020xor,\n      title={XOR QA: Cross-lingual Open-Retrieval Question Answering},\n      author={Akari Asai and Jungo Kasai and Jonathan H. Clark and Kenton Lee and Eunsol Choi and Hannaneh Hajishirzi},\n      year={2020},\n      eprint={2010.11856},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202a", "disabled": false, "gated": false, "likes": 1, "downloads": 422, "paperswithcode_id": "xor-tydi-qa", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xquad", "sha": "8c2924a720ea543c2b6346284e21d3b85b1c2996", "lastModified": "2023-04-05T13:45:22.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:extended|squad", "language:ar", "language:de", "language:el", "language:en", "language:es", "language:hi", "language:ro", "language:ru", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-sa-4.0", "arxiv:1910.11856", "region:us"], "private": false, "author": null, "description": "XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and Romanian. Consequently, the dataset is entirely parallel\nacross 12 languages.", "citation": "@article{Artetxe:etal:2019,\n      author    = {Mikel Artetxe and Sebastian Ruder and Dani Yogatama},\n      title     = {On the cross-lingual transferability of monolingual representations},\n      journal   = {CoRR},\n      volume    = {abs/1910.11856},\n      year      = {2019},\n      archivePrefix = {arXiv},\n      eprint    = {1910.11856}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202b", "disabled": false, "gated": false, "likes": 12, "downloads": 24549, "paperswithcode_id": "xquad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xquad_r", "sha": "540d47e91acde104892068a5fa8c00f6035e2f5d", "lastModified": "2023-06-01T14:59:54.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|squad", "source_datasets:extended|xquad", "language:ar", "language:de", "language:el", "language:en", "language:es", "language:hi", "language:ru", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-sa-4.0", "arxiv:2004.05484", "region:us"], "private": false, "author": null, "description": "XQuAD-R is a retrieval version of the XQuAD dataset (a cross-lingual extractive QA dataset). Like XQuAD, XQUAD-R is an 11-way parallel dataset, where each question appears in 11 different languages and has 11 parallel correct answers across the languages.", "citation": "@article{roy2020lareqa,\n  title={LAReQA: Language-agnostic answer retrieval from a multilingual pool},\n  author={Roy, Uma and Constant, Noah and Al-Rfou, Rami and Barua, Aditya and Phillips, Aaron and Yang, Yinfei},\n  journal={arXiv preprint arXiv:2004.05484},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202c", "disabled": false, "gated": false, "likes": 2, "downloads": 2124, "paperswithcode_id": "xquad-r", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "EdinburghNLP/xsum", "sha": "40db7604fedb616a9d2b0673d11838fa5be8451c", "lastModified": "2023-04-05T13:45:25.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:unknown", "arxiv:1808.08745", "region:us"], "private": false, "author": "EdinburghNLP", "description": "Extreme Summarization (XSum) Dataset.\n\nThere are three features:\n  - document: Input news article.\n  - summary: One sentence summary of the article.\n  - id: BBC ID of the article.", "citation": "@article{Narayan2018DontGM,\n  title={Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},\n  author={Shashi Narayan and Shay B. Cohen and Mirella Lapata},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1808.08745}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202d", "disabled": false, "gated": false, "likes": 46, "downloads": 2778, "paperswithcode_id": "xsum", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xsum_factuality", "sha": "8979c77aa1e8bc7aa04998c457b50646ec49225f", "lastModified": "2023-01-25T15:03:16.000Z", "tags": ["task_categories:summarization", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|other-xsum", "language:en", "license:cc-by-4.0", "hallucinations", "region:us"], "private": false, "author": null, "description": "Neural abstractive summarization models are highly prone to hallucinate content that is unfaithful to the input\ndocument. The popular metric such as ROUGE fails to show the severity of the problem. The dataset consists of\nfaithfulness and factuality annotations of abstractive summaries for the XSum dataset. We have crowdsourced 3 judgements\n for each of 500 x 5 document-system pairs. This will be a valuable resource to the abstractive summarization community.", "citation": "@InProceedings{maynez_acl20,\n  author =      \"Joshua Maynez and Shashi Narayan and Bernd Bohnet and Ryan Thomas Mcdonald\",\n  title =       \"On Faithfulness and Factuality in Abstractive Summarization\",\n  booktitle =   \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n  year =        \"2020\",\n  pages = \"1906--1919\",\n  address = \"Online\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202e", "disabled": false, "gated": false, "likes": 4, "downloads": 448, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "xtreme", "sha": "f15dc7923ee0d8113cdffda831b88a07932009d7", "lastModified": "2023-06-01T14:59:58.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:token-classification", "task_categories:text-classification", "task_categories:text-retrieval", "task_ids:multiple-choice-qa", "task_ids:extractive-qa", "task_ids:open-domain-qa", "task_ids:natural-language-inference", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "multilinguality:translation", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "source_datasets:extended|xnli", "source_datasets:extended|paws-x", "source_datasets:extended|wikiann", "source_datasets:extended|xquad", "source_datasets:extended|mlqa", "source_datasets:extended|tydiqa", "source_datasets:extended|tatoeba", "source_datasets:extended|squad", "language:af", "language:ar", "language:bg", "language:bn", "language:de", "language:el", "language:en", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:he", "language:hi", "language:hu", "language:id", "language:it", "language:ja", "language:jv", "language:ka", "language:kk", "language:ko", "language:ml", "language:mr", "language:ms", "language:my", "language:nl", "language:pt", "language:ru", "language:sw", "language:ta", "language:te", "language:th", "language:tl", "language:tr", "language:ur", "language:vi", "language:yo", "language:zh", "license:apache-2.0", "license:cc-by-4.0", "license:cc-by-2.0", "license:cc-by-sa-4.0", "license:other", "license:cc-by-nc-4.0", "parallel-sentence-retrieval", "paraphrase-identification", "arxiv:2003.11080", "region:us"], "private": false, "author": null, "description": "The Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark is a benchmark for the evaluation of\nthe cross-lingual generalization ability of pre-trained multilingual models. It covers 40 typologically diverse languages\n(spanning 12 language families) and includes nine tasks that collectively require reasoning about different levels of\nsyntax and semantics. The languages in XTREME are selected to maximize language diversity, coverage in existing tasks,\nand availability of training data. Among these are many under-studied languages, such as the Dravidian languages Tamil\n(spoken in southern India, Sri Lanka, and Singapore), Telugu and Malayalam (spoken mainly in southern India), and the\nNiger-Congo languages Swahili and Yoruba, spoken in Africa.", "citation": "@article{hu2020xtreme,\n      author    = {Junjie Hu and Sebastian Ruder and Aditya Siddhant and Graham Neubig and Orhan Firat and Melvin Johnson},\n      title     = {XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization},\n      journal   = {CoRR},\n      volume    = {abs/2003.11080},\n      year      = {2020},\n      archivePrefix = {arXiv},\n      eprint    = {2003.11080}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18202f", "disabled": false, "gated": false, "likes": 61, "downloads": 61610, "paperswithcode_id": "xtreme", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yahoo_answers_qa", "sha": "6de8ee32edf4ac86393663da286c80e35ebe40b0", "lastModified": "2022-11-03T16:30:48.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-yahoo-webscope-l6", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Yahoo Non-Factoid Question Dataset is derived from Yahoo's Webscope L6 collection using machine learning techiques such that the questions would contain non-factoid answers.The dataset contains 87,361 questions and their corresponding answers. Each question contains its best answer along with additional other answers submitted by users. Only the best answer was reviewed in determining the quality of the question-answer pair.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182030", "disabled": false, "gated": false, "likes": 13, "downloads": 740, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yahoo_answers_topics", "sha": "4edd03cc228baaec84c31879c1c198f8545dbfce", "lastModified": "2023-01-25T15:03:25.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:extended|other-yahoo-answers-corpus", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "Yahoo! Answers Topic Classification is text classification dataset. The dataset is the Yahoo! Answers corpus as of 10/25/2007. The Yahoo! Answers topic classification dataset is constructed using 10 largest main categories. From all the answers and other meta-information, this dataset only used the best answer content and the main category information.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182031", "disabled": false, "gated": false, "likes": 26, "downloads": 2893, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yelp_polarity", "sha": "8408a6e97ad102f106e1c5059d73f80479ff4b49", "lastModified": "2023-06-27T07:34:43.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "language:en", "arxiv:1509.01626", "region:us"], "private": false, "author": null, "description": "Large Yelp Review Dataset.\nThis is a dataset for binary sentiment classification. We provide a set of 560,000 highly polar yelp reviews for training, and 38,000 for testing. \nORIGIN\nThe Yelp reviews dataset consists of reviews from Yelp. It is extracted\nfrom the Yelp Dataset Challenge 2015 data. For more information, please\nrefer to http://www.yelp.com/dataset_challenge\n\nThe Yelp reviews polarity dataset is constructed by\nXiang Zhang (xiang.zhang@nyu.edu) from the above dataset.\nIt is first used as a text classification benchmark in the following paper:\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks\nfor Text Classification. Advances in Neural Information Processing Systems 28\n(NIPS 2015).\n\n\nDESCRIPTION\n\nThe Yelp reviews polarity dataset is constructed by considering stars 1 and 2\nnegative, and 3 and 4 positive. For each polarity 280,000 training samples and\n19,000 testing samples are take randomly. In total there are 560,000 trainig\nsamples and 38,000 testing samples. Negative polarity is class 1,\nand positive class 2.\n\nThe files train.csv and test.csv contain all the training samples as\ncomma-sparated values. There are 2 columns in them, corresponding to class\nindex (1 and 2) and review text. The review texts are escaped using double\nquotes (\"), and any internal double quote is escaped by 2 double quotes (\"\").\nNew lines are escaped by a backslash followed with an \"n\" character,\nthat is \"\\n\".", "citation": "@article{zhangCharacterlevelConvolutionalNetworks2015,\n  archivePrefix = {arXiv},\n  eprinttype = {arxiv},\n  eprint = {1509.01626},\n  primaryClass = {cs},\n  title = {Character-Level {{Convolutional Networks}} for {{Text Classification}}},\n  abstract = {This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks.},\n  journal = {arXiv:1509.01626 [cs]},\n  author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},\n  month = sep,\n  year = {2015},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182032", "disabled": false, "gated": false, "likes": 8, "downloads": 3955, "paperswithcode_id": "yelp-review-polarity", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yelp_review_full", "sha": "18a3aad00f96be449c4903b1ac215bc897923a40", "lastModified": "2023-01-25T15:03:32.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "arxiv:1509.01626", "region:us"], "private": false, "author": null, "description": "The Yelp reviews dataset consists of reviews from Yelp. It is extracted from the Yelp Dataset Challenge 2015 data.\nThe Yelp reviews full star dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the above dataset.\nIt is first used as a text classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann LeCun.\nCharacter-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).", "citation": "@inproceedings{zhang2015character,\n  title={Character-level convolutional networks for text classification},\n  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},\n  booktitle={Advances in neural information processing systems},\n  pages={649--657},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182033", "disabled": false, "gated": false, "likes": 41, "downloads": 21420, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yoruba_bbc_topics", "sha": "9c2a2cc646a892bf8c8b6919e7895238d005edad", "lastModified": "2023-01-25T15:03:35.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:yo", "license:unknown", "region:us"], "private": false, "author": null, "description": "A collection of news article headlines in Yoruba from BBC Yoruba.\nEach headline is labeled with one of the following classes: africa,\nentertainment, health, nigeria, politics, sport or world.\n\nThe dataset was presented in the paper:\nHedderich, Adelani, Zhu, Alabi, Markus, Klakow: Transfer Learning and\nDistant Supervision for Multilingual Transformer Models: A Study on\nAfrican Languages (EMNLP 2020).", "citation": "@inproceedings{hedderich-etal-2020-transfer,\n    title = \"Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages\",\n    author = \"Hedderich, Michael A.  and\n      Adelani, David  and\n      Zhu, Dawei  and\n      Alabi, Jesujoba  and\n      Markus, Udia  and\n      Klakow, Dietrich\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.204\",\n    doi = \"10.18653/v1/2020.emnlp-main.204\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182034", "disabled": false, "gated": false, "likes": 0, "downloads": 349, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yoruba_gv_ner", "sha": "f727d87667c48400f41824969c2995d300ebb8ce", "lastModified": "2023-01-25T15:03:39.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:yo", "license:cc-by-3.0", "region:us"], "private": false, "author": null, "description": "The Yoruba GV NER dataset is a labeled dataset for named entity recognition in Yoruba. The texts were obtained from\nYoruba Global Voices News articles https://yo.globalvoices.org/ . We concentrate on\nfour types of named entities: persons [PER], locations [LOC], organizations [ORG], and dates & time [DATE].\n\nThe Yoruba GV NER data files contain 2 columns separated by a tab ('\\t'). Each word has been put on a separate line and\nthere is an empty line after each sentences i.e the CoNLL format. The first item on each line is a word, the second\nis the named entity tag. The named entity tags have the format I-TYPE which means that the word is inside a phrase\nof type TYPE. For every multi-word expression like 'New York', the first word gets a tag B-TYPE and the subsequent words\nhave tags I-TYPE, a word with tag O is not part of a phrase. The dataset is in the BIO tagging scheme.\n\nFor more details, see https://www.aclweb.org/anthology/2020.lrec-1.335/", "citation": "@inproceedings{alabi-etal-2020-massive,\n    title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Yor\u00f9b\u00e1} and {T}wi\",\n    author = \"Alabi, Jesujoba  and\n      Amponsah-Kaakyire, Kwabena  and\n      Adelani, David  and\n      Espa{\\\\~n}a-Bonet, Cristina\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n    pages = \"2754--2762\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182035", "disabled": false, "gated": false, "likes": 0, "downloads": 281, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yoruba_text_c3", "sha": "a9aa4093a83833364a4f12dc6ccd2adb9c13e3b2", "lastModified": "2023-06-16T15:06:58.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:yo", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": null, "description": "Yoruba Text C3 is the largest Yoruba texts collected and used to train FastText embeddings in the\nYorubaTwi Embedding paper: https://www.aclweb.org/anthology/2020.lrec-1.335/", "citation": "@inproceedings{alabi-etal-2020-massive,\n    title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of Yoruba and {T}wi\",\n    author = \"Alabi, Jesujoba  and\n      Amponsah-Kaakyire, Kwabena  and\n      Adelani, David  and\n      Espa{\\\\~n}a-Bonet, Cristina\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n    pages = \"2754--2762\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182036", "disabled": false, "gated": false, "likes": 1, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yoruba_wordsim353", "sha": "9d07d45ddc610cdead4658da2f39c18054977ca6", "lastModified": "2022-11-03T16:07:49.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "task_ids:semantic-similarity-scoring", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:en", "language:yo", "license:unknown", "region:us"], "private": false, "author": null, "description": "A translation of the word pair similarity dataset wordsim-353 to Yor\u00f9b\u00e1.\n\nThe dataset was presented in the paper\nAlabi et al.: Massive vs. Curated Embeddings for Low-Resourced\nLanguages: the Case of Yor\u00f9b\u00e1 and Twi (LREC 2020).", "citation": "@inproceedings{alabi-etal-2020-massive,\n    title = \"Massive vs. Curated Embeddings for Low-Resourced Languages: the Case of {Y}or{\\\\`u}b{\\\\'a} and {T}wi\",\n    author = \"Alabi, Jesujoba  and\n      Amponsah-Kaakyire, Kwabena  and\n      Adelani, David  and\n      Espa{\\\\~n}a-Bonet, Cristina\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.335\",\n    pages = \"2754--2762\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182037", "disabled": false, "gated": false, "likes": 0, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "youtube_caption_corrections", "sha": "05c7731b61112eca36f6a7ed898c15e717469d69", "lastModified": "2023-01-25T15:03:42.000Z", "tags": ["task_categories:other", "task_categories:text-generation", "task_categories:fill-mask", "task_ids:slot-filling", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "token-classification-of-text-errors", "region:us"], "private": false, "author": null, "description": "Dataset built from pairs of YouTube captions where both 'auto-generated' and\n'manually-corrected' captions are available for a single specified language.\nThis dataset labels two-way (e.g. ignoring single-sided insertions) same-length\ntoken differences in the `diff_type` column. The `default_seq` is composed of\ntokens from the 'auto-generated' captions. When a difference occurs between\nthe 'auto-generated' vs 'manually-corrected' captions types, the `correction_seq`\ncontains tokens from the 'manually-corrected' captions.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182038", "disabled": false, "gated": false, "likes": 4, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "zest", "sha": "5815da885d85697fd612a9f3b4d619a84582d336", "lastModified": "2022-11-18T22:05:40.000Z", "tags": ["task_categories:question-answering", "task_categories:token-classification", "task_ids:closed-domain-qa", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "output-structure", "yes-no-qa", "arxiv:2011.08115", "region:us"], "private": false, "author": null, "description": "ZEST tests whether NLP systems can perform unseen tasks in a zero-shot way, given a natural language description of\nthe task. It is an instantiation of our proposed framework \"learning from task descriptions\". The tasks include\nclassification, typed entity extraction and relationship extraction, and each task is paired with 20 different\nannotated (input, output) examples. ZEST's structure allows us to systematically test whether models can generalize\nin five different ways.", "citation": "@inproceedings{weller-etal-2020-learning,\n    title = \"Learning from Task Descriptions\",\n    author = \"Weller, Orion  and\n      Lourie, Nicholas  and\n      Gardner, Matt  and\n      Peters, Matthew\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.105\",\n    pages = \"1361--1375\",\n    abstract = \"Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this frame- work with a new English language dataset, ZEST, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model{'}s ability to solve each task. Moreover, the dataset{'}s structure tests specific types of systematic generalization. We find that the state-of-the-art T5 model achieves a score of 12% on ZEST, leaving a significant challenge for NLP researchers.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182039", "disabled": false, "gated": false, "likes": 1, "downloads": 343, "paperswithcode_id": "zest", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "0n1xus/codexglue", "sha": "e4604616235cdfa7398d489ba1f95d44a18d2f5d", "lastModified": "2021-11-18T08:45:46.000Z", "tags": ["region:us"], "private": false, "author": "0n1xus", "description": "CodeXGLUE is a benchmark dataset to foster machine learning research for program understanding and generation. \nCodeXGLUE includes a collection of 10 tasks across 14 datasets and a platform for model evaluation and comparison.", "citation": "@article{Lu2021,\nauthor = {Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin B. and Drain, Dawn and Jiang, Daxin and Tang, Duyu and Li, Ge and Zhou, Lidong and Shou, Linjun and Zhou, Long and Tufano, Michele and Gong, Ming and Zhou, Ming and Duan, Nan and Sundaresan, Neel and Deng, Shao Kun and Fu, Shengyu and Liu, Shujie},\nyear = {2021},\nbooktitle = {arXiv},\ntitle = {CodeXGLUE - A Machine Learning Benchmark Dataset for Code Understanding and Generation}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18203a", "disabled": false, "gated": false, "likes": 3, "downloads": 852, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "0n1xus/pytorrent-standalone", "sha": "49b5f32829ffe8a88b67accac51d0512bc8a8f3b", "lastModified": "2021-12-02T06:13:15.000Z", "tags": ["region:us"], "private": false, "author": "0n1xus", "description": "pytorrent-standalone is a subset of the PyTorrent dataset, where only functions that does not depend on external libraries\nare kept.", "citation": "@article{Bahrami2021,\nauthor = {Bahrami, Mehdi and Shrikanth, N. C. and Ruangwan, Shade and Liu, Lei and Mizobuchi, Yuji and Fukuyori, Masahiro and Chen, Wei-Peng and Munakata, Kazuki and Menzies, Tim},\nyear = {2021},\njournal = {arXiv},\ntitle = {PyTorrent: A Python Library Corpus for Large-scale Language Models}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18203b", "disabled": false, "gated": false, "likes": 0, "downloads": 281, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "AlekseyKorshuk/comedy-scripts", "sha": "6260f47b5cb584435b993c6b98087802e56dac49", "lastModified": "2022-02-11T14:50:39.000Z", "tags": ["region:us"], "private": false, "author": "AlekseyKorshuk", "description": "This dataset is designed to generate lyrics with HuggingArtists.", "citation": "@InProceedings{huggingartists:dataset,\ntitle = {Lyrics dataset},\nauthor={Aleksey Korshuk\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1820c5", "disabled": false, "gated": false, "likes": 2, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "AlgoveraAI/CryptoPunks", "sha": "c31fe59b441510cba533513a8d35b0d0126d1ced", "lastModified": "2022-02-28T15:25:44.000Z", "tags": ["region:us"], "private": false, "author": "AlgoveraAI", "description": "CryptoPunks is a non-fungible token (NFT) collection on the Ethereum blockchain. The dataset contains 10,000 CryptoPunk images, most of humans but also of three special types: Zombie (88), Ape (24) and Alien (9). They are provided with both clear backgrounds and teal backgrounds.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1820d1", "disabled": false, "gated": false, "likes": 4, "downloads": 144, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ApiInferenceTest/asr_dummy", "sha": "45e764963b548106022c890db9b59eda69d4193a", "lastModified": "2022-02-14T11:18:56.000Z", "tags": ["region:us"], "private": false, "author": "ApiInferenceTest", "description": "Self-supervised learning (SSL) has proven vital for advancing research in\nnatural language processing (NLP) and computer vision (CV). The paradigm\npretrains a shared model on large volumes of unlabeled data and achieves\nstate-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\nspeech processing community lacks a similar setup to systematically explore the\nparadigm. To bridge this gap, we introduce Speech processing Universal\nPERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\nperformance of a shared model across a wide range of speech processing tasks\nwith minimal architecture changes and labeled data. Among multiple usages of the\nshared model, we especially focus on extracting the representation learned from\nSSL due to its preferable re-usability. We present a simple framework to solve\nSUPERB tasks by learning task-specialized lightweight prediction heads on top of\nthe frozen shared model. Our results demonstrate that the framework is promising\nas SSL representations show competitive generalizability and accessibility\nacross SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a\nbenchmark toolkit to fuel the research in representation learning and general\nspeech processing.\n\nNote that in order to limit the required storage for preparing this dataset, the\naudio is stored in the .flac format and is not converted to a float32 array. To\nconvert, the audio file to a float32 array, please make use of the `.map()`\nfunction as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@article{DBLP:journals/corr/abs-2105-01051,\n  author    = {Shu{-}Wen Yang and\n               Po{-}Han Chi and\n               Yung{-}Sung Chuang and\n               Cheng{-}I Jeff Lai and\n               Kushal Lakhotia and\n               Yist Y. Lin and\n               Andy T. Liu and\n               Jiatong Shi and\n               Xuankai Chang and\n               Guan{-}Ting Lin and\n               Tzu{-}Hsien Huang and\n               Wei{-}Cheng Tseng and\n               Ko{-}tik Lee and\n               Da{-}Rong Liu and\n               Zili Huang and\n               Shuyan Dong and\n               Shang{-}Wen Li and\n               Shinji Watanabe and\n               Abdelrahman Mohamed and\n               Hung{-}yi Lee},\n  title     = {{SUPERB:} Speech processing Universal PERformance Benchmark},\n  journal   = {CoRR},\n  volume    = {abs/2105.01051},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2105.01051},\n  archivePrefix = {arXiv},\n  eprint    = {2105.01051},\n  timestamp = {Thu, 01 Jul 2021 13:30:22 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-01051.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182169", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Babelscape/rebel-dataset", "sha": "5b70713c4cca19c341b62b01811c834ee60a33f2", "lastModified": "2023-06-15T12:12:59.000Z", "tags": ["task_categories:text-retrieval", "task_categories:text-generation", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "relation-extraction", "conditional-text-generation", "arxiv:2005.00614", "region:us"], "private": false, "author": "Babelscape", "description": "REBEL is a silver dataset created for the paper REBEL: Relation Extraction By End-to-end Language generation", "citation": "    @inproceedings{huguet-cabot-navigli-2021-rebel,\n    title = \"REBEL: Relation Extraction By End-to-end Language generation\",\n    author = \"Huguet Cabot, Pere-Llu{\\'\\i}s  and\n      Navigli, Roberto\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2021\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and in the Barcel\u00f3 B\u00e1varo Convention Centre, Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://github.com/Babelscape/rebel/blob/main/docs/EMNLP_2021_REBEL__Camera_Ready_.pdf\",\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1821bc", "disabled": false, "gated": false, "likes": 15, "downloads": 393, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Lacito/pangloss", "sha": "f80e65ea3922bfab04afe8f4a07a8ab16bd81553", "lastModified": "2022-09-06T18:02:34.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "source_datasets:original", "language:jya", "language:nru", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "Lacito", "description": "These datasets are extracts from the Pangloss collection and have\nbeen preprocessed for ASR experiments in Na and Japhug.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1821d2", "disabled": false, "gated": false, "likes": 3, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "TheBritishLibrary/EThOS-PhD-metadata", "sha": "66bfd05a6720c6eb0d274779cec9b0632622c682", "lastModified": "2022-07-23T21:14:57.000Z", "tags": ["task_categories:text-classification", "task_categories:fill-mask", "task_ids:multi-label-classification", "task_ids:masked-language-modeling", "multilinguality:monolingual", "language:en", "region:us"], "private": false, "author": "TheBritishLibrary", "description": "The data in this collection comprises the bibliographic metadata for all UK doctoral theses listed in EThOS, the UK's national thesis service.\nWe estimate the data covers around 98% of all PhDs ever awarded by UK Higher Education institutions, dating back to 1787.\nThesis metadata from every PhD-awarding university in the UK is included.", "citation": "\\ \n@misc{british library_genre,\ntitle={UK Doctoral Thesis Metadata from EThOS},\nurl={UK Doctoral Thesis Metadata from EThOS},\nauthor={{British Library} and  {Rosie, Heather}},\nyear={2021}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1821f2", "disabled": false, "gated": false, "likes": 1, "downloads": 422, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "CAiRE/ASCEND", "sha": "b966160952fc5fe9cb036f098dd44f135d5c6f20", "lastModified": "2022-10-24T12:43:58.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:zh", "license:cc-by-sa-4.0", "speech-recognition", "code-switching", "arxiv:2112.06223", "region:us"], "private": false, "author": "CAiRE", "description": "ASCEND (A Spontaneous Chinese-English Dataset) introduces a high-quality resource of spontaneous multi-turn conversational dialogue Chinese-English code-switching corpus collected in Hong Kong. ASCEND consists of 10.62 hours of spontaneous speech with a total of ~12.3K utterances. The corpus is split into 3 sets: training, validation, and test with a ratio of 8:1:1 while maintaining a balanced gender proportion on each set.", "citation": "@inproceedings{lovenia2021ascend,\n  title     = {ASCEND: A Spontaneous Chinese-English Dataset for Code-switching in Multi-turn Conversation},\n  author    = {Lovenia, Holy and Cahyawijaya, Samuel and Winata, Genta Indra and Xu, Peng and Yan, Xu and Liu, Zihan and Frieske, Rita and Yu, Tiezheng and Dai, Wenliang and Barezi, Elham J and others},\n  booktitle = {Proceedings of the International Conference on Language Resources and Evaluation, {LREC} 2022, 20-25 June 2022, Lu Palais du Pharo, France},\n  publisher = {European Language Resources Association},\n  year      = {2022},\n  pages = {}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1821fc", "disabled": false, "gated": false, "likes": 10, "downloads": 312, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "CodedotAI/code_clippy", "sha": "9cca1f325b9f97066a2306b17e24f7d24ac9d42a", "lastModified": "2022-11-17T19:54:28.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:gpl-3.0", "arxiv:2107.03374", "region:us"], "private": false, "author": "CodedotAI", "description": "This dataset was generated by selecting GitHub repositories from a large collection of repositories. These repositories were collected from https://seart-ghs.si.usi.ch/ and Github portion of [The Pile](https://github.com/EleutherAI/github-downloader) (performed on July 7th, 2021). The goal of this dataset is to provide a training set for pretraining large language models on code data for helping software engineering researchers better understand their impacts on software related tasks such as autocompletion of code. The dataset is split into train, validation, and test splits. There is a version containing duplicates (209GBs compressed) and ones where exact duplicates (132GBs compressed) are removed. Contains mostly JavaScript and Python code, but other programming languages are included as well to various degrees.", "citation": "@misc{cooper-2021-code-clippy-data,\n    author       = {Nathan Coooper, Artashes Arutiunian, Santiago Hincapi\u00e9-Potes, Ben Trevett, Arun Raja, Erfan Hossami, Mrinal Mathur, and contributors},\n    title        = {{Code Clippy Data: A large dataset of code data from Github for research into code language models}},\n    month        = jul,\n    year         = 2021,\n    version      = {1.0},\n    publisher    = {GitHub},\n    url          = {https://github.com/ncoop57/gpt-code-clippy}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182237", "disabled": false, "gated": false, "likes": 10, "downloads": 144, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "CodedotAI/code_clippy_github", "sha": "cf9f33dec640f45228f8f3f5e6a7899a37f5f83e", "lastModified": "2022-08-05T02:57:36.000Z", "tags": ["task_ids:language-modeling", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "language:code", "license:mit", "arxiv:2107.03374", "region:us"], "private": false, "author": "CodedotAI", "description": "The Code Clippy dataset consists of various public codebases from GitHub in 22 programming languages with 23 extensions     totalling about 16 TB of data when uncompressed. The dataset was created from the public GitHub dataset on Google BiqQuery.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182239", "disabled": false, "gated": false, "likes": 10, "downloads": 885, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "EMBO/biolang", "sha": "84b6def89e2a005c47b88e66d06b312c4f2880d4", "lastModified": "2023-01-11T15:31:53.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n>1M", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "EMBO", "description": "This dataset is based on abstracts from the open access section of EuropePubMed Central to train language models in the domain of biology.", "citation": "@Unpublished{\n    huggingface: dataset,\n    title = {biolang},\n    authors={Thomas Lemberger, EMBO},\n    year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1822b2", "disabled": false, "gated": false, "likes": 0, "downloads": 718, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "EMBO/sd-nlp", "sha": "57e2a4a23b36d518584a1f1266a4d6ad3348b8a5", "lastModified": "2022-10-21T15:34:09.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:named-entity-recognition", "task_ids:parsing", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "EMBO", "description": "    This dataset is based on the SourceData database and is intented to facilitate training of NLP tasks in the cell and molecualr biology domain.", "citation": "    @Unpublished{\n        huggingface: dataset,\n        title = {SourceData NLP},\n        authors={Thomas Lemberger, EMBO},\n        year={2021}\n    }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1822b3", "disabled": false, "gated": false, "likes": 0, "downloads": 839, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "FRTNX/cosuju", "sha": "10630a174f51f76f6a5fff8ccd60a92d261f5c7b", "lastModified": "2021-03-29T09:01:41.000Z", "tags": ["region:us"], "private": false, "author": "FRTNX", "description": "Court Summaries and Judgements (CoSuJu) Dataset", "citation": "@InProceedings{huggingface:dataset,\ntitle   = {CoSuJu 500+ Court Judegements and Summaries for Machine Text Summarization},\nauthors = {Busani Ndlovu, Luke Jordan},\nyear    = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1822e1", "disabled": false, "gated": false, "likes": 0, "downloads": 419, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Felix-ML/quoteli3", "sha": "a8e3cae5b222602746835ca60d9542ac1b42fc43", "lastModified": "2022-10-25T08:54:20.000Z", "tags": ["multilinguality:monolingual", "size_categories:1K<n<10K", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "Felix-ML", "description": "This dataset is a representation of Muzny et al.'s QuoteLi3 dataset as a Huggingface dataset. It can be best used for \nquote attribution.", "citation": "@inproceedings{muzny2017two,\n  title={A two-stage sieve approach for quote attribution},\n  author={Muzny, Grace and Fang, Michael and Chang, Angel and Jurafsky, Dan},\n  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},\n  pages={460--470},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1822ec", "disabled": false, "gated": false, "likes": 0, "downloads": 145, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Firoj/HumAID", "sha": "6ae265697cb5e7d7bde15a79a51a25bae9b92758", "lastModified": "2022-05-18T04:45:03.000Z", "tags": ["region:us"], "private": false, "author": "Firoj", "description": "The HumAID Twitter dataset consists of several thousands of manually annotated tweets that has been collected during 19 major natural disaster events including earthquakes, hurricanes, wildfires, and floods, which happened from 2016 to 2019 across different parts of the World. The annotations in the provided datasets consists of following humanitarian categories. The dataset consists only english tweets and it is the largest dataset for crisis informatics so far.\n** Humanitarian categories **\n- Caution and advice\n- Displaced people and evacuations\n- Dont know cant judge\n- Infrastructure and utility damage\n- Injured or dead people\n- Missing or found people\n- Not humanitarian\n- Other relevant information\n- Requests or urgent needs\n- Rescue volunteering or donation effort\n- Sympathy and support", "citation": "@inproceedings{humaid2020,\nAuthor = {Firoj Alam, Umair Qazi, Muhammad Imran, Ferda Ofli},\nbooktitle={Proceedings of the Fifteenth International AAAI Conference on Web and Social Media},\nseries={ICWSM~'21},\nKeywords = {Social Media, Crisis Computing, Tweet Text Classification, Disaster Response},\nTitle = {HumAID: Human-Annotated Disaster Incidents Data from Twitter},\nYear = {2021},\npublisher={AAAI},\naddress={Online},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18230d", "disabled": false, "gated": false, "likes": 2, "downloads": 293, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/mnist-text-default", "sha": "79f97a8d8943cabb0127b0e97d6c25afdb6887fb", "lastModified": "2021-02-22T10:48:20.000Z", "tags": ["region:us"], "private": false, "author": "Fraser", "description": "MNIST dataset adapted to a text-based representation.\n\nThis allows testing interpolation quality for Transformer-VAEs.\n\nSystem is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n\nWorks by quantising each MNIST pixel into one of 64 characters.\nEvery sample has an up & down version to encourage the model to learn rotation invarient features.\n\nUse `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n\nData format:\n- text: (30 x 28 tokens, 840 tokens total): Textual representation of MNIST digit, for example:\n```\n00 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n01 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n02 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n03 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n04 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n05 down ! ! ! ! ! ! ! ! ! ! ! ! ! % % % @ C L ' J a ^ @ ! ! ! !\n06 down ! ! ! ! ! ! ! ! ( * 8 G K ` ` ` ` ` Y L ` ] Q 1 ! ! ! !\n07 down ! ! ! ! ! ! ! - \\ ` ` ` ` ` ` ` ` _ 8 5 5 / * ! ! ! ! !\n08 down ! ! ! ! ! ! ! % W ` ` ` ` ` R N ^ ] ! ! ! ! ! ! ! ! ! !\n09 down ! ! ! ! ! ! ! ! 5 H ; ` ` T # ! + G ! ! ! ! ! ! ! ! ! !\n10 down ! ! ! ! ! ! ! ! ! $ ! G ` 7 ! ! ! ! ! ! ! ! ! ! ! ! ! !\n11 down ! ! ! ! ! ! ! ! ! ! ! C ` P ! ! ! ! ! ! ! ! ! ! ! ! ! !\n12 down ! ! ! ! ! ! ! ! ! ! ! # P ` 2 ! ! ! ! ! ! ! ! ! ! ! ! !\n13 down ! ! ! ! ! ! ! ! ! ! ! ! ) ] Y I < ! ! ! ! ! ! ! ! ! ! !\n14 down ! ! ! ! ! ! ! ! ! ! ! ! ! 5 ] ` ` > ' ! ! ! ! ! ! ! ! !\n15 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! , O ` ` F ' ! ! ! ! ! ! ! !\n16 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! % 8 ` ` O ! ! ! ! ! ! ! !\n17 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! _ ` _ 1 ! ! ! ! ! ! !\n18 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! , A N ` ` T ! ! ! ! ! ! ! !\n19 down ! ! ! ! ! ! ! ! ! ! ! ! * F Z ` ` ` _ N ! ! ! ! ! ! ! !\n20 down ! ! ! ! ! ! ! ! ! ! ' = X ` ` ` ` S 4 ! ! ! ! ! ! ! ! !\n21 down ! ! ! ! ! ! ! ! & 1 V ` ` ` ` R 5 ! ! ! ! ! ! ! ! ! ! !\n22 down ! ! ! ! ! ! % K W ` ` ` ` Q 5 # ! ! ! ! ! ! ! ! ! ! ! !\n23 down ! ! ! ! . L Y ` ` ` ` ^ B # ! ! ! ! ! ! ! ! ! ! ! ! ! !\n24 down ! ! ! ! C ` ` ` V B B % ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n25 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n26 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n27 down ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n```\n- label: Just a number with the texts matching label.", "citation": "@dataset{dataset,\n    author = {Fraser Greenlee},\n    year = {2021},\n    month = {1},\n    pages = {},\n    title = {MNIST text dataset.},\n    doi = {}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182314", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/mnist-text-no-spaces", "sha": "afa87a25d2d1e91a07e36508125359b66de9f909", "lastModified": "2021-02-05T16:03:35.000Z", "tags": ["region:us"], "private": false, "author": "Fraser", "description": "MNIST dataset adapted to a text-based representation.\n\nThis allows testing interpolation quality for Transformer-VAEs.\n\nSystem is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n\nWorks by quantising each MNIST pixel into one of 64 characters.\nEvery sample has an up & down version to encourage the model to learn rotation invarient features.\n\nUse `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n\nRemoved spaces to get better BPE compression on sequences.\n**Should only be used with a trained tokenizer.**\n\nData format:\n- text: (30 x 28 tokens, 840 tokens total): Textual representation of MNIST digit, for example:\n```\n00down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n01down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n02down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n03down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n04down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n05down!!!!!!!!!!!!!%%%@CL'Ja^@!!!!\n06down!!!!!!!!(*8GK`````YL`]Q1!!!!\n07down!!!!!!!-\\\\````````_855/*!!!!!\n08down!!!!!!!%W`````RN^]!!!!!!!!!!\n09down!!!!!!!!5H;``T#!+G!!!!!!!!!!\n10down!!!!!!!!!$!G`7!!!!!!!!!!!!!!\n11down!!!!!!!!!!!C`P!!!!!!!!!!!!!!\n12down!!!!!!!!!!!#P`2!!!!!!!!!!!!!\n13down!!!!!!!!!!!!)]YI<!!!!!!!!!!!\n14down!!!!!!!!!!!!!5]``>'!!!!!!!!!\n15down!!!!!!!!!!!!!!,O``F'!!!!!!!!\n16down!!!!!!!!!!!!!!!%8``O!!!!!!!!\n17down!!!!!!!!!!!!!!!!!_`_1!!!!!!!\n18down!!!!!!!!!!!!!!,AN``T!!!!!!!!\n19down!!!!!!!!!!!!*FZ```_N!!!!!!!!\n20down!!!!!!!!!!'=X````S4!!!!!!!!!\n21down!!!!!!!!&1V````R5!!!!!!!!!!!\n22down!!!!!!%KW````Q5#!!!!!!!!!!!!\n23down!!!!.LY````^B#!!!!!!!!!!!!!!\n24down!!!!C```VBB%!!!!!!!!!!!!!!!!\n25down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n26down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n27down!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n```\n- label: Just a number with the texts matching label.", "citation": "@dataset{dataset,\n    author = {Fraser Greenlee},\n    year = {2021},\n    month = {2},\n    pages = {},\n    title = {MNIST text dataset (no spaces).},\n    doi = {}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182315", "disabled": false, "gated": false, "likes": 1, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/mnist-text-small", "sha": "da9c9262c1b62f55a948a194cba107448a7575c1", "lastModified": "2021-02-22T10:21:37.000Z", "tags": ["region:us"], "private": false, "author": "Fraser", "description": "MNIST dataset adapted to a text-based representation.\n\n*Modified images to be ~1/4 the original area.*\nDone by taking a max pool.\n\nThis allows testing interpolation quality for Transformer-VAEs.\n\nSystem is heavily inspired by Matthew Rayfield's work https://youtu.be/Z9K3cwSL6uM\n\nWorks by quantising each MNIST pixel into one of 64 characters.\nEvery sample has an up & down version to encourage the model to learn rotation invarient features.\n\nUse `.array_to_text(` and `.text_to_array(` methods to test your generated data.\n\nData format:\n- text: (16 x 14 tokens, 224 tokens total): Textual representation of MNIST digit, for example:\n```\n00 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n01 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n02 down ! ! ! ! ! ! % % C L a ^ ! !\n03 down ! ! ! - ` ` ` ` ` Y ` Q ! !\n04 down ! ! ! % ` ` ` R ^ ! ! ! ! !\n05 down ! ! ! ! $ G ` ! ! ! ! ! ! !\n06 down ! ! ! ! ! # ` Y < ! ! ! ! !\n07 down ! ! ! ! ! ! 5 ` ` F ! ! ! !\n08 down ! ! ! ! ! ! ! % ` ` 1 ! ! !\n09 down ! ! ! ! ! ! F ` ` ` ! ! ! !\n10 down ! ! ! ! 1 ` ` ` ` 4 ! ! ! !\n11 down ! ! L ` ` ` ` 5 ! ! ! ! ! !\n12 down ! ! ` ` V B ! ! ! ! ! ! ! !\n13 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n```\n- label: Just a number with the texts matching label.", "citation": "@dataset{dataset,\n    author = {Fraser Greenlee},\n    year = {2021},\n    month = {1},\n    pages = {},\n    title = {MNIST small text dataset.},\n    doi = {}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182316", "disabled": false, "gated": false, "likes": 0, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/python-lines", "sha": "c1dd899291e00d83b4eecc9b1e02ae64b809ee2c", "lastModified": "2021-02-22T10:20:34.000Z", "tags": ["region:us"], "private": false, "author": "Fraser", "description": "Dataset of single lines of Python code taken from the [CodeSearchNet](https://github.com/github/CodeSearchNet) dataset.\n\nContext\n\nThis dataset allows checking the validity of Variational-Autoencoder latent spaces by testing what percentage of random/intermediate latent points can be greedily decoded into valid Python code.\n\nContent\n\nEach row has a parsable line of source code.\n{'text': '{python source code line}'}\n\nMost lines are < 100 characters while all are under 125 characters.\n\nContains 2.6 million lines.\n\nAll code is in parsable into a python3 ast.", "citation": "@dataset{dataset,\n    author = {Fraser Greenlee},\n    year = {2020},\n    month = {12},\n    pages = {},\n    title = {Python single line dataset.},\n    doi = {}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182319", "disabled": false, "gated": false, "likes": 1, "downloads": 289, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/python-state-changes", "sha": "ef06b5d8cf560595e3812cff361f8c9be35714cd", "lastModified": "2022-10-11T17:04:35.000Z", "tags": ["language:code", "region:us"], "private": false, "author": "Fraser", "description": "Python state changes from a single line of code.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18231a", "disabled": false, "gated": false, "likes": 6, "downloads": 484, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Fraser/short-jokes", "sha": "114769d1463bf9e45744be2b729b39dd06ded2c1", "lastModified": "2021-02-24T08:31:31.000Z", "tags": ["region:us"], "private": false, "author": "Fraser", "description": "Copy of [Kaggle dataset](https://www.kaggle.com/abhinavmoudgil95/short-jokes), adding to Huggingface for ease of use.\n\nDescription from Kaggle:\n\nContext\n\nGenerating humor is a complex task in the domain of machine learning, and it requires the models to understand the deep semantic meaning of a joke in order to generate new ones. Such problems, however, are difficult to solve due to a number of reasons, one of which is the lack of a database that gives an elaborate list of jokes. Thus, a large corpus of over 0.2 million jokes has been collected by scraping several websites containing funny and short jokes.\n\nVisit my Github repository for more information regarding collection of data and the scripts used.\n\nContent\n\nThis dataset is in the form of a csv file containing 231,657 jokes. Length of jokes ranges from 10 to 200 characters. Each line in the file contains a unique ID and joke.\n\nDisclaimer\n\nIt has been attempted to keep the jokes as clean as possible. Since the data has been collected by scraping websites, it is possible that there may be a few jokes that are inappropriate or offensive to some people.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18231b", "disabled": false, "gated": false, "likes": 5, "downloads": 454, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/ART", "sha": "8fbd9eb015c80542700c19c2e0d8ee023f8431f5", "lastModified": "2022-10-24T13:01:25.000Z", "tags": ["task_categories:other", "annotations_creators:automatically-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:apache-2.0", "reasoning", "arxiv:1908.05739", "arxiv:1906.05317", "region:us"], "private": false, "author": "GEM", "description": "the Abductive Natural Language Generation Dataset from AI2", "citation": "@InProceedings{anli,\n  author = {Chandra, Bhagavatula and Ronan, Le Bras and Chaitanya, Malaviya and Keisuke, Sakaguchi and Ari, Holtzman\n    and Hannah, Rashkin and Doug, Downey and Scott, Wen-tau Yih and Yejin, Choi},\n  title = {Abductive Commonsense Reasoning},\n  year = {2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182326", "disabled": false, "gated": false, "likes": 3, "downloads": 320, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/BiSECT", "sha": "875b884d264ba3b0e7657432b8e963e1acefd723", "lastModified": "2022-09-02T21:58:17.000Z", "tags": ["annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:de", "language:en", "language:fr", "language:es", "license:other", "region:us"], "private": false, "author": "GEM", "description": "BiSECT is a Split and Rephrase corpus created via bilingual pivoting.", "citation": "@inproceedings{kim-etal-2021-bisect,\n    title = \"{B}i{SECT}: Learning to Split and Rephrase Sentences with Bitexts\",\n    author = \"Kim, Joongwon  and\n      Maddela, Mounica  and\n      Kriz, Reno  and\n      Xu, Wei  and\n      Callison-Burch, Chris\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.500\",\n    pages = \"6193--6209\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182327", "disabled": false, "gated": false, "likes": 2, "downloads": 724, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/CrossWOZ", "sha": "0c6f57946a15c70c44b28b81ae5fad9558abae01", "lastModified": "2022-10-24T15:29:55.000Z", "tags": ["task_categories:conversational", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:zh", "license:apache-2.0", "dialog-response-generation", "region:us"], "private": false, "author": "GEM", "description": "CrossWOZ is the first large-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It contains 6K dialogue sessions and 102K utterances for 5 domains, including hotel, restaurant, attraction, metro, and taxi. Moreover, the corpus contains rich annotation of dialogue states and dialogue acts at both user and system sides.", "citation": "@article{zhu2020crosswoz,\n  author = {Qi Zhu and Kaili Huang and Zheng Zhang and Xiaoyan Zhu and Minlie Huang},\n  title = {Cross{WOZ}: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset},\n  journal = {Transactions of the Association for Computational Linguistics},\n  year = {2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182328", "disabled": false, "gated": false, "likes": 5, "downloads": 289, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/RiSAWOZ", "sha": "d9287b21928a811281a349655655ee4be964292a", "lastModified": "2022-10-24T15:30:01.000Z", "tags": ["task_categories:conversational", "annotations_creators:crowd-sourced", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:zh", "license:cc-by-4.0", "dialog-response-generation", "region:us"], "private": false, "author": "GEM", "description": "RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets.Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively.", "citation": "@inproceedings{quan-etal-2020-risawoz,\n    title = \"{R}i{SAWOZ}: A Large-Scale Multi-Domain {W}izard-of-{O}z Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling\",\n    author = \"Quan, Jun  and\n      Zhang, Shian  and\n      Cao, Qian  and\n      Li, Zizhong  and\n      Xiong, Deyi\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.67\",\n    pages = \"930--940\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232a", "disabled": false, "gated": false, "likes": 5, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/RotoWire_English-German", "sha": "4d297ffc7cffbb280b7b4cc8dbc60ba35fa2b1b9", "lastModified": "2022-10-24T15:30:03.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:automatically-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "language:de", "license:cc-by-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "Dataset for the WNGT 2019 DGT shared task on \"Document-Level Generation and Translation\u201d.", "citation": "@article{hayashi2019findings,\n  title={Findings of the Third Workshop on Neural Generation and Translation},\n  author={Hayashi, Hiroaki and Oda, Yusuke and Birch, Alexandra and Konstas, Ioannis and Finch, Andrew and Luong, Minh-Thang and Neubig, Graham and Sudoh, Katsuhito},\n  journal={EMNLP-IJCNLP 2019},\n  pages={1},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232b", "disabled": false, "gated": false, "likes": 2, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/SIMPITIKI", "sha": "399cf2a6baa63c6f96a57b464f89023f19d046f2", "lastModified": "2022-10-24T15:30:05.000Z", "tags": ["task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:crowd-sourced", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:it", "license:cc-by-4.0", "region:us"], "private": false, "author": "GEM", "description": "SIMPITIKI is a Simplification corpus for Italian and it consists of two sets of simplified pairs: the first one is harvested from the Italian Wikipedia in a semi-automatic way; the second one is manually annotated sentence-by-sentence from documents in the administrative domain.", "citation": "@article{tonelli2016simpitiki,\n  title={SIMPITIKI: a Simplification corpus for Italian},\n  author={Tonelli, Sara and Aprosio, Alessio Palmero and Saltori, Francesca},\n  journal={Proceedings of CLiC-it},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232c", "disabled": false, "gated": false, "likes": 2, "downloads": 143, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/SciDuet", "sha": "23c4a628af8312f25fe40efcc094d6502d1198e8", "lastModified": "2022-10-24T15:30:06.000Z", "tags": ["task_categories:other", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:apache-2.0", "text-to-slide", "region:us"], "private": false, "author": "GEM", "description": "SciDuet is the first publicaly available dataset for the challenging task of document2slides generation,\nThe dataset integrated into GEM is the ACL portion of the whole dataset described in \"https://aclanthology.org/2021.naacl-main.111.pdf\".\nIt contains the full Dev and Test sets, and a portion of the Train dataset. \nWe additionally create a challenge dataset in which the slide titles do not match with the \nsection headers of the corresponding paper.\nNote that although we cannot release the whole training dataset due to copyright issues, researchers can still \nuse our released data procurement code from https://github.com/IBM/document2slides\nto generate the training dataset from the online ICML/NeurIPS anthologies. \nIn the released dataset, the original papers and slides (both are in PDF format) are carefully processed by a combination of PDF/Image processing tookits.\nThe text contents from multiple slides that correspond to the same slide title are mreged.", "citation": "@inproceedings{sun-etal-2021-d2s,\n    title = \"{D}2{S}: Document-to-Slide Generation Via Query-Based Text Summarization\",\n    author = \"Sun, Edward  and\n      Hou, Yufang  and\n      Wang, Dakuo  and\n      Zhang, Yunfeng  and\n      Wang, Nancy X. R.\",\n    booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = June,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.naacl-main.111\",\n    doi = \"10.18653/v1/2021.naacl-main.111\",\n    pages = \"1405--1418\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232d", "disabled": false, "gated": false, "likes": 1, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/Taskmaster", "sha": "2298950c4ca70c9fdf8c34e4129b998704f4429a", "lastModified": "2022-10-24T15:30:09.000Z", "tags": ["task_categories:conversational", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-4.0", "dialog-response-generation", "arxiv:2012.12458", "region:us"], "private": false, "author": "GEM", "description": "The Taskmaster-3 (aka TicketTalk) dataset consists of 23,789 movie ticketing dialogs\n(located in Taskmaster/TM-3-2020/data/). By \"movie ticketing\" we mean conversations\nwhere the customer's goal is to purchase tickets after deciding on theater, time,\nmovie name, number of tickets, and date, or opt out of the transaction.\nThe columns are gem_id, 0, 1 for serial numbering, 2 for the text dialog and id\nfor the default id by the authors.", "citation": "@article{byrne2020tickettalk,\n  title={TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems},\n  author={Byrne, Bill and Krishnamoorthi, Karthik and Ganesh, Saravanan and Kale, Mihir Sanjay},\n  journal={arXiv preprint arXiv:2012.12458},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232e", "disabled": false, "gated": false, "likes": 1, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/cochrane-simplification", "sha": "75a92ae445171fa1b7641a229bfe3c77c0d8723d", "lastModified": "2022-10-24T15:30:10.000Z", "tags": ["task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "GEM", "description": "This dataset measures the ability for a model to simplify paragraphs of medical text through the omission non-salient information and simplification of medical jargon.", "citation": "@inproceedings{devaraj-etal-2021-paragraph,\n    title = \"Paragraph-level Simplification of Medical Texts\",\n    author = \"Devaraj, Ashwin  and\n      Marshall, Iain  and\n      Wallace, Byron  and\n      Li, Junyi Jessy\",\n    booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jun,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.naacl-main.395\",\n    doi = \"10.18653/v1/2021.naacl-main.395\",\n    pages = \"4972--4984\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18232f", "disabled": false, "gated": false, "likes": 4, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/common_gen", "sha": "586b0f50565225fbc748b0001a992d1672d62440", "lastModified": "2022-10-24T15:30:11.000Z", "tags": ["task_categories:other", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:mit", "reasoning", "arxiv:1911.03705", "arxiv:1910.13461", "arxiv:2009.12677", "arxiv:2012.00366", "arxiv:1910.10683", "arxiv:2006.08315", "region:us"], "private": false, "author": "GEM", "description": "CommonGen is a constrained text generation task, associated with a benchmark\ndataset, to explicitly test machines for the ability of generative commonsense\nreasoning. Given a set of common concepts; the task is to generate a coherent\nsentence describing an everyday scenario using these concepts.", "citation": "@inproceedings{lin-etal-2020-commongen,\n    title = \"{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning\",\n    author = \"Lin, Bill Yuchen  and\n      Zhou, Wangchunshu  and\n      Shen, Ming  and\n      Zhou, Pei  and\n      Bhagavatula, Chandra  and\n      Choi, Yejin  and\n      Ren, Xiang\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.findings-emnlp.165\",\n    pages = \"1823--1840\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182330", "disabled": false, "gated": false, "likes": 0, "downloads": 501, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/conversational_weather", "sha": "3cbe8a7f0b4e42f42e76c1922ef43e142cf51b78", "lastModified": "2022-10-24T15:30:13.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "The Conversational Weather dataset is designed for generation of responses to weather queries based on a structured input data. The input allows specifying data attributes such as dates, times, locations, weather conditions, and errors, and also offers control over structure of response through discourse relations such as join, contrast, and justification.", "citation": "@inproceedings{balakrishnan-etal-2019-constrained,\n  title = \"Constrained Decoding for Neural {NLG} from Compositional Representations in Task-Oriented Dialogue\",\n  author = \"Balakrishnan, Anusha  and\n    Rao, Jinfeng  and\n    Upasani, Kartikeya  and\n    White, Michael  and\n    Subba, Rajen\",\n  booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n  month = jul,\n  year = \"2019\",\n  address = \"Florence, Italy\",\n  publisher = \"Association for Computational Linguistics\",\n  url = \"https://www.aclweb.org/anthology/P19-1080\",\n  doi = \"10.18653/v1/P19-1080\",\n  pages = \"831--844\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182331", "disabled": false, "gated": false, "likes": 2, "downloads": 429, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/cs_restaurants", "sha": "e9cd3c2f515a919d0ca0734c4711e2f849c82036", "lastModified": "2022-10-24T15:30:14.000Z", "tags": ["task_categories:conversational", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:cs", "license:cc-by-sa-4.0", "dialog-response-generation", "region:us"], "private": false, "author": "GEM", "description": "The task is generating responses in the context of a (hypothetical) dialogue\nsystem that provides information about restaurants. The input is a basic\nintent/dialogue act type and a list of slots (attributes) and their values.\nThe output is a natural language sentence.", "citation": "@inproceedings{cs_restaurants,\n\taddress = {Tokyo, Japan},\n\ttitle = {Neural {Generation} for {Czech}: {Data} and {Baselines}},\n\tshorttitle = {Neural {Generation} for {Czech}},\n\turl = {https://www.aclweb.org/anthology/W19-8670/},\n\turldate = {2019-10-18},\n\tbooktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},\n\tauthor = {Du\u0161ek, Ond\u0159ej and Jur\u010d\u00ed\u010dek, Filip},\n\tmonth = oct,\n\tyear = {2019},\n\tpages = {563--574},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182332", "disabled": false, "gated": false, "likes": 1, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/dart", "sha": "0e97cc8d6efa6858ae6a510a2a65a37271ba1309", "lastModified": "2022-10-24T15:30:16.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:mit", "data-to-text", "arxiv:1910.13461", "arxiv:1908.09022", "arxiv:2007.02871", "arxiv:1709.00103", "arxiv:1706.09254", "arxiv:1810.01170", "region:us"], "private": false, "author": "GEM", "description": "DART is a large and open-domain structured DAta Record to Text generation corpus\nwith high-quality sentence annotations with each input being a set of\nentity-relation triples following a tree-structured ontology. It consists of\n82191 examples across different domains with each input being a semantic RDF\ntriple set derived from data records in tables and the tree ontology of table\nschema, annotated with sentence description that covers all facts in the triple set.", "citation": "@inproceedings{nan-etal-2021-dart,\n    title = \"{DART}: Open-Domain Structured Data Record to Text Generation\",\n    author = \"Nan, Linyong  and\n      Radev, Dragomir  and\n      Zhang, Rui  and\n      Rau, Amrit  and\n      Sivaprasad, Abhinand  and\n      Hsieh, Chiachun  and\n      Tang, Xiangru  and\n      Vyas, Aadit  and\n      Verma, Neha  and\n      Krishna, Pranav  and\n      Liu, Yangxiaokang  and\n      Irwanto, Nadia  and\n      Pan, Jessica  and\n      Rahman, Faiaz  and\n      Zaidi, Ahmad  and\n      Mutuma, Mutethia  and\n      Tarabar, Yasin  and\n      Gupta, Ankit  and\n      Yu, Tao  and\n      Tan, Yi Chern  and\n      Lin, Xi Victoria  and\n      Xiong, Caiming  and\n      Socher, Richard  and\n      Rajani, Nazneen Fatema\",\n    booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jun,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.naacl-main.37\",\n    doi = \"10.18653/v1/2021.naacl-main.37\",\n    pages = \"432--447\",\n    abstract = \"We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182333", "disabled": false, "gated": false, "likes": 0, "downloads": 463, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/e2e_nlg", "sha": "0e089c2ba61c3a0d183815c87c2c95e98fb446a6", "lastModified": "2022-10-24T15:30:18.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "The E2E dataset is designed for a limited-domain data-to-text task --\ngeneration of restaurant descriptions/recommendations based on up to 8 different\nattributes (name, area, price range etc.).", "citation": "@inproceedings{e2e_cleaned,\n\taddress = {Tokyo, Japan},\n\ttitle = {Semantic {Noise} {Matters} for {Neural} {Natural} {Language} {Generation}},\n\turl = {https://www.aclweb.org/anthology/W19-8652/},\n\tbooktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation} ({INLG} 2019)},\n\tauthor = {Du\u0161ek, Ond\u0159ej and Howcroft, David M and Rieser, Verena},\n\tyear = {2019},\n\tpages = {421--426},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182335", "disabled": false, "gated": false, "likes": 1, "downloads": 572, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/mlb_data_to_text", "sha": "f91b5cc190443a15488ca3d54d1e32c28d90c30b", "lastModified": "2022-10-24T15:30:20.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:other", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "The MLB dataset for data to text generation contains Major League Baseball games statistics and \ntheir human-written summaries.", "citation": "@inproceedings{puduppully-etal-2019-data,\n    title = \"Data-to-text Generation with Entity Modeling\",\n    author = \"Puduppully, Ratish  and\n      Dong, Li  and\n      Lapata, Mirella\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1195\",\n    doi = \"10.18653/v1/P19-1195\",\n    pages = \"2023--2035\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182337", "disabled": false, "gated": false, "likes": 1, "downloads": 312, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/mlsum", "sha": "8a22421bf1327ac793893604a8109d65da29eabf", "lastModified": "2022-10-24T15:30:21.000Z", "tags": ["task_categories:summarization", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:de", "language:es", "license:other", "region:us"], "private": false, "author": "GEM", "description": "This is the MLSUM subset of the GEM benchmark. MLSUM is the first large-scale MultiLingual SUMmarization dataset.\nObtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish.\nTogether with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community.\nWe report cross-lingual comparative analyses based on state-of-the-art systems.\nThese highlight existing biases which motivate the use of a multi-lingual dataset.", "citation": "@article{scialom2020mlsum,\n  title={MLSUM: The Multilingual Summarization Corpus},\n  author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},\n  journal={arXiv preprint arXiv:2004.14900},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182338", "disabled": false, "gated": false, "likes": 2, "downloads": 589, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/opusparcus", "sha": "9e9b1f8ef51616073f47f306f7f47dd91663f86a", "lastModified": "2022-10-24T15:30:22.000Z", "tags": ["task_categories:other", "annotations_creators:expert-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:de", "language:en", "language:fi", "language:fr", "language:ru", "language:sv", "license:cc-by-nc-4.0", "paraphrasing", "region:us"], "private": false, "author": "GEM", "description": "Opusparcus is a paraphrase corpus for six European languages: German,\nEnglish, Finnish, French, Russian, and Swedish. The paraphrases are\nextracted from the OpenSubtitles2016 corpus, which contains subtitles\nfrom movies and TV shows.", "citation": "@InProceedings{creutz:lrec2018,\n  title = {Open Subtitles Paraphrase Corpus for Six Languages},\n  author={Mathias Creutz},\n  booktitle={Proceedings of the 11th edition of the Language Resources\n  and Evaluation Conference (LREC 2018)},\n  year={2018},\n  month = {May 7-12},\n  address = {Miyazaki, Japan},\n  editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri\n  and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti\n  Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and\n  H\u00e9l\u00e8ne Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis\n  and Takenobu Tokunaga},\n  publisher = {European Language Resources Association (ELRA)},\n  isbn = {979-10-95546-00-9},\n  language = {english},\n  url={http://www.lrec-conf.org/proceedings/lrec2018/pdf/131.pdf}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182339", "disabled": false, "gated": false, "likes": 1, "downloads": 7656, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/schema_guided_dialog", "sha": "f272b927123ba5c2ead8db0b4437c2f8316b4704", "lastModified": "2022-10-24T15:30:26.000Z", "tags": ["task_categories:conversational", "annotations_creators:crowd-sourced", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "dialog-response-generation", "arxiv:1909.05855", "arxiv:2004.15006", "arxiv:2002.01359", "region:us"], "private": false, "author": "GEM", "description": "The Schema-Guided Dialogue (SGD) dataset contains 18K multi-domain task-oriented\ndialogues between a human and a virtual assistant, which covers 17 domains\nranging from banks and events to media, calendar, travel, and weather. The\nlanguage presents in the datset is only English. The SGD dataset provides a\nchallenging testbed for a number of tasks in task-oriented dialogue, including\nlanguage understanding, slot filling, dialogue state tracking and response\ngeneration. For the creation of the SGD dataset, they developed a multi-domain\ndialogue simulator that generates dialogue outlines over an arbitrary combination\nof APIs, dialogue states and system actions. Then, they used a crowd-sourcing\nprocedure to paraphrase these outlines to natural language utterances. This novel\ncrowd-sourcing procedure preserves all annotations obtained from the simulator and\ndoes not require any extra annotations after dialogue collection.", "citation": "@inproceedings{rastogi2020towards,\n  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},\n  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},\n  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},\n  volume={34},\n  number={05},\n  pages={8689--8696},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18233b", "disabled": false, "gated": false, "likes": 3, "downloads": 404, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/sportsett_basketball", "sha": "24aa031eecf0e19eb782cda91ea159de12dd131b", "lastModified": "2022-10-24T15:30:28.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:mit", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "SportSett:Basketball dataset for Data-to-Text Generation contains NBA games stats aligned with their human written summaries.", "citation": "@inproceedings{thomson-etal-2020-sportsett,\n    title = \"{S}port{S}ett:Basketball - A robust and maintainable data-set for Natural Language Generation\",\n    author = \"Thomson, Craig  and\n      Reiter, Ehud  and\n      Sripada, Somayajulu\",\n    booktitle = \"Proceedings of the Workshop on Intelligent Information Processing and Natural Language Generation\",\n    month = sep,\n    year = \"2020\",\n    address = \"Santiago de Compostela, Spain\",\n    publisher = \"Association for Computational Lingustics\",\n    url = \"https://aclanthology.org/2020.intellang-1.4\",\n    pages = \"32--40\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18233c", "disabled": false, "gated": false, "likes": 6, "downloads": 298, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/squad_v2", "sha": "67199807729e631955056c71c258b7acbee548a3", "lastModified": "2022-10-24T15:30:29.000Z", "tags": ["task_categories:other", "annotations_creators:crowd-sourced", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "question-generation", "arxiv:1806.03822", "region:us"], "private": false, "author": "GEM", "description": " SQuAD2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers\n to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but\n also determine when no answer is supported by the paragraph and abstain from answering.", "citation": "@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18233d", "disabled": false, "gated": false, "likes": 0, "downloads": 327, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/turku_hockey_data2text", "sha": "25220fbd8d12efac81f22ffa0e5dc919de34dd16", "lastModified": "2022-10-24T15:30:33.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:expert-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:fi", "license:cc-by-nc-sa-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "The Turku Hockey Data2Text corpus was developed as a benchmark for evaluating template-free, machine learning methods on Finnish news generation in the area of ice hockey reporting. This dataset is a collection of 3,454 ice hockey games, each including game statistics and a news article describing the game. Each game includes manual alignment of events (such as goals or penalties) and sentences describing the specific event in natural language extracted from the news article. The corpus includes 12,827 annotated events. The natural language passages are manually curated not to include any information not derivable from the input data or world knowledge.", "citation": "@inproceedings{kanerva2019newsgen,\n  Title = {Template-free Data-to-Text Generation of Finnish Sports News},\n  Author = {Jenna Kanerva and Samuel R{\\\"o}nnqvist and Riina Kekki and Tapio Salakoski and Filip Ginter},\n  booktitle = {Proceedings of the 22nd Nordic Conference on Computational Linguistics (NoDaLiDa\u201919)},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182340", "disabled": false, "gated": false, "likes": 0, "downloads": 412, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/turku_paraphrase_corpus", "sha": "0125222c79749bbe4caab3e480aa0f9373b5899e", "lastModified": "2022-10-24T15:29:45.000Z", "tags": ["task_categories:other", "annotations_creators:expert-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:fi", "license:cc-by-sa-4.0", "paraphrasing", "region:us"], "private": false, "author": "GEM", "description": "Turku Paraphrase Corpus is a dataset of 104,645 manually annotated Finnish paraphrases. The vast majority of the data is classified as a paraphrase either in the given context, or universally.", "citation": "@inproceedings{kanerva-etal-2021-finnish,\n  title = {Finnish Paraphrase Corpus},\n  author = {Kanerva, Jenna and Ginter, Filip and Chang, Li-Hsin and Rastas, Iiro and Skantsi, Valtteri and Kilpel\u00e4inen, Jemina and Kupari, Hanna-Mari and Saarni, Jenna and Sev\u00f3n, Maija and Tarkka, Otto},\n  booktitle = {Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa'21)},\n  year = {2021},\n  publisher = {Link\u00f6ping University Electronic Press, Sweden},\n  url = {https://aclanthology.org/2021.nodalida-main.29},\n  pages = {288--298}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182341", "disabled": false, "gated": false, "likes": 0, "downloads": 557, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/viggo", "sha": "c851cd5ff2ee92f0137fcf24014e37427a2d30b7", "lastModified": "2022-10-24T15:31:07.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "ViGGO was designed for the task of data-to-text generation in chatbots (as opposed to task-oriented dialogue systems), with target responses being more conversational than information-seeking, yet constrained to the information presented in a meaning representation. The dataset, being relatively small and clean, can also serve for demonstrating transfer learning capabilities of neural models.", "citation": "@inproceedings{juraska-etal-2019-viggo,\n    title = \"{V}i{GGO}: A Video Game Corpus for Data-To-Text Generation in Open-Domain Conversation\",\n    author = \"Juraska, Juraj  and\n      Bowden, Kevin  and\n      Walker, Marilyn\",\n    booktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\n    month = oct # \"{--}\" # nov,\n    year = \"2019\",\n    address = \"Tokyo, Japan\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W19-8623\",\n    doi = \"10.18653/v1/W19-8623\",\n    pages = \"164--172\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182343", "disabled": false, "gated": false, "likes": 14, "downloads": 1393, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/web_nlg", "sha": "1d41f28b06efb62d39cc83a0c00b231e825720fe", "lastModified": "2022-10-24T15:31:09.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "data-to-text", "region:us"], "private": false, "author": "GEM", "description": "WebNLG is a bi-lingual dataset (English, Russian) of parallel DBpedia triple sets\nand short texts that cover about 450 different DBpedia properties. The WebNLG data\nwas originally created to promote the development of RDF verbalisers able to\ngenerate short text and to handle micro-planning (i.e., sentence segmentation and\nordering, referring expression generation, aggregation); the goal of the task is\nto generate texts starting from 1 to 7 input triples which have entities in common\n(so the input is actually a connected Knowledge Graph). The dataset contains about\n17,000 triple sets and 45,000 crowdsourced texts in English, and 7,000 triples sets\nand 19,000 crowdsourced texts in Russian. A challenging test set section with\nentities and/or properties that have not been seen at training time is available.", "citation": "@inproceedings{castro-ferreira20:bilin-bi-direc-webnl-shared,\n  title={The 2020 Bilingual, Bi-Directional WebNLG+ Shared Task Overview and Evaluation Results (WebNLG+ 2020)},\n  author={Castro Ferreira, Thiago and\n                  Gardent, Claire and\n\t\t  Ilinykh, Nikolai and\n\t\t  van der Lee, Chris and\n\t\t  Mille, Simon and\n\t\t  Moussallem, Diego and\n\t\t  Shimorina, Anastasia},\n  booktitle = {Proceedings of the 3rd WebNLG Workshop on Natural Language Generation from the Semantic Web (WebNLG+ 2020)},\n    pages = \"55--76\",\n  year = \t 2020,\n  address = \t {Dublin, Ireland (Virtual)},\n  publisher = {Association for Computational Linguistics}}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182344", "disabled": false, "gated": false, "likes": 2, "downloads": 500, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/wiki_auto_asset_turk", "sha": "a7cc8c6bd2f5738386363dd48fb97dfbfd37da69", "lastModified": "2022-10-24T15:31:10.000Z", "tags": ["task_categories:text2text-generation", "task_ids:text-simplification", "annotations_creators:crowd-sourced", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:other", "arxiv:1910.02677", "arxiv:2005.00352", "region:us"], "private": false, "author": "GEM", "description": "WikiAuto provides a set of aligned sentences from English Wikipedia and Simple\nEnglish Wikipedia as a resource to train sentence simplification systems.\n\nThe authors first crowd-sourced a set of manual alignments between sentences in\na subset of the Simple English Wikipedia and their corresponding versions in\nEnglish Wikipedia (this corresponds to the manual config in this version of the\ndataset), then trained a neural CRF system to predict these alignments.\n\nThe trained alignment prediction model was then applied to the other articles in\nSimple English Wikipedia with an English counterpart to create a larger corpus\nof aligned sentences (corresponding to the auto and auto_acl configs here).", "citation": "@inproceedings{jiang-etal-2020-neural,\n    title = \"Neural {CRF} Model for Sentence Alignment in Text Simplification\",\n    author = \"Jiang, Chao  and\n      Maddela, Mounica  and\n      Lan, Wuwei  and\n      Zhong, Yang  and\n      Xu, Wei\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.709\",\n    doi = \"10.18653/v1/2020.acl-main.709\",\n    pages = \"7943--7960\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182345", "disabled": false, "gated": false, "likes": 3, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/wiki_cat_sum", "sha": "e732d1703eaad5b34a56370fd137b9d09921a94b", "lastModified": "2022-10-24T15:31:11.000Z", "tags": ["task_categories:summarization", "annotations_creators:automatically-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "arxiv:1906.04687", "arxiv:1801.10198", "arxiv:2009.07032", "region:us"], "private": false, "author": "GEM", "description": "Summarise the most important facts of a given entity in the Film, Company, and Animal domains from a cluster of related documents.", "citation": "@inproceedings{perez2019generating,\n  title={Generating Summaries with Topic Templates and Structured Convolutional Decoders},\n  author={Perez-Beltrachini, Laura and Liu, Yang and Lapata, Mirella},\n  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},\n  pages={5107--5116},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182346", "disabled": false, "gated": false, "likes": 3, "downloads": 1129, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/wiki_lingua", "sha": "af5d0f00b59a6933165c97b384f50d8b563c314d", "lastModified": "2023-02-16T09:23:29.000Z", "tags": ["task_categories:summarization", "annotations_creators:none", "language_creators:unknown", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:original", "language:ar", "language:cs", "language:de", "language:en", "language:es", "language:fr", "language:hi", "language:id", "language:it", "language:ja", "language:ko", "language:nl", "language:pt", "language:ru", "language:th", "language:tr", "language:vi", "language:zh", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": "GEM", "description": "WikiLingua is a large-scale multilingual dataset for the evaluation of\ncrosslingual abstractive summarization systems. The dataset includes ~770k\narticle and summary pairs in 18 languages from WikiHow. The gold-standard\narticle-summary alignments across languages was done by aligning the images\nthat are used to describe each how-to step in an article.", "citation": "@article{ladhak-wiki-2020,\n  title   = {WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\n  authors = {Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\n  journal = {arXiv preprint arXiv:2010.03093},\n  year    = {2020},\n  url     = {https://arxiv.org/abs/2010.03093}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182347", "disabled": false, "gated": false, "likes": 39, "downloads": 48906, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/xlsum", "sha": "b276583480e84c2cf2a17b306f0d1d1ccec546e3", "lastModified": "2022-10-24T15:31:33.000Z", "tags": ["task_categories:summarization", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:und", "license:cc-by-nc-sa-4.0", "arxiv:1607.01759", "region:us"], "private": false, "author": "GEM", "description": "We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally\nannotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics.\nThe dataset covers 45 languages ranging from low to high-resource, for many of which no\npublic dataset is currently available. XL-Sum is highly abstractive, concise,\nand of high quality, as indicated by human and intrinsic evaluation.", "citation": "@inproceedings{hasan-etal-2021-xl,\n    title = \"{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\",\n    author = \"Hasan, Tahmid  and\n      Bhattacharjee, Abhik  and\n      Islam, Md. Saiful  and\n      Mubasshir, Kazi  and\n      Li, Yuan-Fang  and\n      Kang, Yong-Bin  and\n      Rahman, M. Sohel  and\n      Shahriyar, Rifat\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.findings-acl.413\",\n    pages = \"4693--4703\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182348", "disabled": false, "gated": false, "likes": 3, "downloads": 10067, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GEM/xsum", "sha": "46dd444dde879b9ae7770f23d0d5496c4281da8e", "lastModified": "2022-10-24T15:31:30.000Z", "tags": ["task_categories:summarization", "annotations_creators:none", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "GEM", "description": "This is the XSUM subset of the GEM benchmark.", "citation": "@inproceedings{narayan-etal-2018-dont,\n    title = \"Don{'}t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization\",\n    author = \"Narayan, Shashi  and\n      Cohen, Shay B.  and\n      Lapata, Mirella\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D18-1206\",\n    doi = \"10.18653/v1/D18-1206\",\n    pages = \"1797--1807\",\n    abstract = \"We introduce {``}extreme summarization{''}, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question {``}What is the article about?{''}. We collect a real-world, large-scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article{'}s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures long-range dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182349", "disabled": false, "gated": false, "likes": 0, "downloads": 430, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Graphcore/gqa-lxmert", "sha": "23b17564a5d7728a9028a799e5fde07167611d1f", "lastModified": "2023-01-09T11:28:07.000Z", "tags": ["language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "Graphcore", "description": "GQA is a new dataset for real-world visual reasoning and compositional question answering,\nseeking to address key shortcomings of previous visual question answering (VQA) datasets.", "citation": "@inproceedings{hudson2019gqa,\n  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},\n  author={Hudson, Drew A and Manning, Christopher D},\n  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n  pages={6700--6709},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18238e", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Graphcore/vqa-lxmert", "sha": "07d470e8413557334a011dca15132bccca77b660", "lastModified": "2022-10-25T08:59:34.000Z", "tags": ["language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "Graphcore", "description": "VQA is a new dataset containing open-ended questions about images. \nThese questions require an understanding of vision, language and commonsense knowledge to answer.", "citation": "@inproceedings{antol2015vqa,\n  title={Vqa: Visual question answering},\n  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},\n  booktitle={Proceedings of the IEEE international conference on computer vision},\n  pages={2425--2433},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182390", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GroNLP/ik-nlp-22_pestyle", "sha": "50f82b9244b61d9e9ec68dea1e93669ce5ee617e", "lastModified": "2022-10-25T09:06:27.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:it", "license:other", "region:us"], "private": false, "author": "GroNLP", "description": "This dataset contains a sample of sentences taken from the FLORES-101 dataset that were either translated \nfrom scratch or post-edited from an existing automatic translation by three human translators. \nTranslation were performed for the English-Italian language pair, and translators' behavioral data \n(keystrokes, pauses, editing times) were collected using the PET platform.", "citation": "No citation information available.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182397", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GroNLP/ik-nlp-22_slp", "sha": "760fdc5d9fe699699025ff928ab6b5c631694238", "lastModified": "2023-02-01T18:25:21.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-retrieval", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "question-generation", "region:us"], "private": false, "author": "GroNLP", "description": "Paragraphs from the Speech and Language Processing book (3ed) by Jurafsky and Martin extracted semi-automatically\nfrom Chapters 2 to 11 of the original book draft.", "citation": "@book{slp3ed-iknlp2022,\n    author = {Jurafsky, Daniel and Martin, James},\n    year = {2021},\n    month = {12},\n    pages = {1--235, 1--19},\n    title = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},\n    volume = {3}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182398", "disabled": false, "gated": false, "likes": 0, "downloads": 422, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "GroNLP/ik-nlp-22_transqe", "sha": "a632c66397917c1494b0bb090e2b2fa0b7e98868", "lastModified": "2022-10-21T08:06:50.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:machine-generated", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|esnli", "language:en", "language:nl", "license:apache-2.0", "quality-estimation", "region:us"], "private": false, "author": "GroNLP", "description": "The e-SNLI dataset extends the Stanford Natural Language Inference Dataset to\ninclude human-annotated natural language explanations of the entailment\nrelations. This version includes an automatic translation to Dutch and two quality estimation annotations\nfor each translated field.", "citation": "@incollection{NIPS2018_8163,\ntitle = {e-SNLI: Natural Language Inference with Natural Language Explanations},\nauthor = {Camburu, Oana-Maria and Rockt\\\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},\nbooktitle = {Advances in Neural Information Processing Systems 31},\neditor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},\npages = {9539--9549},\nyear = {2018},\npublisher = {Curran Associates, Inc.},\nurl = {http://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182399", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "HUPD/hupd", "sha": "f570a84b03663180b6034c1f7f4c15864f94385e", "lastModified": "2022-10-24T15:47:30.000Z", "tags": ["task_categories:fill-mask", "task_categories:summarization", "task_categories:text-classification", "task_categories:token-classification", "task_ids:masked-language-modeling", "task_ids:multi-class-classification", "task_ids:topic-classification", "task_ids:named-entity-recognition", "language:en", "license:cc-by-sa-4.0", "patents", "arxiv:2207.04043", "region:us"], "private": false, "author": "HUPD", "description": "The Harvard USPTO Patent Dataset (HUPD) is a large-scale, well-structured, and multi-purpose corpus \nof English-language patent applications filed to the United States Patent and Trademark Office (USPTO) \nbetween 2004 and 2018. With more than 4.5 million patent documents, HUPD is two to three times larger \nthan comparable corpora. Unlike other NLP patent datasets, HUPD contains the inventor-submitted versions \nof patent applications, not the final versions of granted patents, allowing us to study patentability at \nthe time of filing using NLP methods for the first time.", "citation": "@InProceedings{suzgun2021:hupd,\ntitle = {The Harvard USPTO Patent Dataset},\nauthors={Mirac Suzgun and Suproteem Sarkar and Luke Melas-Kyriazi and Scott Kominers and Stuart Shieber},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1823af", "disabled": false, "gated": false, "likes": 20, "downloads": 1057, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Helsinki-NLP/tatoeba_mt", "sha": "9635372e5421ccacda7db58e88741617867a9204", "lastModified": "2022-10-21T15:50:25.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:translation", "size_categories:unknown", "source_datasets:original", "language:af", "language:ar", "language:az", "language:be", "language:bg", "language:bn", "language:br", "language:bs", "language:ca", "language:ch", "language:cs", "language:cv", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fo", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:io", "language:is", "language:it", "language:ja", "language:jv", "language:ka", "language:kk", "language:km", "language:ko", "language:ku", "language:kw", "language:la", "language:lb", "language:lt", "language:lv", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:nb", "language:nl", "language:nn", "language:no", "language:oc", "language:pl", "language:pt", "language:qu", "language:rn", "language:ro", "language:ru", "language:sh", "language:sl", "language:sq", "language:sr", "language:sv", "language:sw", "language:ta", "language:te", "language:th", "language:tk", "language:tl", "language:tr", "language:tt", "language:ug", "language:uk", "language:ur", "language:uz", "language:vi", "language:vo", "language:yi", "language:zh", "license:cc-by-2.0", "region:us"], "private": false, "author": "Helsinki-NLP", "description": "The Tatoeba Translation Challenge is a multilingual data set of\nmachine translation benchmarks derived from user-contributed\ntranslations collected by [Tatoeba.org](https://tatoeba.org/) and\nprovided as parallel corpus from [OPUS](https://opus.nlpl.eu/). This\ndataset includes test and development data sorted by language pair. It\nincludes test sets for hundreds of language pairs and is continuously\nupdated. Please, check the version number tag to refer to the release\nthat your are using.", "citation": "@inproceedings{tiedemann-2020-tatoeba,\n    title = \"The {T}atoeba {T}ranslation {C}hallenge {--} {R}ealistic Data Sets for Low Resource and Multilingual {MT}\",\n    author = {Tiedemann, J{\\\"o}rg},\n    booktitle = \"Proceedings of the Fifth Conference on Machine Translation\",\n    month = nov,\n    year = \"2020\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.wmt-1.139\",\n    pages = \"1174--1182\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1823d1", "disabled": false, "gated": false, "likes": 41, "downloads": 119737, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "KBLab/sucx3_ner", "sha": "96acc4fd6dad4b6f9a133cca1efa4dedb07a8b99", "lastModified": "2022-10-25T06:13:36.000Z", "tags": ["task_categories:other", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:sv", "license:cc-by-4.0", "structure-prediction", "region:us"], "private": false, "author": "KBLab", "description": "    The dataset is a conversion of the venerable SUC 3.0 dataset into the\n    huggingface ecosystem. The original dataset does not contain an official\n    train-dev-test split, which is introduced here; the tag distribution for the\n    NER tags between the three splits is mostly the same.\n    \n    The dataset has three different types of tagsets: manually annotated POS,\n    manually annotated NER, and automatically annotated NER. For the\n    automatically annotated NER tags, only sentences were chosen, where the\n    automatic and manual annotations would match (with their respective\n    categories).\n    \n    Additionally we provide remixes of the same data with some or all sentences\n    being lowercased.", "citation": "@article{gustafson2006documentation,\n  title={Documentation of the Stockholm-Ume{\\aa} Corpus},\n  author={Gustafson-Capkov{\\'a}, Sofia and Hartmann, Britt},\n  journal={Stockholm University: Department of Linguistics},\n  year={2006}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18248d", "disabled": false, "gated": false, "likes": 5, "downloads": 974, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "KETI-AIR/nikl", "sha": "2c9acc3b070e6888337eacb0057f25571b78ca1c", "lastModified": "2021-06-08T06:42:34.000Z", "tags": ["region:us"], "private": false, "author": "KETI-AIR", "description": "Description is **formatted** as markdown.\n\nIt should also contain any processing which has been applied (if any),\n(e.g. corrupted example skipped, images cropped,...):", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182494", "disabled": false, "gated": false, "likes": 1, "downloads": 147, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "KTH/nst", "sha": "c32c46a4b84206c99a46ab2e6d4938d4e3cd14dd", "lastModified": "2023-09-05T14:29:06.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:sv", "license:cc0-1.0", "region:us"], "private": false, "author": "KTH", "description": "This database was created by Nordic Language Technology for the development of automatic speech recognition and dictation in Swedish. In this updated version, the organization of the data have been altered to improve the usefulness of the database.\n\nIn the original version of the material, the files were organized in a specific folder structure where the folder names were meaningful. However, the file names were not meaningful, and there were also cases of files with identical names in different folders. This proved to be impractical, since users had to keep the original folder structure in order to use the data. The files have been renamed, such that the file names are unique and meaningful regardless of the folder structure. The original metadata files were in spl format. These have been converted to JSON format. The converted metadata files are also anonymized and the text encoding has been converted from ANSI to UTF-8.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18249a", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "KTH/waxholm", "sha": "75a1e327279b80d7cd04bd754801b80c075cfd5e", "lastModified": "2023-08-09T10:36:10.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:sv", "region:us"], "private": false, "author": "KTH", "description": "The Waxholm corpus was collected in 1993 - 1994 at the department of Speech, Hearing and Music (TMH), KTH.", "citation": "@article{bertenstam1995spoken,\n  title={Spoken dialogue data collected in the {W}axholm project},\n  author={Bertenstam, Johan and Blomberg, Mats and Carlson, Rolf and Elenius, Kjell and Granstr{\\\"o}m, Bj{\\\"o}rn and Gustafson, Joakim and Hunnicutt, Sheri and H{\\\"o}gberg, Jesper and Lindell, Roger and Neovius, Lennart and Nord, Lennart and de~Serpa-Leitao, Antonio and Str{\\\"o}m, Nikko},\n  journal={STH-QPSR, KTH},\n  volume={1},\n  pages={49--74},\n  year={1995}\n}\n@inproceedings{bertenstam1995waxholm,\n  title={The {W}axholm application database.},\n  author={Bertenstam, J and Blomberg, Mats and Carlson, Rolf and Elenius, Kjell and Granstr{\\\"o}m, Bj{\\\"o}rn and Gustafson, Joakim and Hunnicutt, Sheri and H{\\\"o}gberg, Jesper and Lindell, Roger and Neovius, Lennart and Nord, Lennart and de~Serpa-Leitao, Antonio and Str{\\\"o}m, Nikko},\n  booktitle={EUROSPEECH},\n  year={1995}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18249c", "disabled": false, "gated": false, "likes": 0, "downloads": 144, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kili-technology/plastic_in_river", "sha": "f5f200ae1b3593972a8ea288347be6840f62315e", "lastModified": "2022-10-21T07:13:58.000Z", "tags": ["task_categories:object-detection", "size_categories:1K<n<10K", "source_datasets:original", "other-object-detection", "region:us"], "private": false, "author": "kili-technology", "description": "This dataset contains photos of rivers on which there may be waste. The waste items are annotated\n    through bounding boxes, and are assigned to one of the 4 following categories: plastic bottle, plastic bag,\n    another plastic waste, or non-plastic waste. Note that some photos may not contain any waste.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1824b9", "disabled": false, "gated": false, "likes": 14, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "LIAMF-USP/arc-retrieval-c4", "sha": "8d01c039de110c9080f0bc578d00202da40fb85c", "lastModified": "2021-06-05T04:17:21.000Z", "tags": ["region:us"], "private": false, "author": "LIAMF-USP", "description": "A combined ARC/ARC-Easy/OBQA/RegLivEnv train/dev/test sets,\n along with associated retrieved contexts from the full corpus.\n The \"para\" field for each answer choice is the retrieved context,\n typically 10 sentences ordered such that the one with highest IR\n score comes last", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1824f9", "disabled": false, "gated": false, "likes": 0, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "LeverageX/book-summarization", "sha": "b317c61c7d2b9d41e6375dc91eaf9dfa975359e3", "lastModified": "2022-01-20T23:46:26.000Z", "tags": ["region:us"], "private": false, "author": "LeverageX", "description": "Korean Book Summarization Data", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182512", "disabled": false, "gated": false, "likes": 0, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "LeverageX/klue-mrc", "sha": "f710c4c94dab04ef424dd3fa38e4c1c42d5ef0f2", "lastModified": "2022-01-12T05:01:00.000Z", "tags": ["region:us"], "private": false, "author": "LeverageX", "description": "Klue Machine Reading Comprehension Data", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182513", "disabled": false, "gated": false, "likes": 0, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "LeverageX/klue-re", "sha": "1b319ecf8231ba213e425843af76583acf4569e1", "lastModified": "2022-01-10T07:43:15.000Z", "tags": ["region:us"], "private": false, "author": "LeverageX", "description": "Klue Relation Extraction Data", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182514", "disabled": false, "gated": false, "likes": 0, "downloads": 304, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "NbAiLab/NCC", "sha": "eaafe98fa72f1c4b7431e2dc38207560b07948cc", "lastModified": "2023-11-17T12:48:38.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:2G<n<1B", "source_datasets:original", "language:en", "language:nb", "language:no", "language:nn", "language:sv", "language:da", "language:is", "language:fo", "license:other", "arxiv:2104.09617", "region:us"], "private": false, "author": "NbAiLab", "description": "\\\\nNorwegian Colossal Corpus v2. Short sequences of maximum 100k characters.", "citation": "@inproceedings{kummervold-etal-2021-operationalizing,\n    title = \"Operationalizing a National Digital Library: The Case for a {N}orwegian Transformer Model\",\n    author = \"Kummervold, Per E  and\n      De la Rosa, Javier  and\n      Wetjen, Freddy  and\n      Brygfjeld, Svein Arne\",\n    booktitle = \"Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)\",\n    month = may # \" 31--2 \" # jun,\n    year = \"2021\",\n    address = \"Reykjavik, Iceland (Online)\",\n    publisher = {Link{\\\"o}ping University Electronic Press, Sweden},\n    url = \"https://aclanthology.org/2021.nodalida-main.3\",\n    pages = \"20--29\",\n    abstract = \"In this work, we show the process of building a large-scale training set from digital and digitized collections at a national library. The resulting Bidirectional Encoder Representations from Transformers (BERT)-based language model for Norwegian outperforms multilingual BERT (mBERT) models in several token and sequence classification tasks for both Norwegian Bokm{\\aa}l and Norwegian Nynorsk. Our model also improves the mBERT performance for other languages present in the corpus such as English, Swedish, and Danish. For languages not included in the corpus, the weights degrade moderately while keeping strong multilingual properties. Therefore, we show that building high-quality models within a memory institution using somewhat noisy optical character recognition (OCR) content is feasible, and we hope to pave the way for other memory institutions to follow.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1825e3", "disabled": false, "gated": "auto", "likes": 15, "downloads": 11, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "NbAiLab/NPSC", "sha": "026b1dfb9e5c256ff47163e04a686c2332603868", "lastModified": "2023-04-25T09:52:08.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:2G<n<1B", "source_datasets:original", "language:no", "language:nb", "language:nn", "license:cc0-1.0", "speech-modeling", "region:us"], "private": false, "author": "NbAiLab", "description": "The Norwegian Parliament Speech Corpus (NPSC) is a corpus for training a Norwegian ASR (Automatic Speech Recognition) models. The corpus is created by Spr\u00e5kbanken at the National Library in Norway.\n\nNPSC is based on sound recording from meeting in the Norwegian Parliament. These talks are orthographically transcribed to either Norwegian Bokm\u00e5l or Norwegian Nynorsk. In addition to the data actually included in this dataset, there is a significant amount of metadata that is included in the original corpus. Through the speaker id there is additional information about the speaker, like gender, age, and place of birth (ie dialect). Through the proceedings id the corpus can be linked to the official proceedings from the meetings.\n\nThe corpus is in total sound recordings from 40 entire days of meetings. This amounts to 140 hours of speech, 65,000 sentences or 1.2 million words.", "citation": "@inproceedings{johansen2019ner,\n  title={},\n  author={},\n  booktitle={LREC 2022},\n  year={2022},\n  url={https://arxiv.org/abs/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1825e8", "disabled": false, "gated": false, "likes": 5, "downloads": 310, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "NbAiLab/norec_agg", "sha": "539cf25078d1136058e2580552acf5d8b5f26248", "lastModified": "2022-07-01T19:53:24.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2011.02686", "region:us"], "private": false, "author": "NbAiLab", "description": "Aggregated NoRec_fine: A Fine-grained Sentiment Dataset for Norwegian\nThis dataset was created by the Nordic Language Processing Laboratory by\naggregating the fine-grained annotations in NoReC_fine and removing sentences\nwith conflicting or no sentiment.", "citation": "@InProceedings{OvrMaeBar20,\n  author = {Lilja {\\O}vrelid and Petter M{\\ae}hlum and Jeremy Barnes and Erik Velldal},\n  title = {A Fine-grained Sentiment Dataset for {N}orwegian},\n  booktitle = {{Proceedings of the 12th Edition of the Language Resources and Evaluation Conference}},\n  year = 2020,\n  address = \"Marseille, France, 2020\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1825f2", "disabled": false, "gated": false, "likes": 0, "downloads": 299, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "NbAiLab/norwegian_parliament", "sha": "f7393532774c66312378d30b197610b43d751972", "lastModified": "2022-07-01T19:51:13.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:no", "license:cc-by-4.0", "region:us"], "private": false, "author": "NbAiLab", "description": "The Norwegian Parliament Speeches is a collection of text passages from\n1998 to 2016 and pronounced at the Norwegian Parliament (Storting) by members\nof the two major parties: Fremskrittspartiet and Sosialistisk Venstreparti.", "citation": "@InProceedings{--,\n  author = {---},\n  title = {---},\n  booktitle = {---},\n  year = 2021,\n  address = \"---\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1825f4", "disabled": false, "gated": false, "likes": 1, "downloads": 382, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "PlanTL-GOB-ES/SQAC", "sha": "f9928e8819596a601b8887cc5f8598b15d589a82", "lastModified": "2023-10-12T23:35:38.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:es", "license:cc-by-sa-4.0", "arxiv:1606.05250", "region:us"], "private": false, "author": "PlanTL-GOB-ES", "description": "This dataset contains 6,247 contexts and 18,817 questions with their answers, 1 to 5 for each fragment.\n\nThe sources of the contexts are:\n\n* Encyclopedic articles from [Wikipedia in Spanish](https://es.wikipedia.org/), used under [CC-by-sa licence](https://creativecommons.org/licenses/by-sa/3.0/legalcode). \n\n* News from [Wikinews in Spanish](https://es.wikinews.org/), used under [CC-by licence](https://creativecommons.org/licenses/by/2.5/). \n\n* Text from the Spanish corpus [AnCora](http://clic.ub.edu/corpus/en), which is a mix from diferent newswire and literature sources, used under [CC-by licence] (https://creativecommons.org/licenses/by/4.0/legalcode). \n\nThis dataset can be used to build extractive-QA.", "citation": "bibtex\n@article{DBLP:journals/corr/abs-2107-07253,\n  author    = {Asier Guti{\\'{e}}rrez{-}Fandi{\\~{n}}o and\n               Jordi Armengol{-}Estap{\\'{e}} and\n               Marc P{\\`{a}}mies and\n               Joan Llop{-}Palao and\n               Joaqu{\\'{\\i}}n Silveira{-}Ocampo and\n               Casimiro Pio Carrino and\n               Aitor Gonzalez{-}Agirre and\n               Carme Armentano{-}Oller and\n               Carlos Rodr{\\'{\\i}}guez Penagos and\n               Marta Villegas},\n  title     = {Spanish Language Models},\n  journal   = {CoRR},\n  volume    = {abs/2107.07253},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2107.07253},\n  archivePrefix = {arXiv},\n  eprint    = {2107.07253},\n  timestamp = {Wed, 21 Jul 2021 15:55:35 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-07253.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18267c", "disabled": false, "gated": false, "likes": 7, "downloads": 320, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "PlanTL-GOB-ES/pharmaconer", "sha": "0400dea295f345309e77f92656ef65b636fef238", "lastModified": "2022-11-18T12:06:36.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "multilinguality:monolingual", "language:es", "license:cc-by-4.0", "biomedical", "clinical", "spanish", "region:us"], "private": false, "author": "PlanTL-GOB-ES", "description": "PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog\u00edas del Lenguaje (Plan TL).\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an\nopen access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts\nand it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets.\nThe training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\nIn terms of training examples, this translates to a total of 8074, 3764 and 3931 annotated sentences in each set.\nThe original dataset was distributed in Brat format (https://brat.nlplab.org/standoff.html).\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es", "citation": "@inproceedings{,\n    title = \"PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track\",\n    author = \"Gonzalez-Agirre, Aitor  and\n      Marimon, Montserrat  and\n      Intxaurrondo, Ander  and\n      Rabal, Obdulia  and\n      Villegas, Marta  and\n      Krallinger, Martin\",\n    booktitle = \"Proceedings of The 5th Workshop on BioNLP Open Shared Tasks\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D19-5701\",\n    doi = \"10.18653/v1/D19-5701\",\n    pages = \"1--10\",\n    abstract = \"\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18267e", "disabled": false, "gated": false, "likes": 4, "downloads": 300, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "RohanAiLab/persian_blog", "sha": "c81e931641843d953dc134ae4bcfc27866710dd2", "lastModified": "2022-10-25T09:06:36.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "source_datasets:original", "language:fa", "region:us"], "private": false, "author": "RohanAiLab", "description": "persian_blog is a dataset consist of 400K blog posts from various websites and has types of tones.\nthis dataset can be used in different NLG tasks and as a show-case it's is used in training reformer-persian.", "citation": "https://saied71.github.io/RohanAiLab/,\n  author={Saied Alimoradi},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1826d6", "disabled": false, "gated": false, "likes": 2, "downloads": 281, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "RohanAiLab/persian_daily_news", "sha": "234cb96c879728e1cd24fbc535da0bef6098322b", "lastModified": "2022-10-21T16:13:09.000Z", "tags": ["source_datasets:original", "language:fa", "region:us"], "private": false, "author": "RohanAiLab", "description": "Persian Daily News dataset is a collection of 2 million news articles with the headline of each news article.\nThis dataset contains news articles and their summaries for the last 10 years.\nThis dataset is provided by Rohan AI lab for research purposes.", "citation": "https://saied71.github.io/RohanAiLab/,\n  author={Saied Alimoradi},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1826d7", "disabled": false, "gated": false, "likes": 0, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "RohanAiLab/persian_news_dataset", "sha": "883746f06ee0fb9ef98d37721c257d9287f1256e", "lastModified": "2022-10-21T16:13:59.000Z", "tags": ["task_categories:text-classification", "task_ids:language-modeling", "task_ids:multi-class-classification", "source_datasets:original", "language:fa", "region:us"], "private": false, "author": "RohanAiLab", "description": "persian_news_dataset is a collection of 5 million news articles. \nNews articles have been gathered from more than 10 news agencies for the last 12 years. \nThe dataset is provided by Rohan AI lab for research purposes.\nfor more information refer to this link:", "citation": "https://saied71.github.io/RohanAiLab/,\n  author={Saied Alimoradi},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1826d8", "disabled": false, "gated": false, "likes": 1, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SajjadAyoubi/persian_qa", "sha": "5a314e73c690b159983b2e45b9d4c0500a80cfd0", "lastModified": "2021-04-29T06:11:18.000Z", "tags": ["region:us"], "private": false, "author": "SajjadAyoubi", "description": "\\\\\\\\\\\\\\Persian Question Answering (PersianQA) Dataset is a reading comprehension dataset on Persian Wikipedia. \nThe crowd-sourced dataset consists of more than 9,000 entries. Each entry can be either an impossible to answer or a question with one or more answers spanning in the passage (the context) from which the questioner proposed the question. Much like the SQuAD2.0 dataset, the impossible or unanswerable questions can be utilized to create a system which \"knows that it doesn't know the answer\".", "citation": "\\@misc{PersianQA, \n  author          = {Sajjad Ayoubi, Mohammad Yasin Davoodeh},\n  title           = {PersianQA: a dataset for Persian Question Answering},\n  year            = 2021,\n  publisher       = {GitHub},\n  journal         = {GitHub repository},\n  howpublished    = {url{https://github.com/SajjjadAyobi/PersianQA}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182705", "disabled": false, "gated": false, "likes": 5, "downloads": 659, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Sam2021/Arguement_Mining_CL2017", "sha": "3856402ae15e3294f7fe1aab09e27372f24ae1cb", "lastModified": "2021-08-30T23:11:05.000Z", "tags": ["region:us"], "private": false, "author": "Sam2021", "description": "tokens along with chunk id. IOB1 format Begining of arguement denoted by B-ARG,inside arguement\ndenoted by I-ARG, other chunks are O\nOrginial train,test split as used by the paper is provided", "citation": "@article{stab2017parsing,\n  title={Parsing argumentation structures in persuasive essays},\n  author={Stab, Christian and Gurevych, Iryna},\n  journal={Computational Linguistics},\n  volume={43},\n  number={3},\n  pages={619--659},\n  year={2017},\n  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~\u2026}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18270d", "disabled": false, "gated": false, "likes": 1, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Samip/func", "sha": "e4b5e7000236325106d5cb9f4d6ed874bbd18976", "lastModified": "2021-11-15T05:35:47.000Z", "tags": ["region:us"], "private": false, "author": "Samip", "description": "This new dataset is designed to solve this great NLP task and is crafted with a lot of care.", "citation": "\"\"\"\n\n# TODO: Add description of the dataset here\n# You can copy an official description\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182711", "disabled": false, "gated": false, "likes": 0, "downloads": 293, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Serhii/Custom_SQuAD", "sha": "33db8dfbc1d41d58c6b1f66aecbecbf6f47aa4ef", "lastModified": "2021-09-21T10:47:39.000Z", "tags": ["region:us"], "private": false, "author": "Serhii", "description": "Shellcode_IA32 is a dataset for shellcode generation from English intents. The shellcodes are compilable on Intel Architecture 32-bits.", "citation": "    @inproceedings{liguori-etal-2021-shellcode,\n    title = \"{S}hellcode{\\_}{IA}32: A Dataset for Automatic Shellcode Generation\",\n    author = \"Liguori, Pietro  and\n      Al-Hossami, Erfan  and\n      Cotroneo, Domenico  and\n      Natella, Roberto  and\n      Cukic, Bojan  and\n      Shaikh, Samira\",\n    booktitle = \"Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.nlp4prog-1.7\",\n    doi = \"10.18653/v1/2021.nlp4prog-1.7\",\n    pages = \"58--64\",\n    abstract = \"We take the first step to address the task of automatically generating shellcodes, i.e., small pieces of code used as a payload in the exploitation of a software vulnerability, starting from natural language comments. We assemble and release a novel dataset (Shellcode{\\_}IA32), consisting of challenging but common assembly instructions with their natural language descriptions. We experiment with standard methods in neural machine translation (NMT) to establish baseline performance levels on this task.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18273c", "disabled": false, "gated": false, "likes": 1, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SetFit/amazon_counterfactual", "sha": "53e2aca73f7af37bfc24e0670c361d39809ad2ab", "lastModified": "2022-02-08T10:15:40.000Z", "tags": ["arxiv:2104.06893", "region:us"], "private": false, "author": "SetFit", "description": "The dataset contains sentences from Amazon customer reviews (sampled from Amazon product review dataset) annotated for counterfactual detection (CFD) binary classification. Counterfactual statements describe events that did not or cannot take place. Counterfactual statements may be identified as statements of the form \u2013 If p was true, then q would be true (i.e. assertions whose antecedent (p) and consequent (q) are known or assumed to be false).", "citation": "@misc{oneill2021i,\n      title={I Wish I Would Have Loved This One, But I Didn't -- A Multilingual Dataset for Counterfactual Detection in Product Reviews},\n      author={James O'Neill and Polina Rozenshtein and Ryuichi Kiryo and Motoko Kubota and Danushka Bollegala},\n      year={2021},\n      eprint={2104.06893},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182741", "disabled": false, "gated": false, "likes": 0, "downloads": 808, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/one-year-of-r-india", "sha": "83362992f86cdfe9cd057069407d943f1baa2976", "lastModified": "2022-07-01T18:48:19.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This corpus contains the complete data for the activity of the subreddit /r/India from Sep 30, 2020 to Sep 30, 2021.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18278d", "disabled": false, "gated": false, "likes": 1, "downloads": 425, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/reddit-crypto-aug-2021", "sha": "d6b971e2c735261ffba9ec44a60ff4ee492fc431", "lastModified": "2022-07-01T19:08:05.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This corpus contains the complete data for the activity on seven major cryptocurrency subreddits for the entire month of August 2021.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18278e", "disabled": false, "gated": false, "likes": 4, "downloads": 427, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/reddit-nonewnormal-complete", "sha": "70a0d87706eb429c9ecbefe862d8d7ef0e0c7837", "lastModified": "2022-07-01T19:02:06.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This corpus contains the complete data for the activity on subreddit /r/NoNewNormal for the entire duration of its existence.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18278f", "disabled": false, "gated": false, "likes": 1, "downloads": 428, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/reddit-wallstreetbets-aug-2021", "sha": "0de5fd81c695f468b56d8274241e1ad3f40ae9ac", "lastModified": "2022-07-01T19:15:07.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This corpus contains the complete data for the activity on /r/WallStreetBets for the entire month of August 2021.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182790", "disabled": false, "gated": false, "likes": 2, "downloads": 432, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/ten-million-reddit-answers", "sha": "077b6add1d663d3168679a0329eb13b110c3f79a", "lastModified": "2022-07-01T17:38:25.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "A spiritual successor to our One Million Questions, this NLP dataset contains an outstanding ten million of /r/AskReddit answers, going back from the end of November of 2020.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182791", "disabled": false, "gated": false, "likes": 6, "downloads": 428, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/the-reddit-covid-dataset", "sha": "63d8c86b1e3c714fd00c98c986eef9e5c6914b26", "lastModified": "2022-07-01T18:40:57.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This dataset attempts to capture the full extent of COVID-19 discussion across the entire site of Reddit. All posts and comments found to mention the term 'COVID' as of 2021-10-25 have been gathered from the site.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182793", "disabled": false, "gated": false, "likes": 1, "downloads": 446, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "SocialGrep/top-american-universities-on-reddit", "sha": "4e365e048efa0d81fd4ceb4bd79b0be8b9b69fe7", "lastModified": "2022-07-25T18:57:00.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This NLP dataset contains all the posts and comments in the subreddits of top 10 universities in the United States, chosen according to the 2019 Forbes ranking.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182794", "disabled": false, "gated": false, "likes": 2, "downloads": 424, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "TRoboto/names", "sha": "8b370cd6d175cfdfaed3b978d6f583b3d0ebd801", "lastModified": "2022-01-29T16:33:25.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "TRoboto", "description": "List of Arabic first names with meaning and origin of most names", "citation": "@software{Al-Fetyani_Maha_Processing_Library_2021,\nauthor = {Al-Fetyani, Mohammad},\nmonth = {11},\ntitle = {{Maha Processing Library}},\nurl = {https://github.com/TRoboto/Maha},\nyear = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1827bf", "disabled": false, "gated": false, "likes": 1, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Zaid/coqa_expanded", "sha": "2105cc29e007fe54b090150398fe2d67e317f186", "lastModified": "2021-10-04T18:48:15.000Z", "tags": ["region:us"], "private": false, "author": "Zaid", "description": "\\\\nCoQA: A Conversational Question Answering Challenge", "citation": "\\\\n@InProceedings{SivaAndAl:Coca,\n       author = {Siva, Reddy and Danqi, Chen and  Christopher D., Manning},\n        title = {WikiQA: A Challenge Dataset for Open-Domain Question Answering},\n      journal = { arXiv},\n         year = {2018},\n\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1828ad", "disabled": false, "gated": false, "likes": 2, "downloads": 350, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "Zaid/quac_expanded", "sha": "b3989d484b433570bea05083d224a045a442d5ae", "lastModified": "2021-10-04T19:41:30.000Z", "tags": ["region:us"], "private": false, "author": "Zaid", "description": "\\\\nQuestion Answering in Context is a dataset for modeling, understanding,\nand participating in information seeking dialog. Data instances consist\nof an interactive dialog between two crowd workers: (1) a student who\nposes a sequence of freeform questions to learn as much as possible\nabout a hidden Wikipedia text, and (2) a teacher who answers the questions\nby providing short excerpts (spans) from the text. QuAC introduces\nchallenges not found in existing machine comprehension datasets: its\nquestions are often more open-ended, unanswerable, or only meaningful\nwithin the dialog context.", "citation": "\\\\n@inproceedings{choi-etal-2018-quac,\ntitle = \"QUAC: Question answering in context\",\nabstract = \"We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.\",\nauthor = \"Eunsol Choi and He He and Mohit Iyyer and Mark Yatskar and Yih, {Wen Tau} and Yejin Choi and Percy Liang and Luke Zettlemoyer\",\nyear = \"2018\",\nlanguage = \"English (US)\",\nseries = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\npublisher = \"Association for Computational Linguistics\",\npages = \"2174--2184\",\neditor = \"Ellen Riloff and David Chiang and Julia Hockenmaier and Jun'ichi Tsujii\",\nbooktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018\",\nnote = \"2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018 ; Conference date: 31-10-2018 Through 04-11-2018\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1828ae", "disabled": false, "gated": false, "likes": 0, "downloads": 352, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ai4bharat/samanantar", "sha": "21ffe292d98a385daecaa4069a96d4bdcfa5728d", "lastModified": "2022-12-07T15:33:46.000Z", "tags": ["task_categories:text-generation", "task_categories:translation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:unknown", "source_datasets:original", "language:en", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "conditional-text-generation", "arxiv:2104.05596", "region:us"], "private": false, "author": "ai4bharat", "description": "Samanantar is the largest publicly available parallel corpora collection for Indic languages: Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. The corpus has 49.6M sentence pairs between English to Indian Languages.", "citation": "@misc{ramesh2021samanantar,\n      title={Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages},\n      author={Gowtham Ramesh and Sumanth Doddapaneni and Aravinth Bheemaraj and Mayank Jobanputra and Raghavan AK and Ajitesh Sharma and Sujit Sahoo and Harshita Diddee and Mahalakshmi J and Divyanshu Kakwani and Navneet Kumar and Aswin Pradeep and Srihari Nagaraj and Kumar Deepak and Vivek Raghavan and Anoop Kunchukuttan and Pratyush Kumar and Mitesh Shantadevi Khapra},\n      year={2021},\n      eprint={2104.05596},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1829e2", "disabled": false, "gated": false, "likes": 12, "downloads": 1889, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "albertvillanova/pmc_open_access", "sha": "476cc83b6db0c85c8a0cabaa4fbdb17fd062fc47", "lastModified": "2023-01-16T13:43:54.000Z", "tags": ["region:us"], "private": false, "author": "albertvillanova", "description": "The PMC Open Access Subset includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \n\nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than a traditional copyrighted work. \n\nThe PMC Open Access Subset is one part of the PMC Article Datasets", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182a4f", "disabled": false, "gated": false, "likes": 0, "downloads": 715, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "albertvillanova/sat", "sha": "f72e0cbcd52596bac666dead2f266f3e3bafe407", "lastModified": "2022-10-24T15:25:54.000Z", "tags": ["task_categories:text-generation", "task_categories:translation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "source_datasets:extended|bible_para", "source_datasets:extended|kde4", "source_datasets:extended|opus_gnome", "source_datasets:extended|open_subtitles", "source_datasets:extended|tatoeba", "language:en", "language:vi", "license:unknown", "conditional-text-generation", "region:us"], "private": false, "author": "albertvillanova", "description": "SAT (Style Augmented Translation) dataset contains roughly 3.3 million English-Vietnamese pairs of texts.", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182a51", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "allenai/scico", "sha": "1bf636269d478d390cbdab0a604a0d232ff86434", "lastModified": "2023-01-10T20:23:18.000Z", "tags": ["task_categories:token-classification", "task_ids:coreference-resolution", "annotations_creators:domain experts", "multilinguality:monolingual", "language:en", "license:apache-2.0", "cross-document-coreference-resolution", "structure-prediction", "region:us"], "private": false, "author": "allenai", "description": "        SciCo is a dataset for hierarchical cross-document coreference resolution\n        over scientific papers in the CS domain.", "citation": "        @inproceedings{\n    cattan2021scico,\n    title={SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts},\n    author={Arie Cattan and Sophie Johnson and Daniel S. Weld and Ido Dagan and Iz Beltagy and Doug Downey and Tom Hope},\n    booktitle={3rd Conference on Automated Knowledge Base Construction},\n    year={2021},\n    url={https://openreview.net/forum?id=OFLbgUP04nC}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182a88", "disabled": false, "gated": false, "likes": 3, "downloads": 143, "paperswithcode_id": "scico", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "maastrichtlawtech/bsard", "sha": "5effa1b9b5fa3b0f9e12523e6e43e5f86a6e6d59", "lastModified": "2023-09-26T15:28:00.000Z", "tags": ["task_categories:text-retrieval", "task_categories:text-classification", "task_ids:document-retrieval", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fr", "license:cc-by-nc-sa-4.0", "legal", "arxiv:2108.11792", "region:us"], "private": false, "author": "maastrichtlawtech", "description": "The Belgian Statutory Article Retrieval Dataset (BSARD) is a French native dataset for studying legal information retrieval. \nBSARD consists of more than 22,600 statutory articles from Belgian law and about 1,100 legal questions posed by Belgian citizens \nand labeled by experienced jurists with relevant articles from the corpus.", "citation": "@inproceedings{louis-spanakis-2022-statutory,\n    title = \"A Statutory Article Retrieval Dataset in {F}rench\",\n    author = \"Louis, Antoine  and Spanakis, Gerasimos\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = may,\n    year = \"2022\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.acl-long.468\",\n    doi = \"10.18653/v1/2022.acl-long.468\",\n    pages = \"6789--6803\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182ae0", "disabled": false, "gated": false, "likes": 5, "downloads": 680, "paperswithcode_id": "bsard", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "anton-l/superb_dummy", "sha": "108f378cc037db1ac961489eb70d012a1769420b", "lastModified": "2021-12-14T09:39:13.000Z", "tags": ["region:us"], "private": false, "author": "anton-l", "description": "Self-supervised learning (SSL) has proven vital for advancing research in\nnatural language processing (NLP) and computer vision (CV). The paradigm\npretrains a shared model on large volumes of unlabeled data and achieves\nstate-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\nspeech processing community lacks a similar setup to systematically explore the\nparadigm. To bridge this gap, we introduce Speech processing Universal\nPERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\nperformance of a shared model across a wide range of speech processing tasks\nwith minimal architecture changes and labeled data. Among multiple usages of the\nshared model, we especially focus on extracting the representation learned from\nSSL due to its preferable re-usability. We present a simple framework to solve\nSUPERB tasks by learning task-specialized lightweight prediction heads on top of\nthe frozen shared model. Our results demonstrate that the framework is promising\nas SSL representations show competitive generalizability and accessibility\nacross SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a\nbenchmark toolkit to fuel the research in representation learning and general\nspeech processing.", "citation": "@article{DBLP:journals/corr/abs-2105-01051,\n  author    = {Shu{-}Wen Yang and\n               Po{-}Han Chi and\n               Yung{-}Sung Chuang and\n               Cheng{-}I Jeff Lai and\n               Kushal Lakhotia and\n               Yist Y. Lin and\n               Andy T. Liu and\n               Jiatong Shi and\n               Xuankai Chang and\n               Guan{-}Ting Lin and\n               Tzu{-}Hsien Huang and\n               Wei{-}Cheng Tseng and\n               Ko{-}tik Lee and\n               Da{-}Rong Liu and\n               Zili Huang and\n               Shuyan Dong and\n               Shang{-}Wen Li and\n               Shinji Watanabe and\n               Abdelrahman Mohamed and\n               Hung{-}yi Lee},\n  title     = {{SUPERB:} Speech processing Universal PERformance Benchmark},\n  journal   = {CoRR},\n  volume    = {abs/2105.01051},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2105.01051},\n  archivePrefix = {arXiv},\n  eprint    = {2105.01051},\n  timestamp = {Thu, 01 Jul 2021 13:30:22 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2105-01051.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182ae8", "disabled": false, "gated": false, "likes": 0, "downloads": 4394, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lmqg/qg_jaquad", "sha": "59c7622ea1cf5ab07568ba8e161379129c79f7c1", "lastModified": "2022-12-02T18:51:27.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:SkelterLabsInc/JaQuAD", "language:ja", "license:cc-by-sa-3.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[JaQuAD](https://github.com/SkelterLabsInc/JaQuAD) dataset for question generation (QG) task. The test set of the original \ndata is not publicly released, so we randomly sampled test questions from the training set.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b43", "disabled": false, "gated": false, "likes": 4, "downloads": 375, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lmqg/qg_squad", "sha": "57bdaee4b743773b6eb5c4e38490757d18a92ca0", "lastModified": "2022-12-02T18:51:10.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:squad", "language:en", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "arxiv:1705.00106", "region:us"], "private": false, "author": "lmqg", "description": "[SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) evaluation set for the question generation (QG) models. The split \nof test and development set follows the [\"Neural Question Generation\"](https://arxiv.org/abs/1705.00106) work and is \ncompatible with the [leader board](https://paperswithcode.com/sota/question-generation-on-squad11).", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b44", "disabled": false, "gated": false, "likes": 5, "downloads": 1020, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ashraq/dhivehi-corpus", "sha": "26aa8bdedaa4802e41f4eeab35ba24b3ada080dc", "lastModified": "2021-12-19T14:39:45.000Z", "tags": ["region:us"], "private": false, "author": "ashraq", "description": "This is a dataset put together to pretrain a language model in Dhivehi, the language of Maldives.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b52", "disabled": false, "gated": false, "likes": 2, "downloads": 294, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "asi/wikitext_fr", "sha": "813f30b157f1b66b44b224fa33c116cb493d27cc", "lastModified": "2022-10-21T16:23:07.000Z", "tags": ["task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:fr", "license:cc-by-sa-4.0", "arxiv:1609.07843", "region:us"], "private": false, "author": "asi", "description": "Wikitext-fr language modeling dataset consists of over 70 million tokens \nextracted from the set of french Wikipedia articles that are classified as \n\"quality articles\" or \"good articles.\". The aim is to replicate the English \nbenchmark.", "citation": "@inproceedings{simoulin:hal-03265900,\n  TITLE = {{Un mod{\\`e}le Transformer G{\\'e}n{\\'e}ratif Pr{\\'e}-entrain{\\'e} pour le \\_\\_\\_\\_\\_\\_ fran{\\c c}ais}},\n  AUTHOR = {Simoulin, Antoine and Crabb{\\'e}, Benoit},\n  URL = {https://hal.archives-ouvertes.fr/hal-03265900},\n  BOOKTITLE = {{Traitement Automatique des Langues Naturelles}},\n  ADDRESS = {Lille, France},\n  EDITOR = {Denis, Pascal and Grabar, Natalia and Fraisse, Amel and Cardon, R{\\'e}mi and Jacquemin, Bernard and Kergosien, Eric and Balvet, Antonio},\n  PUBLISHER = {{ATALA}},\n  PAGES = {246-255},\n  YEAR = {2021},\n  KEYWORDS = {fran{\\c c}ais. ; GPT ; G{\\'e}n{\\'e}ratif ; Transformer ; Pr{\\'e}-entra{\\^i}n{\\'e}},\n  PDF = {https://hal.archives-ouvertes.fr/hal-03265900/file/7.pdf},\n  HAL_ID = {hal-03265900},\n  HAL_VERSION = {v1},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b54", "disabled": false, "gated": false, "likes": 4, "downloads": 528, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "asoroa/bsbasque", "sha": "3152459d055739e63ea6846ee6c2e8b0c2299436", "lastModified": "2021-11-18T15:00:09.000Z", "tags": ["region:us"], "private": false, "author": "asoroa", "description": "BSBasque dataset. The text is extracted from the following domains:\n\n https://www.berria.eus\n https://eu.wikipedia.org\n https://goiena.eus\n https://www.argia.eus\n https://goierri.hitza.eus", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b55", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "astrideducation/cefr-combined-no-cefr-test", "sha": "3b71e621b42c3a71a9272bb2b33963cf52637cac", "lastModified": "2021-12-02T14:47:44.000Z", "tags": ["region:us"], "private": false, "author": "astrideducation", "description": "This dataset contains 3370555 sentences, which each have an assigned CEFR level derived from EFLLex (https://cental.uclouvain.be/cefrlex/efllex/download).\n    The sentences comes from \"the pile books3\", which is available on Huggingface (https://huggingface.co/datasets/the_pile_books3).\n    The CEFR levels used are A1, A2, B1, B2 and C1, and there are equals number of sentences for each level.\n    Assigning each sentence a CEFR level followed is based on the concept of \"shifted frequency distribution\", introduced by David Alfter and his paper can be found at (https://gupea.ub.gu.se/bitstream/2077/66861/4/gupea_2077_66861_4.pdf).\n    For each word in each sentence, take the CEFR level with the highest \"shifted frequency distribution\" in the EFLLex table. \n    After all words have been processed, the sentence gets annotated with the most frequently appearing CEFR level from the whole senctence.", "citation": "@misc{cefr_book_sentences,\n    author={Astrid Education AB}\n    year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182b60", "disabled": false, "gated": false, "likes": 1, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "badranx/opus_raw", "sha": "fabb9115e9f173c9aaa4897e5b2f3a49e74758a0", "lastModified": "2022-01-28T14:19:19.000Z", "tags": ["region:us"], "private": false, "author": "badranx", "description": "        mono corpus from http://www.opensubtitles.org/. Please check http://www.opensubtitles.org/ for the available corpora and licenses.", "citation": "P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182bef", "disabled": false, "gated": false, "likes": 1, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bavard/personachat_truecased", "sha": "be2fcc045e5f4a9a645527ffbf5ea627218f7c5e", "lastModified": "2021-04-23T13:28:30.000Z", "tags": ["region:us"], "private": false, "author": "bavard", "description": "A version of the PersonaChat dataset that has been true-cased, and also has been given more normalized punctuation.\nThe original PersonaChat dataset is in all lower case, and has extra space around each clause/sentence separating\npunctuation mark. This version of the dataset has more of a natural language look, with sentence capitalization,\nproper noun capitalization, and normalized whitespace. Also, each dialogue turn includes a pool of distractor\ncandidate responses, which can be used by a multiple choice regularization loss during training.", "citation": "@article{zhang2018personalizing,\n  title={Personalizing dialogue agents: I have a dog, do you have pets too?},\n  author={Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and Szlam, Arthur and Kiela, Douwe and Weston, Jason},\n  journal={arXiv preprint arXiv:1801.07243},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182c0b", "disabled": false, "gated": false, "likes": 26, "downloads": 742, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bertin-project/mc4-es-sampled", "sha": "b03a838013ad69fa852d95323fe8f612bccccef2", "lastModified": "2023-03-16T08:56:10.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "size_categories:100M<n<1B", "source_datasets:mc4", "source_datasets:bertin-project/mc4-sampling", "language:es", "license:odc-by", "arxiv:1910.10683", "arxiv:2207.06814", "region:us"], "private": false, "author": "bertin-project", "description": "50 million documents in Spanish extracted from mC4 applying perplexity sampling via mc4-sampling: \"https://huggingface.co/datasets/bertin-project/mc4-sampling\". Please, refer to BERTIN Project. The original dataset is the Multlingual Colossal, Cleaned version of Common Crawl's web crawl corpus (mC4), based on the Common Crawl dataset: \"https://commoncrawl.org\", and processed by AllenAI.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182c39", "disabled": false, "gated": false, "likes": 3, "downloads": 598, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bertin-project/mc4-sampling", "sha": "99745f2a45f9a2672546eaa8abb8481a0dbfbd9f", "lastModified": "2022-11-07T12:40:51.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "size_categories:100M<n<1B", "size_categories:1B<n<10B", "source_datasets:original", "language:af", "language:am", "language:ar", "language:az", "language:be", "language:bg", "language:bn", "language:ca", "language:ceb", "language:co", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fil", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gu", "language:ha", "language:haw", "language:hi", "language:hmn", "language:ht", "language:hu", "language:hy", "language:id", "language:ig", "language:is", "language:it", "language:iw", "language:ja", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:ku", "language:ky", "language:la", "language:lb", "language:lo", "language:lt", "language:lv", "language:mg", "language:mi", "language:mk", "language:ml", "language:mn", "language:mr", "language:ms", "language:mt", "language:my", "language:ne", "language:nl", "language:no", "language:ny", "language:pa", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:sd", "language:si", "language:sk", "language:sl", "language:sm", "language:sn", "language:so", "language:sq", "language:sr", "language:st", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:tg", "language:th", "language:tr", "language:uk", "language:und", "language:ur", "language:uz", "language:vi", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "license:odc-by", "arxiv:1910.10683", "region:us"], "private": false, "author": "bertin-project", "description": "A sampling-enabled version of mC4, the colossal, cleaned version of Common Crawl's web crawl corpus.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is a version of the processed version of Google's mC4 dataset by AllenAI, in which sampling methods are implemented to perform on the fly.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182c3a", "disabled": false, "gated": false, "likes": 8, "downloads": 166, "paperswithcode_id": "mc4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bhigy/buckeye_asr", "sha": "83897de5e66d71057570e94a8665af42d6adfe12", "lastModified": "2022-10-24T15:32:04.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": "bhigy", "description": "The Buckeye Corpus of conversational speech contains high-quality recordings\nfrom 40 speakers in Columbus OH conversing freely with an interviewer. The\nspeech has been orthographically transcribed and phonetically labeled.", "citation": "@misc{pitt2007Buckeye,\ntitle = {Buckeye {Corpus} of {Conversational} {Speech} (2nd release).},\nurl = {www.buckeyecorpus.osu.edu},\npublisher = {Columbus, OH: Department of Psychology, Ohio State University (Distributor)},\nauthor = {Pitt, M.A. and Dilley, L. and Johnson, K. and Kiesling, S. and Raymond, W. and Hume, E. and Fosler-Lussier, E.},\nyear = {2007},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182c61", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "bigscience/P3", "sha": "255b4bb51b0eeceec18b06cb372b73f2b5910550", "lastModified": "2023-02-01T13:38:41.000Z", "tags": ["task_categories:other", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:100M<n<1B", "language:en", "license:apache-2.0", "arxiv:2110.08207", "region:us"], "private": false, "author": "bigscience", "description": "P3 (Public Pool of Prompts) is a collection of prompted English datasets covering a diverse set of NLP tasks. A prompt is the combination of an input template and a target template. The templates are functions mapping a data example into natural language for the input and target sequences. For example, in the case of an NLI dataset, the data example would include fields for *Premise, Hypothesis, Label*. An input template would be *If {Premise} is true, is it also true that {Hypothesis}?*, whereas a target template can be defined with the label choices *Choices[label]*. Here *Choices* is prompt-specific metadata that consists of the options *yes, maybe, no* corresponding to *label* being entailment (0), neutral (1) or contradiction (2).\n\nPrompts are collected using [Promptsource](https://github.com/bigscience-workshop/promptsource), an interface to interactively write prompts on datasets, and collect prompt-specific metadata such as evaluation metrics. As of October 13th, there are 2'000 prompts collected for 270+ data(sub)sets. The collection of prompts of P3 is publicly available on [Promptsource](https://github.com/bigscience-workshop/promptsource).\n\nTo train [T0*](https://huggingface.co/bigscience/T0pp), we used a subset of the prompts available in Promptsource (see details [here](https://huggingface.co/bigscience/T0pp#training-data)). However, some of the prompts use `random.choice`, a method that selects uniformly at random an option in a list of valid possibilities. For reproducibility purposes, we release the collection of prompted examples used to train T0*. **The data available here are the materialized version of the prompted datasets used in [Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/abs/2110.08207) which represent only a subset of the datasets for which there is at least one prompt in Promptsource.**", "citation": "@misc{sanh2021multitask,\n      title={Multitask Prompted Training Enables Zero-Shot Task Generalization},\n      author={Victor Sanh and Albert Webson and Colin Raffel and Stephen H. Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Teven Le Scao and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Stella Biderman and Leo Gao and Tali Bers and Thomas Wolf and Alexander M. Rush},\n      year={2021},\n      eprint={2110.08207},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182c65", "disabled": false, "gated": false, "likes": 161, "downloads": 13398, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qa_align", "sha": "d8ed6544788253c114d64a2ba69c0b6c0f2ffa2d", "lastModified": "2021-11-19T01:01:40.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "This dataset contains QA-Alignments - annotations of cross-text content overlap. \nThe task input is two sentences from two documents, roughly talking about the same event, along with their QA-SRL annotations \nwhich capture verbal predicate-argument relations in question-answer format. The output is a cross-sentence alignment between sets of QAs which denote the same information.   \nSee the paper for details: QA-Align: Representing Cross-Text Content Overlap by Aligning Question-Answer Propositions, Brook Weiss et. al., EMNLP 2021.\nHere we provide both the QASRL annotations and the QA-Align annotations for the target sentences.", "citation": "@inproceedings{brook-weiss-etal-2021-qa,\n    title = \"{QA}-Align: Representing Cross-Text Content Overlap by Aligning Question-Answer Propositions\",\n    author = \"Brook Weiss, Daniela  and\n      Roit, Paul  and\n      Klein, Ayal  and\n      Ernst, Ori  and\n      Dagan, Ido\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.778\",\n    pages = \"9879--9894\",\n    abstract = \"Multi-text applications, such as multi-document summarization, are typically required to model redundancies across related texts. Current methods confronting consolidation struggle to fuse overlapping information. In order to explicitly represent content overlap, we propose to align predicate-argument relations across texts, providing a potential scaffold for information consolidation. We go beyond clustering coreferring mentions, and instead model overlap with respect to redundancy at a propositional level, rather than merely detecting shared referents. Our setting exploits QA-SRL, utilizing question-answer pairs to capture predicate-argument relations, facilitating laymen annotation of cross-text alignments. We employ crowd-workers for constructing a dataset of QA-based alignments, and present a baseline QA alignment model trained over our dataset. Analyses show that our new task is semantically challenging, capturing content overlap beyond lexical similarity and complements cross-document coreference with proposition-level links, offering potential use for downstream tasks.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc1", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qa_discourse", "sha": "b77519ba9b7233931842ee53f65d07fbdc0d937a", "lastModified": "2022-05-16T08:37:44.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "The dataset contains question-answer pairs to model discourse relations. \nWhile answers roughly correspond to spans of the sentence, these spans could have been freely adjusted by annotators to grammaticaly fit the question;\nTherefore, answers are given just as text and not as identified spans of the original sentence.    \nSee the paper for details: QADiscourse - Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines, Pyatkin et. al., 2020", "citation": "@inproceedings{pyatkin2020qadiscourse,\n  title={QADiscourse-Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines},\n  author={Pyatkin, Valentina and Klein, Ayal and Tsarfaty, Reut and Dagan, Ido},\n  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n  pages={2804--2819},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc2", "disabled": false, "gated": false, "likes": 0, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qa_srl2018", "sha": "50e0b9e2fd24b1340e46d124b6e3c9d93b5e7d1b", "lastModified": "2022-10-19T06:16:06.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "The dataset contains question-answer pairs to model verbal predicate-argument structure. The questions start with wh-words (Who, What, Where, What, etc.) and contain a verb predicate in the sentence; the answers are phrases in the sentence.\nThis dataset, a.k.a \"QASRL Bank\", \"QASRL-v2\" or \"QASRL-LS\" (Large Scale), was constructed via crowdsourcing.", "citation": "@inproceedings{fitzgerald2018large,\n  title={Large-Scale QA-SRL Parsing},\n  author={FitzGerald, Nicholas and Michael, Julian and He, Luheng and Zettlemoyer, Luke},\n  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n  pages={2051--2060},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc3", "disabled": false, "gated": false, "likes": 1, "downloads": 421, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qa_srl2020", "sha": "80e6b8ce552fc15f9ee698b414d677db1d6567fd", "lastModified": "2022-10-17T20:49:01.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "The dataset contains question-answer pairs to model verbal predicate-argument structure. \nThe questions start with wh-words (Who, What, Where, What, etc.) and contain a verb predicate in the sentence; the answers are phrases in the sentence.\nThis dataset, a.k.a \"QASRL-GS\" (Gold Standard) or \"QASRL-2020\", was constructed via controlled crowdsourcing.\nSee the paper for details: Controlled Crowdsourcing for High-Quality QA-SRL Annotation, Roit et. al., 2020", "citation": "@inproceedings{roit2020controlled,\n  title={Controlled Crowdsourcing for High-Quality QA-SRL Annotation},\n  author={Roit, Paul and Klein, Ayal and Stepanov, Daniela and Mamou, Jonathan and Michael, Julian and Stanovsky, Gabriel and Zettlemoyer, Luke and Dagan, Ido},\n  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n  pages={7008--7013},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc4", "disabled": false, "gated": false, "likes": 1, "downloads": 560, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qamr", "sha": "256646e66210d166b37af2b9d1b7acb760eca616", "lastModified": "2021-10-20T07:10:13.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "Question-Answer Meaning Representations (QAMR) are a new paradigm for representing predicate-argument structure, which makes use of free-form questions and their answers in order to represent a wide range of semantic phenomena. \nThe semantic expressivity of QAMR compares to (and in some cases exceeds) that of existing formalisms, while the representations can be annotated by non-experts (in particular, using crowdsourcing).\nFormal Notes: \n* The `answer_ranges` feature here has a different meaning from that of the `qanom` and `qa_srl` datasets, although both are structured the same way; \nwhile in qasrl/qanom, each \"answer range\" (i.e. each span, represented as [begin-idx, end-idx]) stands for an independant answer which is read separately \n(e.g., \"John Vincen\", \"head of marketing\"), in this `qamr` dataset each question has a single answer who might be conposed of non-consecutive spans; \n that is, all given spans should be read successively.\n* Another difference is that the meaning of `predicate` in QAMR is different and softer than in QASRL/QANom - here, the predicate is not necessarily within the question, \nit can also be in the answer; it is generally what the annotator marked as the focus of the QA.", "citation": "@inproceedings{michael-etal-2018-crowdsourcing,\n    title = \"Crowdsourcing Question-Answer Meaning Representations\",\n    author = \"Michael, Julian  and\n      Stanovsky, Gabriel  and\n      He, Luheng  and\n      Dagan, Ido  and\n      Zettlemoyer, Luke\",\n    booktitle = \"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)\",\n    month = jun,\n    year = \"2018\",\n    address = \"New Orleans, Louisiana\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/N18-2089\",\n    doi = \"10.18653/v1/N18-2089\",\n    pages = \"560--568\",\n    abstract = \"We introduce Question-Answer Meaning Representations (QAMRs), which represent the predicate-argument structure of a sentence as a set of question-answer pairs. We develop a crowdsourcing scheme to show that QAMRs can be labeled with very little training, and gather a dataset with over 5,000 sentences and 100,000 questions. A qualitative analysis demonstrates that the crowd-generated question-answer pairs cover the vast majority of predicate-argument relationships in existing datasets (including PropBank, NomBank, and QA-SRL) along with many previously under-resourced ones, including implicit arguments and relations. We also report baseline models for question generation and answering, and summarize a recent approach for using QAMR labels to improve an Open IE system. These results suggest the freely available QAMR data and annotation scheme should support significant future work.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc5", "disabled": false, "gated": false, "likes": 0, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "biu-nlp/qanom", "sha": "5499db7c8223f09187bc8b4bc81d689758ceb5f8", "lastModified": "2022-10-18T09:50:01.000Z", "tags": ["region:us"], "private": false, "author": "biu-nlp", "description": "The dataset contains question-answer pairs to model predicate-argument structure of deverbal nominalizations. \nThe questions start with wh-words (Who, What, Where, What, etc.) and contain a the verbal form of a nominalization from the sentence; \nthe answers are phrases in the sentence. \nSee the paper for details: QANom: Question-Answer driven SRL for Nominalizations (Klein et. al., COLING 2020)\nFor previewing the QANom data along with the verbal annotations of QASRL, check out \"https://browse.qasrl.org/\".  \nThis dataset was annotated by selected workers from Amazon Mechanical Turk.", "citation": "@inproceedings{klein2020qanom,\n  title={QANom: Question-Answer driven SRL for Nominalizations},\n  author={Klein, Ayal and Mamou, Jonathan and Pyatkin, Valentina and Stepanov, Daniela and He, Hangfeng and Roth, Dan and Zettlemoyer, Luke and Dagan, Ido},\n  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},\n  pages={3069--3083},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fc6", "disabled": false, "gated": false, "likes": 1, "downloads": 296, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "blinoff/medical_qa_ru_data", "sha": "b7c9fe729920578a60d6a294a6f6a81496d6c6fc", "lastModified": "2022-07-02T06:24:13.000Z", "tags": ["task_categories:question-answering", "task_ids:closed-domain-qa", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ru", "license:unknown", "region:us"], "private": false, "author": "blinoff", "description": "This dataset contains 190,335 Russian Q&A posts from a medical related forum.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f182fce", "disabled": false, "gated": false, "likes": 6, "downloads": 302, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cakiki/args_me", "sha": "da29f2b2fc7c86176813b8a6440f73e0823f05d3", "lastModified": "2022-10-25T09:07:25.000Z", "tags": ["task_categories:text-retrieval", "task_ids:document-retrieval", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "license:cc-by-4.0", "region:us"], "private": false, "author": "cakiki", "description": "The args.me corpus (version 1.0, cleaned) comprises 382 545 arguments crawled from four debate portals in the middle of 2019. The debate portals are Debatewise, IDebate.org, Debatepedia, and Debate.org. The arguments are extracted using heuristics that are designed for each debate portal.", "citation": "@dataset{yamen_ajjour_2020_4139439,\n  author       = {Yamen Ajjour and\n                  Henning Wachsmuth and\n                  Johannes Kiesel and\n                  Martin Potthast and\n                  Matthias Hagen and\n                  Benno Stein},\n  title        = {args.me corpus},\n  month        = oct,\n  year         = 2020,\n  publisher    = {Zenodo},\n  version      = {1.0-cleaned},\n  doi          = {10.5281/zenodo.4139439},\n  url          = {https://doi.org/10.5281/zenodo.4139439}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183036", "disabled": false, "gated": false, "likes": 1, "downloads": 569, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cameronbc/synthtiger", "sha": "db2aec8e35a942b17c3805617d55a4abd5f28f7e", "lastModified": "2022-02-08T04:24:39.000Z", "tags": ["region:us"], "private": false, "author": "cameronbc", "description": "A synthetic scene text OCR dataset derived from the\n[SynthTIGER](https://github.com/clovaai/synthtiger) generator.", "citation": "@inproceedings{yim2021synthtiger,\n  title={Synthtiger: Synthetic text image generator towards better text recognition models},\n  author={Yim, Moonbin and Kim, Yoonsik and Cho, Han-Cheol and Park, Sungrae},\n  booktitle={International Conference on Document Analysis and Recognition},\n  pages={109--124},\n  year={2021},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18303f", "disabled": false, "gated": false, "likes": 0, "downloads": 145, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cassandra-themis/QR-AN", "sha": "1059be355e830b808093595856135651e770d22c", "lastModified": "2022-10-24T20:31:22.000Z", "tags": ["task_categories:summarization", "task_categories:text-classification", "task_categories:text-generation", "task_ids:multi-class-classification", "task_ids:topic-classification", "size_categories:10K<n<100K", "language:fr", "conditional-text-generation", "region:us"], "private": false, "author": "cassandra-themis", "description": " QR-AN Dataset: a classification dataset on french Parliament debates\n This is a dataset for theme/topic classification, made of questions and answers from https://www2.assemblee-nationale.fr/recherche/resultats_questions.\n It contains 188 unbalanced classes, 80k questions-answers divided into 3 splits: train (60k), val (10k) and test (10k).", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18304f", "disabled": false, "gated": false, "likes": 2, "downloads": 733, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "castorini/afriberta-corpus", "sha": "d83da9653ef2a5f823c3693a28018e3009464522", "lastModified": "2022-10-19T21:33:04.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "language:om", "language:am", "language:rw", "language:rn", "language:ha", "language:ig", "language:pcm", "language:so", "language:sw", "language:ti", "language:yo", "language:multilingual", "license:apache-2.0", "region:us"], "private": false, "author": "castorini", "description": "Corpus used for training AfriBERTa models", "citation": "@inproceedings{ogueji-etal-2021-small,\n    title = \"Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages\",\n    author = \"Ogueji, Kelechi  and\n      Zhu, Yuxin  and\n      Lin, Jimmy\",\n    booktitle = \"Proceedings of the 1st Workshop on Multilingual Representation Learning\",\n    month = nov,\n    year = \"2021\",\n    address = \"Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.mrl-1.11\",\n    pages = \"116--126\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183057", "disabled": false, "gated": false, "likes": 7, "downloads": 1545, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cbrew475/hwu66", "sha": "8f6dfa8280ed16b939ef3e283b905c0fa021e16c", "lastModified": "2022-02-22T18:18:36.000Z", "tags": ["region:us"], "private": false, "author": "cbrew475", "description": "This project contains natural language data for human-robot interaction in a projecthome domain which \nXingkun Liu et al, from Heriot-Watt University, collected and annotated. It can be used for evaluating \nNLU services/platforms.", "citation": "@InProceedings{XLiu.etal:IWSDS2019,\n  author    = {Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser},\n  title     = {Benchmarking Natural Language Understanding Services for building Conversational Agents},\n  booktitle = {Proceedings of the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)},\n  month     = {April},\n  year      = {2019},\n  address   = {Ortigia, Siracusa (SR), Italy},\n  publisher = {Springer},\n  pages     = {xxx--xxx},\n  url       = {http://www.xx.xx/xx/}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183067", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccdv/arxiv-classification", "sha": "f9bd92144ed76200d6eb3ce73a8bd4eba9ffdc85", "lastModified": "2022-10-22T09:23:50.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "size_categories:10K<n<100K", "language:en", "long context", "region:us"], "private": false, "author": "ccdv", "description": "Arxiv Classification Dataset: a classification of Arxiv Papers (11 classes).\n It contains 11 slightly unbalanced classes, 33k Arxiv Papers divided into 3 splits: train (23k), val (5k) and test (5k).\n Copied from \"Long Document Classification From Local Word Glimpses via Recurrent Attention Learning\" by JUN HE LIQUN WANG LIU LIU, JIAO FENG AND HAO WU\n See: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8675939\n See: https://github.com/LiqunW/Long-document-dataset", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183069", "disabled": false, "gated": false, "likes": 11, "downloads": 701, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccdv/arxiv-summarization", "sha": "f70ea0378deb9b1c8fa1032168dc4ea7d77f3259", "lastModified": "2022-12-08T06:58:05.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "conditional-text-generation", "region:us"], "private": false, "author": "ccdv", "description": "Arxiv dataset for summarization.\n From paper: A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents\" by A. Cohan et al.\n See: https://aclanthology.org/N18-2097.pdf \n See: https://github.com/armancohan/long-summarization", "citation": "    @inproceedings{cohan-etal-2018-discourse,\n    title = \"A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents\",\n    author = \"Cohan, Arman  and\n      Dernoncourt, Franck  and\n      Kim, Doo Soon  and\n      Bui, Trung  and\n      Kim, Seokhwan  and\n      Chang, Walter  and\n      Goharian, Nazli\",\n    booktitle = \"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)\",\n    month = jun,\n    year = \"2018\",\n    address = \"New Orleans, Louisiana\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/N18-2097\",\n    doi = \"10.18653/v1/N18-2097\",\n    pages = \"615--621\",\n    abstract = \"Neural abstractive summarization models have led to promising results in summarizing relatively short documents. We propose the first model for abstractive summarization of single, longer-form documents (e.g., research papers). Our approach consists of a new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder to generate the summary. Empirical results on two large-scale datasets of scientific papers show that our model significantly outperforms state-of-the-art models.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18306a", "disabled": false, "gated": false, "likes": 38, "downloads": 2893, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccdv/govreport-summarization", "sha": "b949637ab41c9f668a4b83cea46c80b489c02290", "lastModified": "2022-10-24T20:32:47.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "conditional-text-generation", "arxiv:2104.02112", "region:us"], "private": false, "author": "ccdv", "description": "GovReport dataset for summarization.\n From paper: Efficient Attentions for Long Document Summarization\" by L. Huang et al.\n See: https://arxiv.org/pdf/2104.02112.pdf \n See: https://github.com/luyang-huang96/LongDocSum", "citation": "    @misc{huang2021efficient,\n      title={Efficient Attentions for Long Document Summarization}, \n      author={Luyang Huang and Shuyang Cao and Nikolaus Parulian and Heng Ji and Lu Wang},\n      year={2021},\n      eprint={2104.02112},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n    }\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18306c", "disabled": false, "gated": false, "likes": 15, "downloads": 1498, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccdv/patent-classification", "sha": "2f38a1dfdecfacee0184d74eaeafd3c0fb49d2a6", "lastModified": "2022-10-22T09:25:36.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "size_categories:10K<n<100K", "language:en", "long context", "region:us"], "private": false, "author": "ccdv", "description": "Patent Classification Dataset: a classification of Patents (9 classes).\n It contains 9 unbalanced classes, 35k Patents and summaries divided into 3 splits: train (25k), val (5k) and test (5k).\n Data are sampled from \"BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization.\" by Eva Sharma, Chen Li and Lu Wang \n See: https://aclanthology.org/P19-1212.pdf \n See: https://evasharma.github.io/bigpatent/", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18306d", "disabled": false, "gated": false, "likes": 5, "downloads": 558, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ccdv/pubmed-summarization", "sha": "26155ccf2b18393a38a05fafc26c66a068974839", "lastModified": "2022-10-24T20:33:04.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "conditional-text-generation", "region:us"], "private": false, "author": "ccdv", "description": "PubMed dataset for summarization.\n From paper: A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents\" by A. Cohan et al.\n See: https://aclanthology.org/N18-2097.pdf \n See: https://github.com/armancohan/long-summarization", "citation": "    @inproceedings{cohan-etal-2018-discourse,\n    title = \"A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents\",\n    author = \"Cohan, Arman  and\n      Dernoncourt, Franck  and\n      Kim, Doo Soon  and\n      Bui, Trung  and\n      Kim, Seokhwan  and\n      Chang, Walter  and\n      Goharian, Nazli\",\n    booktitle = \"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)\",\n    month = jun,\n    year = \"2018\",\n    address = \"New Orleans, Louisiana\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/N18-2097\",\n    doi = \"10.18653/v1/N18-2097\",\n    pages = \"615--621\",\n    abstract = \"Neural abstractive summarization models have led to promising results in summarizing relatively short documents. We propose the first model for abstractive summarization of single, longer-form documents (e.g., research papers). Our approach consists of a new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder to generate the summary. Empirical results on two large-scale datasets of scientific papers show that our model significantly outperforms state-of-the-art models.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18306e", "disabled": false, "gated": false, "likes": 32, "downloads": 2046, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cdleong/piglatin-mt", "sha": "464088ad69bd568eba869f3af6bc2f16a9cd9a5c", "lastModified": "2022-10-24T19:22:09.000Z", "tags": ["task_categories:translation", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": "cdleong", "description": "\\\\r\\nPig-latin machine and English parallel machine translation corpus. \r\n\r\nBased on \r\nThe Project Gutenberg EBook of \"De Bello Gallico\" and Other Commentaries\r\nhttps://www.gutenberg.org/ebooks/10657\r\n\r\nConverted to pig-latin with https://github.com/bpabel/piglatin", "citation": "\\\\r\\n@InProceedings{huggingface:dataset,\r\ntitle = {A great new dataset},\r\nauthor={huggingface, Inc.\r\n},\r\nyear={2020}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183075", "disabled": false, "gated": false, "likes": 0, "downloads": 1144, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cdminix/iwslt2011", "sha": "787665f83399713599465b50eeae66e24d3ae968", "lastModified": "2021-09-21T12:17:53.000Z", "tags": ["region:us"], "private": false, "author": "cdminix", "description": "Both manual transcripts and ASR outputs from the IWSLT2011 speech translation evalutation campaign are often used for the related punctuation annotation task. This dataset takes care of preprocessing said transcripts and automatically inserts punctuation marks given in the manual transcripts in the ASR outputs using Levenshtein aligment.", "citation": "@inproceedings{Ueffing2013,\n    title={Improved models for automatic punctuation prediction for spoken and written text},\n    author={B. Ueffing and M. Bisani and P. Vozila},\n    booktitle={INTERSPEECH},\n    year={2013}\n}\n@article{Federico2011,\n    author = {M. Federico and L. Bentivogli and M. Paul and S. St\u00fcker},\n    year = {2011},\n    month = {01},\n    pages = {},\n    title = {Overview of the IWSLT 2011 Evaluation Campaign},\n    journal = {Proceedings of the International Workshop on Spoken Language Translation (IWSLT), San Francisco, CA}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183077", "disabled": false, "gated": false, "likes": 0, "downloads": 148, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cdminix/mgb1", "sha": "95dbac889aea3016c15f49ec2048dedfa3670a25", "lastModified": "2021-02-05T16:04:03.000Z", "tags": ["region:us"], "private": false, "author": "cdminix", "description": "The first edition of the Multi-Genre Broadcast (MGB-1) Challenge is an evaluation of speech recognition, speaker diarization, and lightly supervised alignment using TV recordings in English.\n\nThe speech data is broad and multi-genre, spanning the whole range of TV output, and represents a challenging task for speech technology.\n\nIn 2015, the challenge used data from the British Broadcasting Corporation (BBC).", "citation": "@inproceedings{bell2015mgb,\n  title={The MGB challenge: Evaluating multi-genre broadcast media recognition},\n  author={Bell, Peter and Gales, Mark JF and Hain, Thomas and Kilgour, Jonathan and Lanchantin, Pierre and Liu, Xunying and McParland, Andrew and Renals, Steve and Saz, Oscar and Wester, Mirjam and others},\n  booktitle={2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)},\n  pages={687--693},\n  year={2015},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183078", "disabled": false, "gated": false, "likes": 0, "downloads": 300, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cgarciae/point-cloud-mnist", "sha": "b88be4d36f97e51173120d42cd35ce2ffa074cc9", "lastModified": "2021-10-31T23:09:55.000Z", "tags": ["region:us"], "private": false, "author": "cgarciae", "description": "The MNIST dataset consists of 70,000 28x28 black-and-white points in 10 classes (one for each digits), with 7,000\npoints per class. There are 60,000 training points and 10,000 test points.", "citation": "# @article{lecun2010mnist,\n#   title={MNIST handwritten digit database},\n#   author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n#   journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n#   volume={2},\n#   year={2010}\n# }\n#", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183091", "disabled": false, "gated": false, "likes": 2, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cheulyop/dementiabank", "sha": "8d0e7de4d68a93dcd49bb63f37e8f3f57ca16cb0", "lastModified": "2021-10-04T14:18:42.000Z", "tags": ["region:us"], "private": false, "author": "cheulyop", "description": "DementiaBank Pitt Corpus includes audios and transcripts of 99 controls and 194 dementia patients. These transcripts and audio files were gathered as part of a larger protocol administered by the Alzheimer and Related Dementias Study at the University of Pittsburgh School of Medicine. The original acquisition of the DementiaBank data was supported by NIH grants AG005133 and AG003705 to the University of Pittsburgh. Participants included elderly controls, people with probable and possible Alzheimer\u2019s Disease, and people with other dementia diagnoses. Data were gathered longitudinally, on a yearly basis.", "citation": "@article{becker1994natural,\n  title={The natural history of Alzheimer's disease: description of study cohort and accuracy of diagnosis},\n  author={Becker, James T and Boiler, Fran{\\c{c}}ois and Lopez, Oscar L and Saxton, Judith and McGonigle, Karen L},\n  journal={Archives of neurology},\n  volume={51},\n  number={6},\n  pages={585--594},\n  year={1994},\n  publisher={American Medical Association}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830b0", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "cheulyop/ksponspeech", "sha": "d51bd8aa4dcb0d95600de289e7c6ea761d412c2d", "lastModified": "2021-10-02T04:27:13.000Z", "tags": ["region:us"], "private": false, "author": "cheulyop", "description": "KsponSpeech is a large-scale spontaneous speech corpus of Korean conversations. This corpus contains 969 hrs of general open-domain dialog utterances, spoken by about 2,000 native Korean speakers in a clean environment. All data were constructed by recording the dialogue of two people freely conversing on a variety of topics and manually transcribing the utterances. The transcription provides a dual transcription consisting of orthography and pronunciation, and disfluency tags for spontaneity of speech, such as filler words, repeated words, and word fragments. KsponSpeech is publicly available on an open data hub site of the Korea government. (https://aihub.or.kr/aidata/105)", "citation": "@article{bang2020ksponspeech,\n  title={KsponSpeech: Korean spontaneous speech corpus for automatic speech recognition},\n  author={Bang, Jeong-Uk and Yun, Seung and Kim, Seung-Hi and Choi, Mu-Yeol and Lee, Min-Kyu and Kim, Yeo-Jeong and Kim, Dong-Hyun and Park, Jun and Lee, Young-Jik and Kim, Sang-Hun},\n  journal={Applied Sciences},\n  volume={10},\n  number={19},\n  pages={6936},\n  year={2020},\n  publisher={Multidisciplinary Digital Publishing Institute}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830b1", "disabled": false, "gated": false, "likes": 3, "downloads": 408, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clarin-pl/2021-punctuation-restoration", "sha": "6051cc3ed097fbbe93c7cc2c480279e230f43e93", "lastModified": "2022-08-29T16:39:18.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:n<1K", "language:pl", "region:us"], "private": false, "author": "clarin-pl", "description": "This dataset is designed to be used in training models\nthat restore punctuation marks from the output of \nAutomatic Speech Recognition system for Polish language.", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830da", "disabled": false, "gated": false, "likes": 1, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clarin-pl/aspectemo", "sha": "55467c09094ac3a0d8261013f884f8f3247b53a0", "lastModified": "2022-08-29T16:39:32.000Z", "tags": ["task_categories:token-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:mit", "region:us"], "private": false, "author": "clarin-pl", "description": "AspectEmo dataset: Multi-Domain Corpus of Consumer Reviews for Aspect-Based \n                Sentiment Analysis", "citation": "@misc{11321/849,\t\n title = {{AspectEmo} 1.0: Multi-Domain Corpus of Consumer Reviews for Aspect-Based Sentiment Analysis},\t\n author = {Koco{\\'n}, Jan and Radom, Jarema and Kaczmarz-Wawryk, Ewa and Wabnic, Kamil and Zaj{\\c a}czkowska, Ada and Za{\\'s}ko-Zieli{\\'n}ska, Monika},\t\n url = {http://hdl.handle.net/11321/849},\t\n note = {{CLARIN}-{PL} digital repository},\t\n copyright = {The {MIT} License},\t\n year = {2021}\t\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830db", "disabled": false, "gated": false, "likes": 1, "downloads": 373, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clarin-pl/multiwiki_90k", "sha": "6b813757db3c1d50f2a5f96b6bccdd6c03201433", "lastModified": "2022-01-24T18:49:03.000Z", "tags": ["region:us"], "private": false, "author": "clarin-pl", "description": "Multi-Wiki90k: Multilingual benchmark dataset for paragraph\nsegmentation", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830df", "disabled": false, "gated": false, "likes": 1, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clarin-pl/polemo2-official", "sha": "802e35d2b12bae84bb07911d841e8f046dc2fcef", "lastModified": "2022-08-29T16:40:01.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:8K", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "clarin-pl", "description": "PolEmo 2.0:  Corpus of Multi-Domain Consumer Reviews, evaluation data for article presented at CoNLL.", "citation": "@inproceedings{kocon-etal-2019-multi,\n    title = \"Multi-Level Sentiment Analysis of {P}ol{E}mo 2.0: Extended Corpus of Multi-Domain Consumer Reviews\",\n    author = \"Koco{\\'n}, Jan  and\n      Mi{\\l}kowski, Piotr  and\n      Za{\\'s}ko-Zieli{\\'n}ska, Monika\",\n    booktitle = \"Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/K19-1092\",\n    doi = \"10.18653/v1/K19-1092\",\n    pages = \"980--991\",}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e1", "disabled": false, "gated": false, "likes": 4, "downloads": 2472, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/FRENK-hate-en", "sha": "52483dba0ff23291271ee9249839865e3c3e7e50", "lastModified": "2022-10-21T07:52:06.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:en", "license:other", "hate-speech-detection", "offensive-language", "arxiv:1906.02045", "region:us"], "private": false, "author": "classla", "description": "The FRENK Datasets of Socially Unacceptable Discourse in English.", "citation": "@misc{ljube\u0161i\u01072019frenk,\n      title={The FRENK Datasets of Socially Unacceptable Discourse in Slovene and English}, \n      author={Nikola Ljube\u0161i\u0107 and Darja Fi\u0161er and Toma\u017e Erjavec},\n      year={2019},\n      eprint={1906.02045},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/1906.02045}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e4", "disabled": false, "gated": false, "likes": 1, "downloads": 488, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/FRENK-hate-hr", "sha": "e7fc9f3d8d6c5640a26679d8a50b1666b02cc41f", "lastModified": "2022-10-21T07:46:28.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:hr", "license:other", "hate-speech-detection", "offensive-language", "arxiv:1906.02045", "region:us"], "private": false, "author": "classla", "description": "The FRENK Datasets of Socially Unacceptable Discourse in Croatian.", "citation": "@misc{ljube\u0161i\u01072019frenk,\n      title={The FRENK Datasets of Socially Unacceptable Discourse in Slovene and English}, \n      author={Nikola Ljube\u0161i\u0107 and Darja Fi\u0161er and Toma\u017e Erjavec},\n      year={2019},\n      eprint={1906.02045},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/1906.02045}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e5", "disabled": false, "gated": false, "likes": 0, "downloads": 448, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/FRENK-hate-sl", "sha": "37c8b42c63d4eb75f549679158a85eb5bd984caa", "lastModified": "2022-10-21T07:46:11.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:sl", "license:other", "hate-speech-detection", "offensive-language", "arxiv:1906.02045", "region:us"], "private": false, "author": "classla", "description": "The FRENK Datasets of Socially Unacceptable Discourse in Slovene.", "citation": "@misc{ljube\u0161i\u01072019frenk,\n      title={The FRENK Datasets of Socially Unacceptable Discourse in Slovene and English}, \n      author={Nikola Ljube\u0161i\u0107 and Darja Fi\u0161er and Toma\u017e Erjavec},\n      year={2019},\n      eprint={1906.02045},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/1906.02045}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e6", "disabled": false, "gated": false, "likes": 0, "downloads": 447, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/copa_hr", "sha": "f3f3a4708e6f8b92915ab02c20ac7fb829e45173", "lastModified": "2022-10-25T07:32:15.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "language:hr", "license:cc-by-sa-4.0", "causal-reasoning", "textual-entailment", "commonsense-reasoning", "arxiv:2005.00333", "arxiv:2104.09243", "region:us"], "private": false, "author": "classla", "description": "The COPA-HR dataset (Choice of plausible alternatives in Croatian) is a translation \nof the English COPA dataset (https://people.ict.usc.edu/~gordon/copa.html) by following the \nXCOPA dataset translation methodology (https://arxiv.org/abs/2005.00333). The dataset consists of 1000 premises \n(My body cast a shadow over the grass), each given a question (What is the cause?), and two choices \n(The sun was rising; The grass was cut), with a label encoding which of the choices is more plausible \ngiven the annotator or translator (The sun was rising).\n\nThe dataset is split into 400 training samples, 100 validation samples, and 500 test samples. It includes the \nfollowing features: 'premise', 'choice1', 'choice2', 'label', 'question', 'changed' (boolean).", "citation": "@article{DBLP:journals/corr/abs-2104-09243,\n  author    = {Nikola Ljubesic and\n               Davor Lauc},\n  title     = {BERTi{\\'{c}} - The Transformer Language Model for Bosnian, Croatian,\n               Montenegrin and Serbian},\n  journal   = {CoRR},\n  volume    = {abs/2104.09243},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2104.09243},\n  archivePrefix = {arXiv},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e7", "disabled": false, "gated": false, "likes": 0, "downloads": 583, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/hr500k", "sha": "708662e326e2e0ee4ce0fb7fa4e41db6c93771f0", "lastModified": "2022-10-25T07:32:05.000Z", "tags": ["task_categories:other", "task_ids:lemmatization", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "language:hr", "license:cc-by-sa-4.0", "structure-prediction", "normalization", "tokenization", "region:us"], "private": false, "author": "classla", "description": "The hr500k training corpus contains about 500,000 tokens manually annotated on the levels of \ntokenisation, sentence segmentation, morphosyntactic tagging, lemmatisation and named entities. \n\nOn the sentence level, the dataset contains 20159 training samples, 1963 validation samples and 2672 test samples \nacross the respective data splits. Each sample represents a sentence and includes the following features:\nsentence ID ('sent_id'), sentence text ('text'), list of tokens ('tokens'), list of lemmas ('lemmas'), \nlist of Multext-East tags ('xpos_tags), list of UPOS tags ('upos_tags'),\nlist of morphological features ('feats'), and list of IOB tags ('iob_tags'). The 'upos_tags' and 'iob_tags' features\nare encoded as class labels.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e8", "disabled": false, "gated": false, "likes": 0, "downloads": 565, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/janes_tag", "sha": "ba014295e666710c5dfe6215338933ecf235156c", "lastModified": "2022-10-25T07:31:04.000Z", "tags": ["task_categories:other", "task_ids:lemmatization", "task_ids:part-of-speech", "language:si", "license:cc-by-sa-4.0", "structure-prediction", "normalization", "tokenization", "region:us"], "private": false, "author": "classla", "description": "The dataset contains 6273 training samples, 762 validation samples and 749 test samples. \nEach sample represents a sentence and includes the following features: sentence ID ('sent_id'), \nlist of tokens ('tokens'), list of normalised word forms ('norms'), list of lemmas ('lemmas'), \nlist of Multext-East tags ('xpos_tags), list of morphological features ('feats'), \nand list of UPOS tags ('upos_tags'), which are encoded as class labels.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830e9", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/reldi_hr", "sha": "da293b9a70a87a936777e93dd59046ddbc6399ce", "lastModified": "2022-10-25T07:30:56.000Z", "tags": ["task_categories:other", "task_ids:lemmatization", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "language:hr", "license:cc-by-sa-4.0", "structure-prediction", "normalization", "tokenization", "region:us"], "private": false, "author": "classla", "description": "The dataset contains 6339 training samples, 815 validation samples and 785 test samples. \nEach sample represents a sentence and includes the following features: sentence ID ('sent_id'), \nlist of tokens ('tokens'), list of lemmas ('lemmas'), list of UPOS tags ('upos_tags'), \nlist of Multext-East tags ('xpos_tags), list of morphological features ('feats'), \nand list of IOB tags ('iob_tags'), which are encoded as class labels.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830ea", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/reldi_sr", "sha": "10a37a1a9ea782093646e0b03d5ef05b3e1e11d5", "lastModified": "2022-10-25T07:30:33.000Z", "tags": ["task_categories:other", "task_ids:lemmatization", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "language:sr", "license:cc-by-sa-4.0", "structure-prediction", "normalization", "tokenization", "region:us"], "private": false, "author": "classla", "description": "The dataset contains 5462 training samples, 711 validation samples and 725 test samples. \nEach sample represents a sentence and includes the following features: sentence ID ('sent_id'), \nlist of tokens ('tokens'), list of lemmas ('lemmas'), list of UPOS tags ('upos_tags'), \nlist of Multext-East tags ('xpos_tags), list of morphological features ('feats'), \nand list of IOB tags ('iob_tags'), which are encoded as class labels.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830eb", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/setimes_sr", "sha": "42861d4054bc5fb993e6606e3c70a2957ec52e91", "lastModified": "2022-10-25T07:30:04.000Z", "tags": ["task_categories:other", "task_ids:lemmatization", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "language:sr", "license:cc-by-sa-4.0", "structure-prediction", "normalization", "tokenization", "region:us"], "private": false, "author": "classla", "description": "SETimes_sr is a Serbian dataset annotated for morphosyntactic information and named entities.\n\nThe dataset contains 3177 training samples, 395 validation samples and 319 test samples \nacross the respective data splits. Each sample represents a sentence and includes the following features:\nsentence ID ('sent_id'), sentence text ('text'), list of tokens ('tokens'), list of lemmas ('lemmas'), \nlist of Multext-East tags ('xpos_tags), list of UPOS tags ('upos_tags'),\nlist of morphological features ('feats'), and list of IOB tags ('iob_tags'). The 'upos_tags' and 'iob_tags' features\nare encoded as class labels.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830ec", "disabled": false, "gated": false, "likes": 0, "downloads": 561, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "classla/ssj500k", "sha": "446b04c97cb43772a229cebbb8da0ce05ee03d2d", "lastModified": "2022-10-28T05:37:22.000Z", "tags": ["task_categories:token-classification", "task_ids:lemmatization", "task_ids:named-entity-recognition", "task_ids:parsing", "task_ids:part-of-speech", "language:sl", "license:cc-by-sa-4.0", "structure-prediction", "tokenization", "dependency-parsing", "region:us"], "private": false, "author": "classla", "description": "The dataset contains 7432 training samples, 1164 validation samples and 893 test samples. \nEach sample represents a sentence and includes the following features: sentence ID ('sent_id'), \nlist of tokens ('tokens'), list of lemmas ('lemmas'), \nlist of Multext-East tags ('xpos_tags), list of UPOS tags ('upos_tags'), list of morphological features ('feats'), \nlist of IOB tags ('iob_tags'), and list of universal dependency tags ('uds'). Three dataset configurations are\navailable, where the corresponding features are encoded as class labels: 'ner', 'upos', and 'ud'.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1830ed", "disabled": false, "gated": false, "likes": 0, "downloads": 566, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clips/mfaq", "sha": "87a7bada8da4fe2a7b738c6d3e549153383198ad", "lastModified": "2022-10-20T11:32:50.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:original", "language:cs", "language:da", "language:de", "language:en", "language:es", "language:fi", "language:fr", "language:he", "language:hr", "language:hu", "language:id", "language:it", "language:nl", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:sv", "language:tr", "language:vi", "license:cc0-1.0", "arxiv:2109.12870", "region:us"], "private": false, "author": "clips", "description": "We present the first multilingual FAQ dataset publicly available. We collected around 6M FAQ pairs from the web, in 21 different languages.", "citation": "@InProceedings{mfaq_a_multilingual_dataset,\n    title={MFAQ: a Multilingual FAQ Dataset},\n    author={Maxime {De Bruyn} and Ehsan Lotfi and Jeska Buhmann and Walter Daelemans},\n    year={2021},\n    booktitle={MRQA @ EMNLP 2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183101", "disabled": false, "gated": false, "likes": 26, "downloads": 6759, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "clips/mqa", "sha": "27eebc4a00d229f8dd4ae2a6d9f1e4ad45781f3b", "lastModified": "2022-09-27T12:38:50.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:original", "language:ca", "language:en", "language:de", "language:es", "language:fr", "language:ru", "language:ja", "language:it", "language:zh", "language:pt", "language:nl", "language:tr", "language:pl", "language:vi", "language:ar", "language:id", "language:uk", "language:ro", "language:no", "language:th", "language:sv", "language:el", "language:fi", "language:he", "language:da", "language:cs", "language:ko", "language:fa", "language:hi", "language:hu", "language:sk", "language:lt", "language:et", "language:hr", "language:is", "language:lv", "language:ms", "language:bg", "language:sr", "license:cc0-1.0", "region:us"], "private": false, "author": "clips", "description": "MQA is a multilingual corpus of questions and answers parsed from the Common Crawl. Questions are divided between Frequently Asked Questions (FAQ) pages and Community Question Answering (CQA) pages.", "citation": "@misc{debruyn2021mfaq,\n      title={MFAQ: a Multilingual FAQ Dataset}, \n      author={Maxime {De Bruyn} and Ehsan Lotfi and Jeska Buhmann and Walter Daelemans},\n      year={2021},\n      booktitle={MRQA@EMNLP2021},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183102", "disabled": false, "gated": false, "likes": 28, "downloads": 39577, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "coastalcph/fairlex", "sha": "ab5506446dea35e06b6ac00d0b9c7a6677cd43ed", "lastModified": "2023-07-27T12:43:39.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:multi-class-classification", "task_ids:topic-classification", "annotations_creators:found", "annotations_creators:machine-generated", "language_creators:found", "source_datasets:extended", "language:en", "language:de", "language:fr", "language:it", "language:zh", "license:cc-by-nc-sa-4.0", "bias", "gender-bias", "arxiv:2103.13868", "arxiv:2105.03887", "arxiv:2203.07228", "region:us"], "private": false, "author": "coastalcph", "description": "Fairlex: A multilingual benchmark for evaluating fairness in legal text processing.", "citation": "@inproceedings{chalkidis-etal-2022-fairlex,\n    author={Chalkidis, Ilias and Passini, Tommaso and Zhang, Sheng and\n            Tomada, Letizia and Schwemer, Sebastian Felix and S\u00f8gaard, Anders},\n    title={FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing},\n    booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},\n    year={2022},\n    address={Dublin, Ireland}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183110", "disabled": false, "gated": false, "likes": 6, "downloads": 1645, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "collectivat/tv3_parla", "sha": "f646cd6d101c64b6226b3a299aed424f19181672", "lastModified": "2022-12-12T09:01:48.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ca", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "collectivat", "description": "This corpus includes 240 hours of Catalan speech from broadcast material.\nThe details of segmentation, data processing and also model training are explained in K\u00fclebi, \u00d6ktem; 2018.\nThe content is owned by Corporaci\u00f3 Catalana de Mitjans Audiovisuals, SA (CCMA);\nwe processed their material and hereby making it available under their terms of use.\n\nThis project was supported by the Softcatal\u00e0 Association.", "citation": "@inproceedings{kulebi18_iberspeech,\n  author={Baybars K\u00fclebi and Alp \u00d6ktem},\n  title={{Building an Open Source Automatic Speech Recognition System for Catalan}},\n  year=2018,\n  booktitle={Proc. IberSPEECH 2018},\n  pages={25--29},\n  doi={10.21437/IberSPEECH.2018-6}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183119", "disabled": false, "gated": false, "likes": 3, "downloads": 287, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "comodoro/vystadial2016_asr", "sha": "219094aed954b897758697a8921a854f5e199b70", "lastModified": "2022-09-02T08:41:16.000Z", "tags": ["license:cc-by-nc-3.0", "region:us"], "private": false, "author": "comodoro", "description": "This is the Czech data collected during the `VYSTADIAL` project. It is an extension of the 'Vystadial 2013' Czech part data release. The dataset comprises of telephone conversations in Czech, developed for training acoustic models for automatic speech recognition in spoken dialogue systems.", "citation": " @misc{11234/1-1740,\n title = {Vystadial 2016 \u2013 Czech data},\n author = {Pl{\\'a}tek, Ond{\\v r}ej and Du{\\v s}ek, Ond{\\v r}ej and Jur{\\v c}{\\'{\\i}}{\\v c}ek, Filip},\n url = {http://hdl.handle.net/11234/1-1740},\n note = {{LINDAT}/{CLARIAH}-{CZ} digital library at the Institute of Formal and Applied Linguistics ({{\\'U}FAL}), Faculty of Mathematics and Physics, Charles University},\n copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n year = {2016} }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18311c", "disabled": false, "gated": false, "likes": 1, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "corypaik/coda", "sha": "9f47e7ea19a1f969027a138c92e4e3a71b5537d3", "lastModified": "2022-10-20T16:57:23.000Z", "tags": ["annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2110.08182", "region:us"], "private": false, "author": "corypaik", "description": "*The Color Dataset* (CoDa) is a probing dataset to evaluate the representation of visual properties in language models. CoDa consists of color distributions for 521 common objects, which are split into 3 groups: Single, Multi, and Any.", "citation": "@misc{paik2021world,\n      title={The World of an Octopus: How Reporting Bias Influences a Language Model's Perception of Color},\n      author={Cory Paik and St\u00e9phane Aroca-Ouellette and Alessandro Roncone and Katharina Kann},\n      year={2021},\n      eprint={2110.08182},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183120", "disabled": false, "gated": false, "likes": 2, "downloads": 284, "paperswithcode_id": "coda", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "corypaik/prost", "sha": "b3efebf08969fc19335ba894353316878b6fa493", "lastModified": "2022-10-25T09:07:34.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "license:apache-2.0", "arxiv:2106.03634", "region:us"], "private": false, "author": "corypaik", "description": "*Physical Reasoning about Objects Through Space and Time* (PROST) is a probing dataset to evaluate the ability of pretrained LMs to understand and reason about the physical world. PROST consists of 18,736 cloze-style multiple choice questions from 14 manually curated templates, covering 10 physical reasoning concepts:  direction, mass, height, circumference, stackable, rollable, graspable, breakable, slideable, and bounceable.", "citation": "@inproceedings{aroca-ouellette-etal-2021-prost,\n  title = \"{PROST}: {P}hysical Reasoning about Objects through Space and Time\",\n  author = \"Aroca-Ouellette, St{\\'e}phane  and\n    Paik, Cory  and\n    Roncone, Alessandro  and\n    Kann, Katharina\",\n  booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n  month = aug,\n  year = \"2021\",\n  address = \"Online\",\n  publisher = \"Association for Computational Linguistics\",\n  url = \"https://aclanthology.org/2021.findings-acl.404\",\n  pages = \"4597--4608\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183121", "disabled": false, "gated": false, "likes": 1, "downloads": 473, "paperswithcode_id": "prost", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "craffel/openai_lambada", "sha": "17d03ac90af36ba25f9106236c158ad593f39e06", "lastModified": "2021-10-12T20:22:47.000Z", "tags": ["region:us"], "private": false, "author": "craffel", "description": "LAMBADA dataset variant used by OpenAI to evaluate GPT-2 and GPT-3.", "citation": "@InProceedings{paperno-EtAl:2016:P16-1,\n  author    = {Paperno, Denis  and  Kruszewski, Germ\\'{a}n  and  Lazaridou,\nAngeliki  and  Pham, Ngoc Quan  and  Bernardi, Raffaella  and  Pezzelle,\nSandro  and  Baroni, Marco  and  Boleda, Gemma  and  Fernandez, Raquel},\n  title     = {The {LAMBADA} dataset: Word prediction requiring a broad\ndiscourse context},\n  booktitle = {Proceedings of the 54th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers)},\n  month     = {August},\n  year      = {2016},\n  address   = {Berlin, Germany},\n  publisher = {Association for Computational Linguistics},\n  pages     = {1525--1534},\n  url       = {http://www.aclweb.org/anthology/P16-1144}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183127", "disabled": false, "gated": false, "likes": 1, "downloads": 7911, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "csebuetnlp/xlsum", "sha": "30fece425f9a3866e04321773ca7a80056d55ca6", "lastModified": "2023-04-18T01:46:20.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:am", "language:ar", "language:az", "language:bn", "language:my", "language:zh", "language:en", "language:fr", "language:gu", "language:ha", "language:hi", "language:ig", "language:id", "language:ja", "language:rn", "language:ko", "language:ky", "language:mr", "language:ne", "language:om", "language:ps", "language:fa", "language:pcm", "language:pt", "language:pa", "language:ru", "language:gd", "language:sr", "language:si", "language:so", "language:es", "language:sw", "language:ta", "language:te", "language:th", "language:ti", "language:tr", "language:uk", "language:ur", "language:uz", "language:vi", "language:cy", "language:yo", "license:cc-by-nc-sa-4.0", "conditional-text-generation", "arxiv:1607.01759", "region:us"], "private": false, "author": "csebuetnlp", "description": "We present XLSum, a comprehensive and diverse dataset comprising 1.35 million professionally \nannotated article-summary pairs from BBC, extracted using a set of carefully designed heuristics.\nThe dataset covers 45 languages ranging from low to high-resource, for many of which no\npublic dataset is currently available. XL-Sum is highly abstractive, concise, \nand of high quality, as indicated by human and intrinsic evaluation.", "citation": "@inproceedings{hasan-etal-2021-xl,\n    title = \"{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\",\n    author = \"Hasan, Tahmid  and\n      Bhattacharjee, Abhik  and\n      Islam, Md. Saiful  and\n      Mubasshir, Kazi  and\n      Li, Yuan-Fang  and\n      Kang, Yong-Bin  and\n      Rahman, M. Sohel  and\n      Shahriyar, Rifat\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.findings-acl.413\",\n    pages = \"4693--4703\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18313a", "disabled": false, "gated": false, "likes": 59, "downloads": 79659, "paperswithcode_id": "xl-sum", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "csebuetnlp/xnli_bn", "sha": "a18ecb62d7ffd4a6bff5756afb6e799bbb91dd3e", "lastModified": "2022-08-21T13:14:56.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended", "language:bn", "license:cc-by-nc-sa-4.0", "arxiv:2101.00204", "arxiv:2007.01852", "region:us"], "private": false, "author": "csebuetnlp", "description": "This is a Natural Language Inference (NLI) dataset for Bengali, curated using the subset of\nMNLI data used in XNLI and state-of-the-art English to Bengali translation model.", "citation": "@misc{bhattacharjee2021banglabert,\n      title={BanglaBERT: Combating Embedding Barrier in Multilingual Models for Low-Resource Language Understanding},\n      author={Abhik Bhattacharjee and Tahmid Hasan and Kazi Samin and Md Saiful Islam and M. Sohel Rahman and Anindya Iqbal and Rifat Shahriyar},\n      year={2021},\n      eprint={2101.00204},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18313b", "disabled": false, "gated": false, "likes": 1, "downloads": 329, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ctu-aic/anli_cs", "sha": "c09df83957da565576f678c4d42d47cec09384d0", "lastModified": "2021-11-21T21:12:10.000Z", "tags": ["region:us"], "private": false, "author": "ctu-aic", "description": "TODO: Anli_cs is a Czech translation of the Adversarial NLI dataset", "citation": "todo", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183148", "disabled": false, "gated": false, "likes": 0, "downloads": 300, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ctu-aic/csfever", "sha": "c9f2ce78fc92e19353b7f1cb3f4b68f15d32eb1c", "lastModified": "2022-11-01T05:56:15.000Z", "tags": ["license:cc-by-sa-3.0", "arxiv:1803.05355", "arxiv:2201.11115", "region:us"], "private": false, "author": "ctu-aic", "description": "CsFEVER is a Czech localisation of the English FEVER datgaset.", "citation": "@article{DBLP:journals/corr/abs-2201-11115,\n  author    = {Jan Drchal and\n               Herbert Ullrich and\n               Martin R{\\'{y}}par and\n               Hana Vincourov{\\'{a}} and\n               V{\\'{a}}clav Moravec},\n  title     = {CsFEVER and CTKFacts: Czech Datasets for Fact Verification},\n  journal   = {CoRR},\n  volume    = {abs/2201.11115},\n  year      = {2022},\n  url       = {https://arxiv.org/abs/2201.11115},\n  eprinttype = {arXiv},\n  eprint    = {2201.11115},\n  timestamp = {Tue, 01 Feb 2022 14:59:01 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-11115.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183149", "disabled": false, "gated": false, "likes": 2, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ctu-aic/csfever_nli", "sha": "69d0247380ab01c39f2920974a1736e92fe45783", "lastModified": "2022-02-22T11:13:35.000Z", "tags": ["region:us"], "private": false, "author": "ctu-aic", "description": "CsfeverNLI is a NLI version of the Czech Csfever dataset", "citation": "todo", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18314a", "disabled": false, "gated": false, "likes": 1, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ctu-aic/ctkfacts_nli", "sha": "387ae4582c8054cb52ef57ef0941f19bd8012abf", "lastModified": "2022-11-01T06:35:47.000Z", "tags": ["arxiv:2201.11115", "region:us"], "private": false, "author": "ctu-aic", "description": "CtkFactsNLI is a NLI version of the Czech CTKFacts dataset", "citation": "@article{DBLP:journals/corr/abs-2201-11115,\n  author    = {Jan Drchal and\n               Herbert Ullrich and\n               Martin R{\\'{y}}par and\n               Hana Vincourov{\\'{a}} and\n               V{\\'{a}}clav Moravec},\n  title     = {CsFEVER and CTKFacts: Czech Datasets for Fact Verification},\n  journal   = {CoRR},\n  volume    = {abs/2201.11115},\n  year      = {2022},\n  url       = {https://arxiv.org/abs/2201.11115},\n  eprinttype = {arXiv},\n  eprint    = {2201.11115},\n  timestamp = {Tue, 01 Feb 2022 14:59:01 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-11115.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18314c", "disabled": false, "gated": false, "likes": 2, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ctu-aic/snli_cs", "sha": "429e8fea195a87d82f4ac6f869a09cf659dfca64", "lastModified": "2021-11-21T21:07:34.000Z", "tags": ["region:us"], "private": false, "author": "ctu-aic", "description": "TODO: Snli_cs is a Czech translation of the Stanford NLI dataset", "citation": "todo", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18314f", "disabled": false, "gated": false, "likes": 0, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dalle-mini/YFCC100M_OpenAI_subset", "sha": "986e65392adb1f3bdab07c25ed9a23cb83a0b354", "lastModified": "2021-08-26T17:56:01.000Z", "tags": ["arxiv:1503.01817", "region:us"], "private": false, "author": "dalle-mini", "description": "The YFCC100M is one of the largest publicly and freely useable multimedia collection, containing  the metadata of around 99.2 million photos and 0.8 million videos from Flickr, all of which were shared under one of the various Creative Commons licenses.\n\nThis version is a subset defined in openai/CLIP.", "citation": "@article{thomee2016yfcc100m,\nauthor = \"Bart Thomee and David A. Shamma and Gerald Friedland and Benjamin Elizalde and Karl Ni and Douglas Poland and Damian Borth and Li-Jia Li\",\ntitle = \"{YFCC100M}: The New Data in Multimedia Research\",\njournal = \"Communications of the {ACM}\",\nvolume = \"59\",\nnumber = \"2\",\npages = \"64--73\",\nyear = \"2016\",\nurl = \"http://cacm.acm.org/magazines/2016/2/197425-yfcc100m/fulltext\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18315d", "disabled": false, "gated": false, "likes": 9, "downloads": 433, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dataset/wikipedia_bn", "sha": "26f2ce6009be2a738d103277233d6fdbefa96af9", "lastModified": "2021-06-04T16:22:44.000Z", "tags": ["region:us"], "private": false, "author": "dataset", "description": "Bengali Wikipedia from the dump of 03/20/2021.\nThe data was processed using the huggingface datasets wikipedia script early april 2021.\nThe dataset was built from the Wikipedia dump (https://dumps.wikimedia.org/).\nEach example contains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).", "citation": "@ONLINE {wikidump,\n    author = {Wikimedia Foundation},\n    title  = {Wikimedia Downloads},\n    url    = {https://dumps.wikimedia.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18318e", "disabled": false, "gated": false, "likes": 1, "downloads": 288, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "deepset/germandpr", "sha": "5129d02422a66be600ac89cd3e8531b4f97d347d", "lastModified": "2023-04-06T13:59:37.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_ids:extractive-qa", "task_ids:closed-domain-qa", "multilinguality:monolingual", "source_datasets:original", "language:de", "license:cc-by-4.0", "arxiv:2104.12741", "region:us"], "private": false, "author": "deepset", "description": "We take GermanQuAD as a starting point and add hard negatives from a dump of the full German Wikipedia following the approach of the DPR authors (Karpukhin et al., 2020). The format of the dataset also resembles the one of DPR. GermanDPR comprises 9275 question/answer pairs in the training set and 1025 pairs in the test set. For each pair, there are one positive context and three hard negative contexts.", "citation": "@misc{m\u00f6ller2021germanquad,\n      title={GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval}, \n      author={Timo M\u00f6ller and Julian Risch and Malte Pietsch},\n      year={2021},\n      eprint={2104.12741},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1831f0", "disabled": false, "gated": false, "likes": 7, "downloads": 587, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "deepset/germanquad", "sha": "fff05ceaf2ffbe5b65c7e0c57e678f7b7e1a0581", "lastModified": "2023-04-06T13:58:35.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_ids:extractive-qa", "task_ids:closed-domain-qa", "task_ids:open-domain-qa", "multilinguality:monolingual", "source_datasets:original", "language:de", "license:cc-by-4.0", "arxiv:2104.12741", "region:us"], "private": false, "author": "deepset", "description": "In order to raise the bar for non-English QA, we are releasing a high-quality, human-labeled German QA dataset consisting of 13 722 questions, incl. a three-way annotated test set.\nThe creation of GermanQuAD is inspired by insights from existing datasets as well as our labeling experience from several industry projects. We combine the strengths of SQuAD, such as high out-of-domain performance, with self-sufficient questions that contain all relevant information for open-domain QA as in the NaturalQuestions dataset. Our training and test datasets do not overlap like other popular datasets and include complex questions that cannot be answered with a single entity or only a few words.", "citation": "@misc{m\u00f6ller2021germanquad,\n      title={GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval}, \n      author={Timo M\u00f6ller and Julian Risch and Malte Pietsch},\n      year={2021},\n      eprint={2104.12741},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1831f1", "disabled": false, "gated": false, "likes": 26, "downloads": 1214, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "DFKI-SLT/few-nerd", "sha": "6f0944f5a1d47c359b4f5de03ed1d58c98f297b5", "lastModified": "2023-06-21T09:59:09.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|wikipedia", "language:en", "license:cc-by-sa-4.0", "structure-prediction", "region:us"], "private": false, "author": "DFKI-SLT", "description": "Few-NERD is a large-scale, fine-grained manually annotated named entity recognition dataset, \nwhich contains 8 coarse-grained types, 66 fine-grained types, 188,200 sentences, 491,711 entities \nand 4,601,223 tokens. Three benchmark tasks are built, one is supervised: Few-NERD (SUP) and the \nother two are few-shot: Few-NERD (INTRA) and Few-NERD (INTER).", "citation": "@inproceedings{ding2021few,\ntitle={Few-NERD: A Few-Shot Named Entity Recognition Dataset},\nauthor={Ding, Ning and Xu, Guangwei and Chen, Yulin, and Wang, Xiaobin and Han, Xu and Xie, \nPengjun and Zheng, Hai-Tao and Liu, Zhiyuan},\nbooktitle={ACL-IJCNLP},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18320d", "disabled": false, "gated": false, "likes": 13, "downloads": 2293, "paperswithcode_id": "few-nerd", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "DFKI-SLT/mobie", "sha": "6b1bef2a9b7718d9a345d086ad9750123fa380b4", "lastModified": "2022-10-24T06:32:09.000Z", "tags": ["task_categories:other", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "license:cc-by-4.0", "structure-prediction", "region:us"], "private": false, "author": "DFKI-SLT", "description": "MobIE is a German-language dataset which is human-annotated with 20 coarse- and fine-grained entity types and entity linking information for geographically linkable entities. The dataset consists of 3,232 social media texts and traffic reports with 91K tokens, and contains 20.5K annotated entities, 13.1K of which are linked to a knowledge base. A subset of the dataset is human-annotated with seven mobility-related, n-ary relation types, while the remaining documents are annotated using a weakly-supervised labeling approach implemented with the Snorkel framework. The dataset combines annotations for NER, EL and RE, and thus can be used for joint and multi-task learning of these fundamental information extraction tasks.", "citation": "        @inproceedings{hennig-etal-2021-mobie,\n    title = \"{M}ob{IE}: A {G}erman Dataset for Named Entity Recognition, Entity Linking and Relation Extraction in the Mobility Domain\",\n    author = \"Hennig, Leonhard  and\n      Truong, Phuc Tran  and\n      Gabryszak, Aleksandra\",\n    booktitle = \"Proceedings of the 17th Conference on Natural Language Processing (KONVENS 2021)\",\n    month = \"6--9 \" # sep,\n    year = \"2021\",\n    address = {D{\\\"u}sseldorf, Germany},\n    publisher = \"KONVENS 2021 Organizers\",\n    url = \"https://aclanthology.org/2021.konvens-1.22\",\n    pages = \"223--227\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18320e", "disabled": false, "gated": false, "likes": 0, "downloads": 281, "paperswithcode_id": "mobie", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "diwank/hinglish-dump", "sha": "4bc6bb8acfa2b1b370b89138f7af792c36712de1", "lastModified": "2022-03-05T14:28:55.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "diwank", "description": "Raw merged dump of Hinglish (hi-EN) datasets.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183229", "disabled": false, "gated": false, "likes": 1, "downloads": 1001, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "diwank/silicone-merged", "sha": "8ac729015e92e4f02f1ad60e9c595fbeca504e36", "lastModified": "2022-03-06T11:30:57.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "diwank", "description": "Merged and simplified dialog act datasets from the silicone collection.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18322a", "disabled": false, "gated": false, "likes": 1, "downloads": 426, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dk-crazydiv/huggingface-modelhub", "sha": "5b6f20f66d73f38078bc1e543ee4ee0fe68e2865", "lastModified": "2021-06-20T14:09:58.000Z", "tags": ["region:us"], "private": false, "author": "dk-crazydiv", "description": "Metadata information of all the models available on HuggingFace's modelhub", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18322c", "disabled": false, "gated": false, "likes": 3, "downloads": 282, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dlb/plue", "sha": "589d0538b2c05ac37dad771f15b5736732468005", "lastModified": "2022-10-29T12:19:26.000Z", "tags": ["task_categories:text-classification", "task_ids:acceptability-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "task_ids:sentiment-classification", "task_ids:text-scoring", "annotations_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:extended|glue", "language:pt", "license:lgpl-3.0", "paraphrase-identification", "qa-nli", "coreference-nli", "region:us"], "private": false, "author": "dlb", "description": "PLUE: Portuguese Language Understanding Evaluationis a Portuguese translation of \nthe GLUE benchmark and Scitail using OPUS-MT model and Google Cloud Translation.", "citation": "@misc{Gomes2020,\n  author = {GOMES, J. R. S.},\n  title = {Portuguese Language Understanding Evaluation},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\\\url{https://github.com/jubs12/PLUE}},\n  commit = {CURRENT_COMMIT}\n}\n\n@inproceedings{wang2019glue,\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n  note={In the Proceedings of ICLR.},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18322d", "disabled": false, "gated": false, "likes": 6, "downloads": 2615, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dram-conflict/horror-scripts", "sha": "5d439c6aade70845c23ee2877bda2eb29c64390e", "lastModified": "2022-02-21T16:26:48.000Z", "tags": ["region:us"], "private": false, "author": "dram-conflict", "description": "This dataset is designed to generate scripts.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183246", "disabled": false, "gated": false, "likes": 0, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dynabench/dynasent", "sha": "d1e2d5e619bb78fb6dc4d548108c50cb65b8d78c", "lastModified": "2021-04-29T11:30:24.000Z", "tags": ["arxiv:2012.15349", "arxiv:1803.09010", "arxiv:1810.03993", "region:us"], "private": false, "author": "dynabench", "description": "    Dynabench.DynaSent is a Sentiment Analysis dataset collected using a \n    human-and-model-in-the-loop.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18325f", "disabled": false, "gated": false, "likes": 3, "downloads": 807, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "dynabench/qa", "sha": "3c4dbdd9119ff5dfeafe06f06f9ae7a6824e02ae", "lastModified": "2022-07-02T20:17:58.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "arxiv:2002.00293", "arxiv:1606.05250", "region:us"], "private": false, "author": "dynabench", "description": "    Dynabench.QA is a Reading Comprehension dataset collected using a human-and-model-in-the-loop.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183260", "disabled": false, "gated": false, "likes": 0, "downloads": 710, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ebrigham/labels", "sha": "3c8cc81213ada9ab5f4ee6f41c3552908a2a924c", "lastModified": "2022-03-15T15:08:28.000Z", "tags": ["region:us"], "private": false, "author": "ebrigham", "description": "AG is a collection of more than 1 million news articles. News articles have been\ngathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\nactivity. ComeToMyHead is an academic news search engine which has been running\nsince July, 2004. The dataset is provided by the academic comunity for research\npurposes in data mining (clustering, classification, etc), information retrieval\n(ranking, search, etc), xml, data compression, data streaming, and any other\nnon-commercial activity. For more information, please refer to the link\nhttp://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\nThe AG's news topic classification dataset is constructed by Xiang Zhang\n(xiang.zhang@nyu.edu) from the dataset above. It is used as a text\nclassification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\nLeCun. Character-level Convolutional Networks for Text Classification. Advances\nin Neural Information Processing Systems 28 (NIPS 2015).", "citation": "@inproceedings{Zhang2015CharacterlevelCN,\n  title={Character-level Convolutional Networks for Text Classification},\n  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},\n  booktitle={NIPS},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18326d", "disabled": false, "gated": false, "likes": 0, "downloads": 286, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "edbeeching/decision_transformer_gym_replay", "sha": "4441c97718b1f7e03d05f430226b57f658cc156d", "lastModified": "2022-04-20T12:39:58.000Z", "tags": ["license:apache-2.0", "arxiv:2004.07219", "region:us"], "private": false, "author": "edbeeching", "description": "A subset of the D4RL dataset, used for training Decision Transformers", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183275", "disabled": false, "gated": false, "likes": 2, "downloads": 7973, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/BSD100", "sha": "7a20e0a3c51c5e5153a4416c8606a1476565fa74", "lastModified": "2022-10-26T02:20:22.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:other", "image-super-resolution", "region:us"], "private": false, "author": "eugenesiow", "description": "BSD is a dataset used frequently for image denoising and super-resolution. \nBSD100 is the testing set of the Berkeley segmentation dataset BSD300.", "citation": "@inproceedings{martin2001database,\n  title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},\n  author={Martin, David and Fowlkes, Charless and Tal, Doron and Malik, Jitendra},\n  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},\n  volume={2},\n  pages={416--423},\n  year={2001},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f4", "disabled": false, "gated": false, "likes": 0, "downloads": 343, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/Div2k", "sha": "a6aa2cb45e33a4753d28a373bd1125a321a1c21d", "lastModified": "2022-10-21T04:01:10.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:other", "other-image-super-resolution", "region:us"], "private": false, "author": "eugenesiow", "description": "DIV2K dataset: DIVerse 2K resolution high quality images as used for the challenges @ NTIRE (CVPR 2017 and \nCVPR 2018) and @ PIRM (ECCV 2018)", "citation": "@InProceedings{Agustsson_2017_CVPR_Workshops,\nauthor = {Agustsson, Eirikur and Timofte, Radu},\ntitle = {NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study},\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},\nurl = \"http://www.vision.ee.ethz.ch/~timofter/publications/Agustsson-CVPRW-2017.pdf\",\nmonth = {July},\nyear = {2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f5", "disabled": false, "gated": false, "likes": 2, "downloads": 2779, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/PIRM", "sha": "0fbc53ce3af34f8283a46d70ed353ccc67085237", "lastModified": "2022-10-21T04:01:16.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:cc-by-nc-sa-4.0", "other-image-super-resolution", "arxiv:1809.07517", "region:us"], "private": false, "author": "eugenesiow", "description": "The PIRM dataset consists of 200 images, which are divided into two equal sets for validation and testing. \nThese images cover diverse contents, including people, objects, environments, flora, natural scenery, etc. \nImages vary in size, and are typically ~300K pixels in resolution.\n\nThis dataset was first used for evaluating the perceptual quality of super-resolution algorithms in The 2018 PIRM \nchallenge on Perceptual Super-resolution, in conjunction with ECCV 2018.", "citation": "@misc{shoeiby2019pirm2018,\n  title={PIRM2018 Challenge on Spectral Image Super-Resolution: Dataset and Study}, \n  author={Mehrdad Shoeiby and Antonio Robles-Kelly and Ran Wei and Radu Timofte},\n  year={2019},\n  eprint={1904.00540},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f6", "disabled": false, "gated": false, "likes": 0, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/Set14", "sha": "5afcf80d267dba61cdfa9a32b1a6fe4cca57b6d7", "lastModified": "2022-10-21T04:00:31.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:other", "other-image-super-resolution", "region:us"], "private": false, "author": "eugenesiow", "description": "Set14 is an evaluation dataset with 14 RGB images for the image super resolution task.", "citation": "@inproceedings{zeyde2010single,\n  title={On single image scale-up using sparse-representations},\n  author={Zeyde, Roman and Elad, Michael and Protter, Matan},\n  booktitle={International conference on curves and surfaces},\n  pages={711--730},\n  year={2010},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f7", "disabled": false, "gated": false, "likes": 0, "downloads": 317, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/Set5", "sha": "d8b579a20afde95b4d8ed6bf6383447d33027295", "lastModified": "2022-10-21T03:59:16.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:other", "other-image-super-resolution", "region:us"], "private": false, "author": "eugenesiow", "description": "Set5 is a evaluation dataset with 5 RGB images for the image super resolution task.", "citation": "@article{bevilacqua2012low,\n  title={Low-complexity single-image super-resolution based on nonnegative neighbor embedding},\n  author={Bevilacqua, Marco and Roumy, Aline and Guillemot, Christine and Alberi-Morel, Marie Line},\n  year={2012},\n  publisher={BMVA press}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f8", "disabled": false, "gated": false, "likes": 0, "downloads": 500, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "eugenesiow/Urban100", "sha": "fb0d8a4c6b2471d32bd133de40bb8bb10dde69b9", "lastModified": "2022-10-21T03:58:53.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:cc-by-4.0", "other-image-super-resolution", "region:us"], "private": false, "author": "eugenesiow", "description": "The Urban100 dataset contains 100 images of urban scenes. \nIt commonly used as a test set to evaluate the performance of super-resolution models.", "citation": "@inproceedings{martin2001database,\n  title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},\n  author={Martin, David and Fowlkes, Charless and Tal, Doron and Malik, Jitendra},\n  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},\n  volume={2},\n  pages={416--423},\n  year={2001},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1832f9", "disabled": false, "gated": false, "likes": 0, "downloads": 300, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "facebook/multilingual_librispeech", "sha": "d22a730b623deccb518ee6ad0cf8cc8cef98e9cd", "lastModified": "2023-02-13T11:33:31.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "language:nl", "language:fr", "language:it", "language:es", "language:pt", "language:pl", "license:cc-by-4.0", "arxiv:2012.03411", "region:us"], "private": false, "author": "facebook", "description": "This is a streamable version of the Multilingual LibriSpeech (MLS) dataset. \nThe data archives were restructured from the original ones from [OpenSLR](http://www.openslr.org/94) \nto make it easier to stream. \n\nMLS dataset is a large multilingual corpus suitable for speech research. \nThe dataset is derived from read audiobooks from LibriVox and consists of 8 languages: \nEnglish, German, Dutch, Spanish, French, Italian, Portuguese, Polish.", "citation": "@article{Pratap2020MLSAL,\n  title={MLS: A Large-Scale Multilingual Dataset for Speech Research},\n  author={Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},\n  journal={ArXiv},\n  year={2020},\n  volume={abs/2012.03411}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183300", "disabled": false, "gated": false, "likes": 31, "downloads": 2596, "paperswithcode_id": "multilingual-librispeech", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "fhamborg/news_sentiment_newsmtsc", "sha": "98afeae90eadb629ae70cd2d0fc16f64c2cd2f8d", "lastModified": "2022-10-25T09:20:03.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": "fhamborg", "description": "NewsMTSC: A large, manually annotated dataset for target-dependent sentiment classification in English news articles.", "citation": "@InProceedings{Hamborg2021b,\n  author    = {Hamborg, Felix and Donnay, Karsten},\n  title     = {NewsMTSC: (Multi-)Target-dependent Sentiment Classification in News Articles},\n  booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021)},\n  year      = {2021},\n  month     = {Apr.},\n  location  = {Virtual Event},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18334b", "disabled": false, "gated": false, "likes": 9, "downloads": 732, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flax-community/german_common_crawl", "sha": "c3ee6f6b93580246f8ec7ef9db66504c98657fe7", "lastModified": "2023-10-02T16:46:37.000Z", "tags": ["language:de", "region:us"], "private": false, "author": "flax-community", "description": "German Only Extract from Common Crawl\n\nThis Dataset is for pretraining a German Language Model (Unsupervised) or tune a Multilingual Model specifically to German", "citation": "@inproceedings{wenzek2020ccnet,\n  title={CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data},\n  author={Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\\'a}n, Francisco and Joulin, Armand and Grave, {\\'E}douard},\n  booktitle={Proceedings of The 12th Language Resources and Evaluation Conference},\n  pages={4003--4012},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18335c", "disabled": false, "gated": false, "likes": 0, "downloads": 704, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flax-community/swahili-safi", "sha": "ff72b5185de624dd23f890509df733b922a8f74d", "lastModified": "2021-07-18T12:48:55.000Z", "tags": ["region:us"], "private": false, "author": "flax-community", "description": "Cleaned dataset for Swahili Language Modeling", "citation": "@InProceedings{huggingface:flax-community,\ntitle = Cleaned dataset for Swahili Language Modeling,\nauthors={Fitsum, Alok, Patrick},\nyear={2021},\nlink = https://huggingface.co/datasets/flax-community/swahili-safi\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183360", "disabled": false, "gated": false, "likes": 3, "downloads": 319, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flexthink/librig2p-nostress-space", "sha": "e0e90b5d29640a6475a72f4e681441ec30c7e6a8", "lastModified": "2022-06-24T01:23:49.000Z", "tags": ["region:us"], "private": false, "author": "flexthink", "description": "Grapheme-to-Phoneme training, validation and test sets", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18336a", "disabled": false, "gated": false, "likes": 0, "downloads": 418, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "flexthink/ljspeech", "sha": "7367bcc33648be329bbef057cc97d0b83cadee11", "lastModified": "2022-02-06T00:09:16.000Z", "tags": ["region:us"], "private": false, "author": "flexthink", "description": "This is a public domain speech dataset consisting of 13,100 short audio\nclips of a single speaker reading passages from 7 non-fiction books. A\ntranscription is provided for each clip. Clips vary in length from 1 to 10\nseconds and have a total length of approximately 24 hours.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18336c", "disabled": false, "gated": false, "likes": 2, "downloads": 284, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "florianbussmann/FUNSD-vu2020revising", "sha": "92c16c659bc64b56cd25c0261f08a8dce56f9983", "lastModified": "2022-10-25T09:20:31.000Z", "tags": ["multilinguality:monolingual", "language:en", "arxiv:2010.05322", "region:us"], "private": false, "author": "florianbussmann", "description": "\\\r\nFUNSD is one of the limited publicly available datasets for information extraction from document images.\r\nThe information in the FUNSD dataset is defined by text areas of four categories (\"key\", \"value\", \"header\", \"other\", and \"background\")\r\nand connectivity between areas as key-value relations. Inspecting FUNSD, we found several inconsistency in labeling, which impeded its\r\napplicability to the key-value extraction problem. In this report, we described some labeling issues in FUNSD and the revision we made\r\nto the dataset.", "citation": "\\\r\n@article{vu2020revising,\r\n        title={Revising FUNSD dataset for key-value detection in document images},\r\n        author={Vu, Hieu M and Nguyen, Diep Thi-Ngoc},\r\n        journal={arXiv preprint arXiv:2010.05322},\r\n        year={2020}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183374", "disabled": false, "gated": false, "likes": 0, "downloads": 150, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "florianbussmann/train_tickets-yu2020pick", "sha": "23c5c2c370cc60de189b21af8030578680828f5d", "lastModified": "2022-01-19T14:18:09.000Z", "tags": ["region:us"], "private": false, "author": "florianbussmann", "description": "\\\r\nThe train ticket is fixed layout dataset, however, it contains background noise and imaging distortions.\r\nIt contains 1,530 synthetic images and 320 real images for training, and 80 real images for testing.\r\nEvery train ticket has eight key text fields including ticket number, starting station, train number, destination station, date, ticket rates, seat category, and name.\r\nThis dataset mainly consists of digits, English characters, and Chinese characters.", "citation": "\\\r\n@inproceedings{yu2021pick,\r\n               title={PICK: Processing key information extraction from documents using improved graph learning-convolutional networks},\r\n               author={Yu, Wenwen and Lu, Ning and Qi, Xianbiao and Gong, Ping and Xiao, Rong},\r\n               booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},\r\n               pages={4363--4370},\r\n               year={2021},\r\n               organization={IEEE}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183375", "disabled": false, "gated": false, "likes": 0, "downloads": 142, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "frtna/jwt300_mt", "sha": "23a82e3dea67a41b7b749142df5efe963a91cd4a", "lastModified": "2021-12-08T22:29:26.000Z", "tags": ["region:us"], "private": false, "author": "frtna", "description": "This new dataset is designed to be used in the scope of machine translation project.", "citation": "@InProceedings{phd,\ntitle = {JWT-300 OPUS Machine Translation Dataset},\nauthor={hmtkvs, Inc.\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183399", "disabled": false, "gated": false, "likes": 0, "downloads": 323, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "frtna/opensubtitles_mt", "sha": "c2c0be202618bd1d4f9254c19607a00edd00174c", "lastModified": "2021-12-05T20:53:04.000Z", "tags": ["region:us"], "private": false, "author": "frtna", "description": "This new dataset is designed to be used in the scope of PhD project.", "citation": "@InProceedings{phd,\ntitle = {Open Subtitles Machine Translation Dataset},\nauthor={hmtkvs, Inc.\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18339a", "disabled": false, "gated": false, "likes": 0, "downloads": 281, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "frtna/ted_mt", "sha": "981f92e50156dfa5231f18b7d5251d49363b2f66", "lastModified": "2021-12-07T03:28:28.000Z", "tags": ["region:us"], "private": false, "author": "frtna", "description": "This new dataset is designed to be used in the scope of multilingual model project.", "citation": "@InProceedings{phd,\ntitle = {Machine Translation Dataset},\nauthor={hmtkvs, Inc.\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18339c", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gcaillaut/citeseer", "sha": "b6db9f816b945de32a7711f63df7db72cbc708c2", "lastModified": "2021-10-21T15:39:06.000Z", "tags": ["region:us"], "private": false, "author": "gcaillaut", "description": "The CiteSeer dataset consists of 3312 scientific publications classified into one of six classes. The citation network consists of 4732 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 3703 unique words. The README file in the dataset provides more details.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833cc", "disabled": false, "gated": false, "likes": 0, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gcaillaut/cora", "sha": "b9e027e2f04c713476fec873ca8afeb4ab281589", "lastModified": "2021-10-20T07:45:16.000Z", "tags": ["region:us"], "private": false, "author": "gcaillaut", "description": "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833cd", "disabled": false, "gated": false, "likes": 0, "downloads": 278, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gcaillaut/frwiki_good_pages_el", "sha": "e6a41689f90a1148e18c639f2062ecb17fe84b55", "lastModified": "2022-07-04T12:36:42.000Z", "tags": ["task_categories:other", "annotations_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "license:wtfpl", "region:us"], "private": false, "author": "gcaillaut", "description": "French Wikipedia dataset for Entity Linking", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833ce", "disabled": false, "gated": false, "likes": 1, "downloads": 278, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gcaillaut/pubmed", "sha": "893d11ae8f801be416d1af54be4e3c87c2c80e12", "lastModified": "2021-10-21T15:39:47.000Z", "tags": ["region:us"], "private": false, "author": "gcaillaut", "description": "The Pubmed Diabetes dataset consists of 19717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links. Each publication in the dataset is described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words. The README file in the dataset provides more details.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833cf", "disabled": false, "gated": false, "likes": 0, "downloads": 283, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "german-nlp-group/german_common_crawl", "sha": "493f46641b0e5b43fd139712e7c16acabbe3835c", "lastModified": "2023-10-03T14:50:28.000Z", "tags": ["language:de", "region:us"], "private": false, "author": "german-nlp-group", "description": "German Only Extract from Common Crawl \n\nThis Dataset is for pretraining a German Language Model (Unsupervised) or tune a Multilingual Model specifically to German", "citation": "@inproceedings{wenzek2020ccnet,\n  title={CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data},\n  author={Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\\'a}n, Francisco and Joulin, Armand and Grave, {\\'E}douard},\n  booktitle={Proceedings of The 12th Language Resources and Evaluation Conference},\n  pages={4003--4012},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833e3", "disabled": false, "gated": false, "likes": 7, "downloads": 639, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ghomasHudson/character_id", "sha": "e2bcd549228fb99a946a6c36685c8651ba488902", "lastModified": "2022-01-13T23:29:38.000Z", "tags": ["region:us"], "private": false, "author": "ghomasHudson", "description": "The character types identification dataset consists of movie\nscripts annotated with character archetypes (Hero, Villain, Mentor, etc.).", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833f8", "disabled": false, "gated": false, "likes": 0, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ghomasHudson/muld", "sha": "eb92b66ad9d8b6a59cad50beccfc170346a013c8", "lastModified": "2022-11-02T12:55:17.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-generation", "task_categories:translation", "task_ids:abstractive-qa", "annotations_creators:found", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:translation", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "source_datasets:extended|hotpot_qa", "source_datasets:extended|open_subtitles", "language:en", "language:de", "conditional-text-generation", "arxiv:2202.07362", "region:us"], "private": false, "author": "ghomasHudson", "description": "MuLD: The Multitask Long Document Benchmark\nA set of NLP tasks where each example is over 10,000 tokens long.", "citation": "@misc{hudson2022muld,\n    title{MuLD: The Multitask Long Document Benchmark},\n    author={G Thomas Hudson, Noura Al Moubayed}\n    year={2022},\n    eprint={TODO},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\nSome of these datasets are directly based on existing datasets. Please cite these works.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833fb", "disabled": false, "gated": false, "likes": 5, "downloads": 1231, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ghomasHudson/vlsp", "sha": "0458b63225091d3bf55d72492c3aa60419fd6f4b", "lastModified": "2022-10-25T09:20:37.000Z", "tags": ["language:en", "region:us"], "private": false, "author": "ghomasHudson", "description": "Very Long version of the scientific papers summarization dataset. Only includes theses over 10,000 tokens long.", "citation": "\"\"\"\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833fc", "disabled": false, "gated": false, "likes": 0, "downloads": 279, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gigant/african_accented_french", "sha": "643cc6391a43781f688022acd18b872d0789c309", "lastModified": "2022-10-24T17:39:03.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:fr", "license:cc", "region:us"], "private": false, "author": "gigant", "description": "\\\r\nThis corpus consists of approximately 22 hours of speech recordings. Transcripts are provided for all the recordings. The corpus can be divided into 3 parts:\r\n\r\n1. Yaounde\r\n\r\nCollected by a team from the U.S. Military Academy's Center for Technology Enhanced Language Learning (CTELL) in 2003 in Yaound\u00e9, Cameroon. It has recordings from 84 speakers, 48 male and 36 female.\r\n\r\n2. CA16\r\n\r\nThis part was collected by a RDECOM Science Team who participated in the United Nations exercise Central Accord 16 (CA16) in Libreville, Gabon in June 2016. The Science Team included DARPA's Dr. Boyan Onyshkevich and Dr. Aaron Lawson (SRI International), as well as RDECOM scientists. It has recordings from 125 speakers from Cameroon, Chad, Congo and Gabon.\r\n\r\n3. Niger\r\n\r\nThis part was collected from 23 speakers in Niamey, Niger, Oct. 26-30 2015. These speakers were students in a course for officers and sergeants presented by Army trainers assigned to U.S. Army Africa. The data was collected by RDECOM Science & Technology Advisors Major Eddie Strimel and Mr. Bill Bergen.", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1833ff", "disabled": false, "gated": false, "likes": 4, "downloads": 291, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gigant/m-ailabs_speech_dataset_fr", "sha": "71ec8b9e1b5351ea514cdf748c92592b13b14175", "lastModified": "2022-10-24T17:38:45.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:fr", "license:cc", "region:us"], "private": false, "author": "gigant", "description": "\\\r\nThe M-AILABS Speech Dataset is the first large dataset that we are providing free-of-charge, freely usable as training data for speech recognition and speech synthesis.\r\n\r\nMost of the data is based on LibriVox and Project Gutenberg. The training data consist of nearly thousand hours of audio and the text-files in prepared format.\r\n\r\nA transcription is provided for each clip. Clips vary in length from 1 to 20 seconds and have a total length of approximately shown in the list (and in the respective info.txt-files) below.\r\n\r\n\r\nThe texts were published between 1884 and 1964, and are in the public domain. The audio was recorded by the LibriVox project and is also in the public domain \u2013 except for Ukrainian.\r\n\r\nUkrainian audio was kindly provided either by Nash Format or Gwara Media for machine learning purposes only (please check the data info.txt files for details).", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183400", "disabled": false, "gated": false, "likes": 0, "downloads": 280, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gigant/romanian_speech_synthesis_0_8_1", "sha": "b4dd8109d62276134bdc035cb274018825428582", "lastModified": "2022-10-24T17:38:35.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:ro", "license:unknown", "region:us"], "private": false, "author": "gigant", "description": "\\\r\nThe Romanian speech synthesis (RSS) corpus was recorded in a hemianechoic chamber (anechoic walls and ceiling; floor partially anechoic) at the University of Edinburgh. We used three high quality studio microphones: a Neumann u89i (large diaphragm condenser), a Sennheiser MKH 800 (small diaphragm condenser with very wide bandwidth) and a DPA 4035 (headset-mounted condenser). Although the current release includes only speech data recorded via Sennheiser MKH 800, we may release speech data recorded via other microphones in the future. All recordings were made at 96 kHz sampling frequency and 24 bits per sample, then downsampled to 48 kHz sampling frequency. For recording, downsampling and bit rate conversion, we used ProTools HD hardware and software. We conducted 8 sessions over the course of a month, recording about 500 sentences in each session. At the start of each session, the speaker listened to a previously recorded sample, in order to attain a similar voice quality and intonation.", "citation": "\\\r\n@article{Stan2011442,\r\n  author = {Adriana Stan and Junichi Yamagishi and Simon King and\r\n                   Matthew Aylett},\r\n  title = {The {R}omanian speech synthesis ({RSS}) corpus:\r\n                   Building a high quality {HMM}-based speech synthesis\r\n                   system using a high sampling rate},\r\n  journal = {Speech Communication},\r\n  volume = {53},\r\n  number = {3},\r\n  pages = {442--450},\r\n  note = {},\r\n  abstract = {This paper first introduces a newly-recorded high\r\n                   quality Romanian speech corpus designed for speech\r\n                   synthesis, called ''RSS'', along with Romanian\r\n                   front-end text processing modules and HMM-based\r\n                   synthetic voices built from the corpus. All of these\r\n                   are now freely available for academic use in order to\r\n                   promote Romanian speech technology research. The RSS\r\n                   corpus comprises 3500 training sentences and 500 test\r\n                   sentences uttered by a female speaker and was recorded\r\n                   using multiple microphones at 96 kHz sampling\r\n                   frequency in a hemianechoic chamber. The details of the\r\n                   new Romanian text processor we have developed are also\r\n                   given. Using the database, we then revisit some basic\r\n                   configuration choices of speech synthesis, such as\r\n                   waveform sampling frequency and auditory frequency\r\n                   warping scale, with the aim of improving speaker\r\n                   similarity, which is an acknowledged weakness of\r\n                   current HMM-based speech synthesisers. As we\r\n                   demonstrate using perceptual tests, these configuration\r\n                   choices can make substantial differences to the quality\r\n                   of the synthetic speech. Contrary to common practice in\r\n                   automatic speech recognition, higher waveform sampling\r\n                   frequencies can offer enhanced feature extraction and\r\n                   improved speaker similarity for HMM-based speech\r\n                   synthesis.},\r\n  doi = {10.1016/j.specom.2010.12.002},\r\n  issn = {0167-6393},\r\n  keywords = {Speech synthesis, HTS, Romanian, HMMs, Sampling\r\n                   frequency, Auditory scale},\r\n  url = {http://www.sciencedirect.com/science/article/pii/S0167639310002074},\r\n  year = 2011\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183402", "disabled": false, "gated": false, "likes": 2, "downloads": 295, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gmnlp/tico19", "sha": "55d70dc0b1d1d0b2151c5e22815d823fedac3f2f", "lastModified": "2021-10-03T19:00:13.000Z", "tags": ["region:us"], "private": false, "author": "gmnlp", "description": "In response to the on-going crisis, several academic (Carnegie Mellon University, \nGeorge Mason University, Johns Hopkins University) and industry (Amazon, Appen, \nFacebook, Google, Microsoft, Translated) partners have partnered with the Translators \nwithout Borders to prepare COVID-19 materials for a variety of the world\u2019s languages \nto be used by professional translators and for training state-of-the-art Machine \nTranslation (MT) models. The focus is on making emergency and crisis-related content \navailable in as many languages as possible. The collected, curated and translated \ncontent across nearly 90 languages will be available to the professional translation \nas well the MT research community.", "citation": "@article{DBLP:journals/corr/abs-2007-01788,\n  author    = {Antonios Anastasopoulos and\n               Alessandro Cattelan and\n               Zi{-}Yi Dou and\n               Marcello Federico and\n               Christian Federmann and\n               Dmitriy Genzel and\n               Francisco Guzm{\\'{a}}n and\n               Junjie Hu and\n               Macduff Hughes and\n               Philipp Koehn and\n               Rosie Lazar and\n               William Lewis and\n               Graham Neubig and\n               Mengmeng Niu and\n               Alp {\\\"{O}}ktem and\n               Eric Paquin and\n               Grace Tang and\n               Sylwia Tur},\n  title     = {{TICO-19:} the Translation Initiative for Covid-19},\n  journal   = {CoRR},\n  volume    = {abs/2007.01788},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2007.01788},\n  archivePrefix = {arXiv},\n  eprint    = {2007.01788},\n  timestamp = {Thu, 08 Apr 2021 11:46:39 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-01788.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183413", "disabled": false, "gated": false, "likes": 1, "downloads": 5620, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gsarti/change_it", "sha": "ceb0129e499ea5344dba1391c0a046222ddba631", "lastModified": "2022-10-27T08:37:09.000Z", "tags": ["task_categories:summarization", "task_categories:text-generation", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:it", "license:cc-by-nc-sa-4.0", "conditional-text-generation", "style-transfer", "region:us"], "private": false, "author": "gsarti", "description": "The CHANGE-IT dataset contains approximately 152,000 article-headline pairs, collected from two Italian \nnewspapers situated at opposite ends of the political spectrum, namely la Repubblica (left) and \nIl Giornale (right), with the two newspapers equally represented. The dataset has been used in the context \nof the CHANGE-IT task (https://sites.google.com/view/change-it) during the Evalita 2020 evaluation campaign \n(http://www.evalita.it/2020). CHANGE-IT is a generation task for Italian \u2013 more specifically, a style transfer \ntask for headlines of Italian newspapers. Given a (collection of) headlines from one newspaper, namely \nIl Giornale (G) or La Repubblica (R), it challenges automatic systems to change all G-headlines to headlines in \nstyle R, and all R-headlines to headlines in style G. Although the task only concerns headline change, the dataset \ncomprehends both the headlines as well as their respective full articles.", "citation": "@inproceedings{demattei-etal-2020-changeit,\n    author = {De Mattei, Lorenzo and Cafagna, Michele and Dell'Orletta, Felice and Nissim, Malvina and Gatt, Albert},\n    title = {{CHANGE-IT @ EVALITA 2020}: Change Headlines, Adapt News, GEnerate},\n    booktitle = {Proceedings of Seventh Evaluation Campaign of Natural Language Processing and Speech Tools for Italian. Final Workshop (EVALITA 2020)},\n    editor = {Basile, Valerio and Croce, Danilo and Di Maro, Maria, and Passaro, Lucia C.},\n    publisher = {CEUR.org},\n    year = {2020},\n    address = {Online}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183430", "disabled": false, "gated": false, "likes": 1, "downloads": 427, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gsarti/clean_mc4_it", "sha": "8281df3f5a2e765a5cc30e4feacac61e94ffdce4", "lastModified": "2022-10-23T09:01:21.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "source_datasets:extended", "language:it", "license:odc-by", "arxiv:1910.10683", "arxiv:2203.03759", "region:us"], "private": false, "author": "gsarti", "description": "A thoroughly cleaned version of the Italian portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.", "citation": "@article{JMLR:v21:20-074,\n  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n  journal = {Journal of Machine Learning Research},\n  year    = {2020},\n  volume  = {21},\n  number  = {140},\n  pages   = {1-67},\n  url     = {http://jmlr.org/papers/v21/20-074.html}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183431", "disabled": false, "gated": false, "likes": 6, "downloads": 1135, "paperswithcode_id": "mc4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gsarti/flores_101", "sha": "bc58ae43b22607b3e1e2bf3ae1bc5cb053495abb", "lastModified": "2022-10-27T08:37:36.000Z", "tags": ["task_categories:text-generation", "task_categories:translation", "annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|flores", "language:af", "language:am", "language:ar", "language:hy", "language:as", "language:ast", "language:az", "language:be", "language:bn", "language:bs", "language:bg", "language:my", "language:ca", "language:ceb", "language:zho", "language:hr", "language:cs", "language:da", "language:nl", "language:en", "language:et", "language:tl", "language:fi", "language:fr", "language:ff", "language:gl", "language:lg", "language:ka", "language:de", "language:el", "language:gu", "language:ha", "language:he", "language:hi", "language:hu", "language:is", "language:ig", "language:id", "language:ga", "language:it", "language:ja", "language:jv", "language:kea", "language:kam", "language:kn", "language:kk", "language:km", "language:ko", "language:ky", "language:lo", "language:lv", "language:ln", "language:lt", "language:luo", "language:lb", "language:mk", "language:ms", "language:ml", "language:mt", "language:mi", "language:mr", "language:mn", "language:ne", "language:ns", "language:no", "language:ny", "language:oc", "language:or", "language:om", "language:ps", "language:fa", "language:pl", "language:pt", "language:pa", "language:ro", "language:ru", "language:sr", "language:sn", "language:sd", "language:sk", "language:sl", "language:so", "language:ku", "language:es", "language:sw", "language:sv", "language:tg", "language:ta", "language:te", "language:th", "language:tr", "language:uk", "language:umb", "language:ur", "language:uz", "language:vi", "language:cy", "language:wo", "language:xh", "language:yo", "language:zu", "license:cc-by-sa-4.0", "conditional-text-generation", "arxiv:2106.03193", "region:us"], "private": false, "author": "gsarti", "description": "One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the \nlack of good evaluation benchmarks. Current evaluation benchmarks either lack good coverage of low-resource \nlanguages, consider only restricted domains, or are low quality because they are constructed using \nsemi-automatic procedures. In this work, we introduce the FLORES evaluation benchmark, consisting of 3001 \nsentences extracted from English Wikipedia and covering a variety of different topics and domains. \nThese sentences have been translated in 101 languages by professional translators through a carefully \ncontrolled process. The resulting dataset enables better assessment of model quality on the long tail of \nlow-resource languages, including the evaluation of many-to-many multilingual translation systems, as all \ntranslations are multilingually aligned. By publicly releasing such a high-quality and high-coverage dataset, \nwe hope to foster progress in the machine translation community and beyond.", "citation": "@inproceedings{,\n  title={The {FLORES}-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation},\n  author={\n      Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and \n      Ju, Da and Krishnan, Sanjana and Ranzato, Marc'Aurelio and Guzm\\'{a}n, Francisco and Fan, Angela\n  },\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183433", "disabled": false, "gated": false, "likes": 12, "downloads": 16221, "paperswithcode_id": "flores", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gsarti/itacola", "sha": "f8f98e5c4d3059cf1a00c8eb3d70aa271423f636", "lastModified": "2022-07-01T15:38:55.000Z", "tags": ["task_categories:text-classification", "task_ids:acceptability-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:it", "license:unknown", "arxiv:2109.12053", "region:us"], "private": false, "author": "gsarti", "description": "The Italian Corpus of Linguistic Acceptability includes almost 10k sentences taken from \nlinguistic literature with a binary annotation made by the original authors themselves. \nThe work is inspired by the English Corpus of Linguistic Acceptability (CoLA) by Warstadt et al.\nPart of the dataset has been manually annotated to highlight 9 linguistic phenomena.", "citation": "@inproceedings{trotta-etal-2021-monolingual,\n    author = {Trotta, Daniela and Guarasci, Raffaele and Leonardelli, Elisa and Tonelli, Sara},\n    title = {Monolingual and Cross-Lingual Acceptability Judgments with the Italian {CoLA} corpus},\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2021\",\n    month = nov,\n    year = {2021},\n    address = \"Punta Cana, Dominican Republic and Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://arxiv.org/abs/2109.12053\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183434", "disabled": false, "gated": false, "likes": 1, "downloads": 468, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "gsarti/wmt_vat", "sha": "986c40d9c5a10d748051440873fffa65f37e82d9", "lastModified": "2022-10-27T08:37:41.000Z", "tags": ["task_categories:text-generation", "task_categories:translation", "annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|wmt16", "source_datasets:extended|wmt17", "source_datasets:extended|wmt18", "source_datasets:extended|wmt19", "source_datasets:extended|wmt20", "language:cs", "language:de", "language:en", "language:et", "language:fi", "language:fr", "language:gu", "language:iu", "language:ja", "language:kk", "language:km", "language:lt", "language:lv", "language:pl", "language:ps", "language:ro", "language:ru", "language:ta", "language:tr", "language:zh", "license:unknown", "conditional-text-generation", "region:us"], "private": false, "author": "gsarti", "description": "The Variance-Aware Machine Translation corpus contains 70 small and discriminative test sets for machine translation (MT) \nevaluation called variance-aware test sets (VAT), covering 35 translation directions from WMT16 to WMT20 competitions. \nVAT is automatically created by a novel variance-aware filtering method that filters the indiscriminative test instances \nof the current MT benchmark without any human labor. Experimental results show that VAT outperforms the original WMT benchmark \nin terms of the correlation with human judgment across mainstream language pairs and test sets. Further analysis on the properties \nof VAT reveals the challenging linguistic features (e.g., translation of low-frequency words and proper nouns) for the competitive \nMT systems, providing guidance for constructing future MT test sets.", "citation": "@inproceedings{\n    zhan2021varianceaware,\n    title={Variance-Aware Machine Translation Test Sets},\n    author={Runzhe Zhan and Xuebo Liu and Derek F. Wong and Lidia S. Chao},\n    booktitle={Thirty-fifth Conference on Neural Information Processing Systems, Datasets and Benchmarks Track},\n    year={2021},\n    url={https://openreview.net/forum?id=hhKA5k0oVy5}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183437", "disabled": false, "gated": false, "likes": 8, "downloads": 9982, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "hf-internal-testing/librispeech_asr_demo", "sha": "997cc70bf07335d6cf5ab62c7a0570ba92a217a6", "lastModified": "2022-04-07T07:06:24.000Z", "tags": ["region:us"], "private": false, "author": "hf-internal-testing", "description": "LibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an ASR corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1834ab", "disabled": false, "gated": false, "likes": 2, "downloads": 7424, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "it5/datasets", "sha": "ea495b3b96a44982211996370a3975d25e782670", "lastModified": "2022-04-26T09:21:47.000Z", "tags": ["region:us"], "private": false, "author": "it5", "description": "\"\"\"\n\n_HOMEPAGE = \"\"\n\n_LICENSE = \"\"\n\n_BASE_URL = \"https://huggingface.co/datasets/it5/datasets/resolve/main/data/{config}_{split}.json.gz\"\n\n# Formality Style Transfer with XFormal\n_FST_SPLITS = [\"train\", \"valid\", \"test_0\", \"test_1\", \"test_2\", \"test_3\"]\n\n# Headline Generation with CHANGE-it\n_HG_SPLITS = [\"train\", \"valid\", \"test\"]\n\n# News Summarization with Fanpage/IlPost\n_NS_SPLITS = [\"train\", \"valid\", \"test_fanpage\", \"test_ilpost\"]\n\n# Question Answering with SQUAD-it\n_QA_SPLITS = [\"train\", \"valid\", \"test\"]\n\n# Question Generation with SQUAD-it\n_QG_SPLITS = [\"train\", \"valid\", \"test\"]\n\n# Headline Style Transfer Giornale -> Repubblica with CHANGE-it\n_ST_G2R_SPLITS = [\"train\", \"valid\", \"test\"]\n\n# Headline Style Transfer Repubblica -> Giornale with CHANGE-it\n_ST_R2G_SPLITS = [\"train\", \"valid\", \"test\"]\n\n# Wikipedia Summarization with WITS\n_WITS_SPLITS = [\"train\", \"valid\", \"test\"]\n\n_CONFIG_SPLITS = {\n    \"fst\": _FST_SPLITS,\n    \"hg\": _HG_SPLITS,\n    \"ns\": _NS_SPLITS,\n    \"qa\": _QA_SPLITS,\n    \"qg\": _QG_SPLITS,\n    \"st_g2r\": _ST_G2R_SPLITS,\n    \"st_r2g\": _ST_R2G_SPLITS,\n    \"wits\": _WITS_SPLITS,\n}\n\n_CONFIG_FEATS = {\n    \"fst\": [\"formal\", \"informal\"],\n    \"hg\": [\"text\", \"target\"],\n    \"ns\": [\"source\", \"target\"],\n    \"qa\": [\"source\", \"target\"],\n    \"qg\": [\"text\", \"target\"],\n    \"st_g2r\": [\"headline\", \"full_text\"],\n    \"st_r2g\": [\"headline\", \"full_text\"],\n    \"wits\": [\"summary\", \"source\"]\n}\n\nclass IT5ExperimentsConfig(datasets.BuilderConfig):\n\n    def __init__(self, features, **kwargs):", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183635", "disabled": false, "gated": "manual", "likes": 0, "downloads": 22, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jegormeister/dutch-snli", "sha": "9a3686ebeddd8751304c63f0be2fa4d28b8b0854", "lastModified": "2023-10-02T19:06:35.000Z", "tags": ["language:nl", "region:us"], "private": false, "author": "jegormeister", "description": "This is the Dutch version of the original SNLI dataset. The translation was performed using Google Translate. Original SNLI available at https://nlp.stanford.edu/projects/snli/", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183683", "disabled": false, "gated": false, "likes": 0, "downloads": 277, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jfrenz/legalglue", "sha": "7019f71cc4cdfe11bf8f52f18375bc1b407313ca", "lastModified": "2022-10-22T22:14:36.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:multi-label-classification", "task_ids:topic-classification", "multilinguality:multilingual", "source_datasets:extended", "language:en", "language:da", "language:de", "language:nl", "language:sv", "language:bg", "language:cs", "language:hr", "language:pl", "language:sk", "language:sl", "language:es", "language:fr", "language:it", "language:pt", "language:ro", "language:et", "language:fi", "language:hu", "language:lt", "language:lv", "language:el", "language:mt", "german-ler", "lener-br", "arxiv:2003.13016", "arxiv:2110.00806", "arxiv:2109.00904", "region:us"], "private": false, "author": "jfrenz", "description": "\\\r\nLegal General Language Understanding Evaluation (LegalGLUE) benchmark is\r\na collection of datasets for evaluating model performance across a diverse set of legal NLP tasks", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18369a", "disabled": false, "gated": false, "likes": 6, "downloads": 4524, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jglaser/binding_affinity", "sha": "11e49b7ece33d62afd7f65bc05ce60ad37f9ba7b", "lastModified": "2022-03-12T00:29:11.000Z", "tags": ["molecules", "chemistry", "SMILES", "region:us"], "private": false, "author": "jglaser", "description": "A dataset to fine-tune language models on protein-ligand binding affinity prediction.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {jglaser/binding_affinity},\nauthor={Jens Glaser, ORNL\n},\nyear={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18369e", "disabled": false, "gated": false, "likes": 5, "downloads": 701, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jimregan/clarinpl_sejmsenat", "sha": "12ef6ff7249d499ae2255caa3d3d80a1cccb308d", "lastModified": "2023-01-22T13:37:24.000Z", "tags": ["task_categories:other", "task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pl", "license:other", "region:us"], "private": false, "author": "jimregan", "description": "A collection of 97 hours of parliamentary speeches published on the ClarinPL website\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@article{marasek2014system,\n  title={System for automatic transcription of sessions of the {P}olish {S}enate},\n  author={Marasek, Krzysztof and Kor{\\v{z}}inek, Danijel and Brocki, {\\L}ukasz},\n  journal={Archives of Acoustics},\n  volume={39},\n  number={4},\n  pages={501--509},\n  year={2014}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1836b1", "disabled": false, "gated": false, "likes": 1, "downloads": 278, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jimregan/clarinpl_studio", "sha": "f306efab67c654660955f251fa7fa3f7d687cae1", "lastModified": "2023-01-21T12:27:08.000Z", "tags": ["task_categories:other", "task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:other", "arxiv:1706.00245", "region:us"], "private": false, "author": "jimregan", "description": "The corpus consists of 317 speakers recorded in 554\nsessions, where each session consists of 20 read sentences and 10 phonetically rich words. The size of\nthe audio portion of the corpus amounts to around 56 hours, with transcriptions containing 356674 words\nfrom a vocabulary of size 46361.\n\nNote that in order to limit the required storage for preparing this dataset, the audio\nis stored in the .wav format and is not converted to a float32 array. To convert the audio\nfile to a float32 array, please make use of the `.map()` function as follows:\n\n```python\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech_array, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech_array\n    return batch\n\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\n```", "citation": "@article{korvzinek2017polish,\n  title={Polish read speech corpus for speech tools and services},\n  author={Kor{\\v{z}}inek, Danijel and Marasek, Krzysztof and Brocki, {\\L}ukasz and Wo{\\l}k, Krzysztof},\n  journal={arXiv preprint arXiv:1706.00245},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1836b2", "disabled": false, "gated": false, "likes": 1, "downloads": 285, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jimregan/foinse", "sha": "7ecb120fa64fc7b85fa37f6b6a49c75db2a2fe17", "lastModified": "2021-10-06T20:42:52.000Z", "tags": ["region:us"], "private": false, "author": "jimregan", "description": "Foinse was an Irish-language magazine site.\nThis script uses a list of articles retrieved from the\nWayback Machine to build a corpus", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1836b3", "disabled": false, "gated": false, "likes": 0, "downloads": 144, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "jimregan/lasid", "sha": "90cbeb0e452cab6263934764282c6d9479905dcc", "lastModified": "2021-10-06T23:31:28.000Z", "tags": ["region:us"], "private": false, "author": "jimregan", "description": "Linguistic Atlas and Survey of Irish Dialects, volume 1", "citation": "@book{wagner1958linguistic,\n  title={Linguistic Atlas and Survey of Irish Dialects: Introduction, 300 maps.},\n  author={Wagner, H.},\n  number={v. 1},\n  year={1958},\n  publisher={Dublin Institute for Advanced Studies}\n}\n\n@phdthesis{mckendry1982computer,\n  title={Computer-aided contributions to the study of Irish dialects},\n  author={McKendry, Eugene},\n  year={1982},\n  school={Queen's University Belfast}\n}\n\n@article{mckendry1998linguistic,\n  title={The Linguistic Atlas and Survey of Irish Dialects (LASID) and the Computer},\n  author={McKendry, Eugene},\n  journal={Studia Celtica Upsaliensia},\n  volume={2},\n  pages={345--354},\n  year={1998}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1836b4", "disabled": false, "gated": false, "likes": 0, "downloads": 142, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ju-bezdek/conll2003-SK-NER", "sha": "b56484636d458e72c094ef81c6e85b3a695ee7e4", "lastModified": "2023-03-21T08:13:05.000Z", "tags": ["task_categories:other", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|conll2003", "language:sk", "license:unknown", "structure-prediction", "region:us"], "private": false, "author": "ju-bezdek", "description": "This is translated version of the original CONLL2003 dataset (translated from English to Slovak via Google translate) Annotation was done mostly automatically with word matching scripts. Records where some tags were not matched, were annotated manually (10%) Unlike the original Conll2003 dataset, this one contains only NER tags", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18371a", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "k-halid/ar", "sha": "732277696e54f33273e0e006d6e8638edb44eb1e", "lastModified": "2021-02-05T16:05:32.000Z", "tags": ["region:us"], "private": false, "author": "k-halid", "description": "The corpus is a part of the MultiUN corpus.It is a collection of translated documents from the United Nations.The corpus is download from the following website : [open parallel corpus](http://opus.datasetsl.eu/)  \\", "citation": "@inproceedings{eisele2010multiun,\n  title={MultiUN: A Multilingual Corpus from United Nation Documents.},\n  author={Eisele, Andreas and Chen, Yu},\n  booktitle={LREC},\n  year={2010}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183751", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "keshan/clean-si-mc4", "sha": "65abe73d128fe38c1da174718ecef300f8e204c0", "lastModified": "2021-07-14T10:14:11.000Z", "tags": ["region:us"], "private": false, "author": "keshan", "description": "A colossal, cleaned version of Common Crawl's web crawl corpus.\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's mC4 dataset by AllenAI.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183798", "disabled": false, "gated": false, "likes": 0, "downloads": 247, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kresnik/librispeech_asr_test", "sha": "82f059766e9ddfc75a5653f977ea69d7f6b3fb06", "lastModified": "2022-01-18T15:51:58.000Z", "tags": ["region:us"], "private": false, "author": "kresnik", "description": "\\\r\nLibriSpeech is a corpus of approximately 1000 hours of read English speech with sampling rate of 16 kHz,\r\nprepared by Vassil Panayotov with the assistance of Daniel Povey. The data is derived from read\r\naudiobooks from the LibriVox project, and has been carefully segmented and aligned.\r\nNote that in order to limit the required storage for preparing this dataset, the audio\r\nis stored in the .flac format and is not converted to a float32 array. To convert, the audio\r\nfile to a float32 array, please make use of the `.map()` function as follows:\r\n```python\r\nimport soundfile as sf\r\ndef map_to_array(batch):\r\n    speech_array, _ = sf.read(batch[\"file\"])\r\n    batch[\"speech\"] = speech_array\r\n    return batch\r\ndataset = dataset.map(map_to_array, remove_columns=[\"file\"])\r\n```", "citation": "\\\r\n@inproceedings{panayotov2015librispeech,\r\n  title={Librispeech: an ASR corpus based on public domain audio books},\r\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\r\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},\r\n  pages={5206--5210},\r\n  year={2015},\r\n  organization={IEEE}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1837ff", "disabled": false, "gated": false, "likes": 2, "downloads": 15, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "kresnik/zeroth_korean", "sha": "1acd883ba10c5eb39d892395fec1ae9980e17a8c", "lastModified": "2023-01-04T06:54:55.000Z", "tags": ["region:us"], "private": false, "author": "kresnik", "description": "This is Zeroth-Korean corpus,\nlicensed under Attribution 4.0 International (CC BY 4.0)\nThe data set contains transcriebed audio data for Korean. There are 51.6 hours transcribed Korean audio for training data (22,263 utterances, 105 people, 3000 sentences) and 1.2 hours transcribed Korean audio for testing data (457 utterances, 10 people). This corpus also contains pre-trained/designed language model, lexicon and morpheme-based segmenter(morfessor).\nZeroth project introduces free Korean speech corpus and aims to make Korean speech recognition more broadly accessible to everyone.\nThis project was developed in collaboration between Lucas Jo(@Atlas Guide Inc.) and Wonkyum Lee(@Gridspace Inc.).\n\nContact: Lucas Jo(lucasjo@goodatlas.com), Wonkyum Lee(wonkyum@gridspace.com)", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183800", "disabled": false, "gated": false, "likes": 5, "downloads": 165, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lavis-nlp/german_legal_sentences", "sha": "fbf9bb8761bafeb5d7e158901446da58f6a71d9c", "lastModified": "2022-10-20T18:34:19.000Z", "tags": ["task_categories:text-retrieval", "task_ids:semantic-similarity-scoring", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n>1M", "source_datasets:original", "language:de", "license:unknown", "arxiv:2005.13342", "arxiv:2010.10252", "region:us"], "private": false, "author": "lavis-nlp", "description": "German Legal Sentences (GLS) is an automatically generated training dataset for semantic sentence \nmatching in the domain in german legal documents. It follows the concept of weak supervision, where \nimperfect labels are generated using multiple heuristics. For this purpose we use a combination of \nlegal citation matching and BM25 similarity. The contained sentences and their citations are parsed \nfrom real judicial decisions provided by [Open Legal Data](http://openlegaldata.io/)", "citation": "coming soon", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18385b", "disabled": false, "gated": false, "likes": 3, "downloads": 29, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "lhoestq/test", "sha": "8af5b3fc20bfa28cc0f09ddc1a0c0bcddf906e3a", "lastModified": "2022-07-01T15:26:34.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": "lhoestq", "description": "This is a test dataset.", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1838b7", "disabled": false, "gated": false, "likes": 0, "downloads": 355, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "liweili/c4_200m", "sha": "1b0382449b4273d9de8e6d6ad15ca6873884758a", "lastModified": "2022-10-23T11:00:46.000Z", "tags": ["task_categories:text-generation", "source_datasets:allenai/c4", "language:en", "grammatical-error-correction", "region:us"], "private": false, "author": "liweili", "description": "\\\r\nGEC Dataset Generated from C4", "citation": "\\\r\n@InProceedings{huggingface:c4_200m_dataset,\r\ntitle = {c4_200m},\r\nauthor={Li Liwei},\r\nyear={2021}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1838d8", "disabled": false, "gated": false, "likes": 25, "downloads": 29, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "codeparrot/github-code", "sha": "b5661e6b17396364b2bcf8e68977b0d28e1ebd19", "lastModified": "2022-10-20T15:01:14.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "language:code", "license:other", "region:us"], "private": false, "author": "codeparrot", "description": "The GitHub Code dataest consists of 115M code files from GitHub in 32 programming languages with 60 extensions totalling in 1TB of text data. The dataset was created from the GitHub dataset on BiqQuery.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183929", "disabled": false, "gated": false, "likes": 193, "downloads": 4405, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "m3hrdadfi/recipe_nlg_lite", "sha": "d91ce8bd583c4cbaad3420e16e1d112e3b5c9113", "lastModified": "2021-07-03T09:34:56.000Z", "tags": ["region:us"], "private": false, "author": "m3hrdadfi", "description": "RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation - Lite version\nThe dataset we publish contains 7,198 cooking recipes (>7K). \nIt's processed in more careful way and provides more samples than any other dataset in the area.", "citation": "@misc{RecipeNLGLite, \n  author          = {Mehrdad Farahani},\n  title           = {RecipeNLG: A Cooking Recipes Dataset for Semi-Structured Text Generation (Lite)},\n  year            = 2021,\n  publisher       = {GitHub},\n  journal         = {GitHub repository},\n  howpublished    = {url{https://github.com/m3hrdadfi/recipe-nlg-lite}},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183971", "disabled": false, "gated": false, "likes": 3, "downloads": 352, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metaeval/blimp_classification", "sha": "340b7b6ca58a930b5d2ffa0c4f25f05055085168", "lastModified": "2023-01-09T10:50:25.000Z", "tags": ["task_categories:text-classification", "task_ids:acceptability-classification", "size_categories:10K<n<100K", "language:en", "license:apache-2.0", "cola", "region:us"], "private": false, "author": "metaeval", "description": "Acceptable/non acceptable sentences (recasted as a classification task)", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a13", "disabled": false, "gated": false, "likes": 1, "downloads": 45, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tasksource/crowdflower", "sha": "6d2c046fd8032a11c5779deb27d2c1880297dac9", "lastModified": "2023-06-21T12:50:08.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "language:en", "region:us"], "private": false, "author": "tasksource", "description": "Collection of crowdflower classification datasets", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a15", "disabled": false, "gated": false, "likes": 0, "downloads": 78, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metaeval/ethics", "sha": "1d762d62f0b8f28d1699af28efd177131935e472", "lastModified": "2023-06-02T14:45:34.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "language:en", "region:us"], "private": false, "author": "metaeval", "description": "Probing for ethics understanding", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a16", "disabled": false, "gated": false, "likes": 4, "downloads": 1730, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metaeval/linguisticprobing", "sha": "61090105f7e52a6b08978dce2dbd1f3b5cfda1b0", "lastModified": "2022-11-09T15:41:29.000Z", "tags": ["task_categories:text-classification", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "language:en", "region:us"], "private": false, "author": "metaeval", "description": "10 probing tasks designed to capture simple linguistic features of sentences,", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a17", "disabled": false, "gated": false, "likes": 0, "downloads": 131, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "metaeval/recast", "sha": "aec774df2787114414cc592d17e3c7953d1e4a56", "lastModified": "2023-06-02T14:40:17.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:apache-2.0", "nli", "natural-language-inference", "region:us"], "private": false, "author": "metaeval", "description": "A diverse collection of tasks recasted as natural language inference tasks.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a18", "disabled": false, "gated": false, "likes": 0, "downloads": 83, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "midas/inspec", "sha": "9617780e99705df88a4cb239174c86b9d8d8300f", "lastModified": "2022-03-05T03:08:37.000Z", "tags": ["arxiv:1910.08840", "region:us"], "private": false, "author": "midas", "description": "Benchmark dataset for automatic identification of keyphrases from text published with the work - Improved automatic keyword extraction given more linguistic knowledge. Anette Hulth. In Proceedings of EMNLP 2003. p. 216-223.", "citation": "@inproceedings{hulth2003improved,\n  title={Improved automatic keyword extraction given more linguistic knowledge},\n  author={Hulth, Anette},\n  booktitle={Proceedings of the 2003 conference on Empirical methods in natural language processing},\n  pages={216--223},\n  year={2003}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a4c", "disabled": false, "gated": false, "likes": 9, "downloads": 459, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "midas/ldkp10k", "sha": "5e73606ea32a9456e235015e11241a5dfd5da7d6", "lastModified": "2022-04-02T16:49:45.000Z", "tags": ["region:us"], "private": false, "author": "midas", "description": "This new dataset is designed to solve kp NLP task and is crafted with a lot of care.", "citation": "TBA", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a55", "disabled": false, "gated": false, "likes": 2, "downloads": 10, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mideind/icelandic-error-corpus-IceEC", "sha": "6f1df59ddca5d65f3bd6c822f384e2ea8b5f7c3b", "lastModified": "2022-10-25T09:51:04.000Z", "tags": ["annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:is", "license:cc-by-4.0", "region:us"], "private": false, "author": "mideind", "description": "The Icelandic Error Corpus (IceEC) is a collection of texts in modern Icelandic annotated for mistakes related to spelling, grammar, and other issues. The texts are organized by genre. The current version includes sentences from student essays, online news texts and Wikipedia articles.\nSentences within texts in the student essays had to be shuffled due to the license which they were originally published under, but neither the online news texts nor the Wikipedia articles needed to be shuffled.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a63", "disabled": false, "gated": false, "likes": 1, "downloads": 32, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ml6team/cnn_dailymail_nl", "sha": "eccff1c84ba55f542a1f003ef9a621da692e1380", "lastModified": "2022-10-22T14:03:06.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:https://github.com/huggingface/datasets/tree/master/datasets/cnn_dailymail", "language:nl", "license:mit", "region:us"], "private": false, "author": "ml6team", "description": "    This dataset is the CNN/Dailymail dataset translated to Dutch.\n    This is the original dataset:\n    ```\n    load_dataset(\"cnn_dailymail\", '3.0.0')\n    ```\n    And this is the HuggingFace translation pipeline:\n    ```\n    pipeline(\n        task='translation_en_to_nl',\n        model='Helsinki-NLP/opus-mt-en-nl',\n        tokenizer='Helsinki-NLP/opus-mt-en-nl')\n    ```", "citation": "@article{DBLP:journals/corr/SeeLM17,\n  author    = {Abigail See and\n               Peter J. Liu and\n               Christopher D. Manning},\n  title     = {Get To The Point: Summarization with Pointer-Generator Networks},\n  journal   = {CoRR},\n  volume    = {abs/1704.04368},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.04368},\n  archivePrefix = {arXiv},\n  eprint    = {1704.04368},\n  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n\n@inproceedings{hermann2015teaching,\n  title={Teaching machines to read and comprehend},\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n  booktitle={Advances in neural information processing systems},\n  pages={1693--1701},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183a85", "disabled": false, "gated": false, "likes": 13, "downloads": 50, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mulcyber/europarl-mono", "sha": "5d592f8f59a8549c1c27e6af11ab77312543916f", "lastModified": "2021-02-05T16:05:40.000Z", "tags": ["region:us"], "private": false, "author": "mulcyber", "description": "Europarl Monolingual Dataset.\n\nThe Europarl parallel corpus is extracted from the proceedings of the\nEuropean Parliament (from 2000 to 2011). It includes versions in 21 European\nlanguages: Romanic (French, Italian, Spanish, Portuguese, Romanian),\nGermanic (English, Dutch, German, Danish, Swedish), Slavik (Bulgarian,\nCzech, Polish, Slovak, Slovene), Finni-Ugric (Finnish, Hungarian, Estonian),\nBaltic (Latvian, Lithuanian), and Greek.\n\nUpstream url: https://www.statmt.org/europarl/", "citation": "@inproceedings{koehn2005europarl,\n  title={Europarl: A parallel corpus for statistical machine translation},\n  author={Koehn, Philipp},\n  booktitle={MT summit},\n  volume={5},\n  pages={79--86},\n  year={2005},\n  organization={Citeseer}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183b02", "disabled": false, "gated": false, "likes": 0, "downloads": 61, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "indonesian-nlp/mc4-id", "sha": "38479a7a477f2388e20048c6161dc3b122575ea9", "lastModified": "2022-10-25T11:52:34.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "source_datasets:extended", "language:id", "license:odc-by", "arxiv:1910.10683", "region:us"], "private": false, "author": "indonesian-nlp", "description": "A thoroughly cleaned version of the Italian portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.", "citation": "@article{JMLR:v21:20-074,\n  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n  journal = {Journal of Machine Learning Research},\n  year    = {2020},\n  volume  = {21},\n  number  = {140},\n  pages   = {1-67},\n  url     = {http://jmlr.org/papers/v21/20-074.html}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183b05", "disabled": false, "gated": false, "likes": 3, "downloads": 72, "paperswithcode_id": "mc4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "mvarma/medwiki", "sha": "7d9f19d0cb4e7dcedfe2dafdda3ac8d6b7c9dbd9", "lastModified": "2022-10-25T09:51:06.000Z", "tags": ["task_categories:text-retrieval", "task_ids:entity-linking-retrieval", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:extended|wikipedia", "license:cc-by-4.0", "arxiv:2110.08228", "region:us"], "private": false, "author": "mvarma", "description": "MedWiki is a large-scale sentence dataset collected from Wikipedia with medical entity (UMLS) annotations. This dataset is intended for pretraining.", "citation": "@inproceedings{medwiki,\n    title={Cross-Domain Data Integration for Named Entity Disambiguation in Biomedical Text}, \n    author={Maya Varma and Laurel Orr and Sen Wu and Megan Leszczynski and Xiao Ling and Christopher R\u00e9},\n    year={2021},\n    booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183b10", "disabled": false, "gated": false, "likes": 3, "downloads": 37, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nateraw/imagenette", "sha": "ef44f5fb86fd36370d5c8d98fc601685d58cbe10", "lastModified": "2021-09-26T08:00:07.000Z", "tags": ["region:us"], "private": false, "author": "nateraw", "description": "Imagenette is a subset of 10 easily classified classes from the Imagenet\ndataset. It was originally prepared by Jeremy Howard of FastAI. The objective\nbehind putting together a small version of the Imagenet dataset was mainly\nbecause running new ideas/algorithms/experiments on the whole Imagenet take a\nlot of time.\nThis version of the dataset allows researchers/practitioners to quickly try out\nideas and share with others. The dataset comes in three variants:\n  * Full size\n  * 320 px\n  * 160 px\nNote: The v2 config correspond to the new 70/30 train/valid split (released\nin Dec 6 2019).", "citation": "@misc{imagenette,\n  author    = \"Jeremy Howard\",\n  title     = \"imagenette\",\n  url       = \"https://github.com/fastai/imagenette/\"\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183b44", "disabled": false, "gated": false, "likes": 2, "downloads": 21, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "openclimatefix/nimrod-uk-1km", "sha": "f433a990cca7574d4ed4687e7fa969ccad0dbeb3", "lastModified": "2022-06-08T14:49:03.000Z", "tags": ["region:us"], "private": false, "author": "openclimatefix", "description": "This dataset contains UK Nimrod rainfall radar data for 2016-2019 as used in the Skillful Precipitation Nowcasting Using Deep Generative Model of Radar paper by DeepMind.", "citation": "@article{ravuris2021skillful,\n  author={Suman Ravuri and Karel Lenc and Matthew Willson and Dmitry Kangin and Remi Lam and Piotr Mirowski and Megan Fitzsimons and Maria Athanassiadou and Sheleem Kashem and Sam Madge and Rachel Prudden Amol Mandhane and Aidan Clark and Andrew Brock and Karen Simonyan and Raia Hadsell and Niall Robinson Ellen Clancy and Alberto Arribas\u2020 and Shakir Mohamed},\n  title={Skillful Precipitation Nowcasting using Deep Generative Models of Radar},\n  journal={Nature},\n  volume={597},\n  pages={672--677},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183c78", "disabled": false, "gated": "auto", "likes": 7, "downloads": 292, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "oscar-corpus/OSCAR-2109", "sha": "ff99fc6fcee76887657c0b002350d81f13a38a9e", "lastModified": "2022-11-08T09:04:43.000Z", "tags": ["task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "source_datasets:original", "language:af", "language:als", "language:gsw", "language:am", "language:an", "language:ar", "language:arz", "language:as", "language:ast", "language:av", "language:az", "language:azb", "language:ba", "language:bar", "language:be", "language:bg", "language:bh", "language:bn", "language:bo", "language:bpy", "language:br", "language:bs", "language:bxr", "language:ca", "language:cbk", "language:ce", "language:ceb", "language:ckb", "language:cs", "language:cv", "language:cy", "language:da", "language:de", "language:diq", "language:dsb", "language:dv", "language:el", "language:eml", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:frr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:gom", "language:gu", "language:gv", "language:he", "language:hi", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:ilo", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:krc", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lb", "language:lez", "language:li", "language:lmo", "language:lo", "language:lrc", "language:lt", "language:lv", "language:mai", "language:mg", "language:mhr", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:mrj", "language:ms", "language:mt", "language:mwl", "language:my", "language:myv", "language:mzn", "language:nah", "language:nap", "language:nds", "language:ne", "language:new", "language:nl", "language:nn", "language:no", "language:oc", "language:or", "language:os", "language:pa", "language:pam", "language:pl", "language:pms", "language:pnb", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:ru", "language:rue", "language:sa", "language:sah", "language:scn", "language:sco", "language:sd", "language:sh", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tl", "language:tr", "language:tt", "language:tyv", "language:ug", "language:uk", "language:ur", "language:uz", "language:vec", "language:vi", "language:vls", "language:vo", "language:wa", "language:war", "language:wuu", "language:xal", "language:xmf", "language:yi", "language:yo", "language:zh", "license:cc0-1.0", "arxiv:2010.14571", "arxiv:2103.12028", "region:us"], "private": false, "author": "oscar-corpus", "description": "The Open Super-large Crawled Aggregated coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the goclassy architecture.\\", "citation": "@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Beno{\\^i}t Sagot},\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\n  editor    = {Harald L{\\\"u}ngen and Marc Kupietz and Piotr Ba\u0144ski and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\n  publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-10468},\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\n  pages     = {1 -- 9},\n  year      = {2021},\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics. However, most of these large raw corpora are either available only for English or not available to the general public due to copyright issues. Nevertheless, there are some examples of freely available multilingual corpora for training Deep Learning NLP models, such as the OSCAR and Paracrawl corpora. However, they have quality issues, especially for low-resource languages. Moreover, recreating or updating these corpora is very complex. In this work, we try to reproduce and improve the goclassy pipeline used to create the OSCAR corpus. We propose a new pipeline that is faster, modular, parameterizable, and well documented. We use it to create a corpus similar to OSCAR but larger and based on recent data. Also, unlike OSCAR, the metadata information is at the document level. We release our pipeline under an open source license and publish the corpus under a research-only license.},\n  language  = {en}\n}\n\n@article{caswell-etal-2021-quality,\n       author = {{Caswell}, Isaac and {Kreutzer}, Julia and {Wang}, Lisa and {Wahab}, Ahsan and {van Esch}, Daan and {Ulzii-Orshikh}, Nasanbayar and {Tapo}, Allahsera and {Subramani}, Nishant and {Sokolov}, Artem and {Sikasote}, Claytone and {Setyawan}, Monang and {Sarin}, Supheakmungkol and {Samb}, Sokhar and {Sagot}, Beno{\\^\\i}t and {Rivera}, Clara and {Rios}, Annette and {Papadimitriou}, Isabel and {Osei}, Salomey and {Ortiz Su{\\'a}rez}, Pedro Javier and {Orife}, Iroro and {Ogueji}, Kelechi and {Niyongabo}, Rubungo Andre and {Nguyen}, Toan Q. and {M{\\\"u}ller}, Mathias and {M{\\\"u}ller}, Andr{\\'e} and {Hassan Muhammad}, Shamsuddeen and {Muhammad}, Nanda and {Mnyakeni}, Ayanda and {Mirzakhalov}, Jamshidbek and {Matangira}, Tapiwanashe and {Leong}, Colin and {Lawson}, Nze and {Kudugunta}, Sneha and {Jernite}, Yacine and {Jenny}, Mathias and {Firat}, Orhan and {Dossou}, Bonaventure F.~P. and {Dlamini}, Sakhile and {de Silva}, Nisansa and {{\\c{C}}abuk Ball{\\i}}, Sakine and {Biderman}, Stella and {Battisti}, Alessia and {Baruwa}, Ahmed and {Bapna}, Ankur and {Baljekar}, Pallavi and {Abebe Azime}, Israel and {Awokoya}, Ayodele and {Ataman}, Duygu and {Ahia}, Orevaoghene and {Ahia}, Oghenefego and {Agrawal}, Sweta and {Adeyemi}, Mofetoluwa},\n        title = \"{Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets}\",\n      journal = {arXiv e-prints},\n     keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},\n         year = 2021,\n        month = mar,\n          eid = {arXiv:2103.12028},\n        pages = {arXiv:2103.12028},\narchivePrefix = {arXiv},\n       eprint = {2103.12028},\n primaryClass = {cs.CL},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210312028C},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n@inproceedings{ortiz-suarez-etal-2020-monolingual,\n    title = \"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages\",\n    author = \"Ortiz Su{\\'a}rez, Pedro Javier  and\n      Romary, Laurent  and\n      Sagot, Benoit\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.156\",\n    pages = \"1703--1714\",\n    abstract = \"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures.\",\n}\n\n@inproceedings{OrtizSuarezSagotRomary2019,\n  author    = {Pedro Javier {Ortiz Su{\\'a}rez} and Benoit Sagot and Laurent Romary},\n  title     = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},\n  editor    = {Piotr Ba\u0144ski and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\\\"u}ngen and Caroline Iliadi},\n  publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-9021},\n  url       = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},\n  pages     = {9 -- 16},\n  year      = {2019},\n  abstract  = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},\n  language  = {en}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183c8b", "disabled": false, "gated": "auto", "likes": 31, "downloads": 283, "paperswithcode_id": "oscar", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ought/raft", "sha": "9ee50172ea9afda2f1033c6f1b986e568b862fb3", "lastModified": "2022-10-25T09:54:19.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "source_datasets:extended|ade_corpus_v2", "source_datasets:extended|banking77", "language:en", "license:other", "arxiv:2109.14076", "region:us"], "private": false, "author": "ought", "description": "Large pre-trained language models have shown promise for few-shot learning, completing text-based tasks given only a few task-specific examples. Will models soon solve classification tasks that have so far been reserved for human research assistants? \n\n[RAFT](https://raft.elicit.org) is a few-shot classification benchmark that tests language models:\n\n- across multiple domains (lit review, tweets, customer interaction, etc.)\n- on economically valuable classification tasks (someone inherently cares about the task)\n- in a setting that mirrors deployment (50 examples per task, info retrieval allowed, hidden test set)", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183c99", "disabled": false, "gated": false, "likes": 35, "downloads": 15611, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pasinit/xlwic", "sha": "cca3cfb747db5bf97b95126ec79d5b7d743f9654", "lastModified": "2022-10-25T09:54:22.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:bg", "language:zh", "language:hr", "language:da", "language:nl", "language:et", "language:fa", "language:ja", "language:ko", "language:it", "language:fr", "language:de", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "pasinit", "description": "A system's task on any of the XL-WiC datasets is to identify the intended meaning of a word in a context of a given language. XL-WiC is framed as a binary classification task. Each instance in XL-WiC has a target word w, either a verb or a noun, for which two contexts are provided. Each of these contexts triggers a specific meaning of w. The task is to identify if the occurrences of w in the two contexts correspond to the same meaning or not.\n\nXL-WiC provides dev and test sets in the following 12 languages:\n\nBulgarian (BG)\nDanish (DA)\nGerman (DE)\nEstonian (ET)\nFarsi (FA)\nFrench (FR)\nCroatian (HR)\nItalian (IT)\nJapanese (JA)\nKorean (KO)\nDutch (NL)\nChinese (ZH)\nand training sets in the following 3 languages:\n\nGerman (DE)\nFrench (FR)\nItalian (IT)", "citation": "@inproceedings{raganato-etal-2020-xl-wic,\n  title={XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization},\n  author={Raganato, Alessandro and Pasini, Tommaso and Camacho-Collados, Jose and Pilehvar, Mohammad Taher},\n  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n  pages={7193--7206},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183cb6", "disabled": false, "gated": false, "likes": 4, "downloads": 336, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "peixian/equity_evaluation_corpus", "sha": "0f68047bb0d5d17e273ea7bd87b8964cdbe00028", "lastModified": "2022-10-20T23:35:15.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "gender-classification", "region:us"], "private": false, "author": "peixian", "description": "Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems and resources. Further, there is a lack of benchmark datasets for examining inappropriate biases in system predictions. Here, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We used the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 \u2018Affect in Tweets\u2019. We found that several of the systems showed statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available, and encourage its use to evaluate biases in sentiment and other NLP tasks.", "citation": "@article{DBLP:journals/corr/abs-1805-04508,\n  author    = {Svetlana Kiritchenko and\n               Saif M. Mohammad},\n  title     = {Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems},\n  journal   = {CoRR},\n  volume    = {abs/1805.04508},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1805.04508},\n  archivePrefix = {arXiv},\n  eprint    = {1805.04508},\n  timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-04508.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183cd1", "disabled": false, "gated": false, "likes": 3, "downloads": 35, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "peixian/rtGender", "sha": "74ef139a2d70372a878e406056ff37b1f0d561a5", "lastModified": "2022-10-25T09:54:24.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": "peixian", "description": "RtGender is a corpus for studying responses to gender online, including posts and responses from Facebook, TED, Fitocracy, and Reddit where the gender of the source poster/speaker is known.", "citation": "@inproceedings{voigt-etal-2018-rtgender,\n    title = \"{R}t{G}ender: A Corpus for Studying Differential Responses to Gender\",\n    author = \"Voigt, Rob  and\n      Jurgens, David  and\n      Prabhakaran, Vinodkumar  and\n      Jurafsky, Dan  and\n      Tsvetkov, Yulia\",\n    booktitle = \"Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)\",\n    month = may,\n    year = \"2018\",\n    address = \"Miyazaki, Japan\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"https://www.aclweb.org/anthology/L18-1445\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183cd2", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persiannlp/parsinlu_entailment", "sha": "c49b2d8fa0d6476520695c52207690b7ec854043", "lastModified": "2022-10-22T15:13:00.000Z", "tags": ["task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|translated|mnli", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": "persiannlp", "description": "A Persian textual entailment task (deciding `sent1` entails `sent2`).", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ce1", "disabled": false, "gated": false, "likes": 0, "downloads": 56, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persiannlp/parsinlu_query_paraphrasing", "sha": "ec675bb3ac50c1a52317c101fe1d724b4601f47a", "lastModified": "2022-10-22T15:13:22.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|quora|google", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": "persiannlp", "description": "A Persian query paraphrasing task (paraphrase or not, given two questions). \nThe questions are partly mined using Google auto-complete, and partly translated from Quora paraphrasing dataset.", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ce2", "disabled": false, "gated": false, "likes": 0, "downloads": 20, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persiannlp/parsinlu_reading_comprehension", "sha": "701cb4096c7e12695123c254f757ed56b12c49b8", "lastModified": "2022-10-25T09:54:26.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|wikipedia|google", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": "persiannlp", "description": "A Persian reading comprehenion task (generating an answer, given a question and a context paragraph). \nThe questions are mined using Google auto-complete, their answers and the corresponding evidence documents are manually annotated by native speakers.", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ce3", "disabled": false, "gated": false, "likes": 0, "downloads": 17, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persiannlp/parsinlu_sentiment", "sha": "abecf6a01a45174b7aa9b861fcc4a586cc4c7f9d", "lastModified": "2022-10-22T15:13:40.000Z", "tags": ["task_ids:sentiment-analysis", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|translated|mnli", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": "persiannlp", "description": "A Persian sentiment analysis task (deciding whether a given sentence contains a particular sentiment).", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ce4", "disabled": false, "gated": false, "likes": 4, "downloads": 61, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "persiannlp/parsinlu_translation_en_fa", "sha": "aac51e2d1d2d464c7c0a123ffbe66c43fb30c8e7", "lastModified": "2022-10-24T16:50:37.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:fa", "multilinguality:en", "size_categories:1K<n<10K", "source_datasets:extended", "language:fa", "license:cc-by-nc-sa-4.0", "arxiv:2012.06154", "region:us"], "private": false, "author": "persiannlp", "description": "A Persian translation dataset (English -> Persian).", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ce5", "disabled": false, "gated": false, "likes": 1, "downloads": 57, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "piEsposito/br-quad-2.0", "sha": "7a43d7628c664bbd64b21fbf935e1dc647d147c6", "lastModified": "2021-02-05T16:05:51.000Z", "tags": ["region:us"], "private": false, "author": "piEsposito", "description": "Translates SQuAD 2.0 from english to portuguese using Google Cloud API", "citation": "@article{2020braquad,\n       author = {{Esposito}, Wladimir and {Esposito}, Piero and {Tamais},\n                 Ana Laura and {Gatti}, Daniel},\n        title = \"{BrQuAD - Brazilian\n                  Question-Answering Dataset: Dataset para benchmark de modelos de\n                  Machine Learning para question-answering em\n                  Portugu^es brasileiro traduzindo o SQuAD com Google Cloud API}\",\n         year = 2020,\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183cff", "disabled": false, "gated": false, "likes": 0, "downloads": 24, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "pile-of-law/pile-of-law", "sha": "0dc9f2c26b42af4cb6330f36d6146e82f9117a3b", "lastModified": "2023-01-08T03:10:35.000Z", "tags": ["task_categories:fill-mask", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "language:en", "license:cc-by-nc-sa-4.0", "arxiv:2207.00220", "region:us"], "private": false, "author": "pile-of-law", "description": "We curate a large corpus of legal and administrative data. The utility of this data is twofold: (1) to aggregate legal and administrative data sources that demonstrate different norms and legal standards for data filtering; (2) to collect a dataset that can be used in the future for pretraining legal-domain language models, a key direction in access-to-justice initiatives.", "citation": "@misc{hendersonkrass2022pileoflaw,\n  url = {https://arxiv.org/abs/2207.00220},\n  author = {Henderson, Peter and Krass, Mark S. and Zheng, Lucia and Guha, Neel and Manning, Christopher D. and Jurafsky, Dan and Ho, Daniel E.},\n  title = {Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset},\n  publisher = {arXiv},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d15", "disabled": false, "gated": false, "likes": 132, "downloads": 2926, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "MLCommons/ml_spoken_words", "sha": "0bc9df68e92fd6bb54176bf7eb29e2b9e97cb218", "lastModified": "2022-12-06T11:11:02.000Z", "tags": ["task_categories:audio-classification", "annotations_creators:machine-generated", "language_creators:other", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:extended|common_voice", "language:ar", "language:as", "language:br", "language:ca", "language:cnh", "language:cs", "language:cv", "language:cy", "language:de", "language:dv", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fr", "language:fy", "language:ga", "language:gn", "language:ha", "language:ia", "language:id", "language:it", "language:ka", "language:ky", "language:lt", "language:lv", "language:mn", "language:mt", "language:nl", "language:or", "language:pl", "language:pt", "language:rm", "language:ro", "language:ru", "language:rw", "language:sah", "language:sk", "language:sl", "language:sv", "language:ta", "language:tr", "language:tt", "language:uk", "language:vi", "language:zh", "license:cc-by-4.0", "other-keyword-spotting", "region:us"], "private": false, "author": "MLCommons", "description": "Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken\nwords in 50 languages collectively spoken by over 5 billion people, for academic\nresearch and commercial applications in keyword spotting and spoken term search,\nlicensed under CC-BY 4.0. The dataset contains more than 340,000 keywords,\ntotaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset\nhas many use cases, ranging from voice-enabled consumer devices to call center\nautomation. This dataset is generated by applying forced alignment on crowd-sourced sentence-level\naudio to produce per-word timing estimates for extraction.\nAll alignments are included in the dataset.", "citation": "@inproceedings{mazumder2021multilingual,\n  title={Multilingual Spoken Words Corpus},\n  author={Mazumder, Mark and Chitlangia, Sharad and Banbury, Colby and Kang, Yiping and Ciro, Juan Manuel and Achorn, Keith and Galvez, Daniel and Sabini, Mark and Mattson, Peter and Kanter, David and others},\n  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d29", "disabled": false, "gated": false, "likes": 16, "downloads": 101, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/ancora-ca-ner", "sha": "aee489ef9560a5eb8adbf8c29317c0d43dc2069d", "lastModified": "2023-09-13T12:44:29.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-4.0", "arxiv:2107.07903", "region:us"], "private": false, "author": "projecte-aina", "description": "AnCora Catalan NER.\n                  This is a dataset for Named Eentity Reacognition (NER) from Ancora corpus adapted for \n                  Machine Learning and Language Model evaluation purposes.\n                  Since multiwords (including Named Entites) in the original Ancora corpus are aggregated as \n                  a single lexical item using underscores (e.g. \"Ajuntament_de_Barcelona\") \n                  we splitted them to align with word-per-line format, and added conventional Begin-Inside-Outside (IOB)\n                   tags to mark and classify Named Entites. \n                   We did not filter out the different categories of NEs from Ancora (weak and strong). \n                   We did 6 minor edits by hand.\n                  AnCora corpus is used under [CC-by] (https://creativecommons.org/licenses/by/4.0/) licence.\n                  This dataset was developed by BSC TeMU as part of the AINA project, and to enrich the Catalan Language Understanding Benchmark (CLUB).", "citation": "", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d5c", "disabled": false, "gated": false, "likes": 0, "downloads": 42, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/casum", "sha": "8d4bc89595621e6bcad68f150421425aa3bccef1", "lastModified": "2023-09-13T12:49:03.000Z", "tags": ["task_categories:summarization", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-nc-4.0", "arxiv:2202.06871", "region:us"], "private": false, "author": "projecte-aina", "description": "CaSum is a summarization dataset. It is extracted from a newswire corpus crawled from the Catalan News Agency. The corpus consists of 217,735 instances that are composed by the headline and the body.", "citation": "@misc{degibert2022sequencetosequence,\n      title={Sequence-to-Sequence Resources for Catalan}, \n      author={Ona de Gibert and Ksenia Kharitonova and Blanca Calvo Figueras and Jordi Armengol-Estap\u00e9 and Maite Melero},\n      year={2022},\n      eprint={2202.06871},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d5d", "disabled": false, "gated": false, "likes": 0, "downloads": 50, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/parlament_parla", "sha": "79d37c12b9cc8827e4351521ab8802325c9c3620", "lastModified": "2023-09-13T12:38:52.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:speaker-identification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:ca", "license:cc-by-4.0", "region:us"], "private": false, "author": "projecte-aina", "description": "This is the ParlamentParla speech corpus for Catalan prepared by Col\u00b7lectivaT. The audio segments were extracted from recordings the Catalan Parliament (Parlament de Catalunya) plenary sessions, which took place between 2007/07/11 - 2018/07/17. We aligned the transcriptions with the recordings and extracted the corpus. The content belongs to the Catalan Parliament and the data is released conforming their terms of use.\n\nPreparation of this corpus was partly supported by the Department of Culture of the Catalan autonomous government, and the v2.0 was supported by the Barcelona Supercomputing Center, within the framework of the project AINA of the Departament de Pol\u00edtiques Digitals.\n\nAs of v2.0 the corpus is separated into 211 hours of clean and 400 hours of other quality segments. Furthermore, each speech segment is tagged with its speaker and each speaker with their gender. The statistics are detailed in the readme file.\n\nFor more information, go to https://github.com/CollectivaT-dev/ParlamentParla or mail info@collectivat.cat.", "citation": "@dataset{kulebi_baybars_2021_5541827,\n  author       = {K\u00fclebi, Baybars},\n  title        = {{ParlamentParla - Speech corpus of Catalan \n                   Parliamentary sessions}},\n  month        = oct,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = {v2.0},\n  doi          = {10.5281/zenodo.5541827},\n  url          = {https://doi.org/10.5281/zenodo.5541827}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d61", "disabled": false, "gated": false, "likes": 1, "downloads": 19, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/sts-ca", "sha": "ee61638c447bc59e4f72877e90752cad957ac4fe", "lastModified": "2023-11-25T05:27:49.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-4.0", "arxiv:2107.07903", "region:us"], "private": false, "author": "projecte-aina", "description": "Semantic Textual Similarity in Catalan.\n                  STS corpus is a benchmark for evaluating Semantic Text Similarity in Catalan.\n                  It consists of more than 3000 sentence pairs, annotated with the semantic similarity between them, \n                  using a scale from 0 (no similarity at all) to 5 (semantic equivalence). \n                  It is done manually by 4 different annotators following our guidelines based on previous work from the SemEval challenges (https://www.aclweb.org/anthology/S13-1004.pdf).\n                  The source data are scraped sentences from the Catalan Textual Corpus (https://doi.org/10.5281/zenodo.4519349), used under CC-by-SA-4.0 licence (https://creativecommons.org/licenses/by-sa/4.0/). The dataset is released under the same licence.\n                  This dataset was developed by BSC TeMU as part of the AINA project, and to enrich the Catalan Language Understanding Benchmark (CLUB).\n                  This is the version 1.0.2 of the dataset with the complete human and automatic annotations and the analysis scripts. It also has a more accurate license.\n                  This dataset can be used to build and score semantic similiarity models.", "citation": "Rodriguez-Penagos, Carlos Gerardo, Armentano-Oller, Carme, Gonzalez-Agirre, Aitor, & Gibert Bonet, Ona. (2021). \n               Semantic Textual Similarity in Catalan (Version 1.0.1) [Data set]. \n               Zenodo. http://doi.org/10.5281/zenodo.4761434", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d62", "disabled": false, "gated": false, "likes": 0, "downloads": 17, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/teca", "sha": "feff109328ea5c8d7c90b8ab81d85b20c37f371b", "lastModified": "2023-11-25T05:30:02.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-nc-nd-4.0", "arxiv:2107.07903", "region:us"], "private": false, "author": "projecte-aina", "description": "TECA consists of two subsets of textual entailment in Catalan, *catalan_TE1* and *vilaweb_TE*, which contain 14997 and 6166 pairs of premises and hypotheses, annotated according to the inference relation they have (implication, contradiction or neutral). This dataset was developed by BSC TeMU as part of the AINA project and intended as part of the Catalan Language Understanding Benchmark (CLUB).", "citation": "@inproceedings{armengol-estape-etal-2021-multilingual,\n                title = \"Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? {A} Comprehensive Assessment for {C}atalan\",\n                author = \"Armengol-Estap{\\'e}, Jordi  and\n                  Carrino, Casimiro Pio  and\n                  Rodriguez-Penagos, Carlos  and\n                  de Gibert Bonet, Ona  and\n                  Armentano-Oller, Carme  and\n                  Gonzalez-Agirre, Aitor  and\n                  Melero, Maite  and\n                  Villegas, Marta\",\n                booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n                month = aug,\n                year = \"2021\",\n                address = \"Online\",\n                publisher = \"Association for Computational Linguistics\",\n                url = \"https://aclanthology.org/2021.findings-acl.437\",\n                doi = \"10.18653/v1/2021.findings-acl.437\",\n                pages = \"4933--4946\",\n            }", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d63", "disabled": false, "gated": false, "likes": 0, "downloads": 40, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/tecla", "sha": "2364a2f052ddf75659c7912aa0f3e951b6075b1d", "lastModified": "2023-11-25T06:24:24.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": "projecte-aina", "description": "TeCla: Text Classification Catalan dataset\n                   Catalan News corpus for Text classification, crawled from ACN (Catalan News Agency) site: www.acn.cat\n                   Corpus de not\u00edcies en catal\u00e0 per a classificaci\u00f3 textual, extret del web de l'Ag\u00e8ncia Catalana de Not\u00edcies - www.acn.cat", "citation": "Baucells, Irene, Carrino, Casimiro Pio, Rodriguez-Penagos, Carlos Gerardo, & Armentano-Oller, Carme. (2021).\n               TeCla: Text Classification Catalan dataset (Version 2.0) [Data set].\n               Zenodo. http://doi.org/10.5281/zenodo.7334110", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d64", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/viquiquad", "sha": "586b37f87c9fd0705b7364a8f127a3d278e28cb1", "lastModified": "2023-09-13T12:44:04.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ca", "license:cc-by-sa-4.0", "arxiv:2107.07903", "arxiv:1606.05250", "region:us"], "private": false, "author": "projecte-aina", "description": "ViquiQuAD: an extractive QA dataset from Catalan Wikipedia.\nThis dataset contains 3111 contexts extracted from a set of 597 high quality original (no translations) \narticles in the Catalan Wikipedia \"Viquip\u00e8dia\" (ca.wikipedia.org), and 1 to 5 questions with their\nanswer for each fragment. Viquipedia articles are used under CC-by-sa licence. \nThis dataset can be used to build extractive-QA and Language Models.\nFunded by the Generalitat de Catalunya, Departament de Pol\u00edtiques Digitals i Administraci\u00f3 P\u00fablica (AINA),\nMT4ALL and Plan de Impulso de las Tecnolog\u00edas del Lenguaje (Plan TL).", "citation": "Rodriguez-Penagos, Carlos Gerardo, & Armentano-Oller, Carme. (2021). \nViquiQuAD: an extractive QA dataset from Catalan Wikipedia (Version ViquiQuad_v.1.0.1) \n[Data set]. Zenodo. http://doi.org/10.5281/zenodo.4761412", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d67", "disabled": false, "gated": false, "likes": 1, "downloads": 69, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/wnli-ca", "sha": "ec69bc35b897f666902ab400cb18666aac276471", "lastModified": "2023-09-13T12:42:10.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:extended|glue", "language:ca", "license:cc-by-4.0", "region:us"], "private": false, "author": "projecte-aina", "description": "professional translation into Catalan of Winograd NLI dataset as published in GLUE Benchmark.\n               The Winograd NLI dataset presents 855 sentence pairs, \n               in which the first sentence contains an ambiguity and the second one a possible interpretation of it. \n               The label indicates if the interpretation is correct (1) or not (0).", "citation": "ADD CITATION", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d68", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "projecte-aina/xquad-ca", "sha": "aa8d49172029aee66a874a7562429f5f8cf200f3", "lastModified": "2023-11-25T05:37:46.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-sa-4.0", "arxiv:2107.07903", "arxiv:1606.05250", "arxiv:1910.11856", "region:us"], "private": false, "author": "projecte-aina", "description": "Professional translation into Catalan of XQuAD dataset (https://github.com/deepmind/xquad).\n                  XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating \n                  cross-lingual question answering performance. \n                  The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from \n                  the development set of SQuAD v1.1 (Rajpurkar et al., 2016) together with \n                  their professional translations into ten languages: \n                  Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, and Hindi. \n                  Rumanian was added later.\n                  We added the 13th language to the corpus using also professional native catalan translators.\n                  XQuAD and XQuAD-Ca datasets are released under CC-by-sa licence.", "citation": "Carlos Gerardo Rodriguez-Penagos, & Carme Armentano-Oller. (2021). XQuAD-ca [Data set].\n                Zenodo. http://doi.org/10.5281/zenodo.4757559", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d69", "disabled": false, "gated": false, "likes": 1, "downloads": 23, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qanastek/WMT-16-PubMed", "sha": "d74986fdd2f8aa542ca4b875d9fd37979518a027", "lastModified": "2022-10-22T15:20:12.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "region:us"], "private": false, "author": "qanastek", "description": "WMT'16 Biomedical Translation Task - PubMed parallel datasets\nhttp://www.statmt.org/wmt16/biomedical-translation-task.html", "citation": "@inproceedings{bojar-etal-2016-findings,\n    title = Findings of the 2016 Conference on Machine Translation,\n    author = {\n      Bojar, Ondrej  and\n      Chatterjee, Rajen  and\n      Federmann, Christian  and\n      Graham, Yvette  and\n      Haddow, Barry  and\n      Huck, Matthias  and\n      Jimeno Yepes, Antonio  and\n      Koehn, Philipp  and\n      Logacheva, Varvara  and\n      Monz, Christof  and\n      Negri, Matteo  and\n      Neveol, Aurelie  and\n      Neves, Mariana  and\n      Popel, Martin  and\n      Post, Matt  and\n      Rubino, Raphael  and\n      Scarton, Carolina  and\n      Specia, Lucia  and\n      Turchi, Marco  and\n      Verspoor, Karin  and\n      Zampieri, Marcos\n    },\n    booktitle = Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers,\n    month = aug,\n    year = 2016,\n    address = Berlin, Germany,\n    publisher = Association for Computational Linguistics,\n    url = https://aclanthology.org/W16-2301,\n    doi = 10.18653/v1/W16-2301,\n    pages = 131--198,\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d92", "disabled": false, "gated": false, "likes": 2, "downloads": 27, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "qwant/squad_fr", "sha": "39c7dcea4794e2224243c87a81b9ccf21ae3b417", "lastModified": "2023-04-19T14:37:09.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:closed-domain-qa", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:extended|squad", "language:fr", "license:cc-by-4.0", "region:us"], "private": false, "author": "qwant", "description": "SQuAD-fr is a French translated version of the Stanford Question Answering Dataset (SQuAD), the reference corpus to evaluate question answering models' performances in English.\nIt consists of 100K question-answer pairs on 500+ articles derived from the original English dataset and represents a large-scale dataset for closed-domain question answering on factoid questions in French.\nSQuAD-fr serves as a means of data augmentation on FQuAD and PIAF benchmarks, with 90K+ translated training pairs.", "citation": "@inproceedings{cattan:hal-03336060,\n  TITLE = {{On the Usability of Transformers-based models for a French Question-Answering task}},\n  AUTHOR = {Cattan, Oralie and Servan, Christophe and Rosset, Sophie},\n  URL = {https://hal.archives-ouvertes.fr/hal-03336060},\n  BOOKTITLE = {{Recent Advances in Natural Language Processing (RANLP)}},\n  ADDRESS = {Varna, Bulgaria},\n  YEAR = {2021},\n  MONTH = Sep,\n  PDF = {https://hal.archives-ouvertes.fr/hal-03336060/file/RANLP_2021_transformers_usability.pdf},\n  HAL_ID = {hal-03336060},\n  HAL_VERSION = {v1},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183d9f", "disabled": false, "gated": false, "likes": 6, "downloads": 125, "paperswithcode_id": "squad", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "rahular/itihasa", "sha": "56645be151b61e1143597f922ccf666b43a5c02b", "lastModified": "2022-10-24T18:06:01.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:unknown", "source_datasets:original", "language:sa", "language:en", "license:apache-2.0", "conditional-text-generation", "region:us"], "private": false, "author": "rahular", "description": "A Sanskrit-English machine translation dataset.", "citation": "@inproceedings{aralikatte-etal-2021-itihasa,\n    title = \"Itihasa: A large-scale corpus for {S}anskrit to {E}nglish translation\",\n    author = \"Aralikatte, Rahul  and\n      de Lhoneux, Miryam  and\n      Kunchukuttan, Anoop  and\n      S{\\o}gaard, Anders\",\n    booktitle = \"Proceedings of the 8th Workshop on Asian Translation (WAT2021)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.wat-1.22\",\n    pages = \"191--197\",\n    abstract = \"This work introduces Itihasa, a large-scale translation dataset containing 93,000 pairs of Sanskrit shlokas and their English translations. The shlokas are extracted from two Indian epics viz., The Ramayana and The Mahabharata. We first describe the motivation behind the curation of such a dataset and follow up with empirical analysis to bring out its nuances. We then benchmark the performance of standard translation models on this corpus and show that even state-of-the-art transformer architectures perform poorly, emphasizing the complexity of the dataset.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183dc0", "disabled": false, "gated": false, "likes": 4, "downloads": 341, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ramybaly/conll2012", "sha": "c48ce17a02518318ac0e5badea2099c2f2bdf2cb", "lastModified": "2021-08-20T04:43:27.000Z", "tags": ["region:us"], "private": false, "author": "ramybaly", "description": "The CoNLL-2012 shared task involved predicting coreference in English, Chinese, and Arabic, using the final version, v5.0,\nof the OntoNotes corpus. It was a follow-on to the English-only task organized in 2011. Until the creation of the OntoNotes\ncorpus, resources in this sub-field of language processing were limited to noun phrase coreference, often on a restricted\nset of entities, such as the ACE entities. OntoNotes provides a large-scale corpus of general anaphoric coreference not\nrestricted to noun phrases or to a specified set of entity types, and covers multiple languages. OntoNotes also provides\nadditional layers of integrated annotation, capturing additional shallow semantic structure. This paper describes the\nOntoNotes annotation (coreference and other layers) and then describes the parameters of the shared task including the\nformat, pre-processing information, evaluation criteria, and presents and discusses the results achieved by the participating\nsystems. The task of coreference has had a complex evaluation history. Potentially many evaluation conditions, have, in the past,\nmade it difficult to judge the improvement in new algorithms over previously reported results. Having a standard test set\nand standard evaluation parameters, all based on a resource that provides multiple integrated annotation layers (syntactic\nparses, semantic roles, word senses, named entities and coreference) and in multiple languages could support joint modeling\nand help ground and energize ongoing research in the task of entity and event coreference.\nFor more details see https://aclanthology.org/W12-4501.pdf", "citation": "@inproceedings{pradhan2012conll,\n  title={CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes},\n  author={Pradhan, Sameer and Moschitti, Alessandro and Xue, Nianwen and Uryupina, Olga and Zhang, Yuchen},\n  booktitle={Joint Conference on EMNLP and CoNLL-Shared Task},\n  pages={1--40},\n  year={2012}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183dd2", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "roskoN/dailydialog", "sha": "5214b2a66405abf87fd229e5c1007985501ffe3e", "lastModified": "2021-08-06T14:14:18.000Z", "tags": ["region:us"], "private": false, "author": "roskoN", "description": "The DailyDialog dataset as provided in the original form with a bit of preprocessing applied to enable dast prototyping.\nThe splits are as in the original distribution.", "citation": "@inproceedings{li2017dailydialog,\n  title={DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset},\n  author={Li, Yanran and Su, Hui and Shen, Xiaoyu and Li, Wenjie and Cao, Ziqiang and Niu, Shuzi},\n  booktitle={Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},\n  pages={986--995},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183e34", "disabled": false, "gated": false, "likes": 1, "downloads": 65, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sagnikrayc/mctest", "sha": "00355bee8104a40d80665be0e4570f4a8b2c96f7", "lastModified": "2022-10-25T00:16:37.000Z", "tags": ["task_categories:question-answering", "task_ids:multiple-choice-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:en", "license:other", "explanations-in-question-answering", "region:us"], "private": false, "author": "sagnikrayc", "description": "MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension.", "citation": "@inproceedings{richardson-etal-2013-mctest,\n    title = \"{MCT}est: A Challenge Dataset for the Open-Domain Machine Comprehension of Text\",\n    author = \"Richardson, Matthew  and\n      Burges, Christopher J.C.  and\n      Renshaw, Erin\",\n    booktitle = \"Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct,\n    year = \"2013\",\n    address = \"Seattle, Washington, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D13-1020\",\n    pages = \"193--203\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183e77", "disabled": false, "gated": false, "likes": 2, "downloads": 668, "paperswithcode_id": "mctest", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sagteam/author_profiling", "sha": "71a7c86c0432a0320f2b825c4064d00e79c4705b", "lastModified": "2022-08-09T12:33:07.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ru", "license:apache-2.0", "region:us"], "private": false, "author": "sagteam", "description": "he corpus for the author profiling analysis contains texts in Russian-language which labeled for 5 tasks:\n1) gender -- 13530 texts with the labels, who wrote this: text female or male;\n2) age -- 13530 texts with the labels, how old the person who wrote the text. This is a number from 12 to 80. In addition, for the classification task we added 5 age groups: 1-19; 20-29; 30-39; 40-49; 50+;\n3) age imitation -- 7574 texts, where crowdsource authors is asked to write three texts: \n  a) in their natural manner, \n  b) imitating the style of someone younger, \n  c) imitating the style of someone older;\n4) gender imitation -- 5956 texts, where the crowdsource authors is asked to write texts: in their origin gender and pretending to be the opposite gender;\n5) style imitation -- 5956 texts, where crowdsource authors is asked to write a text on behalf of another person of your own gender, with a distortion of the authors usual style.", "citation": "\\", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183e7a", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "sarulab-speech/bvcc-voicemos2022", "sha": "88d0f589da061ef1ffcd2bfb1fee21ad7a09e7ce", "lastModified": "2022-02-25T06:26:53.000Z", "tags": ["region:us"], "private": false, "author": "sarulab-speech", "description": "This dataset is for internal use only. For voicemos challenge", "citation": "@misc{cooper2021generalization,\n    title={Generalization Ability of MOS Prediction Networks}, \n    author={Erica Cooper and Wen-Chin Huang and Tomoki Toda and Junichi Yamagishi},\n    year={2021},\n    eprint={2110.02635},\n    archivePrefix={arXiv},\n    primaryClass={eess.AS}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f183ec3", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "stas/c4-en-10k", "sha": "641dc93c008f3290112ae324a754aaf7e77dee15", "lastModified": "2022-10-19T21:40:11.000Z", "tags": ["language:en", "license:apache-2.0", "region:us"], "private": false, "author": "stas", "description": "This is a small subset representing the first 10K records of the original C4 dataset, \"en\" subset - created for testing. The records were extracted after having been shuffled.\n\nThe full 1TB+ dataset is at https://huggingface.co/datasets/c4.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184040", "disabled": false, "gated": false, "likes": 2, "downloads": 4451, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "stas/openwebtext-10k", "sha": "152771d7ae284673c3ad7ffdd9b3afc2741f1d00", "lastModified": "2021-09-15T00:18:50.000Z", "tags": ["region:us"], "private": false, "author": "stas", "description": "An open-source replication of the WebText dataset from OpenAI.\n\nThis is a small subset representing the first 10K records from the original dataset - created for testing.\n\nThe full 8M-record dataset is at https://huggingface.co/datasets/openwebtext", "citation": "@misc{Gokaslan2019OpenWeb,\n  title={OpenWebText Corpus},\n  author={Aaron Gokaslan*, Vanya Cohen*, Ellie Pavlick, Stefanie Tellex},\n  howpublished{\\\\url{http://Skylion007.github.io/OpenWebTextCorpus}},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184041", "disabled": false, "gated": false, "likes": 7, "downloads": 7316, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "stas/oscar-en-10k", "sha": "07713bf01c6e590a5d80b2c246de207d47724482", "lastModified": "2022-10-19T21:40:14.000Z", "tags": ["language:en", "license:apache-2.0", "region:us"], "private": false, "author": "stas", "description": "This is a small subset representing 10K records from the original OSCAR dataset, \"unshuffled_deduplicated_en\" subset - created for testing. The records were extracted after having been shuffled.\n\nThe full 1TB+ dataset is at https://huggingface.co/datasets/oscar.", "citation": "@inproceedings{OrtizSuarezSagotRomary2019,\n  author    = {Pedro Javier {Ortiz Su{'a}rez} and Benoit Sagot and Laurent Romary},\n  title     = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},\n  editor    = {Piotr Ba\u0144ski and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\"u}ngen and Caroline Iliadi},\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-9021},\n  url       = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},\n  pages     = {9 -- 16},\n  year      = {2019},\n  abstract  = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},\n  language  = {en}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184042", "disabled": false, "gated": false, "likes": 2, "downloads": 48, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "susumu2357/squad_v2_sv", "sha": "d9709e0c5512c125ce34aea05b3de3f912092c1b", "lastModified": "2022-07-01T18:31:20.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|wikipedia", "language:sv", "license:apache-2.0", "region:us"], "private": false, "author": "susumu2357", "description": "SQuAD_v2_sv is a Swedish version of SQuAD2.0. Translation was done automatically by using Google Translate API but it is not so straightforward because;\n\n1. the span which determines the start and the end of the answer in the context may vary after translation,\n2. tne translated context may not contain the translated answer if we translate both independently.\n\nMore details on how to handle these will be provided in another blog post.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18407a", "disabled": false, "gated": false, "likes": 0, "downloads": 68, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tanfiona/causenet_wiki", "sha": "1415dba18f16ad3597931a36ed2e13c2f2b130c7", "lastModified": "2022-06-06T03:47:17.000Z", "tags": ["region:us"], "private": false, "author": "tanfiona", "description": "Crawled Wikipedia Data from CIKM 2020 paper \n'CauseNet: Towards a Causality Graph Extracted from the Web.'", "citation": "@inproceedings{heindorf2020causenet,\n  author    = {Stefan Heindorf and\n               Yan Scholten and\n               Henning Wachsmuth and\n               Axel-Cyrille Ngonga Ngomo and\n               Martin Potthast},\n  title     = CauseNet: Towards a Causality Graph Extracted from the Web,\n  booktitle = CIKM,\n  publisher = ACM,\n  year      = 2020\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18409e", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tau/mrqa", "sha": "5f30172931a026570e979244199c1cc4dff28bb7", "lastModified": "2022-03-21T19:26:55.000Z", "tags": ["region:us"], "private": false, "author": "tau", "description": "The MRQA 2019 Shared Task focuses on generalization in question answering.\nAn effective question answering system should do more than merely\ninterpolate from the training set to answer test examples drawn\nfrom the same distribution: it should also be able to extrapolate\nto out-of-distribution examples \u2014 a significantly harder challenge.\nThe dataset is a collection of 18 existing QA dataset (carefully selected\nsubset of them) and converted to the same format (SQuAD format). Among\nthese 18 datasets, six datasets were made available for training,\nsix datasets were made available for development, and the final six\nfor testing. The dataset is released as part of the MRQA 2019 Shared Task.", "citation": "@inproceedings{fisch2019mrqa,\n    title={{MRQA} 2019 Shared Task: Evaluating Generalization in Reading Comprehension},\n    author={Adam Fisch and Alon Talmor and Robin Jia and Minjoon Seo and Eunsol Choi and Danqi Chen},\n    booktitle={Proceedings of 2nd Machine Reading for Reading Comprehension (MRQA) Workshop at EMNLP},\n    year={2019},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1840a4", "disabled": false, "gated": false, "likes": 0, "downloads": 188, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "tau/scrolls", "sha": "a198f7622e91b27a55e43762721f8cff4c0d9231", "lastModified": "2023-05-23T10:15:40.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-generation", "task_ids:multiple-choice-qa", "task_ids:natural-language-inference", "language:en", "query-based-summarization", "long-texts", "arxiv:2201.03533", "arxiv:2104.02112", "arxiv:2104.07091", "arxiv:2104.05938", "arxiv:1712.07040", "arxiv:2105.03011", "arxiv:2112.08608", "arxiv:2110.01799", "region:us"], "private": false, "author": "tau", "description": "SCROLLS: Standardized CompaRison Over Long Language Sequences.\nA suite of natural language datasets that require reasoning over long texts.\nhttps://scrolls-benchmark.com/", "citation": "@misc{shaham2022scrolls,\n      title={SCROLLS: Standardized CompaRison Over Long Language Sequences}, \n      author={Uri Shaham and Elad Segal and Maor Ivgi and Avia Efrat and Ori Yoran and Adi Haviv and Ankit Gupta and Wenhan Xiong and Mor Geva and Jonathan Berant and Omer Levy},\n      year={2022},\n      eprint={2201.03533},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\nNote that each SCROLLS dataset has its own citation. Please see the source to\nget the correct citation for each contained dataset.", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1840a6", "disabled": false, "gated": false, "likes": 17, "downloads": 8918, "paperswithcode_id": "scrolls", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "toloka/VoxDIY-RusNews", "sha": "0849275e6db59dd3b66c68ca63d848d55cd897f8", "lastModified": "2022-12-06T15:24:30.000Z", "tags": ["task_categories:summarization", "task_categories:automatic-speech-recognition", "task_categories:text2text-generation", "annotations_creators:found", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:ru", "license:cc-by-4.0", "conditional-text-generation", "stuctured-to-text", "speech-recognition", "arxiv:2107.01091", "region:us"], "private": false, "author": "toloka", "description": "VoxDIY:  Benchmark Dataset for Russian Crowdsourced Audio Transcription.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184112", "disabled": false, "gated": false, "likes": 2, "downloads": 29, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "turingbench/TuringBench", "sha": "940fa0c860325e199aeaa8d6dbfceec69f13a7e8", "lastModified": "2022-10-25T09:56:51.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:found", "language_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "turingbench", "description": "This benchmark environment contains a dataset comprised of generated texts from pre-trained language models.\nWe also have two benchmark tasks - human vs. machine (i.e., binary classification) and authorship\nattribution (i.e., multi-class classification). These benchmark tasks and dataset are hosted on the\nTuringBench website with Leaderboards for each task.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184168", "disabled": false, "gated": false, "likes": 0, "downloads": 55, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "uitnlp/vietnamese_students_feedback", "sha": "7b56c6cb1c9c8523249f407044c838660df3811a", "lastModified": "2022-10-13T15:39:37.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:topic-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:vi", "license:unknown", "region:us"], "private": false, "author": "uitnlp", "description": "Students\u2019 feedback is a vital resource for the interdisciplinary research involving the combining of two different\nresearch fields between sentiment analysis and education.\n\nVietnamese Students\u2019 Feedback Corpus (UIT-VSFC) is the resource consists of over 16,000 sentences which are\nhuman-annotated with two different tasks: sentiment-based and topic-based classifications.\n\nTo assess the quality of our corpus, we measure the annotator agreements and classification evaluation on the\nUIT-VSFC corpus. As a result, we obtained the inter-annotator agreement of sentiments and topics with more than over\n91% and 71% respectively. In addition, we built the baseline model with the Maximum Entropy classifier and achieved\napproximately 88% of the sentiment F1-score and over 84% of the topic F1-score.", "citation": "@InProceedings{8573337,\n  author={Nguyen, Kiet Van and Nguyen, Vu Duc and Nguyen, Phu X. V. and Truong, Tham T. H. and Nguyen, Ngan Luu-Thuy},\n  booktitle={2018 10th International Conference on Knowledge and Systems Engineering (KSE)},\n  title={UIT-VSFC: Vietnamese Students\u2019 Feedback Corpus for Sentiment Analysis},\n  year={2018},\n  volume={},\n  number={},\n  pages={19-24},\n  doi={10.1109/KSE.2018.8573337}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18417a", "disabled": false, "gated": false, "likes": 9, "downloads": 216, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "usc-isi/WikiConvert", "sha": "839230b8ff8b06ae3707e3b4ea418b34600061f5", "lastModified": "2022-10-24T17:40:43.000Z", "tags": ["task_categories:fill-mask", "task_categories:other", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|wikipedia", "language:en", "license:mit", "numeracy", "natural-language-understanding", "tokenization", "region:us"], "private": false, "author": "usc-isi", "description": "Language Modelling with Cardinal Number Annotations.", "citation": "@inproceedings{thawani-etal-2021-numeracy,\n    title = \"Numeracy enhances the Literacy of Language Models\",\n    author = \"Thawani, Avijit  and\n      Pujara, Jay  and\n      Ilievski, Filip\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.557\",\n    pages = \"6960--6967\",\n    abstract = \"Specialized number representations in NLP have shown improvements on numerical reasoning tasks like arithmetic word problems and masked number prediction. But humans also use numeracy to make better sense of world concepts, e.g., you can seat 5 people in your {`}room{'} but not 500. Does a better grasp of numbers improve a model{'}s understanding of other concepts and words? This paper studies the effect of using six different number encoders on the task of masked word prediction (MWP), as a proxy for evaluating literacy. To support this investigation, we develop Wiki-Convert, a 900,000 sentence dataset annotated with numbers and units, to avoid conflating nominal and ordinal number occurrences. We find a significant improvement in MWP for sentences containing numbers, that exponent embeddings are the best number encoders, yielding over 2 points jump in prediction accuracy over a BERT baseline, and that these enhanced literacy skills also generalize to contexts without annotated numbers. We release all code at https://git.io/JuZXn.\",\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184189", "disabled": false, "gated": false, "likes": 5, "downloads": 93, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "vblagoje/wikipedia_snippets_streamed", "sha": "19f6b93fe8faeb79f38c61e25b329cf698859a73", "lastModified": "2021-07-01T15:32:09.000Z", "tags": ["region:us"], "private": false, "author": "vblagoje", "description": "The dataset was built from the Wikipedia dump (https://dumps.wikimedia.org/).\nEach example contains the content of one full Wikipedia article with cleaning to strip\nmarkdown and unwanted sections (references, etc.).", "citation": "@ONLINE {wikidump,\n    author = {Wikimedia Foundation},\n    title  = {Wikimedia Downloads},\n    url    = {https://dumps.wikimedia.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1841b6", "disabled": false, "gated": false, "likes": 0, "downloads": 203, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "vershasaxena91/squad_multitask", "sha": "45988f23763862dcc4780d649b7ddca8b4698262", "lastModified": "2021-05-06T09:29:54.000Z", "tags": ["region:us"], "private": false, "author": "vershasaxena91", "description": "\\Stanford Question Answering Dataset (SQuAD) is a reading comprehension \\dataset, consisting of questions posed by crowdworkers on a set of Wikipedia \\articles, where the answer to every question is a segment of text, or span, \\from the corresponding reading passage, or the question might be unanswerable.", "citation": "\\@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f1841ce", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "w11wo/imdb-javanese", "sha": "11bef3dfce0ce107eb5e276373dcd28759ce85ee", "lastModified": "2022-10-25T10:01:48.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:jv", "license:odbl", "region:us"], "private": false, "author": "w11wo", "description": "Large Movie Review Dataset translated to Javanese.\r\nThis is a dataset for binary sentiment classification containing substantially\r\nmore data than previous benchmark datasets. We provide a set of 25,000 highly\r\npolar movie reviews for training, and 25,000 for testing. There is additional\r\nunlabeled data for use as well. We translated the original IMDB Dataset to\r\nJavanese using the multi-lingual MarianMT Transformer model from\r\n`Helsinki-NLP/opus-mt-en-mul`.", "citation": "\\\r\n@InProceedings{maas-EtAl:2011:ACL-HLT2011,\r\n  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\r\n  title     = {Learning Word Vectors for Sentiment Analysis},\r\n  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\r\n  month     = {June},\r\n  year      = {2011},\r\n  address   = {Portland, Oregon, USA},\r\n  publisher = {Association for Computational Linguistics},\r\n  pages     = {142--150},\r\n  url       = {http://www.aclweb.org/anthology/P11-1015}\r\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18424f", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "wietsedv/stsbenchmark", "sha": "1a79b56019535b76eaaf09d21870b63be061af20", "lastModified": "2022-03-09T09:14:43.000Z", "tags": ["license:cc-by-sa-4.0", "region:us"], "private": false, "author": "wietsedv", "description": "STS Benchmark comprises a selection of the English datasets used in the STS tasks organized in the context of SemEval between 2012 and 2017. The selection of datasets include text from image captions, news headlines and user forums.", "citation": null, "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184281", "disabled": false, "gated": false, "likes": 0, "downloads": 73, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "ydshieh/coco_dataset_script", "sha": "6414bae7a39b5f41feab2fd6a1cb773033254c93", "lastModified": "2022-02-14T17:32:43.000Z", "tags": ["region:us"], "private": false, "author": "ydshieh", "description": "COCO is a large-scale object detection, segmentation, and captioning dataset.", "citation": "@article{DBLP:journals/corr/LinMBHPRDZ14,\n  author    = {Tsung{-}Yi Lin and\n               Michael Maire and\n               Serge J. Belongie and\n               Lubomir D. Bourdev and\n               Ross B. Girshick and\n               James Hays and\n               Pietro Perona and\n               Deva Ramanan and\n               Piotr Doll{'{a} }r and\n               C. Lawrence Zitnick},\n  title     = {Microsoft {COCO:} Common Objects in Context},\n  journal   = {CoRR},\n  volume    = {abs/1405.0312},\n  year      = {2014},\n  url       = {http://arxiv.org/abs/1405.0312},\n  archivePrefix = {arXiv},\n  eprint    = {1405.0312},\n  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184313", "disabled": false, "gated": false, "likes": 8, "downloads": 13854, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yhavinga/mc4_nl_cleaned", "sha": "115b07a46bbf4876a6deb631ec17682df4d915f1", "lastModified": "2022-12-16T09:24:34.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "multilinguality:en-nl", "source_datasets:extended", "language:nl", "language:en", "license:odc-by", "arxiv:1910.10683", "region:us"], "private": false, "author": "yhavinga", "description": "A thoroughly cleaned version of the Dutch portion of the multilingual \ncolossal, cleaned version of Common Crawl's web crawl corpus (mC4) by AllenAI.\n\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\n\nThis is the processed version of Google's mC4 dataset by AllenAI, with further cleaning\ndetailed in the repository README file.", "citation": "@article{JMLR:v21:20-074,\n  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n  journal = {Journal of Machine Learning Research},\n  year    = {2020},\n  volume  = {21},\n  number  = {140},\n  pages   = {1-67},\n  url     = {http://jmlr.org/papers/v21/20-074.html}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f18431a", "disabled": false, "gated": false, "likes": 7, "downloads": 322, "paperswithcode_id": "mc4", "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "yuanchuan/annotated_reference_strings", "sha": "86de7d45936fe0885b6783dff6bdd6e6eca8eff0", "lastModified": "2022-10-26T14:53:23.000Z", "tags": ["task_categories:token-classification", "task_ids:parsing", "annotations_creators:other", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "yuanchuan", "description": "A repository of reference strings annotated using CSL processor using citations obtained from various sources.", "citation": "@techreport{kee2021,\n    author = {Yuan Chuan Kee},\n    title = {Synthesis of a large dataset of annotated reference strings for developing citation parsers},\n    institution = {National University of Singapore},\n    year = {2021}\n}", "cardData": null, "siblings": [], "_id": "621ffdd236468d709f184338", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-03-02T23:29:22.000Z"}, {"id": "nlpaueb/finer-139", "sha": "080f677a026e304c38666d759ef625d621dc8cb9", "lastModified": "2022-10-23T05:05:03.000Z", "tags": ["task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "language:en", "license:cc-by-sa-4.0", "arxiv:2203.06482", "region:us"], "private": false, "author": "nlpaueb", "description": "FiNER-139 is a named entity recognition dataset consisting of 10K annual \nand quarterly English reports (filings) of publicly traded companies \ndownloaded from the U.S. Securities and Exchange Commission (SEC) \nannotated with 139 XBRL tags in the IOB2 format.", "citation": "@inproceedings{loukas-etal-2022-finer,\n    title = \"{FiNER: Financial Numeric Entity Recognition for XBRL Tagging}\",\n    author = \"Loukas, Lefteris  and\n      Fergadiotis, Manos  and\n      Chalkidis, Ilias and\n      Spyropoulou, Eirini and\n      Malakasiotis, Prodromos  and\n      Androutsopoulos, Ion and\n      Paliouras George\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\",\n    month = \"may\",\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "6221e33783606827f5694d8b", "disabled": false, "gated": false, "likes": 12, "downloads": 213, "createdAt": "2022-03-04T10:00:23.000Z"}, {"id": "google/xtreme_s", "sha": "3cf59334aa52a74c008a67a3de30f98dd8a28118", "lastModified": "2022-07-28T12:47:02.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|multilingual_librispeech", "source_datasets:extended|covost2", "language:afr", "language:amh", "language:ara", "language:asm", "language:ast", "language:azj", "language:bel", "language:ben", "language:bos", "language:cat", "language:ceb", "language:cmn", "language:ces", "language:cym", "language:dan", "language:deu", "language:ell", "language:eng", "language:spa", "language:est", "language:fas", "language:ful", "language:fin", "language:tgl", "language:fra", "language:gle", "language:glg", "language:guj", "language:hau", "language:heb", "language:hin", "language:hrv", "language:hun", "language:hye", "language:ind", "language:ibo", "language:isl", "language:ita", "language:jpn", "language:jav", "language:kat", "language:kam", "language:kea", "language:kaz", "language:khm", "language:kan", "language:kor", "language:ckb", "language:kir", "language:ltz", "language:lug", "language:lin", "language:lao", "language:lit", "language:luo", "language:lav", "language:mri", "language:mkd", "language:mal", "language:mon", "language:mar", "language:msa", "language:mlt", "language:mya", "language:nob", "language:npi", "language:nld", "language:nso", "language:nya", "language:oci", "language:orm", "language:ory", "language:pan", "language:pol", "language:pus", "language:por", "language:ron", "language:rus", "language:bul", "language:snd", "language:slk", "language:slv", "language:sna", "language:som", "language:srp", "language:swe", "language:swh", "language:tam", "language:tel", "language:tgk", "language:tha", "language:tur", "language:ukr", "language:umb", "language:urd", "language:uzb", "language:vie", "language:wol", "language:xho", "language:yor", "language:yue", "language:zul", "license:cc-by-4.0", "arxiv:2203.10752", "arxiv:2205.12446", "arxiv:2007.10310", "region:us"], "private": false, "author": "google", "description": "XTREME-S covers four task families: speech recognition, classification, speech-to-text translation and retrieval. Covering 102\nlanguages from 10+ language families, 3 different domains and 4\ntask families, XTREME-S aims to simplify multilingual speech\nrepresentation evaluation, as well as catalyze research in \u201cuniversal\u201d speech representation learning.", "citation": "@article{conneau2022xtreme,\n  title={XTREME-S: Evaluating Cross-lingual Speech Representations},\n  author={Conneau, Alexis and Bapna, Ankur and Zhang, Yu and Ma, Min and von Platen, Patrick and Lozhkov, Anton and Cherry, Colin and Jia, Ye and Rivera, Clara and Kale, Mihir and others},\n  journal={arXiv preprint arXiv:2203.10752},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "62221de0028e7e9fcbf074c3", "disabled": false, "gated": false, "likes": 35, "downloads": 4037, "paperswithcode_id": "librispeech-1", "createdAt": "2022-03-04T14:10:40.000Z"}, {"id": "ruanchaves/loyola", "sha": "e51544fd07e72dfa6bf830b56e417adba8dc50ba", "lastModified": "2022-10-20T19:13:04.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:unknown", "word-segmentation", "region:us"], "private": false, "author": "ruanchaves", "description": "In programming languages, identifiers are tokens (also called symbols) which name language entities.\r\nSome of the kinds of entities an identifier might denote include variables, types, labels, subroutines, and packages.\r\n\r\nThe Loyola University of Delaware Identifier Splitting Oracle is a dataset for identifier segmentation, \r\ni.e. the task of adding spaces between the words on a identifier.", "citation": "@article{hill2014empirical,\r\n  title={An empirical study of identifier splitting techniques},\r\n  author={Hill, Emily and Binkley, David and Lawrie, Dawn and Pollock, Lori and Vijay-Shanker, K},\r\n  journal={Empirical Software Engineering},\r\n  volume={19},\r\n  number={6},\r\n  pages={1754--1780},\r\n  year={2014},\r\n  publisher={Springer}\r\n}", "cardData": null, "siblings": [], "_id": "6223b8a91dedc9092a5ed13e", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2022-03-05T19:23:21.000Z"}, {"id": "mbartolo/synQA", "sha": "f60c3e93c0985c90741d15948afc694f9460b3d9", "lastModified": "2022-10-25T10:02:24.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "task_ids:open-domain-qa", "annotations_creators:generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:mit", "arxiv:1606.05250", "region:us"], "private": false, "author": "mbartolo", "description": "SynQA is a Reading Comprehension dataset created in the work \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\" (https://aclanthology.org/2021.emnlp-main.696/).\nIt consists of 314,811 synthetically generated questions on the passages in the SQuAD v1.1 (https://arxiv.org/abs/1606.05250) training set.\n\nIn this work, we use a synthetic adversarial data generation to make QA models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA (https://adversarialqa.github.io/) dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation to show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8% of the time on average, compared to 17.6% for a model trained without synthetic data.\n\nFor full details on how the dataset was created, kindly refer to the paper.", "citation": "@inproceedings{bartolo-etal-2021-improving,\n    title = \"Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation\",\n    author = \"Bartolo, Max  and\n      Thrush, Tristan  and\n      Jia, Robin  and\n      Riedel, Sebastian  and\n      Stenetorp, Pontus  and\n      Kiela, Douwe\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.696\",\n    doi = \"10.18653/v1/2021.emnlp-main.696\",\n    pages = \"8830--8848\",\n    abstract = \"Despite recent progress, state-of-the-art question answering models remain vulnerable to a variety of adversarial attacks. While dynamic adversarial data collection, in which a human annotator tries to write examples that fool a model-in-the-loop, can improve model robustness, this process is expensive which limits the scale of the collected data. In this work, we are the first to use synthetic adversarial data generation to make question answering models more robust to human adversaries. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve quality. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation and show that our models are considerably more robust to new human-written adversarial examples: crowdworkers can fool our model only 8.8{\\%} of the time on average, compared to 17.6{\\%} for a model trained without synthetic data.\",\n}", "cardData": null, "siblings": [], "_id": "6223d51d03d9dcbb0e2b8a7e", "disabled": false, "gated": false, "likes": 2, "downloads": 10, "createdAt": "2022-03-05T21:24:45.000Z"}, {"id": "ruanchaves/bt11", "sha": "1877395c47bcf77735761c694234dd55d3598bc5", "lastModified": "2022-10-20T19:13:02.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:unknown", "word-segmentation", "region:us"], "private": false, "author": "ruanchaves", "description": "In programming languages, identifiers are tokens (also called symbols) which name language entities.\r\nSome of the kinds of entities an identifier might denote include variables, types, labels, subroutines, and packages.\r\n\r\nBT11 is a dataset for identifier segmentation, \r\ni.e. the task of adding spaces between the words on a identifier.", "citation": "@inproceedings{li2018helpful,\r\n  title={Helpful or Not? An investigation on the feasibility of identifier splitting via CNN-BiLSTM-CRF.},\r\n  author={Li, Jiechu and Du, Qingfeng and Shi, Kun and He, Yu and Wang, Xin and Xu, Jincheng},\r\n  booktitle={SEKE},\r\n  pages={175--174},\r\n  year={2018}\r\n}", "cardData": null, "siblings": [], "_id": "6223e71e0129f2097d69a444", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-03-05T22:41:34.000Z"}, {"id": "ruanchaves/binkley", "sha": "5ccd62cfd185abd77dffc846d2cd3499e0c286c9", "lastModified": "2022-10-20T19:12:56.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:unknown", "word-segmentation", "region:us"], "private": false, "author": "ruanchaves", "description": "In programming languages, identifiers are tokens (also called symbols) which name language entities.\r\nSome of the kinds of entities an identifier might denote include variables, types, labels, subroutines, and packages.\r\n\r\nBinkley is a dataset for identifier segmentation, \r\ni.e. the task of adding spaces between the words on a identifier.", "citation": "@inproceedings{inproceedings,\r\nauthor = {Lawrie, Dawn and Binkley, David and Morrell, Christopher},\r\nyear = {2010},\r\nmonth = {11},\r\npages = {3 - 12},\r\ntitle = {Normalizing Source Code Vocabulary},\r\njournal = {Proceedings - Working Conference on Reverse Engineering, WCRE},\r\ndoi = {10.1109/WCRE.2010.10}\r\n}", "cardData": null, "siblings": [], "_id": "6223eab3af5df9d9e5582f4a", "disabled": false, "gated": false, "likes": 0, "downloads": 20, "createdAt": "2022-03-05T22:56:51.000Z"}, {"id": "ruanchaves/jhotdraw", "sha": "df859ecce54578af17e873cf79438b082632de1d", "lastModified": "2022-10-20T19:12:53.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:unknown", "word-segmentation", "region:us"], "private": false, "author": "ruanchaves", "description": "In programming languages, identifiers are tokens (also called symbols) which name language entities.\r\nSome of the kinds of entities an identifier might denote include variables, types, labels, subroutines, and packages.\r\n\r\nJhotdraw is a dataset for identifier segmentation, \r\ni.e. the task of adding spaces between the words on a identifier.", "citation": "@inproceedings{li2018helpful,\r\n  title={Helpful or Not? An investigation on the feasibility of identifier splitting via CNN-BiLSTM-CRF.},\r\n  author={Li, Jiechu and Du, Qingfeng and Shi, Kun and He, Yu and Wang, Xin and Xu, Jincheng},\r\n  booktitle={SEKE},\r\n  pages={175--174},\r\n  year={2018}\r\n}", "cardData": null, "siblings": [], "_id": "6223eea103d9dcbb0e2b8a89", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-03-05T23:13:37.000Z"}, {"id": "ruanchaves/snap", "sha": "dec0e19ff4bab5b5b1a972909b2ea38118644d0f", "lastModified": "2022-10-20T19:12:47.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:unknown", "word-segmentation", "region:us"], "private": false, "author": "ruanchaves", "description": "Automatically segmented 803K SNAP Twitter Data Set hashtags with the heuristic described in the paper \"Segmenting hashtags using automatically created training data\".", "citation": "@inproceedings{celebi2016segmenting,\r\n  title={Segmenting hashtags using automatically created training data},\r\n  author={Celebi, Arda and {\\\"O}zg{\\\"u}r, Arzucan},\r\n  booktitle={Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)},\r\n  pages={2981--2985},\r\n  year={2016}\r\n}", "cardData": null, "siblings": [], "_id": "6223fd9303d9dcbb0e2b8a8b", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2022-03-06T00:17:23.000Z"}, {"id": "shpotes/bosch-small-traffic-lights-dataset", "sha": "b333b72d400f6b4a23fd33524065cb732b372c8a", "lastModified": "2022-03-10T20:00:45.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "shpotes", "description": "This dataset contains 13427 camera images at a resolution of 1280x720 pixels and contains about \n24000 annotated traffic lights. The annotations include bounding boxes of traffic lights as well \nas the current state (active light) of each traffic light. The camera images are provided as raw \n12bit HDR images taken with a red-clear-clear-blue filter and as reconstructed 8-bit RGB color \nimages. The RGB images are provided for debugging and can also be used for training. However, the \nRGB conversion process has some drawbacks. Some of the converted images may contain artifacts and \nthe color distribution may seem unusual.", "citation": "@inproceedings{BehrendtNovak2017ICRA,\n  title={A Deep Learning Approach to Traffic Lights: Detection, Tracking, and Classification},\n  author={Behrendt, Karsten and Novak, Libor},\n  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "62276caea5e47a80eebc0fae", "disabled": false, "gated": false, "likes": 4, "downloads": 21, "createdAt": "2022-03-08T14:48:14.000Z"}, {"id": "fmplaza/EmoEvent", "sha": "1bacdbe742f7a05c7f2b14d2f92f786da022f601", "lastModified": "2023-03-27T08:19:58.000Z", "tags": ["language:en", "language:es", "license:apache-2.0", "region:us"], "private": false, "author": "fmplaza", "description": "EmoEvent is a multilingual emotion dataset of tweets based on different events that took place in April 2019. \nThree annotators labeled the tweets following the six Ekman\u2019s basic emotion model (anger, fear, sadness, joy, disgust, surprise) plus the \u201cneutral or other emotions\u201d category.", "citation": "@inproceedings{plaza-del-arco-etal-2020-emoevent, \ntitle = \"{{E}mo{E}vent: A Multilingual Emotion Corpus based on different Events}\", \nauthor = \"{Plaza-del-Arco}, {Flor Miriam} and Strapparava, Carlo and {Ure{~n}a-L{\\\u2019o}pez}, L. Alfonso and {Mart{\\\u2019i}n-Valdivia}, M. Teresa\", \nbooktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\", month = may, year = \"2020\", address = \"Marseille, France\", publisher = \"European Language Resources Association\", \nurl = \"https://www.aclweb.org/anthology/2020.lrec-1.186\", \npages = \"1492--1498\", \nlanguage = \"English\", \nISBN = \"979-10-95546-34-4\" }", "cardData": null, "siblings": [], "_id": "62287eca4323cef93a956a28", "disabled": false, "gated": "auto", "likes": 6, "downloads": 33, "createdAt": "2022-03-09T10:17:46.000Z"}, {"id": "ai4bharat/IndicParaphrase", "sha": "d74c67aec2ac5a2f561bcb30aa8e1fc7d7d88b92", "lastModified": "2022-10-13T06:08:55.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "arxiv:2203.05437", "region:us"], "private": false, "author": "ai4bharat", "description": "This is the paraphrasing dataset released as part of IndicNLG Suite. Each \ninput is paired with up to 5 references. We create this dataset in eleven \nlanguages including as, bn, gu, hi, kn, ml, mr, or, pa, ta, te. The total\nsize of the dataset is 5.57M.", "citation": "@inproceedings{Kumar2022IndicNLGSM,\n  title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages},\n  author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\n  year={2022},\n  url = \"https://arxiv.org/abs/2203.05437\"\n}", "cardData": null, "siblings": [], "_id": "62288f75f83ec595d158f24a", "disabled": false, "gated": false, "likes": 1, "downloads": 96, "createdAt": "2022-03-09T11:28:53.000Z"}, {"id": "drAbreu/bc4chemd_ner", "sha": "2615416d7c8cd65fbd6b2b7094f4136d4f8d9515", "lastModified": "2022-10-25T10:02:51.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:GitHub", "language:en", "license:unknown", "region:us"], "private": false, "author": "drAbreu", "description": "The automatic extraction of chemical information from text requires the recognition of chemical entity mentions as one of its key steps. When developing supervised named entity recognition (NER) systems, the availability of a large, manually annotated text corpus is desirable. Furthermore, large corpora permit the robust evaluation and comparison of different approaches that detect chemicals in documents. We present the CHEMDNER corpus, a collection of 10,000 PubMed abstracts that contain a total of 84,355 chemical entity mentions labeled manually by expert chemistry literature curators, following annotation guidelines specifically defined for this task. The abstracts of the CHEMDNER corpus were selected to be representative for all major chemical disciplines. Each of the chemical entity mentions was manually labeled according to its structure-associated chemical entity mention (SACEM) class: abbreviation, family, formula, identifier, multiple, systematic and trivial. The difficulty and consistency of tagging chemicals in text was measured using an agreement study between annotators, obtaining a percentage agreement of 91. For a subset of the CHEMDNER corpus (the test set of 3,000 abstracts) we provide not only the Gold Standard manual annotations, but also mentions automatically detected by the 26 teams that participated in the BioCreative IV CHEMDNER chemical mention recognition task. In addition, we release the CHEMDNER silver standard corpus of automatically extracted mentions from 17,000 randomly selected PubMed abstracts. A version of the CHEMDNER corpus in the BioC format has been generated as well. We propose a standard for required minimum information about entity annotations for the construction of domain specific corpora on chemical and drug entities. The CHEMDNER corpus and annotation guidelines are available at: http://www.biocreative.org/resources/biocreative-iv/chemdner-corpus/", "citation": "@article{Krallinger2015TheCC,\n  title={The CHEMDNER corpus of chemicals and drugs and its annotation principles},\n  author={Martin Krallinger and Obdulia Rabal and Florian Leitner and Miguel Vazquez and David Salgado and Zhiyong Lu and Robert Leaman and Yanan Lu and Dong-Hong Ji and Daniel M. Lowe and Roger A. Sayle and Riza Theresa Batista-Navarro and Rafal Rak and Torsten Huber and Tim Rockt{\\\"a}schel and S{\\'e}rgio Matos and David Campos and Buzhou Tang and Hua Xu and Tsendsuren Munkhdalai and Keun Ho Ryu and S. V. Ramanan and P. Senthil Nathan and Slavko Zitnik and Marko Bajec and Lutz Weber and Matthias Irmer and Saber Ahmad Akhondi and Jan A. Kors and Shuo Xu and Xin An and Utpal Kumar Sikdar and Asif Ekbal and Masaharu Yoshioka and Thaer M. Dieb and Miji Choi and Karin M. Verspoor and Madian Khabsa and C. Lee Giles and Hongfang Liu and K. E. Ravikumar and Andre Lamurias and Francisco M. Couto and Hong-Jie Dai and Richard Tzong-Han Tsai and C Ata and Tolga Can and Anabel Usie and Rui Alves and Isabel Segura-Bedmar and Paloma Mart{\\'i}nez and Julen Oyarz{\\'a}bal and Alfonso Valencia},\n  journal={Journal of Cheminformatics},\n  year={2015},\n  volume={7},\n  pages={S2 - S2}\n}", "cardData": null, "siblings": [], "_id": "6228c01010cf7d6eae384422", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "paperswithcode_id": "bc4chemd", "createdAt": "2022-03-09T14:56:16.000Z"}, {"id": "CLUTRR/v1", "sha": "a8158d1fac10864c3424d53662fe63bf7d82dd87", "lastModified": "2022-10-25T10:03:19.000Z", "tags": ["multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:unknown", "arxiv:1908.06177", "region:us"], "private": false, "author": "CLUTRR", "description": "CLUTRR (Compositional Language Understanding and Text-based Relational Reasoning),\n a diagnostic benchmark suite, is first introduced in (https://arxiv.org/abs/1908.06177) \n to test the systematic generalization and inductive reasoning capabilities of NLU systems.", "citation": "@article{sinha2019clutrr,\n  Author = {Koustuv Sinha and Shagun Sodhani and Jin Dong and Joelle Pineau and William L. Hamilton},\n  Title = {CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text},\n  Year = {2019},\n  journal = {Empirical Methods of Natural Language Processing (EMNLP)},\n  arxiv = {1908.06177}\n}", "cardData": null, "siblings": [], "_id": "622900ec080040f7388fd53c", "disabled": false, "gated": false, "likes": 2, "downloads": 1686, "createdAt": "2022-03-09T19:33:00.000Z"}, {"id": "PaddlePaddle/dureader_robust", "sha": "142e3e33e59f6c13239b5b743f16e5bfcfbc9abf", "lastModified": "2022-03-10T05:14:18.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "PaddlePaddle", "description": "DureaderRobust is a chinese reading comprehension dataset, designed to evaluate the MRC models from three aspects: over-sensitivity, over-stability and generalization.", "citation": null, "cardData": null, "siblings": [], "_id": "622982a242b684199a8d3bc4", "disabled": false, "gated": false, "likes": 1, "downloads": 71, "createdAt": "2022-03-10T04:46:26.000Z"}, {"id": "ai4bharat/IndicHeadlineGeneration", "sha": "d9845634dc0f9cb48d4a26c9f6d8986fb87d2027", "lastModified": "2022-10-13T06:08:20.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:27K<n<341K", "source_datasets:original for Hindi, and modified [IndicGLUE](https://indicnlp.ai4bharat.org/indic-glue/) for other languages.", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "arxiv:2203.05437", "region:us"], "private": false, "author": "ai4bharat", "description": "This is the new headline generation dataset released as part of IndicNLG Suite. Each \ninput document is paired an output title. We create this dataset in eleven \nlanguages including as, bn, gu, hi, kn, ml, mr, or, pa, ta, te. The total\nsize of the dataset is 1.43M.", "citation": "@inproceedings{Kumar2022IndicNLGSM,\n  title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages},\n  author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\n  year={2022},\n  url = \"https://arxiv.org/abs/2203.05437\"\n}", "cardData": null, "siblings": [], "_id": "6229cbc379337db2b0bf0c42", "disabled": false, "gated": false, "likes": 0, "downloads": 33, "createdAt": "2022-03-10T09:58:27.000Z"}, {"id": "ai4bharat/IndicSentenceSummarization", "sha": "53cfce5e0ca8da828ee1b6223dcf3ea986582812", "lastModified": "2022-10-13T06:08:31.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:5K<n<112K", "source_datasets:original for Hindi, and modified [IndicGLUE](https://indicnlp.ai4bharat.org/indic-glue/) for other languages.", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "arxiv:2203.05437", "region:us"], "private": false, "author": "ai4bharat", "description": "This is the sentence summarization dataset released as part of IndicNLG Suite. Each \ninput sentence is paired with an output summary. We create this dataset in eleven \nlanguages including as, bn, gu, hi, kn, ml, mr, or, pa, ta and te. The total\nsize of the dataset is 431K.", "citation": "@inproceedings{Kumar2022IndicNLGSM,\n  title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages},\n  author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\n  year={2022},\n  url = \"https://arxiv.org/abs/2203.05437\"\n}", "cardData": null, "siblings": [], "_id": "6229cbe9b8c5f583fa931c54", "disabled": false, "gated": false, "likes": 0, "downloads": 77, "createdAt": "2022-03-10T09:59:05.000Z"}, {"id": "ai4bharat/IndicWikiBio", "sha": "9b177ff8d3eeaf8d07d2918546e9b79ee655e29b", "lastModified": "2022-10-13T06:08:34.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:1960<n<11,502", "source_datasets:none. Originally generated from www.wikimedia.org.", "language:as", "language:bn", "language:hi", "language:kn", "language:ml", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "arxiv:2203.05437", "region:us"], "private": false, "author": "ai4bharat", "description": "This is the WikiBio dataset released as part of IndicNLG Suite. Each \nexample has four fields: id, infobox, serialized infobox and summary. We create this dataset in nine \nlanguages including as, bn, hi, kn, ml, or, pa, ta, te. The total\nsize of the dataset is 57,426.", "citation": "@inproceedings{Kumar2022IndicNLGSM,\n  title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages},\n  author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\n  year={2022},\n  url = \"https://arxiv.org/abs/2203.05437\"\n}", "cardData": null, "siblings": [], "_id": "6229cbfbb8c5f583fa931c56", "disabled": false, "gated": false, "likes": 0, "downloads": 52, "createdAt": "2022-03-10T09:59:23.000Z"}, {"id": "ai4bharat/IndicQuestionGeneration", "sha": "3c9cfa7c513097aa3e475ad34d8578c52b48514f", "lastModified": "2022-10-13T06:08:25.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:98K<n<98K", "source_datasets:we start with the SQuAD question answering dataset repurposed to serve as a question generation dataset. We translate this dataset into different Indic languages.", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc-by-nc-4.0", "arxiv:2203.05437", "region:us"], "private": false, "author": "ai4bharat", "description": "This is the Question Generation dataset released as part of IndicNLG Suite. Each \nexample has five fields: id, squad_id, answer, context and question. We create this dataset in eleven \nlanguages including as, bn, gu, hi, kn, ml, mr, or, pa, ta, te. This is a translated data. The examples in each language are exactly similar but in different languages. \nThe number of examples in each language is 98,027.", "citation": "@inproceedings{Kumar2022IndicNLGSM,\n  title={IndicNLG Suite: Multilingual Datasets for Diverse NLG Tasks in Indic Languages},\n  author={Aman Kumar and Himani Shrotriya and Prachi Sahu and Raj Dabre and Ratish Puduppully and Anoop Kunchukuttan and Amogh Mishra and Mitesh M. Khapra and Pratyush Kumar},\n  year={2022},\n  url = \"https://arxiv.org/abs/2203.05437\"\n}", "cardData": null, "siblings": [], "_id": "6229cc0d79337db2b0bf0c44", "disabled": false, "gated": false, "likes": 1, "downloads": 37, "createdAt": "2022-03-10T09:59:41.000Z"}, {"id": "ruanchaves/reddit_china", "sha": "e61aa47174a7d42c6d472264280d3e1402329f59", "lastModified": "2022-03-10T20:10:55.000Z", "tags": ["region:us"], "private": false, "author": "ruanchaves", "description": "Reddit comments with the word 'China' between 2010 and 2022.", "citation": "", "cardData": null, "siblings": [], "_id": "622a540e1e93c49887738d46", "disabled": false, "gated": false, "likes": 0, "downloads": 106, "createdAt": "2022-03-10T19:39:58.000Z"}, {"id": "gigant/horse2zebra", "sha": "04bb1414d14d63bffc026c6f12d047b7a3232930", "lastModified": "2022-10-24T17:37:53.000Z", "tags": ["task_categories:image-to-image", "license:cc", "GAN", "unpaired-image-to-image-translation", "arxiv:1703.10593", "region:us"], "private": false, "author": "gigant", "description": "Two unpaired sets of photos of respectively horses and zebras, designed for unpaired image-to-image translation, as seen in the paper introducing CycleGAN", "citation": "@inproceedings{CycleGAN2017,\n  title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},\n  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n  booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "622b1d6776c20fee5d14505d", "disabled": false, "gated": false, "likes": 1, "downloads": 41, "createdAt": "2022-03-11T09:59:03.000Z"}, {"id": "wikitablequestions", "sha": "d39cd162ebf1b780c9c369b98ccf62f2582b1468", "lastModified": "2023-04-05T13:45:42.000Z", "tags": ["task_categories:question-answering", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "table-question-answering", "arxiv:1508.00305", "region:us"], "private": false, "author": null, "description": "This WikiTableQuestions dataset is a large-scale dataset for the task of question answering on semi-structured tables.", "citation": "@inproceedings{pasupat-liang-2015-compositional,\n    title = \"Compositional Semantic Parsing on Semi-Structured Tables\",\n    author = \"Pasupat, Panupong and Liang, Percy\",\n    booktitle = \"Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2015\",\n    address = \"Beijing, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P15-1142\",\n    doi = \"10.3115/v1/P15-1142\",\n    pages = \"1470--1480\",\n}", "cardData": null, "siblings": [], "_id": "622f2424b4aa5adc490f3477", "disabled": false, "gated": false, "likes": 9, "downloads": 1889, "createdAt": "2022-03-14T11:16:52.000Z"}, {"id": "marsyas/gtzan", "sha": "7ea28ac19cd3ba9924de1940b9840be4f1419f8f", "lastModified": "2022-11-06T20:34:20.000Z", "tags": ["region:us"], "private": false, "author": "marsyas", "description": "GTZAN is a dataset for musical genre classification of audio signals. The dataset consists of 1,000 audio tracks, each of 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22,050Hz Mono 16-bit audio files in WAV format. The genres are: blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, and rock.", "citation": "@misc{tzanetakis_essl_cook_2001,\nauthor    = \"Tzanetakis, George and Essl, Georg and Cook, Perry\",\ntitle     = \"Automatic Musical Genre Classification Of Audio Signals\",\nurl       = \"http://ismir2001.ismir.net/pdf/tzanetakis.pdf\",\npublisher = \"The International Society for Music Information Retrieval\",\nyear      = \"2001\"\n}", "cardData": null, "siblings": [], "_id": "622f5743bc2a392eaf21b43b", "disabled": false, "gated": false, "likes": 6, "downloads": 1020, "createdAt": "2022-03-14T14:54:59.000Z"}, {"id": "GEM/xwikis", "sha": "73a091b01dfbf7865ee2d1ebef45f2e0cc7c6f73", "lastModified": "2023-02-22T13:05:19.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:de", "language:en", "language:fr", "language:cs", "license:cc-by-sa-4.0", "arxiv:2202.09583", "region:us"], "private": false, "author": "GEM", "description": "The XWikis Corpus (Perez-Beltrachini and Lapata, 2021) provides datasets with different language pairs and directions for cross-lingual abstractive document summarisation. This current version includes four languages: English, German, French, and Czech. The dataset is derived from Wikipedia. It is based on the observation that for a Wikipedia title, the lead section provides an overview conveying salient information, while the body provides detailed information. It thus assumes the body and lead paragraph as a document-summary pair. Furthermore, as a Wikipedia title can be associated with Wikipedia articles in various languages, 1) Wikipedia\u2019s Interlanguage Links are used to find titles across languages and 2) given any two related Wikipedia titles, e.g., Huile d\u2019Olive (French) and Olive Oil (English), the lead paragraph from one title is paired with the body of the other to derive cross-lingual pairs.", "citation": "@inproceedings{perez2021models,\n  title={Models and Datasets for Cross-Lingual Summarisation},\n  author={Perez-Beltrachini, Laura and Lapata, Mirella},\n  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},\n  pages={9408--9423},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "622f5fe4b4aa5adc490f34d8", "disabled": false, "gated": false, "likes": 2, "downloads": 141, "createdAt": "2022-03-14T15:31:48.000Z"}, {"id": "oscar-corpus/OSCAR-2201", "sha": "648664f0f63aa5901cc1bcdc2922558433c07dc7", "lastModified": "2023-05-30T07:48:15.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "source_datasets:original", "language:af", "language:sq", "language:am", "language:ar", "language:an", "language:hy", "language:as", "language:ast", "language:av", "language:az", "language:bn", "language:ba", "language:eu", "language:be", "language:bh", "language:bpy", "language:bs", "language:br", "language:bg", "language:my", "language:ca", "language:ceb", "language:ckb", "language:ce", "language:zh", "language:cv", "language:kw", "language:hr", "language:cs", "language:da", "language:diq", "language:dv", "language:nl", "language:mhr", "language:arz", "language:en", "language:eo", "language:et", "language:tl", "language:fi", "language:fr", "language:gl", "language:ka", "language:de", "language:gom", "language:el", "language:gn", "language:gu", "language:he", "language:hi", "language:hu", "language:is", "language:io", "language:ilo", "language:id", "language:ia", "language:ga", "language:it", "language:ja", "language:jv", "language:xal", "language:kn", "language:krc", "language:kk", "language:km", "language:kv", "language:ko", "language:ku", "language:ky", "language:lo", "language:la", "language:lv", "language:lez", "language:li", "language:lt", "language:jbo", "language:lmo", "language:nds", "language:dsb", "language:lb", "language:mk", "language:mai", "language:mg", "language:ms", "language:ml", "language:mt", "language:mr", "language:mzn", "language:min", "language:xmf", "language:mn", "language:nah", "language:ne", "language:new", "language:no", "language:nn", "language:oc", "language:or", "language:os", "language:ps", "language:fa", "language:pms", "language:pl", "language:pt", "language:pa", "language:qu", "language:ro", "language:bxr", "language:ru", "language:sah", "language:sa", "language:gd", "language:sr", "language:sh", "language:scn", "language:sd", "language:si", "language:sk", "language:sl", "language:so", "language:azb", "language:es", "language:su", "language:sw", "language:sv", "language:tg", "language:ta", "language:tt", "language:te", "language:th", "language:bo", "language:als", "language:tr", "language:tk", "language:uk", "language:eml", "language:hsb", "language:ur", "language:ug", "language:uz", "language:vi", "language:vo", "language:wa", "language:war", "language:cy", "language:fy", "language:mrj", "language:pnb", "language:wuu", "language:yi", "language:yo", "language:mul", "license:cc0-1.0", "arxiv:2010.14571", "arxiv:2201.06642", "arxiv:2103.12028", "region:us"], "private": false, "author": "oscar-corpus", "description": "The Open Super-large Crawled Aggregated coRpus is a huge multilingual corpus obtained by language classification and filtering of the Common Crawl corpus using the Ungoliant architecture.\\", "citation": "\n@ARTICLE{2022arXiv220106642A,\n  author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Beno{\\^\\i}t},\n  title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\n  journal = {arXiv e-prints},\n  keywords = {Computer Science - Computation and Language},\n  year = 2022,\n  month = jan,\n  eid = {arXiv:2201.06642},\n  pages = {arXiv:2201.06642},\n  archivePrefix = {arXiv},\n  eprint = {2201.06642},\n  primaryClass = {cs.CL},\n  adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Beno{\\^i}t Sagot},\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\n  editor    = {Harald L{\\\"u}ngen and Marc Kupietz and Piotr Ba\u0144ski and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\n  publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-10468},\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\n  pages     = {1 -- 9},\n  year      = {2021},\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics. However, most of these large raw corpora are either available only for English or not available to the general public due to copyright issues. Nevertheless, there are some examples of freely available multilingual corpora for training Deep Learning NLP models, such as the OSCAR and Paracrawl corpora. However, they have quality issues, especially for low-resource languages. Moreover, recreating or updating these corpora is very complex. In this work, we try to reproduce and improve the goclassy pipeline used to create the OSCAR corpus. We propose a new pipeline that is faster, modular, parameterizable, and well documented. We use it to create a corpus similar to OSCAR but larger and based on recent data. Also, unlike OSCAR, the metadata information is at the document level. We release our pipeline under an open source license and publish the corpus under a research-only license.},\n  language  = {en}\n}\n\n@article{caswell-etal-2021-quality,\n       author = {{Caswell}, Isaac and {Kreutzer}, Julia and {Wang}, Lisa and {Wahab}, Ahsan and {van Esch}, Daan and {Ulzii-Orshikh}, Nasanbayar and {Tapo}, Allahsera and {Subramani}, Nishant and {Sokolov}, Artem and {Sikasote}, Claytone and {Setyawan}, Monang and {Sarin}, Supheakmungkol and {Samb}, Sokhar and {Sagot}, Beno{\\^\\i}t and {Rivera}, Clara and {Rios}, Annette and {Papadimitriou}, Isabel and {Osei}, Salomey and {Ortiz Su{\\'a}rez}, Pedro Javier and {Orife}, Iroro and {Ogueji}, Kelechi and {Niyongabo}, Rubungo Andre and {Nguyen}, Toan Q. and {M{\\\"u}ller}, Mathias and {M{\\\"u}ller}, Andr{\\'e} and {Hassan Muhammad}, Shamsuddeen and {Muhammad}, Nanda and {Mnyakeni}, Ayanda and {Mirzakhalov}, Jamshidbek and {Matangira}, Tapiwanashe and {Leong}, Colin and {Lawson}, Nze and {Kudugunta}, Sneha and {Jernite}, Yacine and {Jenny}, Mathias and {Firat}, Orhan and {Dossou}, Bonaventure F.~P. and {Dlamini}, Sakhile and {de Silva}, Nisansa and {{\\c{C}}abuk Ball{\\i}}, Sakine and {Biderman}, Stella and {Battisti}, Alessia and {Baruwa}, Ahmed and {Bapna}, Ankur and {Baljekar}, Pallavi and {Abebe Azime}, Israel and {Awokoya}, Ayodele and {Ataman}, Duygu and {Ahia}, Orevaoghene and {Ahia}, Oghenefego and {Agrawal}, Sweta and {Adeyemi}, Mofetoluwa},\n        title = \"{Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets}\",\n      journal = {arXiv e-prints},\n     keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},\n         year = 2021,\n        month = mar,\n          eid = {arXiv:2103.12028},\n        pages = {arXiv:2103.12028},\narchivePrefix = {arXiv},\n       eprint = {2103.12028},\n primaryClass = {cs.CL},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210312028C},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n@inproceedings{ortiz-suarez-etal-2020-monolingual,\n    title = \"A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages\",\n    author = \"Ortiz Su{\\'a}rez, Pedro Javier  and\n      Romary, Laurent  and\n      Sagot, Benoit\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.156\",\n    pages = \"1703--1714\",\n    abstract = \"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures.\",\n}\n\n@inproceedings{OrtizSuarezSagotRomary2019,\n  author    = {Pedro Javier {Ortiz Su{\\'a}rez} and Benoit Sagot and Laurent Romary},\n  title     = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019},\n  editor    = {Piotr Ba\u0144ski and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\\\"u}ngen and Caroline Iliadi},\n  publisher = {Leibniz-Institut f{\\\"u}r Deutsche Sprache},\n  address   = {Mannheim},\n  doi       = {10.14618/ids-pub-9021},\n  url       = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},\n  pages     = {9 -- 16},\n  year      = {2019},\n  abstract  = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},\n  language  = {en}\n}", "cardData": null, "siblings": [], "_id": "622fcb1a334b7d0297a37ae4", "disabled": false, "gated": "auto", "likes": 77, "downloads": 601, "paperswithcode_id": "oscar", "createdAt": "2022-03-14T23:09:14.000Z"}, {"id": "tdklab/Hebrew_Squad_v1", "sha": "f887b0aa23f386116e46690f4630b2f2c204a880", "lastModified": "2022-08-04T04:59:05.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:auto_translation", "language_creators:auto_translation", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:squad", "region:us"], "private": false, "author": "tdklab", "description": "SStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. This Hebrew dataset is an automatic translation of the English SQuAD dataset.", "citation": null, "cardData": null, "siblings": [], "_id": "622fe14f49d1a18ef7878dac", "disabled": false, "gated": "auto", "likes": 1, "downloads": 13, "createdAt": "2022-03-15T00:43:59.000Z"}, {"id": "conll2012_ontonotesv5", "sha": "20571dc2f93826ba87e69216a4ed8211b95d1d72", "lastModified": "2023-01-25T15:03:49.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "task_ids:coreference-resolution", "task_ids:parsing", "task_ids:lemmatization", "task_ids:word-sense-disambiguation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ar", "language:en", "language:zh", "license:cc-by-nc-nd-4.0", "semantic-role-labeling", "region:us"], "private": false, "author": null, "description": "OntoNotes v5.0 is the final version of OntoNotes corpus, and is a large-scale, multi-genre,\nmultilingual corpus manually annotated with syntactic, semantic and discourse information.\n\nThis dataset is the version of OntoNotes v5.0 extended and is used in the CoNLL-2012 shared task.\nIt includes v4 train/dev and v9 test data for English/Chinese/Arabic and corrected version v12 train/dev/test data (English only).\n\nThe source of data is the Mendeley Data repo [ontonotes-conll2012](https://data.mendeley.com/datasets/zmycy7t9h9), which seems to be as the same as the official data, but users should use this dataset on their own responsibility.\n\nSee also summaries from paperwithcode, [OntoNotes 5.0](https://paperswithcode.com/dataset/ontonotes-5-0) and [CoNLL-2012](https://paperswithcode.com/dataset/conll-2012-1)\n\nFor more detailed info of the dataset like annotation, tag set, etc., you can refer to the documents in the Mendeley repo mentioned above.", "citation": "@inproceedings{pradhan-etal-2013-towards,\n    title = \"Towards Robust Linguistic Analysis using {O}nto{N}otes\",\n    author = {Pradhan, Sameer  and\n      Moschitti, Alessandro  and\n      Xue, Nianwen  and\n      Ng, Hwee Tou  and\n      Bj{\\\"o}rkelund, Anders  and\n      Uryupina, Olga  and\n      Zhang, Yuchen  and\n      Zhong, Zhi},\n    booktitle = \"Proceedings of the Seventeenth Conference on Computational Natural Language Learning\",\n    month = aug,\n    year = \"2013\",\n    address = \"Sofia, Bulgaria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W13-3516\",\n    pages = \"143--152\",\n}\n\nRalph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, Ann Houston. OntoNotes Release 5.0 LDC2013T19. Web Download. Philadelphia: Linguistic Data Consortium, 2013.", "cardData": null, "siblings": [], "_id": "62306efca7ea9e7951f54927", "disabled": false, "gated": false, "likes": 27, "downloads": 2858, "paperswithcode_id": "ontonotes-5-0", "createdAt": "2022-03-15T10:48:28.000Z"}, {"id": "cfilt/iwn_wordlists", "sha": "6dfbbdc8bf9da9500f8eaa2eeb13f150186941d0", "lastModified": "2022-11-23T12:06:02.000Z", "tags": ["task_categories:token-classification", "annotations_creators:Shivam Mhaskar, Diptesh Kanojia", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:as", "language:bn", "language:mni", "language:gu", "language:hi", "language:kn", "language:ks", "language:kok", "language:ml", "language:mr", "language:or", "language:ne", "language:pa", "language:sa", "language:ta", "language:te", "language:ur", "license:cc-by-nc-sa-4.0", "abbreviation-detection", "region:us"], "private": false, "author": "cfilt", "description": "We provide the unique word list form the IndoWordnet (IWN) knowledge base.", "citation": "@inproceedings{bhattacharyya2010indowordnet,\n  title={IndoWordNet},\n  author={Bhattacharyya, Pushpak},\n  booktitle={Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)},\n  year={2010}\n}", "cardData": null, "siblings": [], "_id": "62347379cd8a0462e55bdc13", "disabled": false, "gated": false, "likes": 2, "downloads": 34, "paperswithcode_id": "plod-filtered", "createdAt": "2022-03-18T11:56:41.000Z"}, {"id": "yhavinga/ccmatrix", "sha": "9d4d238fbdad8ccfc9058cdcda552527f54bca2a", "lastModified": "2023-03-09T07:44:58.000Z", "tags": ["task_categories:text2text-generation", "task_categories:translation", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "source_datasets:original", "language:af", "language:am", "language:ar", "language:ast", "language:az", "language:be", "language:bg", "language:bn", "language:br", "language:ca", "language:ceb", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:fy", "language:ga", "language:gd", "language:gl", "language:ha", "language:he", "language:hi", "language:hr", "language:hu", "language:hy", "language:id", "language:ig", "language:ilo", "language:is", "language:it", "language:ja", "language:jv", "language:ka", "language:kk", "language:km", "language:ko", "language:la", "language:lb", "language:lg", "language:lt", "language:lv", "language:mg", "language:mk", "language:ml", "language:mr", "language:ms", "language:my", "language:ne", "language:nl", "language:no", "language:oc", "language:om", "language:or", "language:pl", "language:pt", "language:ro", "language:ru", "language:sd", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:su", "language:sv", "language:sw", "language:ta", "language:tl", "language:tr", "language:tt", "language:uk", "language:ur", "language:uz", "language:vi", "language:wo", "language:xh", "language:yi", "language:yo", "language:zh", "language:zu", "language:se", "license:unknown", "conditional-text-generation", "arxiv:1911.04944", "arxiv:1911.00359", "arxiv:2010.11125", "region:us"], "private": false, "author": "yhavinga", "description": "CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB\n\nWe show that margin-based bitext mining in LASER's multilingual sentence space can be applied to\nmonolingual corpora of billions of sentences to produce high quality aligned translation data.\nWe use thirty-two snapshots of a curated common crawl corpus [1] totaling 69 billion unique sentences.\nUsing one unified approach for 80 languages, we were able to mine 10.8 billion parallel sentences,\nout of which only 2.9 billion are aligned with English.\n\nIMPORTANT: Please cite reference [2][3] if you use this data.\n\n[1] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzm\u00e1n, Armand Jouli\n    and Edouard Grave, CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data\n\n[2] Holger Schwenk, Guillaume Wenzek, Sergey Edunov, Edouard Grave and Armand Joulin,\n    CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB\n\n[3] Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines,\n    Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky,\n    Sergey Edunov, Edouard Grave, Michael Auli, and Armand Joulin.\n    Beyond English-Centric Multilingual Machine Translation\n    \n90 languages, 1,197 bitexts\ntotal number of files: 90\ntotal number of tokens: 112.14G\ntotal number of sentence fragments: 7.37G", "citation": " Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzm\u00e1n, Armand Jouli and Edouard Grave, CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data", "cardData": null, "siblings": [], "_id": "62359a534266c6917d404c09", "disabled": false, "gated": false, "likes": 18, "downloads": 4900, "paperswithcode_id": "ccmatrix", "createdAt": "2022-03-19T08:54:43.000Z"}, {"id": "TomTBT/pmc_open_access_xml", "sha": "653138ab91b809173ba0d4f53b2f1e837d92ec1c", "lastModified": "2023-09-17T08:43:36.000Z", "tags": ["task_categories:text-classification", "task_categories:summarization", "task_categories:other", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc0-1.0", "license:cc-by-4.0", "license:cc-by-sa-4.0", "license:cc-by-nc-4.0", "license:cc-by-nd-4.0", "license:cc-by-nc-nd-4.0", "license:cc-by-nc-sa-4.0", "license:unknown", "license:other", "research papers", "biology", "medecine", "region:us"], "private": false, "author": "TomTBT", "description": "The PMC Open Access Subset includes more than 3.4 million journal articles and preprints that are made available under\nlicense terms that allow reuse. \nNot all articles in PMC are available for text mining and other reuse, many have copyright protection, however articles\nin the PMC Open Access Subset are made available under Creative Commons or similar licenses that generally allow more\nliberal redistribution and reuse than a traditional copyrighted work. \nThe PMC Open Access Subset is one part of the PMC Article Datasets\n\nThis version takes XML version as source, benefiting from the structured text\nto split the articles in parts, naming the introduction, methods, results,\ndiscussion and conclusion, and refers with keywords in the text to external or internal\nresources (articles, figures, tables, formulas, boxed-text, quotes, code, footnotes, chemicals, graphics, medias).", "citation": null, "cardData": null, "siblings": [], "_id": "6236f829dd2a2967bd993df8", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-03-20T09:47:21.000Z"}, {"id": "monash_tsf", "sha": "58aafbe2712ff481c014f562e42723f2820fd5d4", "lastModified": "2023-06-13T13:26:34.000Z", "tags": ["task_categories:time-series-forecasting", "task_ids:univariate-time-series-forecasting", "task_ids:multivariate-time-series-forecasting", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Monash Time Series Forecasting Repository which contains 30+ datasets of related time series for global forecasting research. This repository includes both real-world and competition time series datasets covering varied domains.", "citation": "@InProceedings{godahewa2021monash,\n    author = \"Godahewa, Rakshitha and Bergmeir, Christoph and Webb, Geoffrey I. and Hyndman, Rob J. and Montero-Manso, Pablo\",\n    title = \"Monash Time Series Forecasting Archive\",\n    booktitle = \"Neural Information Processing Systems Track on Datasets and Benchmarks\",\n    year = \"2021\",\n    note = \"forthcoming\"\n}", "cardData": null, "siblings": [], "_id": "62384a76a022015f518c348e", "disabled": false, "gated": false, "likes": 22, "downloads": 5588, "createdAt": "2022-03-21T09:50:46.000Z"}, {"id": "roman_urdu_hate_speech", "sha": "1cf017b38e0f3e7b9849f947335d44ff7be895af", "lastModified": "2023-01-25T15:03:53.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ur", "license:mit", "binary classification", "region:us"], "private": false, "author": null, "description": " The Roman Urdu Hate-Speech and Offensive Language Detection (RUHSOLD) dataset is a  Roman Urdu dataset of tweets annotated by experts in the relevant language.  The authors develop the gold-standard for two sub-tasks.  First sub-task is based on binary labels of Hate-Offensive content and Normal content (i.e., inoffensive language).  These labels are self-explanatory.  The authors refer to this sub-task as coarse-grained classification.  Second sub-task defines Hate-Offensive content with  four labels at a granular level.  These labels are the most relevant for the demographic of users who converse in RU and  are defined in related literature. The authors refer to this sub-task as fine-grained classification.  The objective behind creating two gold-standards is to enable the researchers to evaluate the hate speech detection  approaches on both easier (coarse-grained) and challenging (fine-grained) scenarios. \\", "citation": "@inproceedings{rizwan2020hate,\n  title={Hate-speech and offensive language detection in roman Urdu},\n  author={Rizwan, Hammad and Shakeel, Muhammad Haroon and Karim, Asim},\n  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n  pages={2512--2522},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "623de5110232e09daffc1e06", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2022-03-25T15:51:45.000Z"}, {"id": "facebook/winoground", "sha": "0d783a9fe5e53539e7bc40df462c5a641dd48ce3", "lastModified": "2023-11-02T17:15:41.000Z", "tags": ["task_categories:image-to-text", "task_categories:text-to-image", "task_categories:image-classification", "language:en", "arxiv:2204.03162", "region:us"], "private": false, "author": "facebook", "description": "Winoground is a novel task and dataset for evaluating the ability of vision and language models to conduct visio-linguistic compositional reasoning. Given two images and two captions, the goal is to match them correctly\u2014but crucially, both captions contain a completely identical set of words/morphemes, only in a different order. The dataset was carefully hand-curated by expert annotators and is labeled with a rich set of fine-grained tags to assist in analyzing model performance. In our accompanying paper, we probe a diverse range of state-of-the-art vision and language models and find that, surprisingly, none of them do much better than chance. Evidently, these models are not as skilled at visio-linguistic compositional reasoning as we might have hoped. In the paper, we perform an extensive analysis to obtain insights into how future work might try to mitigate these models\u2019 shortcomings. We aim for Winoground to serve as a useful evaluation set for advancing the state of the art and driving further progress in the field.", "citation": "@inproceedings{thrush_and_ross2022winoground,\n  author = {Tristan Thrush and Ryan Jiang and Max Bartolo and Amanpreet Singh and Adina Williams and Douwe Kiela and Candace Ross},\n  title = {Winoground: Probing vision and language models for visio-linguistic compositionality},\n  booktitle = {CVPR},\n  year = 2022,\n}", "cardData": null, "siblings": [], "_id": "623e41d5fa81e3493cdb89eb", "disabled": false, "gated": "auto", "likes": 63, "downloads": 5963, "createdAt": "2022-03-25T22:27:33.000Z"}, {"id": "adv_glue", "sha": "6b7a3b0b7be43e4b255f5fc0451071ec58b20978", "lastModified": "2023-06-01T14:57:45.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:sentiment-classification", "annotations_creators:other", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:extended|glue", "language:en", "license:cc-by-sa-4.0", "paraphrase-identification", "qa-nli", "arxiv:2111.02840", "region:us"], "private": false, "author": null, "description": "Adversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark\nthat focuses on the adversarial robustness evaluation of language models. It covers five\nnatural language understanding tasks from the famous GLUE tasks and is an adversarial\nversion of GLUE benchmark.", "citation": "@article{Wang2021AdversarialGA,\n  title={Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models},\n  author={Boxin Wang and Chejian Xu and Shuohang Wang and Zhe Gan and Yu Cheng and Jianfeng Gao and Ahmed Hassan Awadallah and B. Li},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2111.02840}\n}", "cardData": null, "siblings": [], "_id": "624198213534f6d909d1b922", "disabled": false, "gated": false, "likes": 4, "downloads": 745, "createdAt": "2022-03-28T11:12:33.000Z"}, {"id": "carolina-c4ai/corpus-carolina", "sha": "7ea460abd146b010b3668f374c1f51068c6ff032", "lastModified": "2023-03-23T19:46:16.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:masked-language-modeling", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1B<n<10B", "source_datasets:original", "language:pt", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "carolina-c4ai", "description": "Carolina is an Open Corpus for Linguistics and Artificial Intelligence with a\nrobust volume of texts of varied typology in contemporary Brazilian Portuguese\n(1970-2021).", "citation": null, "cardData": null, "siblings": [], "_id": "6241b8793534f6d909d2edb4", "disabled": false, "gated": false, "likes": 12, "downloads": 622, "createdAt": "2022-03-28T13:30:33.000Z"}, {"id": "metashift", "sha": "7317fd411dc50b90aef4a546e4e1d8e5b50c070b", "lastModified": "2023-01-25T15:03:59.000Z", "tags": ["task_categories:image-classification", "task_categories:other", "task_ids:multi-label-image-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "domain-generalization", "arxiv:2202.06523", "region:us"], "private": false, "author": null, "description": "The MetaShift is a dataset of datasets for evaluating distribution shifts and training conflicts.\nThe MetaShift dataset is a collection of 12,868 sets of natural images across 410 classes.\nIt was created for understanding the performance of a machine learning model across diverse data distributions.", "citation": "@InProceedings{liang2022metashift,\ntitle={MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts},\nauthor={Weixin Liang and James Zou},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=MTex8qKavoS}\n}", "cardData": null, "siblings": [], "_id": "624717693f063354aba3f3de", "disabled": false, "gated": false, "likes": 3, "downloads": 19, "paperswithcode_id": "metashift", "createdAt": "2022-04-01T15:16:57.000Z"}, {"id": "PolyAI/minds14", "sha": "3a0bb29c446edbb0c461b27706cee1f3862191b8", "lastModified": "2023-04-12T12:08:02.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_ids:keyword-spotting", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "language:en", "language:fr", "language:it", "language:es", "language:pt", "language:de", "language:nl", "language:ru", "language:pl", "language:cs", "language:ko", "language:zh", "license:cc-by-4.0", "arxiv:2104.08524", "region:us"], "private": false, "author": "PolyAI", "description": "MINDS-14 is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.", "citation": "@article{gerz2021multilingual,\n  title={Multilingual and cross-lingual intent detection from spoken data},\n  author={Gerz, Daniela and Su, Pei-Hao and Kusztos, Razvan and Mondal, Avishek and Lis, Michal and Singhal, Eshan and Mrk{\\v{s}}i{\\'c}, Nikola and Wen, Tsung-Hsien and Vuli{\\'c}, Ivan},\n  journal={arXiv preprint arXiv:2104.08524},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "624bf3c5d84cc6ac39070753", "disabled": false, "gated": false, "likes": 33, "downloads": 5630, "createdAt": "2022-04-05T07:46:13.000Z"}, {"id": "SocialGrep/the-reddit-place-dataset", "sha": "8ec4ba6640805906d0c61886e65810c8ee78a982", "lastModified": "2022-07-01T17:51:57.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "The written history or /r/Place, in posts and comments.", "citation": null, "cardData": null, "siblings": [], "_id": "624cb3d95ee9cb3d455610d4", "disabled": false, "gated": false, "likes": 1, "downloads": 23, "createdAt": "2022-04-05T21:25:45.000Z"}, {"id": "albertvillanova/mtet", "sha": "1cad77bdc16e9965ba15285d5fc9ca347d6cec3a", "lastModified": "2022-10-08T07:42:34.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:found", "multilinguality:translation", "size_categories:1M<n<10M", "source_datasets:original", "source_datasets:extended|bible_para", "source_datasets:extended|kde4", "source_datasets:extended|opus_gnome", "source_datasets:extended|open_subtitles", "source_datasets:extended|tatoeba", "language:en", "language:vi", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "albertvillanova", "description": "MTet (Multi-domain Translation for English-Vietnamese) dataset contains roughly 4.2 million English-Vietnamese pairs of\ntexts, ranging across multiple different domains such as medical publications, religious texts, engineering articles,\nliterature, news, and poems.\n\nThis dataset extends our previous SAT (Style Augmented Translation) dataset (v1.0) by adding more high-quality\nEnglish-Vietnamese sentence pairs on various domains.", "citation": "@article{mTet2022,\n    author  = {Chinh Ngo, Hieu Tran, Long Phan, Trieu H. Trinh, Hieu Nguyen, Minh Nguyen, Minh-Thang Luong},\n    title   = {MTet: Multi-domain Translation for English and Vietnamese},\n    journal = {https://github.com/vietai/mTet},\n    year    = {2022},\n}", "cardData": null, "siblings": [], "_id": "624d6aa6300264d00b63f136", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2022-04-06T10:25:42.000Z"}, {"id": "StanBienaives/french-open-fiscal-texts", "sha": "e4b81eb76e142bbe07326db59b0e77c9a0f0b831", "lastModified": "2022-10-25T10:03:56.000Z", "tags": ["task_categories:summarization", "task_categories:feature-extraction", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "license:cc0-1.0", "region:us"], "private": false, "author": "StanBienaives", "description": "  This dataset is an extraction from the OPENDATA/JADE. A list of case laws from the French court \"Conseil d'Etat\".", "citation": "@InProceedings{huggingface:dataset,\ntitle = {French Fiscal texts},\nauthor={Stan Bienaives\n},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "624d7c8ec23d8d1859d307e9", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-04-06T11:42:06.000Z"}, {"id": "skt/kobest_v1", "sha": "46d3e24187694e12e7b4ae59b94c80b86ab774d8", "lastModified": "2022-08-22T09:00:17.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "license:cc-by-sa-4.0", "arxiv:2204.04541", "region:us"], "private": false, "author": "skt", "description": "    The dataset contains data for KoBEST dataset", "citation": null, "cardData": null, "siblings": [], "_id": "624eed0f9d608e45938769c2", "disabled": false, "gated": false, "likes": 21, "downloads": 14037, "createdAt": "2022-04-07T13:54:23.000Z"}, {"id": "McGill-NLP/TopiOCQA", "sha": "66cd1dbf5577c653ecb99b385200f08e15e12f30", "lastModified": "2023-09-29T19:37:48.000Z", "tags": ["task_categories:text-retrieval", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100k", "language:en", "license:cc-by-nc-sa-4.0", "conversational-question-answering", "arxiv:2110.00768", "region:us"], "private": false, "author": "McGill-NLP", "description": "TopiOCQA is an information-seeking conversational dataset with challenging topic switching phenomena.", "citation": null, "cardData": null, "siblings": [], "_id": "62507f215bf543dbd26063db", "disabled": false, "gated": false, "likes": 4, "downloads": 304, "createdAt": "2022-04-08T18:29:53.000Z"}, {"id": "csebuetnlp/squad_bn", "sha": "3b2935a74731f120004bdcbc3f9fd73f7d854c96", "lastModified": "2022-08-21T13:17:43.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended", "language:bn", "license:cc-by-nc-sa-4.0", "arxiv:2101.00204", "arxiv:2007.01852", "arxiv:1606.05250", "arxiv:2003.05002", "region:us"], "private": false, "author": "csebuetnlp", "description": "SQuAD-bn is derived from the SQuAD-2.0 and TyDI-QA datasets.", "citation": "@misc{bhattacharjee2021banglabert,\n      title={BanglaBERT: Combating Embedding Barrier in Multilingual Models for Low-Resource Language Understanding},\n      author={Abhik Bhattacharjee and Tahmid Hasan and Kazi Samin and Md Saiful Islam and M. Sohel Rahman and Anindya Iqbal and Rifat Shahriyar},\n      year={2021},\n      eprint={2101.00204},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "6253fffab90cb184e3860254", "disabled": false, "gated": false, "likes": 4, "downloads": 197, "createdAt": "2022-04-11T10:16:26.000Z"}, {"id": "taln-ls2n/inspec", "sha": "dd723264101153ba5ddf3451e65446346000f496", "lastModified": "2022-07-21T14:14:59.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:en", "license:unknown", "region:us"], "private": false, "author": "taln-ls2n", "description": "Inspec benchmark dataset for keyphrase extraction an generation.", "citation": "@inproceedings{hulth2003improved,\n  title={Improved automatic keyword extraction given more linguistic knowledge},\n  author={Hulth, Anette},\n  booktitle={Proceedings of the 2003 conference on Empirical methods in natural language processing},\n  pages={216--223},\n  year={2003}\n}", "cardData": null, "siblings": [], "_id": "6255340593dead146186ccb2", "disabled": false, "gated": false, "likes": 3, "downloads": 71, "createdAt": "2022-04-12T08:10:45.000Z"}, {"id": "gsm8k", "sha": "be45a9e2ae111e0cbfd91a7028f8de6aa80bc9a5", "lastModified": "2022-11-18T22:06:26.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:mit", "math-word-problems", "arxiv:2110.14168", "region:us"], "private": false, "author": null, "description": "GSM8K (Grade School Math 8K) is a dataset of 8.5K high quality\nlinguistically diverse grade school math word problems. The\ndataset was created to support the task of question answering\non basic mathematical problems that require multi-step reasoning.", "citation": "@misc{cobbe2021training,\n      title={Training Verifiers to Solve Math Word Problems},\n      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},\n      year={2021},\n      eprint={2110.14168},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}", "cardData": null, "siblings": [], "_id": "625552d2b339bb03abe3432d", "disabled": false, "gated": false, "likes": 116, "downloads": 246521, "paperswithcode_id": "gsm8k", "createdAt": "2022-04-12T10:22:10.000Z"}, {"id": "sbu_captions", "sha": "174da1f0b11d8f220d51a1ed01b61133db7e579b", "lastModified": "2023-06-02T20:56:01.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The SBU Captioned Photo Dataset is a collection of over 1 million images with associated text descriptions extracted from Flicker.", "citation": "@inproceedings{NIPS2011_5dd9db5e,\n author = {Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},\n pages = {},\n publisher = {Curran Associates, Inc.},\n title = {Im2Text: Describing Images Using 1 Million Captioned Photographs},\n url = {https://proceedings.neurips.cc/paper/2011/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf},\n volume = {24},\n year = {2011}\n}", "cardData": null, "siblings": [], "_id": "6255577093dead1461879d20", "disabled": false, "gated": false, "likes": 9, "downloads": 230, "paperswithcode_id": "sbu-captions-dataset", "createdAt": "2022-04-12T10:41:52.000Z"}, {"id": "taln-ls2n/kp20k", "sha": "4b51f4dae6b6ad746445f05059d6793c1f6ea988", "lastModified": "2023-09-13T13:15:04.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:unknown", "keyphrase-generation", "keyphrase-extraction", "text-mining", "region:us"], "private": false, "author": "taln-ls2n", "description": "KP20k dataset for keyphrase extraction and generation in scientific paper.", "citation": "@InProceedings{meng-EtAl:2017:Long,\n  author    = {Meng, Rui  and  Zhao, Sanqiang  and  Han, Shuguang  and  He, Daqing  and  Brusilovsky, Peter  and  Chi, Yu},\n  title     = {Deep Keyphrase Generation},\n  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n  month     = {July},\n  year      = {2017},\n  address   = {Vancouver, Canada},\n  publisher = {Association for Computational Linguistics},\n  pages     = {582--592},\n  url       = {http://aclweb.org/anthology/P17-1054}\n}", "cardData": null, "siblings": [], "_id": "6257e2928c6638f8a94036aa", "disabled": false, "gated": false, "likes": 1, "downloads": 32, "createdAt": "2022-04-14T09:00:02.000Z"}, {"id": "patriziobellan/PET", "sha": "5eb9bca5c7dc850b2a42df268b78b88190ab2466", "lastModified": "2023-07-05T14:03:24.000Z", "tags": ["task_categories:token-classification", "size_categories:n<1K", "language:en", "license:mit", "Business Process Management", "NLP", "ML", "DL", "arxiv:2203.04860", "region:us"], "private": false, "author": "patriziobellan", "description": "Abstract. Although there is a long tradition of work in NLP on extracting entities and relations from text, to date there exists little work on the acquisition of business processes from unstructured data such as textual corpora of process descriptions. With this work we aim at filling this gap and establishing the first steps towards bridging data-driven information extraction methodologies from Natural Language Processing and the model-based formalization that is aimed from Business Process Management. For this, we develop the first corpus of business process descriptions annotated with activities, gateways, actors and flow information. We present our new resource, including a detailed overview of the annotation schema and guidelines, as well as a variety of baselines to benchmark the difficulty and challenges of business process extraction from text.", "citation": "@inproceedings{DBLP:conf/bpm/BellanADGP22,\n  author       = {Patrizio Bellan and\n                  Han van der Aa and\n                  Mauro Dragoni and\n                  Chiara Ghidini and\n                  Simone Paolo Ponzetto},\n  editor       = {Cristina Cabanillas and\n                  Niels Frederik Garmann{-}Johnsen and\n                  Agnes Koschmider},\n  title        = {{PET:} An Annotated Dataset for Process Extraction from Natural Language\n                  Text Tasks},\n  booktitle    = {Business Process Management Workshops - {BPM} 2022 International Workshops,\n                  M{\\\"{u}}nster, Germany, September 11-16, 2022, Revised Selected\n                  Papers},\n  series       = {Lecture Notes in Business Information Processing},\n  volume       = {460},\n  pages        = {315--321},\n  publisher    = {Springer},\n  year         = {2022},\n  url          = {https://doi.org/10.1007/978-3-031-25383-6\\_23},\n  doi          = {10.1007/978-3-031-25383-6\\_23},\n  timestamp    = {Tue, 14 Feb 2023 09:47:10 +0100},\n  biburl       = {https://dblp.org/rec/conf/bpm/BellanADGP22.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n@inproceedings{DBLP:conf/aiia/BellanGDPA22,\n  author       = {Patrizio Bellan and\n                  Chiara Ghidini and\n                  Mauro Dragoni and\n                  Simone Paolo Ponzetto and\n                  Han van der Aa},\n  editor       = {Debora Nozza and\n                  Lucia C. Passaro and\n                  Marco Polignano},\n  title        = {Process Extraction from Natural Language Text: the {PET} Dataset and\n                  Annotation Guidelines},\n  booktitle    = {Proceedings of the Sixth Workshop on Natural Language for Artificial\n                  Intelligence {(NL4AI} 2022) co-located with 21th International Conference\n                  of the Italian Association for Artificial Intelligence (AI*IA 2022),\n                  Udine, November 30th, 2022},\n  series       = {{CEUR} Workshop Proceedings},\n  volume       = {3287},\n  pages        = {177--191},\n  publisher    = {CEUR-WS.org},\n  year         = {2022},\n  url          = {https://ceur-ws.org/Vol-3287/paper18.pdf},\n  timestamp    = {Fri, 10 Mar 2023 16:23:01 +0100},\n  biburl       = {https://dblp.org/rec/conf/aiia/BellanGDPA22.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "6257eacf73e71f6d393cc155", "disabled": false, "gated": false, "likes": 6, "downloads": 145, "createdAt": "2022-04-14T09:35:11.000Z"}, {"id": "conceptual_captions", "sha": "e1a96a49d0b314b3a9f4d71672d4dac97d6e146a", "lastModified": "2022-11-03T16:32:04.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": null, "description": "Google's Conceptual Captions dataset has more than 3 million images, paired with natural-language captions.\nIn contrast with the curated style of the MS-COCO images, Conceptual Captions images and their raw descriptions are harvested from the web,\nand therefore represent a wider variety of styles. The raw descriptions are harvested from the Alt-text HTML attribute associated with web images.\nThe authors developed an automatic pipeline that extracts, filters, and transforms candidate image/caption pairs, with the goal of achieving a balance of cleanliness,\ninformativeness, fluency, and learnability of the resulting captions.", "citation": "@inproceedings{sharma2018conceptual,\n  title = {Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning},\n  author = {Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},\n  booktitle = {Proceedings of ACL},\n  year = {2018},\n}", "cardData": null, "siblings": [], "_id": "62581cc50efac682e4de7619", "disabled": false, "gated": false, "likes": 39, "downloads": 2447, "paperswithcode_id": "conceptual-captions", "createdAt": "2022-04-14T13:08:21.000Z"}, {"id": "conceptual_12m", "sha": "2fd749bd49b36c4243cda8d800ed74753d442f5a", "lastModified": "2022-11-03T16:31:22.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:other", "arxiv:2102.08981", "region:us"], "private": false, "author": null, "description": "Conceptual 12M is a large-scale dataset of 12 million\nimage-text pairs specifically meant to be used for visionand-language pre-training.\nIts data collection pipeline is a relaxed version of the one used in Conceptual Captions 3M.", "citation": "@inproceedings{changpinyo2021cc12m,\n  title = {{Conceptual 12M}: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},\n  author = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},\n  booktitle = {CVPR},\n  year = {2021},\n}", "cardData": null, "siblings": [], "_id": "625927a2a68a1fd2395fd26d", "disabled": false, "gated": false, "likes": 12, "downloads": 134, "paperswithcode_id": "cc12m", "createdAt": "2022-04-15T08:06:58.000Z"}, {"id": "surrey-nlp/PLOD-filtered", "sha": "8a852d571fd838da91f2beb879f489f382d1462b", "lastModified": "2023-01-14T23:30:12.000Z", "tags": ["task_categories:token-classification", "annotations_creators:Leonardo Zilio, Hadeel Saadany, Prashant Sharma, Diptesh Kanojia, Constantin Orasan", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "abbreviation-detection", "arxiv:2204.12061", "region:us"], "private": false, "author": "surrey-nlp", "description": "This is the dataset repository for PLOD Dataset accepted to be published at LREC 2022.\nThe dataset can help build sequence labelling models for the task Abbreviation Detection.", "citation": "", "cardData": null, "siblings": [], "_id": "625ad7a7af150f08af77e3e3", "disabled": false, "gated": false, "likes": 0, "downloads": 44, "paperswithcode_id": "plod-filtered", "createdAt": "2022-04-16T14:50:15.000Z"}, {"id": "Divyanshu/indicxnli", "sha": "7092c27872e919f31d0496fb8b9c47bd2cba3f6c", "lastModified": "2022-10-06T15:26:00.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "license:cc0-1.0", "arxiv:2204.08776", "region:us"], "private": false, "author": "Divyanshu", "description": "IndicXNLI is a translated version of XNLI to 11 Indic Languages. As with XNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).", "citation": "@misc{https://doi.org/10.48550/arxiv.2204.08776,\n  doi = {10.48550/ARXIV.2204.08776},\n  \n  url = {https://arxiv.org/abs/2204.08776},\n  \n  author = {Aggarwal, Divyanshu and Gupta, Vivek and Kunchukuttan, Anoop},\n  \n  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {IndicXNLI: Evaluating Multilingual Inference for Indian Languages}, \n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {Creative Commons Attribution 4.0 International}\n}\n}", "cardData": null, "siblings": [], "_id": "625c52da2087135c4fcd104f", "disabled": false, "gated": false, "likes": 1, "downloads": 682, "createdAt": "2022-04-17T17:48:10.000Z"}, {"id": "taln-ls2n/taln-archives", "sha": "986fd2f2865cc142a9177e27e11b5585bd0c885a", "lastModified": "2022-09-23T07:58:07.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:multilingual", "size_categories:1K<n<10K", "language:fr", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "taln-ls2n", "description": "TALN Archives benchmark dataset for keyphrase extraction an generation.", "citation": "@inproceedings{boudin-2013-taln,\n    title = \"{TALN} Archives : a digital archive of {F}rench research articles in Natural Language Processing ({TALN} Archives : une archive num{\\'e}rique francophone des articles de recherche en Traitement Automatique de la Langue) [in {F}rench]\",\n    author = \"Boudin, Florian\",\n    booktitle = \"Proceedings of TALN 2013 (Volume 2: Short Papers)\",\n    month = jun,\n    year = \"2013\",\n    address = \"Les Sables d{'}Olonne, France\",\n    publisher = \"ATALA\",\n    url = \"https://aclanthology.org/F13-2001\",\n    pages = \"507--514\",\n}", "cardData": null, "siblings": [], "_id": "625ebcfd0f1d3ed7c8cf2bc6", "disabled": false, "gated": false, "likes": 3, "downloads": 13, "createdAt": "2022-04-19T13:45:33.000Z"}, {"id": "NbAiLab/NST", "sha": "81dd00f3ce6d26dd7b103af91ef0013a535caacd", "lastModified": "2022-08-12T14:09:29.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "NbAiLab", "description": "This database was created by Nordic Language Technology for the development of automatic speech recognition and dictation in Norwegian. In this version, the organization of the data have been altered to improve the usefulness of the database.\n\nThe acoustic databases described below were developed by the firm Nordisk spr\u00e5kteknologi holding AS (NST), which went bankrupt in 2003. In 2006, a consortium consisting of the University of Oslo, the University of Bergen, the Norwegian University of Science and Technology, the Norwegian Language Council and IBM bought the bankruptcy estate of NST, in order to ensure that the language resources developed by NST were preserved. In 2009, the Norwegian Ministry of Culture charged the National Library of Norway with the task of creating a Norwegian language bank, which they initiated in 2010. The resources from NST were transferred to the National Library in May 2011, and are now made available in Spr\u00e5kbanken, for the time being without any further modification. Spr\u00e5kbanken is open for feedback from users about how the resources can be improved, and we are also interested in improved versions of the databases that users wish to share with other users. Please send response and feedback to sprakbanken@nb.no.", "citation": "@inproceedings{,\n  title={},\n  author={},\n  booktitle={},\n  year={2022},\n  url={https://arxiv.org/abs/}\n}", "cardData": null, "siblings": [], "_id": "625ff760e3dd8b49f35e9ee5", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-04-20T12:06:56.000Z"}, {"id": "Yaxin/SemEval2016Task5Raw", "sha": "a4c705e2d97d1bbc7ed9feeedd1691ccb9cc20b0", "lastModified": "2022-08-15T08:19:35.000Z", "tags": ["region:us"], "private": false, "author": "Yaxin", "description": "A collection of SemEval2016 specifically designed to aid research in multilingual Aspect Based Sentiment Analysis.", "citation": "@inproceedings{pontiki2016semeval,\n  title={Semeval-2016 task 5: Aspect based sentiment analysis},\n  author={Pontiki, Maria and Galanis, Dimitrios and Papageorgiou, Haris and Androutsopoulos, Ion and Manandhar, Suresh and Al-Smadi, Mohammad and Al-Ayyoub, Mahmoud and Zhao, Yanyan and Qin, Bing and De Clercq, Orph{\\'e}e and others},\n  booktitle={International workshop on semantic evaluation},\n  pages={19--30},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "62601b2a904d346f75578f90", "disabled": false, "gated": false, "likes": 2, "downloads": 64, "createdAt": "2022-04-20T14:39:38.000Z"}, {"id": "mweiss/fashion_mnist_corrupted", "sha": "74ddfcfd50ea96a8ebc1456bf5d8e63eb840a084", "lastModified": "2023-03-19T11:45:31.000Z", "tags": ["task_categories:image-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|fashion_mnist", "language:en", "license:mit", "arxiv:1906.02337", "region:us"], "private": false, "author": "mweiss", "description": "Fashion-MNIST is dataset of fashion images, indended as a drop-in replacement for the MNIST dataset.\nThis dataset (Fashion-Mnist-Corrupted) provides out-of-distribution data for the Fashion-Mnist\ndataset. Fashion-Mnist-Corrupted is based on a similar project for MNIST, called MNIST-C, by Mu et. al.", "citation": "@inproceedings{Weiss2022SimpleTechniques,\n  title={Simple Techniques Work Surprisingly Well for Neural Network Test Prioritization and Active Learning},\n  author={Weiss, Michael and Tonella, Paolo},\n  booktitle={Proceedings of the 31th ACM SIGSOFT International Symposium on Software Testing and Analysis},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6261412a0568e418d6903c97", "disabled": false, "gated": false, "likes": 3, "downloads": 154, "createdAt": "2022-04-21T11:34:02.000Z"}, {"id": "visual_genome", "sha": "65bc9e7e7353fff750326c9523e384701934e530", "lastModified": "2023-06-29T15:23:59.000Z", "tags": ["task_categories:image-to-text", "task_categories:object-detection", "task_categories:visual-question-answering", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": null, "description": "Visual Genome enable to model objects and relationships between objects.\nThey collect dense annotations of objects, attributes, and relationships within each image.\nSpecifically, the dataset contains over 108K images where each image has an average of 35 objects, 26 attributes, and 21 pairwise relationships between objects.", "citation": "@article{Krishna2016VisualGC,\n  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},\n  author={Ranjay Krishna and Yuke Zhu and Oliver Groth and Justin Johnson and Kenji Hata and Joshua Kravitz and Stephanie Chen and Yannis Kalantidis and Li-Jia Li and David A. Shamma and Michael S. Bernstein and Li Fei-Fei},\n  journal={International Journal of Computer Vision},\n  year={2017},\n  volume={123},\n  pages={32-73},\n  url={https://doi.org/10.1007/s11263-016-0981-7},\n  doi={10.1007/s11263-016-0981-7}\n}", "cardData": null, "siblings": [], "_id": "626157816c57f7447804e945", "disabled": false, "gated": false, "likes": 35, "downloads": 787, "paperswithcode_id": "visual-genome", "createdAt": "2022-04-21T13:09:21.000Z"}, {"id": "Yaxin/SemEval2014Task4Raw", "sha": "4b2611a5fcaf8b94553c9d697e95a7d62bcd5557", "lastModified": "2022-08-15T08:20:00.000Z", "tags": ["region:us"], "private": false, "author": "Yaxin", "description": "A collection of SemEval2014 specifically designed to aid research in Aspect Based Sentiment Analysis.", "citation": "@article{2014SemEval,\n  title={SemEval-2014 Task 4: Aspect Based Sentiment Analysis},\n  author={ Pontiki, M.  and D Galanis and  Pavlopoulos, J.  and  Papageorgiou, H.  and  Manandhar, S. },\n  journal={Proceedings of International Workshop on Semantic Evaluation at},\n  year={2014},\n}", "cardData": null, "siblings": [], "_id": "62615d0baee4bea0213fdf30", "disabled": false, "gated": false, "likes": 7, "downloads": 35, "createdAt": "2022-04-21T13:32:59.000Z"}, {"id": "Yaxin/SemEval2015Task12Raw", "sha": "973dcb33cd5488e97c59e74d82fcbf71382e5f35", "lastModified": "2022-08-14T16:01:41.000Z", "tags": ["region:us"], "private": false, "author": "Yaxin", "description": "A collection of SemEval2015 specifically designed to aid research in Aspect Based Sentiment Analysis.", "citation": "@inproceedings{pontiki2015semeval,\n  title={Semeval-2015 task 12: Aspect based sentiment analysis},\n  author={Pontiki, Maria and Galanis, Dimitrios and Papageorgiou, Harris and Manandhar, Suresh and Androutsopoulos, Ion},\n  booktitle={Proceedings of the 9th international workshop on semantic evaluation (SemEval 2015)},\n  pages={486--495},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "6261644f6c57f744780535c8", "disabled": false, "gated": false, "likes": 2, "downloads": 14, "createdAt": "2022-04-21T14:03:59.000Z"}, {"id": "aharley/rvl_cdip", "sha": "f4c8f95b2143cc3d276df440d57f66e9e4ab1346", "lastModified": "2023-05-02T09:06:16.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|iit_cdip", "language:en", "license:other", "arxiv:1502.07058", "region:us"], "private": false, "author": "aharley", "description": "The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images.", "citation": "@inproceedings{harley2015icdar,\n    title = {Evaluation of Deep Convolutional Nets for Document Image Classification and Retrieval},\n    author = {Adam W Harley and Alex Ufkes and Konstantinos G Derpanis},\n    booktitle = {International Conference on Document Analysis and Recognition ({ICDAR})}},\n    year = {2015}\n}", "cardData": null, "siblings": [], "_id": "6261684d6dae705b25672d0d", "disabled": false, "gated": false, "likes": 30, "downloads": 1112, "paperswithcode_id": "rvl-cdip", "createdAt": "2022-04-21T14:21:01.000Z"}, {"id": "taln-ls2n/termith-eval", "sha": "2dceb8142327bf9eac3ff8927e2f39533a4afc8e", "lastModified": "2022-09-23T07:49:04.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:multilingual", "size_categories:n<1K", "language:fr", "license:cc-by-4.0", "region:us"], "private": false, "author": "taln-ls2n", "description": "TermITH-Eval benchmark dataset for keyphrase extraction an generation.", "citation": "@inproceedings{bougouin-etal-2016-termith,\n    title = \"{T}erm{ITH}-Eval: a {F}rench Standard-Based Resource for Keyphrase Extraction Evaluation\",\n    author = \"Bougouin, Adrien  and\n      Barreaux, Sabine  and\n      Romary, Laurent  and\n      Boudin, Florian  and\n      Daille, B{\\'e}atrice\",\n    booktitle = \"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)\",\n    month = may,\n    year = \"2016\",\n    address = \"Portoro{\\v{z}}, Slovenia\",\n    publisher = \"European Language Resources Association (ELRA)\",\n    url = \"https://aclanthology.org/L16-1304\",\n    pages = \"1924--1927\",\n    abstract = \"Keyphrase extraction is the task of finding phrases that represent the important content of a document. The main aim of keyphrase extraction is to propose textual units that represent the most important topics developed in a document. The output keyphrases of automatic keyphrase extraction methods for test documents are typically evaluated by comparing them to manually assigned reference keyphrases. Each output keyphrase is considered correct if it matches one of the reference keyphrases. However, the choice of the appropriate textual unit (keyphrase) for a topic is sometimes subjective and evaluating by exact matching underestimates the performance. This paper presents a dataset of evaluation scores assigned to automatically extracted keyphrases by human evaluators. Along with the reference keyphrases, the manual evaluations can be used to validate new evaluation measures. Indeed, an evaluation measure that is highly correlated to the manual evaluation is appropriate for the evaluation of automatic keyphrase extraction methods.\",\n}", "cardData": null, "siblings": [], "_id": "626270c3f66aed28cef1f91f", "disabled": false, "gated": false, "likes": 1, "downloads": 27, "createdAt": "2022-04-22T09:09:23.000Z"}, {"id": "cfilt/HiNER-collapsed", "sha": "3671c49f3c072e6ec8047f15926db10e02de487c", "lastModified": "2023-03-07T16:32:27.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:hi", "license:cc-by-sa-4.0", "arxiv:2204.13743", "region:us"], "private": false, "author": "cfilt", "description": "This is the repository for HiNER - a large Hindi Named Entity Recognition dataset.", "citation": "XX", "cardData": null, "siblings": [], "_id": "626288a302cd5952e013fcbe", "disabled": false, "gated": false, "likes": 0, "downloads": 61, "paperswithcode_id": "hiner-collapsed-1", "createdAt": "2022-04-22T10:51:15.000Z"}, {"id": "taln-ls2n/semeval-2010-pre", "sha": "c98da16de9bf6c8c09143b61be6079f85bfd1373", "lastModified": "2022-09-23T07:37:43.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:n<1K", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "taln-ls2n", "description": "Preprocessed SemEval-2010 Benchmark dataset for Keyphrase Generation.", "citation": "@inproceedings{boudin-etal-2016-document,\n    title = \"How Document Pre-processing affects Keyphrase Extraction Performance\",\n    author = \"Boudin, Florian  and\n      Mougard, Hugo  and\n      Cram, Damien\",\n    booktitle = \"Proceedings of the 2nd Workshop on Noisy User-generated Text ({WNUT})\",\n    month = dec,\n    year = \"2016\",\n    address = \"Osaka, Japan\",\n    publisher = \"The COLING 2016 Organizing Committee\",\n    url = \"https://aclanthology.org/W16-3917\",\n    pages = \"121--128\",\n    abstract = \"The SemEval-2010 benchmark dataset has brought renewed attention to the task of automatic keyphrase extraction. This dataset is made up of scientific articles that were automatically converted from PDF format to plain text and thus require careful preprocessing so that irrevelant spans of text do not negatively affect keyphrase extraction performance. In previous work, a wide range of document preprocessing techniques were described but their impact on the overall performance of keyphrase extraction models is still unexplored. Here, we re-assess the performance of several keyphrase extraction models and measure their robustness against increasingly sophisticated levels of document preprocessing.\",\n}", "cardData": null, "siblings": [], "_id": "62629b4e94ee6a5a43385178", "disabled": false, "gated": false, "likes": 1, "downloads": 38, "createdAt": "2022-04-22T12:10:54.000Z"}, {"id": "qanastek/MASSIVE", "sha": "44fe0b34f20ba09aa287148447873c1f3992e265", "lastModified": "2022-12-23T21:28:08.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:af", "language:am", "language:ar", "language:az", "language:bn", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:es", "language:fa", "language:fi", "language:fr", "language:he", "language:hi", "language:hu", "language:hy", "language:id", "language:is", "language:it", "language:ja", "language:jv", "language:ka", "language:km", "language:kn", "language:ko", "language:lv", "language:ml", "language:mn", "language:ms", "language:my", "language:nb", "language:nl", "language:pl", "language:pt", "language:ro", "language:ru", "language:sl", "language:sq", "language:sv", "language:sw", "language:ta", "language:te", "language:th", "language:tl", "language:tr", "language:ur", "language:vi", "language:zh", "arxiv:2204.08582", "region:us"], "private": false, "author": "qanastek", "description": "MASSIVE is a parallel dataset of > 1M utterances across 51 languages with annotations\nfor the Natural Language Understanding tasks of intent prediction and slot annotation.\nUtterances span 60 intents and include 55 slot types. MASSIVE was created by localizing\nthe SLURP dataset, composed of general Intelligent Voice Assistant single-shot interactions.", "citation": "@misc{fitzgerald2022massive,\n      title={MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages}, \n      author={Jack FitzGerald and Christopher Hench and Charith Peris and Scott Mackie and Kay Rottmann and Ana Sanchez and Aaron Nash and Liam Urbach and Vishesh Kakarala and Richa Singh and Swetha Ranganath and Laurie Crist and Misha Britan and Wouter Leeuwis and Gokhan Tur and Prem Natarajan},\n      year={2022},\n      eprint={2204.08582},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@inproceedings{bastianelli-etal-2020-slurp,\n    title = \"{SLURP}: A Spoken Language Understanding Resource Package\",\n    author = \"Bastianelli, Emanuele  and\n      Vanzo, Andrea  and\n      Swietojanski, Pawel  and\n      Rieser, Verena\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.emnlp-main.588\",\n    doi = \"10.18653/v1/2020.emnlp-main.588\",\n    pages = \"7252--7262\",\n    abstract = \"Spoken Language Understanding infers semantic meaning directly from audio data, and thus promises to reduce error propagation and misunderstandings in end-user applications. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following: (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets; (2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at https://github.com/pswietojanski/slurp.\"\n}", "cardData": null, "siblings": [], "_id": "626427ed247eba6089332e56", "disabled": false, "gated": false, "likes": 16, "downloads": 1127, "createdAt": "2022-04-23T16:23:09.000Z"}, {"id": "McGill-NLP/FaithDial", "sha": "7a414e80725eac766f2602676dc8b39f80b061e4", "lastModified": "2023-02-05T04:09:45.000Z", "tags": ["task_categories:conversational", "task_categories:text-generation", "task_ids:dialogue-modeling", "annotations_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100k", "language:en", "license:mit", "faithful-dialogue-modeling", "trustworthy-dialogue-modeling", "arxiv:2204.10757", "region:us"], "private": false, "author": "McGill-NLP", "description": "FaithDial is a new benchmark for hallucination-free dialogues, created by manually editing hallucinated and uncooperative responses in Wizard of Wikipedia.", "citation": "@article{dziri2022faithdial,\n  title={FaithDial: A Faithful Benchmark for Information-Seeking Dialogue},\n  author={Dziri, Nouha and Kamalloo, Ehsan and Milton, Sivan and Zaiane, Osmar and Yu, Mo and Ponti, Edoardo and Reddy, Siva},\n  journal={arXiv preprint, arXiv:2204.10757},\n  year={2022},\n  url={https://arxiv.org/abs/2204.10757}\n}", "cardData": null, "siblings": [], "_id": "6265d8fc93e0b04d757582fb", "disabled": false, "gated": false, "likes": 12, "downloads": 929, "createdAt": "2022-04-24T23:10:52.000Z"}, {"id": "cfilt/HiNER-original", "sha": "bbafadc05d7fdc9c668653a5e81bb034a99af3d9", "lastModified": "2023-03-07T16:42:05.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:hi", "license:cc-by-sa-4.0", "arxiv:2204.13743", "region:us"], "private": false, "author": "cfilt", "description": "This is the dataset repository for HiNER Dataset accepted to be published at LREC 2022.\nThe dataset can help build sequence labelling models for the task Named Entity Recognitin for the Hindi language.", "citation": "", "cardData": null, "siblings": [], "_id": "6266a847fcf21ddcb0266c6e", "disabled": false, "gated": false, "likes": 2, "downloads": 266, "paperswithcode_id": "hiner-original-1", "createdAt": "2022-04-25T13:55:19.000Z"}, {"id": "BigScienceBiasEval/crows_pairs_multilingual", "sha": "ac47d0f12d6905b94389e937e8f24fae21b9c66c", "lastModified": "2022-04-26T16:26:28.000Z", "tags": ["license:cc-by-sa-4.0", "arxiv:2010.00133", "region:us"], "private": false, "author": "BigScienceBiasEval", "description": "This is a revised version of CrowS-Pairs that measures stereotypes in language modelling in both English and French.", "citation": "@inproceedings{neveol2022french,\n  title={French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English},\n  author={N{\\'e}v{\\'e}ol, Aur{\\'e}lie and Dupont, Yoann and Bezan{\\c{c}}on, Julien and Fort, Kar{\\\"e}n},\n  booktitle={ACL 2022-60th Annual Meeting of the Association for Computational Linguistics},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6267a40b07a1d534972685a4", "disabled": false, "gated": false, "likes": 2, "downloads": 7171, "createdAt": "2022-04-26T07:49:31.000Z"}, {"id": "khalidalt/HuffPost", "sha": "01020533529fc1cda0af7d99231eb96e7837f883", "lastModified": "2023-05-19T18:35:08.000Z", "tags": ["license:cc0-1.0", "region:us"], "private": false, "author": "khalidalt", "description": "A dataset of approximately 200K news headlines from the year 2012 to 2018 collected from HuffPost.", "citation": "@book{book,\n  author = {Misra, Rishabh and Grover, Jigyasa},\n  year = {2021},\n  month = {01},\n  pages = {},\n  title = {Sculpting Data for ML: The first act of Machine Learning},\n  isbn = {978-0-578-83125-1}\n}\n\n@dataset{dataset,\n  author = {Misra, Rishabh},\n  year = {2018},\n  month = {06},\n  pages = {},\n  title = {News Category Dataset},\n  doi = {10.13140/RG.2.2.20331.18729}\n}", "cardData": null, "siblings": [], "_id": "6267bc491f415823f63b6127", "disabled": false, "gated": false, "likes": 0, "downloads": 157, "createdAt": "2022-04-26T09:32:57.000Z"}, {"id": "SocialGrep/the-reddit-nft-dataset", "sha": "5fc63ea7788cd5b4edb6aeba801cdc7083cf07e9", "lastModified": "2022-07-01T17:52:49.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "A comprehensive dataset of Reddit's NFT discussion.", "citation": null, "cardData": null, "siblings": [], "_id": "62684d7d87d7f9040e0523d5", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2022-04-26T19:52:29.000Z"}, {"id": "AmazonScience/massive", "sha": "ff6bd8e4b27c3543e4f8fe2108f32bb95a6f8740", "lastModified": "2022-11-16T15:44:51.000Z", "tags": ["task_categories:text-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:af-ZA", "multilinguality:am-ET", "multilinguality:ar-SA", "multilinguality:az-AZ", "multilinguality:bn-BD", "multilinguality:ca-ES", "multilinguality:cy-GB", "multilinguality:da-DK", "multilinguality:de-DE", "multilinguality:el-GR", "multilinguality:en-US", "multilinguality:es-ES", "multilinguality:fa-IR", "multilinguality:fi-FI", "multilinguality:fr-FR", "multilinguality:he-IL", "multilinguality:hi-IN", "multilinguality:hu-HU", "multilinguality:hy-AM", "multilinguality:id-ID", "multilinguality:is-IS", "multilinguality:it-IT", "multilinguality:ja-JP", "multilinguality:jv-ID", "multilinguality:ka-GE", "multilinguality:km-KH", "multilinguality:kn-IN", "multilinguality:ko-KR", "multilinguality:lv-LV", "multilinguality:ml-IN", "multilinguality:mn-MN", "multilinguality:ms-MY", "multilinguality:my-MM", "multilinguality:nb-NO", "multilinguality:nl-NL", "multilinguality:pl-PL", "multilinguality:pt-PT", "multilinguality:ro-RO", "multilinguality:ru-RU", "multilinguality:sl-SL", "multilinguality:sq-AL", "multilinguality:sv-SE", "multilinguality:sw-KE", "multilinguality:ta-IN", "multilinguality:te-IN", "multilinguality:th-TH", "multilinguality:tl-PH", "multilinguality:tr-TR", "multilinguality:ur-PK", "multilinguality:vi-VN", "multilinguality:zh-CN", "multilinguality:zh-TW", "size_categories:100K<n<1M", "source_datasets:original", "license:cc-by-4.0", "natural-language-understanding", "arxiv:2204.08582", "region:us"], "private": false, "author": "AmazonScience", "description": "        MASSIVE is a parallel dataset of > 1M utterances across 51 languages with annotations\n        for the Natural Language Understanding tasks of intent prediction and slot annotation.\n        Utterances span 60 intents and include 55 slot types. MASSIVE was created by localizing\n        the SLURP dataset, composed of general Intelligent Voice Assistant single-shot interactions.", "citation": "        @misc{fitzgerald2022massive,\n              title={MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages},\n              author={Jack FitzGerald and Christopher Hench and Charith Peris and Scott Mackie and Kay Rottmann and Ana Sanchez and Aaron Nash and Liam Urbach and Vishesh Kakarala and Richa Singh and Swetha Ranganath and Laurie Crist and Misha Britan and Wouter Leeuwis and Gokhan Tur and Prem Natarajan},\n              year={2022},\n              eprint={2204.08582},\n              archivePrefix={arXiv},\n              primaryClass={cs.CL}\n        }\n                @inproceedings{bastianelli-etal-2020-slurp,\n            title = \"{SLURP}: A Spoken Language Understanding Resource Package\",\n            author = \"Bastianelli, Emanuele  and\n              Vanzo, Andrea  and\n              Swietojanski, Pawel  and\n              Rieser, Verena\",\n            booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n            month = nov,\n            year = \"2020\",\n            address = \"Online\",\n            publisher = \"Association for Computational Linguistics\",\n            url = \"https://aclanthology.org/2020.emnlp-main.588\",\n            doi = \"10.18653/v1/2020.emnlp-main.588\",\n            pages = \"7252--7262\",\n            abstract = \"Spoken Language Understanding infers semantic meaning directly from audio data, and thus promises to reduce error propagation and misunderstandings in end-user applications. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following: (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets; (2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at https://github.com/pswietojanski/slurp.\"\n        }", "cardData": null, "siblings": [], "_id": "6269ac2ea6a7bba9e46c3aa6", "disabled": false, "gated": false, "likes": 42, "downloads": 9770, "paperswithcode_id": "massive", "createdAt": "2022-04-27T20:48:46.000Z"}, {"id": "strombergnlp/broad_twitter_corpus", "sha": "d766cb8a7497d0d507d81f5f681a8d58deedf495", "lastModified": "2022-07-01T15:46:36.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "strombergnlp", "description": "This is the Broad Twitter corpus, a dataset of tweets collected over stratified times, places and social uses. \nThe goal is to represent a broad range of activities, giving a dataset more representative of the language used \nin this hardest of social media formats to process. Further, the BTC is annotated for named entities.\n\nFor more details see [https://aclanthology.org/C16-1111/](https://aclanthology.org/C16-1111/)", "citation": "@inproceedings{derczynski2016broad,\n  title={Broad twitter corpus: A diverse named entity recognition resource},\n  author={Derczynski, Leon and Bontcheva, Kalina and Roberts, Ian},\n  booktitle={Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers},\n  pages={1169--1179},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "626a65314909b521e1f55086", "disabled": false, "gated": false, "likes": 4, "downloads": 102, "paperswithcode_id": "broad-twitter-corpus", "createdAt": "2022-04-28T09:58:09.000Z"}, {"id": "strombergnlp/ipm_nel", "sha": "cc150b1a28983f4796ab486f6e1ef1d1047e523a", "lastModified": "2022-10-25T21:41:26.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:en", "license:cc-by-4.0", "named-entity-linking", "region:us"], "private": false, "author": "strombergnlp", "description": "This data is for the task of named entity recognition and linking/disambiguation over tweets. It comprises\nthe addition of an entity URI layer on top of an NER-annotated tweet dataset. The task is to detect entities\nand then provide a correct link to them in DBpedia, thus disambiguating otherwise ambiguous entity surface\nforms; for example, this means linking \"Paris\" to the correct instance of a city named that (e.g. Paris, \nFrance vs. Paris, Texas).\n\nThe data concentrates on ten types of named entities: company, facility, geographic location, movie, musical\nartist, person, product, sports team, TV show, and other.\n\nThe file is tab separated, in CoNLL format, with line breaks between tweets.\nData preserves the tokenisation used in the Ritter datasets.\nPoS labels are not present for all tweets, but where they could be found in the Ritter\ndata, they're given. In cases where a URI could not be agreed, or was not present in\nDBpedia, there is a NIL. See the paper for a full description of the methodology.\n\nFor more details see http://www.derczynski.com/papers/ner_single.pdf or https://www.sciencedirect.com/science/article/abs/pii/S0306457314001034", "citation": "@article{derczynski2015analysis,\n  title={Analysis of named entity recognition and linking for tweets},\n  author={Derczynski, Leon and Maynard, Diana and Rizzo, Giuseppe and Van Erp, Marieke and Gorrell, Genevieve and Troncy, Rapha{\\\"e}l and Petrak, Johann and Bontcheva, Kalina},\n  journal={Information Processing \\& Management},\n  volume={51},\n  number={2},\n  pages={32--49},\n  year={2015},\n  publisher={Elsevier}\n}", "cardData": null, "siblings": [], "_id": "626a6712adf559c88de9772d", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "paperswithcode_id": "ipm-nel", "createdAt": "2022-04-28T10:06:10.000Z"}, {"id": "strombergnlp/twitter_pos_vcb", "sha": "12ff587afc996106440872be6b3656218fad0e82", "lastModified": "2022-10-25T21:42:56.000Z", "tags": ["task_categories:token-classification", "task_ids:part-of-speech", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "strombergnlp", "description": "Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis data is the vote-constrained bootstrapped data generate to support state-of-the-art results.\n\nThe data is about 1.5 million English tweets annotated for part-of-speech using Ritter's extension of the PTB tagset.\nThe tweets are from 2012 and 2013, tokenized using the GATE tokenizer and tagged\njointly using the CMU ARK tagger and Ritter's T-POS tagger. Only when both these taggers' outputs\nare completely compatible over a whole tweet, is that tweet added to the dataset.\n\nThis data is recommend for use a training data **only**, and not evaluation data.\n\nFor more details see https://gate.ac.uk/wiki/twitter-postagger.html and https://aclanthology.org/R13-1026.pdf", "citation": "@inproceedings{derczynski2013twitter,\n  title={Twitter part-of-speech tagging for all: Overcoming sparse and noisy data},\n  author={Derczynski, Leon and Ritter, Alan and Clark, Sam and Bontcheva, Kalina},\n  booktitle={Proceedings of the international conference recent advances in natural language processing ranlp 2013},\n  pages={198--206},\n  year={2013}\n}", "cardData": null, "siblings": [], "_id": "626a6833adf559c88de981d5", "disabled": false, "gated": false, "likes": 2, "downloads": 11, "paperswithcode_id": "twitter-pos-vcb", "createdAt": "2022-04-28T10:10:59.000Z"}, {"id": "BigScienceBiasEval/bias-shades", "sha": "788a707f7a58202e1a9dbd012ff986c935d4d113", "lastModified": "2022-10-03T13:49:04.000Z", "tags": ["license:cc-by-sa-4.0", "region:us"], "private": false, "author": "BigScienceBiasEval", "description": "This is a preliminary version of the bias SHADES dataset for evaluating LMs for social biases.", "citation": "\"\"\"\n\n# TODO: Add description of the dataset here\n# You can copy an official description\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "626ac4d305fe1cb65721f4f2", "disabled": false, "gated": false, "likes": 1, "downloads": 25, "createdAt": "2022-04-28T16:46:11.000Z"}, {"id": "aps/dynahate", "sha": "1735d9b700c9096b95d0a5f1ec12e239779a3920", "lastModified": "2022-05-18T00:11:13.000Z", "tags": ["region:us"], "private": false, "author": "aps", "description": "We present a human-and-model-in-the-loop process for dynamically generating datasets and training better performing and more robust hate detection models. We provide a new dataset of ~40,000 entries, generated and labelled by trained annotators over four rounds of dynamic data creation. It includes ~15,000 challenging perturbations and each hateful entry has fine-grained labels for the type and target of hate. Hateful entries make up 54% of the dataset, which is substantially higher than comparable datasets. We show that model performance is substantially improved using this approach. Models trained on later rounds of data collection perform better on test sets and are harder for annotators to trick. They also perform better on HATECHECK, a suite of functional tests for online hate detection. See https://arxiv.org/abs/2012.15761 for more details.", "citation": "@inproceedings{vidgen2021learning,\n  title={Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection},\n  author={Vidgen, Bertie and Thrush, Tristan and Waseem, Zeerak and Kiela, Douwe},\n  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},\n  pages={1667--1682},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "626c338f974d6a67df71ee20", "disabled": false, "gated": false, "likes": 1, "downloads": 122, "createdAt": "2022-04-29T18:50:55.000Z"}, {"id": "Filippo/osdg_cd", "sha": "e8ae5ab634fd26487d0686488fd8abfb833ff283", "lastModified": "2023-10-08T09:57:13.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "Filippo", "description": "The OSDG Community Dataset (OSDG-CD) is a public dataset of thousands of text excerpts, which were validated by approximately 1,000 OSDG Community Platform (OSDG-CP) citizen scientists from over 110 countries, with respect to the Sustainable Development Goals (SDGs).", "citation": "@dataset{osdg_2023_8397907,\n  author       = {OSDG and\n                  UNDP IICPSD SDG AI Lab and\n                  PPMI},\n  title        = {OSDG Community Dataset (OSDG-CD)},\n  month        = oct,\n  year         = 2023,\n  note         = {{This CSV file uses UTF-8 character encoding. For\n                   easy access on MS Excel, open the file using Data\n                   \u2192 From Text/CSV.  Please split CSV data into\n                   different columns by using a TAB delimiter.}},\n  publisher    = {Zenodo},\n  version      = {2023.10},\n  doi          = {10.5281/zenodo.8397907},\n  url          = {https://doi.org/10.5281/zenodo.8397907}\n}", "cardData": null, "siblings": [], "_id": "626daffc41c3c9d3263b5138", "disabled": false, "gated": false, "likes": 1, "downloads": 33, "createdAt": "2022-04-30T21:54:04.000Z"}, {"id": "skg/toxigen-data", "sha": "fed332421fbf9afc326f2490ec5bb49ffec180f3", "lastModified": "2022-06-20T11:12:11.000Z", "tags": ["task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "arxiv:2203.09509", "region:us"], "private": false, "author": "skg", "description": "Toxigen is a large-scale dataset containing implicitly toxic and benign sentences mentioning 13 minority groups, and a tool to stress test a given off-the-shelf toxicity classifier. The dataset is generated using a large language model (GPT3). It is intended to be used for training classifiers that learn to detect subtle hate speech that includes no slurs or profanity.", "citation": "@inproceedings{hartvigsen2022toxigen,\n  title={ToxiGen: A Large-Scale Machine-Generated Dataset for Implicit and Adversarial Hate Speech Detection},\n  author={Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece},\n  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "626eabee7813dcaa243984c4", "disabled": false, "gated": "auto", "likes": 26, "downloads": 1724, "createdAt": "2022-05-01T15:49:02.000Z"}, {"id": "google/wit", "sha": "b52b6486b38d74ddaf95626b15e0f0c50fa5e959", "lastModified": "2022-07-04T10:47:07.000Z", "tags": ["task_categories:text-retrieval", "task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "source_datasets:extended|wikipedia", "language:af", "language:ar", "language:ast", "language:azb", "language:be", "language:bg", "language:bn", "language:br", "language:ca", "language:cs", "language:cy", "language:da", "language:de", "language:el", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:fy", "language:ga", "language:gl", "language:hr", "language:hu", "language:hy", "language:id", "language:it", "language:iw", "language:ja", "language:ka", "language:ko", "language:la", "language:lt", "language:lv", "language:mk", "language:ml", "language:ms", "language:nl", "language:nn", "language:no", "language:pl", "language:pt", "language:ro", "language:ru", "language:sk", "language:sl", "language:sr", "language:sv", "language:th", "language:tr", "language:uk", "language:ur", "language:vi", "language:vo", "language:zh", "license:cc-by-sa-3.0", "arxiv:2103.01913", "region:us"], "private": false, "author": "google", "description": "Wikipedia-based Image Text (WIT) Dataset is a large multimodal multilingual dataset.\nWIT is composed of a curated set of 37.6 million entity rich image-text examples with 11.5 million unique images across 108 Wikipedia languages.\nIts size enables WIT to be used as a pretraining dataset for multimodal machine learning models.", "citation": "@article{srinivasan2021wit,\n  title={WIT: Wikipedia-based Image Text Dataset for Multimodal Multilingual Machine Learning},\n  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},\n  journal={arXiv preprint arXiv:2103.01913},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "626fbef8533b7b85cfe59def", "disabled": false, "gated": false, "likes": 14, "downloads": 30, "paperswithcode_id": "wit", "createdAt": "2022-05-02T11:22:32.000Z"}, {"id": "imagenet-1k", "sha": "0c4d3acf04a7458f5a11341dbe01d390859c40cc", "lastModified": "2023-09-25T19:42:34.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:other", "arxiv:1409.0575", "arxiv:1912.07726", "arxiv:1811.12231", "arxiv:2109.13228", "region:us"], "private": false, "author": null, "description": "ILSVRC 2012, commonly known as 'ImageNet' is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a \"synonym set\" or \"synset\". There are more than 100,000 synsets in WordNet, majority of them are nouns (80,000+). ImageNet aims to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated. In its completion, ImageNet hopes to offer tens of millions of cleanly sorted images for most of the concepts in the WordNet hierarchy. ImageNet 2012 is the most commonly used subset of ImageNet. This dataset spans 1000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images", "citation": "@article{imagenet15russakovsky,\n    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},\n    Title = { {ImageNet Large Scale Visual Recognition Challenge} },\n    Year = {2015},\n    journal   = {International Journal of Computer Vision (IJCV)},\n    doi = {10.1007/s11263-015-0816-y},\n    volume={115},\n    number={3},\n    pages={211-252}\n}", "cardData": null, "siblings": [], "_id": "627007d3becab9e2dcf15a40", "disabled": false, "gated": "auto", "likes": 195, "downloads": 23205, "paperswithcode_id": "imagenet", "createdAt": "2022-05-02T16:33:23.000Z"}, {"id": "arbml/masader", "sha": "d2d59a4ccf942da4f70948219362271f14efc5c8", "lastModified": "2022-07-08T14:45:05.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "arbml", "description": "Masader is the largest public catalogue for Arabic NLP datasets, which consists of more than 200 datasets annotated with 25 attributes.", "citation": "@misc{alyafeai2021masader,\n      title={Masader: Metadata Sourcing for Arabic Text and Speech Data Resources}, \n      author={Zaid Alyafeai and Maraim Masoud and Mustafa Ghaleb and Maged S. Al-shaibani},\n      year={2021},\n      eprint={2110.06744},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n      }", "cardData": null, "siblings": [], "_id": "6270892679f1824b12233038", "disabled": false, "gated": false, "likes": 6, "downloads": 13, "createdAt": "2022-05-03T01:45:10.000Z"}, {"id": "orieg/elsevier-oa-cc-by", "sha": "77840f2f84038fdf4b608fff764b21b7ef18eb34", "lastModified": "2022-07-01T15:59:58.000Z", "tags": ["task_categories:fill-mask", "task_categories:summarization", "task_categories:text-classification", "task_ids:masked-language-modeling", "task_ids:news-articles-summarization", "task_ids:news-articles-headline-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2008.00774", "region:us"], "private": false, "author": "orieg", "description": "Elsevier OA CC-By is a corpus of 40k (40, 091) open access (OA) CC-BY articles\nfrom across Elsevier\u2019s journals and include the full text of the article, the metadata,\nthe bibliographic information for each reference, and author highlights.", "citation": "@article{Kershaw2020ElsevierOC,\n  title     = {Elsevier OA CC-By Corpus},\n  author    = {Daniel James Kershaw and R. Koeling},\n  journal   = {ArXiv},\n  year      = {2020},\n  volume    = {abs/2008.00774},\n  doi       = {https://doi.org/10.48550/arXiv.2008.00774},\n  url       = {https://elsevier.digitalcommonsdata.com/datasets/zm33cdndxs},\n  keywords  = {Science, Natural Language Processing, Machine Learning, Open Dataset},\n  abstract  = {We introduce the Elsevier OA CC-BY corpus. This is the first open\n               corpus of Scientific Research papers which has a representative sample\n               from across scientific disciplines. This corpus not only includes the\n               full text of the article, but also the metadata of the documents, \n               along with the bibliographic information for each reference.}\n}", "cardData": null, "siblings": [], "_id": "6271a90dab9243b5d40eaa20", "disabled": false, "gated": false, "likes": 8, "downloads": 11, "paperswithcode_id": "elsevier-oa-cc-by", "createdAt": "2022-05-03T22:13:33.000Z"}, {"id": "Saptarshi7/covid_qa_cleaned_CS", "sha": "dcc956a84f4f5209279e4b91916672dbd27289b1", "lastModified": "2023-10-31T20:58:52.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Saptarshi7", "description": "Cleaned version of COVID-QA containing fixes as mentioned in <paper yet to be published>.", "citation": null, "cardData": null, "siblings": [], "_id": "6272ce2165c359baa064d86c", "disabled": false, "gated": false, "likes": 0, "downloads": 155, "createdAt": "2022-05-04T19:04:01.000Z"}, {"id": "textvqa", "sha": "a014c2cdba456a2fbd44c788b3ea24a5f441e54a", "lastModified": "2022-11-18T22:07:01.000Z", "tags": ["task_categories:visual-question-answering", "task_ids:visual-question-answering", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1904.08920", "arxiv:2007.00398", "region:us"], "private": false, "author": null, "description": "TextVQA requires models to read and reason about text in images to answer questions about them.\nSpecifically, models need to incorporate a new modality of text present in the images and reason\nover it to answer TextVQA questions. TextVQA dataset contains 45,336 questions over 28,408 images\nfrom the OpenImages dataset.", "citation": "@inproceedings{singh2019towards,\n    title={Towards VQA Models That Can Read},\n    author={Singh, Amanpreet and Natarjan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},\n    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n    pages={8317-8326},\n    year={2019}\n}", "cardData": null, "siblings": [], "_id": "62737268c8d55dd434ba85a8", "disabled": false, "gated": false, "likes": 11, "downloads": 1212, "createdAt": "2022-05-05T06:44:56.000Z"}, {"id": "ett", "sha": "273b0eba2d7bd27b7cd1ad33bf9a7739ecfe1f19", "lastModified": "2022-11-18T22:07:07.000Z", "tags": ["task_categories:time-series-forecasting", "task_ids:univariate-time-series-forecasting", "task_ids:multivariate-time-series-forecasting", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "license:cc-by-4.0", "arxiv:2012.07436", "region:us"], "private": false, "author": null, "description": "The data of Electricity Transformers from two separated counties\nin China collected for two years at hourly and 15-min frequencies.\nEach data point consists of the target value \"oil temperature\" and\n6 power load features. The train/val/test is 12/4/4 months.", "citation": "@inproceedings{haoyietal-informer-2021,\n  author    = {Haoyi Zhou and\n               Shanghang Zhang and\n               Jieqi Peng and\n               Shuai Zhang and\n               Jianxin Li and\n               Hui Xiong and\n               Wancai Zhang},\n  title     = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},\n  booktitle = {The Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI} 2021, Virtual Conference},\n  volume    = {35},\n  number    = {12},\n  pages     = {11106--11115},\n  publisher = {{AAAI} Press},\n  year      = {2021},\n}", "cardData": null, "siblings": [], "_id": "6273bf39a512a506234032b2", "disabled": false, "gated": false, "likes": 3, "downloads": 48, "createdAt": "2022-05-05T12:12:41.000Z"}, {"id": "BK-V/arman", "sha": "f92d782173a8cbd51aa80eabe9fc1874d95d3a73", "lastModified": "2022-05-08T16:57:22.000Z", "tags": ["region:us"], "private": false, "author": "BK-V", "description": "ArmanPersoNERCorpus includes 250,015 tokens and 7,682 Persian sentences in total.The NER tags are in IOB format.", "citation": "@inproceedings{poostchi-etal-2016-personer,\n    title = \"{P}erso{NER}: {P}ersian Named-Entity Recognition\",\n    author = \"Poostchi, Hanieh  and\n      Zare Borzeshi, Ehsan  and\n      Abdous, Mohammad  and\n      Piccardi, Massimo\",\n    booktitle = \"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers\",\n    month = dec,\n    year = \"2016\",\n    address = \"Osaka, Japan\",\n    publisher = \"The COLING 2016 Organizing Committee\",\n    url = \"https://aclanthology.org/C16-1319\",\n    pages = \"3381--3389\",\n    abstract = \"Named-Entity Recognition (NER) is still a challenging task for languages with low digital resources. The main difficulties arise from the scarcity of annotated corpora and the consequent problematic training of an effective NER pipeline. To abridge this gap, in this paper we target the Persian language that is spoken by a population of over a hundred million people world-wide. We first present and provide ArmanPerosNERCorpus, the first manually-annotated Persian NER corpus. Then, we introduce PersoNER, an NER pipeline for Persian that leverages a word embedding and a sequential max-margin classifier. The experimental results show that the proposed approach is capable of achieving interesting MUC7 and CoNNL scores while outperforming two alternatives based on a CRF and a recurrent neural network.\",\n}", "cardData": null, "siblings": [], "_id": "6273c9810a0f8c32ea0c5bc3", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-05-05T12:56:33.000Z"}, {"id": "searle-j/kote", "sha": "66f0eefe4b675a5d5411c7aa08e2c97fc9a9b17f", "lastModified": "2022-10-20T19:16:24.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:kor", "license:mit", "region:us"], "private": false, "author": "searle-j", "description": "50k Korean online comments labeled for 44 emotion categories.", "citation": "@article{jeon2022user,\n  title={User Guide for KOTE: Korean Online Comments Emotions Dataset},\n  author={Jeon, Duyoung and Lee, Junho and Kim, Cheongtag},\n  journal={arXiv preprint arXiv:2205.05300},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6274b8385d12b3a734ae69a2", "disabled": false, "gated": false, "likes": 3, "downloads": 42, "createdAt": "2022-05-06T05:55:04.000Z"}, {"id": "medmcqa", "sha": "ceae7147ff9ce2dc56fd79968a34250fa4c8684f", "lastModified": "2023-01-25T15:04:10.000Z", "tags": ["task_categories:question-answering", "task_categories:multiple-choice", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": null, "description": "MedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.\nThe dataset contains questions about the following topics: Anesthesia, Anatomy, Biochemistry, Dental, ENT, Forensic Medicine (FM)\nObstetrics and Gynecology (O&G), Medicine, Microbiology, Ophthalmology, Orthopedics Pathology, Pediatrics, Pharmacology, Physiology,\nPsychiatry, Radiology Skin, Preventive & Social Medicine (PSM) and Surgery", "citation": "@InProceedings{pmlr-v174-pal22a,\n  title = \t {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},\n  author =       {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},\n  booktitle = \t {Proceedings of the Conference on Health, Inference, and Learning},\n  pages = \t {248--260},\n  year = \t {2022},\n  editor = \t {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},\n  volume = \t {174},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {07--08 Apr},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},\n  url = \t {https://proceedings.mlr.press/v174/pal22a.html},\n  abstract = \t {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects & topics. A detailed explanation of the solution, along with the above information, is provided in this study.}\n}", "cardData": null, "siblings": [], "_id": "6274dfacbe455dadd1060ffb", "disabled": false, "gated": false, "likes": 54, "downloads": 4521, "paperswithcode_id": "medmcqa", "createdAt": "2022-05-06T08:43:24.000Z"}, {"id": "taln-ls2n/kptimes", "sha": "36d51f10c05d1598552a0374b04d7b8e58efddbc", "lastModified": "2022-09-23T07:38:28.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "taln-ls2n", "description": "KPTimes benchmark dataset for keyphrase extraction an generation.", "citation": "@inproceedings{gallina-etal-2019-kptimes,\n    title = \"{KPT}imes: A Large-Scale Dataset for Keyphrase Generation on News Documents\",\n    author = \"Gallina, Ygor  and\n      Boudin, Florian  and\n      Daille, Beatrice\",\n    booktitle = \"Proceedings of the 12th International Conference on Natural Language Generation\",\n    month = oct # \"{--}\" # nov,\n    year = \"2019\",\n    address = \"Tokyo, Japan\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W19-8617\",\n    doi = \"10.18653/v1/W19-8617\",\n    pages = \"130--135\",\n    abstract = \"Keyphrase generation is the task of predicting a set of lexical units that conveys the main content of a source text. Existing datasets for keyphrase generation are only readily available for the scholarly domain and include non-expert annotations. In this paper we present KPTimes, a large-scale dataset of news texts paired with editor-curated keyphrases. Exploring the dataset, we show how editors tag documents, and how their annotations differ from those found in existing datasets. We also train and evaluate state-of-the-art neural keyphrase generation models on KPTimes to gain insights on how well they perform on the news domain. The dataset is available online at https:// github.com/ygorg/KPTimes.\",\n}", "cardData": null, "siblings": [], "_id": "6274ebb07e0996042580b821", "disabled": false, "gated": false, "likes": 1, "downloads": 13, "createdAt": "2022-05-06T09:34:40.000Z"}, {"id": "strombergnlp/twitter_pos", "sha": "e2fd67fea2d92b54b613fa1eb2af9023f172e91a", "lastModified": "2022-10-25T21:43:15.000Z", "tags": ["task_categories:token-classification", "task_ids:part-of-speech", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "strombergnlp", "description": "Part-of-speech information is basic NLP task. However, Twitter text\nis difficult to part-of-speech tag: it is noisy, with linguistic errors and idiosyncratic style.\nThis dataset contains two datasets for English PoS tagging for tweets:\n\n* Ritter, with train/dev/test\n* Foster, with dev/test\n\nSplits defined in the Derczynski paper, but the data is from Ritter and Foster.\n\nFor more details see:\n\n* https://gate.ac.uk/wiki/twitter-postagger.html\n* https://aclanthology.org/D11-1141.pdf\n* https://www.aaai.org/ocs/index.php/ws/aaaiw11/paper/download/3912/4191", "citation": "@inproceedings{ritter2011named,\n  title={Named entity recognition in tweets: an experimental study},\n  author={Ritter, Alan and Clark, Sam and Etzioni, Oren and others},\n  booktitle={Proceedings of the 2011 conference on empirical methods in natural language processing},\n  pages={1524--1534},\n  year={2011}\n}\n\n@inproceedings{foster2011hardtoparse,\n  title={\\# hardtoparse: POS Tagging and Parsing the Twitterverse},\n  author={Foster, Jennifer and Cetinoglu, Ozlem and Wagner, Joachim and Le Roux, Joseph and Hogan, Stephen and Nivre, Joakim and Hogan, Deirdre and Van Genabith, Josef},\n  booktitle={Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence},\n  year={2011}\n}\n\n@inproceedings{derczynski2013twitter,\n  title={Twitter part-of-speech tagging for all: Overcoming sparse and noisy data},\n  author={Derczynski, Leon and Ritter, Alan and Clark, Sam and Bontcheva, Kalina},\n  booktitle={Proceedings of the international conference recent advances in natural language processing ranlp 2013},\n  pages={198--206},\n  year={2013}\n}", "cardData": null, "siblings": [], "_id": "6275727df947741f94e67fec", "disabled": false, "gated": false, "likes": 2, "downloads": 12, "paperswithcode_id": "ritter-pos", "createdAt": "2022-05-06T19:09:49.000Z"}, {"id": "nateraw/imagenet-sketch", "sha": "ab6223087bf5d6f2e81fef71cb174750266305d1", "lastModified": "2022-05-08T05:41:33.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "nateraw", "description": "ImageNet-Sketch data set consists of 50000 images, 50 images for each of the 1000 ImageNet classes.\nWe construct the data set with Google Image queries \"sketch of __\", where __ is the standard class name.\nWe only search within the \"black and white\" color scheme. We initially query 100 images for every class,\nand then manually clean the pulled images by deleting the irrelevant images and images that are for similar\nbut different classes. For some classes, there are less than 50 images after manually cleaning, and then we\naugment the data set by flipping and rotating the images.", "citation": "@inproceedings{wang2019learning,\n        title={Learning Robust Global Representations by Penalizing Local Predictive Power},\n        author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},\n        booktitle={Advances in Neural Information Processing Systems},\n        pages={10506--10518},\n        year={2019}\n}", "cardData": null, "siblings": [], "_id": "627755e186cf863dc37239b8", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2022-05-08T05:32:17.000Z"}, {"id": "pile-of-law/eoir_privacy", "sha": "212b8789f3958e28a961b7147be3c52b83992918", "lastModified": "2022-07-07T08:44:32.000Z", "tags": ["task_categories:text-classification", "language_creators:found", "multilinguality:monolingual", "language:en", "license:cc-by-nc-sa-4.0", "arxiv:2207.00220", "region:us"], "private": false, "author": "pile-of-law", "description": "A living legal dataset.", "citation": "TODO", "cardData": null, "siblings": [], "_id": "6278447c4d1d478192085745", "disabled": false, "gated": false, "likes": 9, "downloads": 78, "createdAt": "2022-05-08T22:30:20.000Z"}, {"id": "strombergnlp/rustance", "sha": "a2a4aa7bb2f872f0164a04f198b1c875df065a8a", "lastModified": "2022-10-25T21:46:32.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:ru", "license:cc-by-4.0", "stance-detection", "arxiv:1809.01574", "region:us"], "private": false, "author": "strombergnlp", "description": "This is a stance prediction dataset in Russian. The dataset contains comments on news articles,\nand rows are a comment, the title of the news article it responds to, and the stance of the comment\ntowards the article.", "citation": "@inproceedings{lozhnikov2018stance,\n  title={Stance prediction for Russian: data and analysis},\n  author={Lozhnikov, Nikita and Derczynski, Leon and Mazzara, Manuel},\n  booktitle={International Conference in Software Engineering for Defence Applications},\n  pages={176--186},\n  year={2018},\n  organization={Springer}\n}", "cardData": null, "siblings": [], "_id": "6278d687bba7c62cbaaf68b2", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "paperswithcode_id": "rustance", "createdAt": "2022-05-09T08:53:27.000Z"}, {"id": "ccdv/WCEP-10", "sha": "f223cad3fce49e4490733772610a0cbdb7fbcb9d", "lastModified": "2022-10-25T10:55:52.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:en", "conditional-text-generation", "arxiv:2005.10070", "arxiv:2110.08499", "region:us"], "private": false, "author": "ccdv", "description": "WCEP10 dataset for summarization.\n From paper: \"A Large-Scale Multi-Document Summarization Dataset from the Wikipedia\n                Current Events Portal\" by D. Gholipour et al.\"\n From paper: \"PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document\n                Summarization\" by W. Xiao et al.\"", "citation": "    @article{DBLP:journals/corr/abs-2005-10070,\n    author    = {Demian Gholipour Ghalandari and\n                Chris Hokamp and\n                Nghia The Pham and\n                John Glover and\n                Georgiana Ifrim},\n    title     = {A Large-Scale Multi-Document Summarization Dataset from the Wikipedia\n                Current Events Portal},\n    journal   = {CoRR},\n    volume    = {abs/2005.10070},\n    year      = {2020},\n    url       = {https://arxiv.org/abs/2005.10070},\n    eprinttype = {arXiv},\n    eprint    = {2005.10070},\n    timestamp = {Fri, 22 May 2020 16:21:28 +0200},\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2005-10070.bib},\n    bibsource = {dblp computer science bibliography, https://dblp.org}\n    }\n\n\n    @article{DBLP:journals/corr/abs-2110-08499,\n    author    = {Wen Xiao and\n                Iz Beltagy and\n                Giuseppe Carenini and\n                Arman Cohan},\n    title     = {{PRIMER:} Pyramid-based Masked Sentence Pre-training for Multi-document\n                Summarization},\n    journal   = {CoRR},\n    volume    = {abs/2110.08499},\n    year      = {2021},\n    url       = {https://arxiv.org/abs/2110.08499},\n    eprinttype = {arXiv},\n    eprint    = {2110.08499},\n    timestamp = {Fri, 22 Oct 2021 13:33:09 +0200},\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2110-08499.bib},\n    bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "62792186541f3d2dfa7a6526", "disabled": false, "gated": false, "likes": 3, "downloads": 30, "createdAt": "2022-05-09T14:13:26.000Z"}, {"id": "HugoLaurencon/libri_light", "sha": "8f4803696352556aa3404c403ec6c882ccdc0c20", "lastModified": "2022-05-10T15:51:37.000Z", "tags": ["region:us"], "private": false, "author": "HugoLaurencon", "description": "Libri-light is a large dataset of 60K hours of unlabelled speech from audiobooks in English.\nIt is a benchmark for the training of automatic speech recognition (ASR) systems with limited or no supervision.", "citation": "@INPROCEEDINGS{librilight,\n  author={J. Kahn and M. Rivi\u00e8re and W. Zheng and E. Kharitonov and Q. Xu and P. E. Mazar\u00e9 and J. Karadayi and V. Liptchinsky and R. Collobert and C. Fuegen and T. Likhomanenko and G. Synnaeve and A. Joulin and A. Mohamed and E. Dupoux},\n  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, \n  title={Libri-Light: A Benchmark for ASR with Limited or No Supervision}, \n  year={2020},\n  pages={7669-7673},\n}", "cardData": null, "siblings": [], "_id": "627925c6541f3d2dfa7a80a0", "disabled": false, "gated": false, "likes": 2, "downloads": 51, "createdAt": "2022-05-09T14:31:34.000Z"}, {"id": "strombergnlp/offenseval_2020", "sha": "0594adab4ce7680af4dd0f8df7471d4acd6594c6", "lastModified": "2022-05-12T10:04:57.000Z", "tags": ["task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "arxiv:2006.07235", "arxiv:2004.02192", "arxiv:1908.04531", "arxiv:2004.14454", "arxiv:2003.07459", "region:us"], "private": false, "author": "strombergnlp", "description": "OffensEval 2020 features a multilingual dataset with five languages. The languages included in OffensEval 2020 are:\n\n* Arabic\n* Danish\n* English\n* Greek\n* Turkish\n\nThe annotation follows the hierarchical tagset proposed in the Offensive Language Identification Dataset (OLID) and used in OffensEval 2019. \nIn this taxonomy we break down offensive content into the following three sub-tasks taking the type and target of offensive content into account. \nThe following sub-tasks were organized:\n\n* Sub-task A - Offensive language identification;\n* Sub-task B - Automatic categorization of offense types;\n* Sub-task C - Offense target identification.\n\nThe English training data isn't included here (the text isn't available and needs rehydration of 9 million tweets; \nsee [https://zenodo.org/record/3950379#.XxZ-aFVKipp](https://zenodo.org/record/3950379#.XxZ-aFVKipp))", "citation": "@inproceedings{zampieri-etal-2020-semeval,\n    title = \"{S}em{E}val-2020 Task 12: Multilingual Offensive Language Identification in Social Media ({O}ffens{E}val 2020)\",\n    author = {Zampieri, Marcos  and\n      Nakov, Preslav  and\n      Rosenthal, Sara  and\n      Atanasova, Pepa  and\n      Karadzhov, Georgi  and\n      Mubarak, Hamdy  and\n      Derczynski, Leon  and\n      Pitenis, Zeses  and\n      Coltekin, Cagri,\n    booktitle = \"Proceedings of the Fourteenth Workshop on Semantic Evaluation\",\n    month = dec,\n    year = \"2020\",\n    address = \"Barcelona (online)\",\n    publisher = \"International Committee for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.semeval-1.188\",\n    doi = \"10.18653/v1/2020.semeval-1.188\",\n    pages = \"1425--1447\",\n}", "cardData": null, "siblings": [], "_id": "627a3cf7c7f48ed9dc4d3e51", "disabled": false, "gated": false, "likes": 1, "downloads": 66, "createdAt": "2022-05-10T10:22:47.000Z"}, {"id": "MilaNLProc/honest", "sha": "e10910c64b77382d127ec3d957b3b1cc2524d04d", "lastModified": "2022-09-28T15:45:09.000Z", "tags": ["task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "license:mit", "region:us"], "private": false, "author": "MilaNLProc", "description": "HONEST dataset comprises a set of templates for measuring hurtful sentence completions in language models. The templates are provided in six languages (English, Italian, French, Portuguese, Romanian, and Spanish) for binary gender and in English for LGBTQAI+ individuals. WARNING: This dataset contains content that are offensive and/or hateful in nature.", "citation": "    @inproceedings{nozza-etal-2021-honest,\n        title = {\"{HONEST}: Measuring Hurtful Sentence Completion in Language Models\"},\n        author = \"Nozza, Debora and Bianchi, Federico  and Hovy, Dirk\",\n        booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n        month = jun,\n        year = \"2021\",\n        address = \"Online\",\n        publisher = \"Association for Computational Linguistics\",\n        url = \"https://aclanthology.org/2021.naacl-main.191\",\n        doi = \"10.18653/v1/2021.naacl-main.191\",\n        pages = \"2398--2406\",\n    }\n\n    @inproceedings{nozza-etal-2022-measuring,\n        title = {Measuring Harmful Sentence Completion in Language Models for LGBTQIA+ Individuals},\n        author = \"Nozza, Debora and Bianchi, Federico and Lauscher, Anne and Hovy, Dirk\",\n        booktitle = \"Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion\",\n        publisher = \"Association for Computational Linguistics\",\n        year={2022}\n    }", "cardData": null, "siblings": [], "_id": "627a4347440059bc20797918", "disabled": false, "gated": false, "likes": 4, "downloads": 262, "paperswithcode_id": "honest-en", "createdAt": "2022-05-10T10:49:43.000Z"}, {"id": "facebook/voxpopuli", "sha": "719aaef8225945c0d80b277de6c79aa42ab053d5", "lastModified": "2022-10-14T13:43:12.000Z", "tags": ["task_categories:automatic-speech-recognition", "multilinguality:multilingual", "language:en", "language:de", "language:fr", "language:es", "language:pl", "language:it", "language:ro", "language:hu", "language:cs", "language:nl", "language:fi", "language:hr", "language:sk", "language:sl", "language:et", "language:lt", "license:cc0-1.0", "license:other", "arxiv:2101.00390", "region:us"], "private": false, "author": "facebook", "description": "A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.", "citation": "@inproceedings{wang-etal-2021-voxpopuli,\n    title = \"{V}ox{P}opuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, \n    Semi-Supervised Learning and Interpretation\",\n    author = \"Wang, Changhan  and\n      Riviere, Morgane  and\n      Lee, Ann  and\n      Wu, Anne  and\n      Talnikar, Chaitanya  and\n      Haziza, Daniel  and\n      Williamson, Mary  and\n      Pino, Juan  and\n      Dupoux, Emmanuel\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics \n    and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.80\",\n    doi = \"10.18653/v1/2021.acl-long.80\",\n    pages = \"993--1003\",\n}", "cardData": null, "siblings": [], "_id": "627a79e9c7f48ed9dc4eb531", "disabled": false, "gated": false, "likes": 33, "downloads": 3939, "createdAt": "2022-05-10T14:42:49.000Z"}, {"id": "strombergnlp/nordic_langid", "sha": "e254179d18ab0165fdb6dbef91178266222bee2a", "lastModified": "2022-10-25T21:42:02.000Z", "tags": ["task_categories:text-classification", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:da", "language:nn", "language:nb", "language:fo", "language:is", "language:sv", "license:cc-by-sa-3.0", "language-identification", "region:us"], "private": false, "author": "strombergnlp", "description": "Automatic language identification is a challenging problem. Discriminating\nbetween closely related languages is especially difficult. This paper presents\na machine learning approach for automatic language identification for the\nNordic languages, which often suffer miscategorisation by existing \nstate-of-the-art tools. Concretely we will focus on discrimination between six \nNordic languages: Danish, Swedish, Norwegian (Nynorsk), Norwegian (Bokm\u00e5l), \nFaroese and Icelandic.\n\nThis is the data for the tasks. Two variants are provided: 10K and 50K, with\nholding 10,000 and 50,000 examples for each language respectively.", "citation": "@inproceedings{haas-derczynski-2021-discriminating,\n    title = \"Discriminating Between Similar Nordic Languages\",\n    author = \"Haas, Ren{\\'e}  and\n      Derczynski, Leon\",\n    booktitle = \"Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects\",\n    month = apr,\n    year = \"2021\",\n    address = \"Kiyv, Ukraine\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.vardial-1.8\",\n    pages = \"67--75\",\n}", "cardData": null, "siblings": [], "_id": "627aa06788cfd9790fd80a71", "disabled": false, "gated": false, "likes": 3, "downloads": 101, "paperswithcode_id": "nordic-langid", "createdAt": "2022-05-10T17:27:03.000Z"}, {"id": "HuggingFaceM4/charades", "sha": "a9a9e7a8a2dc35bdb905b3df9d7a44cd60dfa2de", "lastModified": "2022-10-20T21:35:42.000Z", "tags": ["task_categories:other", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:other", "arxiv:1604.01753", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "Charades is dataset composed of 9848 videos of daily indoors activities collected through Amazon Mechanical Turk. 267 different users were presented with a sentence, that includes objects and actions from a fixed vocabulary, and they recorded a video acting out the sentence (like in a game of Charades). The dataset contains 66,500 temporal annotations for 157 action classes, 41,104 labels for 46 object classes, and 27,847 textual descriptions of the videos.", "citation": "@article{sigurdsson2016hollywood,\n    author = {Gunnar A. Sigurdsson and G{\\\"u}l Varol and Xiaolong Wang and Ivan Laptev and Ali Farhadi and Abhinav Gupta},\n    title = {Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},\n    journal = {ArXiv e-prints},\n    eprint = {1604.01753},\n    year = {2016},\n    url = {http://arxiv.org/abs/1604.01753},\n}", "cardData": null, "siblings": [], "_id": "627b60c38b6ecd7ece81b101", "disabled": false, "gated": false, "likes": 2, "downloads": 23, "paperswithcode_id": "charades", "createdAt": "2022-05-11T07:07:47.000Z"}, {"id": "strombergnlp/bornholmsk_parallel", "sha": "3bc5cfb4ec514264fe2db5615fac9016f7251552", "lastModified": "2022-07-01T15:45:35.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "license:cc-by-4.0", "region:us"], "private": false, "author": "strombergnlp", "description": "This dataset is parallel text for Bornholmsk and Danish. \n\nFor more details, see the paper [Bornholmsk Natural Language Processing: Resources and Tools](https://aclanthology.org/W19-6138/).", "citation": "@inproceedings{derczynski-kjeldsen-2019-bornholmsk,\n    title = \"Bornholmsk Natural Language Processing: Resources and Tools\",\n    author = \"Derczynski, Leon  and\n      Kjeldsen, Alex Speed\",\n    booktitle = \"Proceedings of the 22nd Nordic Conference on Computational Linguistics\",\n    month = sep # \"{--}\" # oct,\n    year = \"2019\",\n    address = \"Turku, Finland\",\n    publisher = {Link{\\\"o}ping University Electronic Press},\n    url = \"https://aclanthology.org/W19-6138\",\n    pages = \"338--344\",\n    abstract = {This paper introduces language processing resources and tools for Bornholmsk, a language spoken on the island of Bornholm, with roots in Danish and closely related to Scanian. This presents an overview of the language and available data, and the first NLP models for this living, minority Nordic language. Sammenfattnijng p{\\aa} borrijnholmst: D{\\ae}jnna artikkelijn introduserer naturspr{\\aa}gsresurser {\\aa} varktoi for borrijnholmst, ed spr{\\aa}g a d{\\ae}r snakkes p{\\aa} {\\\"o}n Borrijnholm me r{\\o}dder i danst {\\aa} i n{\\ae}r familia me sk{\\aa}nst. Artikkelijn gjer ed {\\^a}uersyn {\\^a}uer spr{\\aa}ged {\\aa} di datan som fijnnes, {\\aa} di fosste NLP mod{\\ae}llarna for d{\\ae}tta l{\\ae}wenes nordiska minnret{\\^a}lsspr{\\aa}ged.},\n}", "cardData": null, "siblings": [], "_id": "627b73f27b1c10c349ff720f", "disabled": false, "gated": false, "likes": 2, "downloads": 116, "paperswithcode_id": "bornholmsk-parallel", "createdAt": "2022-05-11T08:29:38.000Z"}, {"id": "lmqg/qg_subjqa", "sha": "4cf327a1f4262582f0760bac0786eb32fc4e88cd", "lastModified": "2022-12-02T18:56:32.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:subjqa", "language:en", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[SubjQA](https://github.com/megagonlabs/SubjQA) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "627b9afd1b02d7b5bf62175c", "disabled": false, "gated": false, "likes": 0, "downloads": 28, "createdAt": "2022-05-11T11:16:13.000Z"}, {"id": "MLRS/korpus_malti", "sha": "0d61e8e55c55e5397783a26e8ff3b7b4a9360bd6", "lastModified": "2022-08-30T08:59:09.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:mt", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "MLRS", "description": "General Corpora for the Maltese language.", "citation": "@inproceedings{BERTu,\n    title = \"Pre-training Data Quality and Quantity for a Low-Resource Language: New Corpus and {BERT} Models for {M}altese\",\n    author = \"Micallef, Kurt  and\n              Gatt, Albert  and\n              Tanti, Marc  and\n              van der Plas, Lonneke  and\n              Borg, Claudia\",\n    booktitle = \"Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing\",\n    month = jul,\n    year = \"2022\",\n    address = \"Hybrid\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.deeplo-1.10\",\n    doi = \"10.18653/v1/2022.deeplo-1.10\",\n    pages = \"90--101\",\n}", "cardData": null, "siblings": [], "_id": "627bb07054fc29f80ee82478", "disabled": false, "gated": false, "likes": 0, "downloads": 71, "createdAt": "2022-05-11T12:47:44.000Z"}, {"id": "ncats/EpiSet4NER-v2", "sha": "c2745ea380ea553b9d0d146d1e0869d29da6a73a", "lastModified": "2022-09-20T15:25:56.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "epidemiology", "rare disease", "named entity recognition", "NER", "NIH", "region:us"], "private": false, "author": "ncats", "description": "**REWRITE*\nEpiSet4NER-2 is a dataset generated from 620 rare disease abstracts labeled using statistical and rule-base methods. \nFor more details see *INSERT PAPER* and https://github.com/ncats/epi4GARD/tree/master/EpiExtract4GARD#epiextract4gard", "citation": "*REDO*\n@inproceedings{wang2019crossweigh,\n  title={CrossWeigh: Training Named Entity Tagger from Imperfect Annotations},\n  author={Wang, Zihan and Shang, Jingbo and Liu, Liyuan and Lu, Lihao and Liu, Jiacheng and Han, Jiawei},\n  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n  pages={5157--5166},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "627cc988a09edfe6223ab22f", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-05-12T08:47:04.000Z"}, {"id": "strombergnlp/rumoureval_2019", "sha": "c9c0c7279d591d2fa4d692501d85f4e46d4b0572", "lastModified": "2022-10-25T21:43:58.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "stance-detection", "arxiv:1809.06683", "region:us"], "private": false, "author": "strombergnlp", "description": "\nStance prediction task in English. The goal is to predict whether a given reply to a claim either supports, denies, questions, or simply comments on the claim. Ran as a SemEval task in 2019.", "citation": "@inproceedings{gorrell-etal-2019-semeval,\n    title = \"{S}em{E}val-2019 Task 7: {R}umour{E}val, Determining Rumour Veracity and Support for Rumours\",\n    author = \"Gorrell, Genevieve  and\n      Kochkina, Elena  and\n      Liakata, Maria  and\n      Aker, Ahmet  and\n      Zubiaga, Arkaitz  and\n      Bontcheva, Kalina  and\n      Derczynski, Leon\",\n    booktitle = \"Proceedings of the 13th International Workshop on Semantic Evaluation\",\n    month = jun,\n    year = \"2019\",\n    address = \"Minneapolis, Minnesota, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/S19-2147\",\n    doi = \"10.18653/v1/S19-2147\",\n    pages = \"845--854\",\n}", "cardData": null, "siblings": [], "_id": "627cd94063fd471b33b0932b", "disabled": false, "gated": false, "likes": 2, "downloads": 10, "createdAt": "2022-05-12T09:54:08.000Z"}, {"id": "HuggingFaceM4/webvid", "sha": "db53d86c7ec9dc0692fc868686bc4f2407be1ec6", "lastModified": "2022-05-13T21:44:02.000Z", "tags": ["region:us"], "private": false, "author": "HuggingFaceM4", "description": "WebVid is a large-scale dataset of video clips with textual descriptions sourced from the web. The videos are diverse and rich in their content.", "citation": "@InProceedings{Bain21,\n  author       = \"Max Bain and Arsha Nagrani and G{\\\"u}l Varol and Andrew Zisserman\",\n  title        = \"Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval\",\n  booktitle    = \"IEEE International Conference on Computer Vision\",\n  year         = \"2021\",\n}", "cardData": null, "siblings": [], "_id": "627d6c17cecd686d4cda9efa", "disabled": false, "gated": false, "likes": 8, "downloads": 986, "createdAt": "2022-05-12T20:20:39.000Z"}, {"id": "HuggingFaceM4/vatex", "sha": "97f73ff148a124edacbbfa92a84534736c23a613", "lastModified": "2022-05-13T21:27:03.000Z", "tags": ["region:us"], "private": false, "author": "HuggingFaceM4", "description": "VATEX is a large-scale multilingual video description dataset, which contains over 41,250 videos and 825,000 captions\nin both English and Chinese. VATEX is characterized by the following major unique properties.\nFirst, it contains both English and Chinese descriptions at scale, which can support many multilingual studies\nthat are constrained by monolingual datasets. Secondly, VATEX has a high number of clip-sentence pairs\nwith each video clip annotated with multiple unique sentences, and every caption is unique in\nthe whole corpus. Third, VATEX contains more comprehensive yet representative video content,\ncovering 600 human activities in total. Furthermore, both the English and Chinese corpora in\nVATEX are lexically richer and thus allow more natural and diverse caption generation.", "citation": "@InProceedings{Wang_2019_ICCV,\nauthor = {Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},\ntitle = {VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research},\nbooktitle = {The IEEE International Conference on Computer Vision (ICCV)},\nmonth = {October},\nyear = {2019}\n}", "cardData": null, "siblings": [], "_id": "627ebb8f846c433077d80f2a", "disabled": false, "gated": false, "likes": 3, "downloads": 88, "createdAt": "2022-05-13T20:11:59.000Z"}, {"id": "mwritescode/slither-audited-smart-contracts", "sha": "13594107c7afa216cb0c126f38b8ff6548112dcf", "lastModified": "2022-07-14T14:12:44.000Z", "tags": ["task_categories:text-classification", "task_categories:text-generation", "task_ids:multi-label-classification", "task_ids:multi-input-text-classification", "task_ids:language-modeling", "annotations_creators:other", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": "mwritescode", "description": "This dataset contains source code and deployed bytecode for Solidity Smart Contracts that have been verified on Etherscan.io, along with a classification of their vulnerabilities according to the Slither static analysis framework.", "citation": "@misc{rossini2022slitherauditedcontracts,\n    title = {Slither Audited Smart Contracts Dataset},\n    author={Martina Rossini},\n    year={2022}\n}", "cardData": null, "siblings": [], "_id": "62823d9a9624ab5f75c7503c", "disabled": false, "gated": false, "likes": 21, "downloads": 1980, "createdAt": "2022-05-16T12:03:38.000Z"}, {"id": "wdc/products-2017", "sha": "bee4f71ca1bcfc51eb8fc41d65720fb6f487df9d", "lastModified": "2022-10-23T05:50:24.000Z", "tags": ["task_categories:text-classification", "annotations_creators:weak supervision", "annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": "wdc", "description": "Many e-shops have started to mark-up product data within their HTML pages using the schema.org vocabulary. The Web Data Commons project regularly extracts such data from the Common Crawl, a large public web crawl. The Web Data Commons Training and Test Sets for Large-Scale Product Matching contain product offers from different e-shops in the form of binary product pairs (with corresponding label \"match\" or \"no match\")\n\nIn order to support the evaluation of machine learning-based matching methods, the data is split into training, validation and test set. We provide training and validation sets in four different sizes for four product categories. The labels of the test sets were manually checked while those of the training sets were derived using shared product identifiers from the Web via weak supervision.\n\nThe data stems from the WDC Product Data Corpus for Large-Scale Product Matching - Version 2.0 which consists of 26 million product offers originating from 79 thousand websites.", "citation": "@inproceedings{primpeli2019wdc,\n  title={The WDC training dataset and gold standard for large-scale product matching},\n  author={Primpeli, Anna and Peeters, Ralph and Bizer, Christian},\n  booktitle={Companion Proceedings of The 2019 World Wide Web Conference},\n  pages={381--386},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "628250499624ab5f75c7c6c1", "disabled": false, "gated": false, "likes": 2, "downloads": 265, "paperswithcode_id": "wdc-products", "createdAt": "2022-05-16T13:23:21.000Z"}, {"id": "HuggingFaceM4/TGIF", "sha": "2042af8ea928da30559f8a56dd81f36a945c6fc6", "lastModified": "2022-10-25T10:25:38.000Z", "tags": ["task_categories:question-answering", "task_categories:visual-question-answering", "task_ids:closed-domain-qa", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "arxiv:1604.02748", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "The Tumblr GIF (TGIF) dataset contains 100K animated GIFs and 120K sentences describing visual content of the animated GIFs. \nThe animated GIFs have been collected from Tumblr, from randomly selected posts published between May and June of 2015. \nWe provide the URLs of animated GIFs in this release. The sentences are collected via crowdsourcing, with a carefully designed\nannotationinterface that ensures high quality dataset. We provide one sentence per animated GIF for the training and validation splits,\nand three sentences per GIF for the test split. The dataset shall be used to evaluate animated GIF/video description techniques.", "citation": "@InProceedings{tgif-cvpr2016,\n  author = {Li, Yuncheng and Song, Yale and Cao, Liangliang and Tetreault, Joel and Goldberg, Larry and Jaimes, Alejandro and Luo, Jiebo},\n  title = \"{TGIF: A New Dataset and Benchmark on Animated GIF Description}\",\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month = {June},\n  year = {2016}\n}", "cardData": null, "siblings": [], "_id": "628389b4463f9697f51350eb", "disabled": false, "gated": false, "likes": 7, "downloads": 16, "createdAt": "2022-05-17T11:40:36.000Z"}, {"id": "strombergnlp/x-stance", "sha": "74ef270ce4489431ee869b06985fc55183e0552b", "lastModified": "2022-10-25T21:45:25.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "language:de", "language:fr", "license:mit", "stance-detection", "arxiv:2003.08385", "region:us"], "private": false, "author": "strombergnlp", "description": "The x-stance dataset contains more than 150 political questions, and 67k comments written by candidates on those questions. The comments are partly German, partly French and Italian. The data have been extracted from the Swiss voting advice platform Smartvote.", "citation": "@inproceedings{vamvas2020xstance,\n    author    = \"Vamvas, Jannis and Sennrich, Rico\",\n    title     = \"{X-Stance}: A Multilingual Multi-Target Dataset for Stance Detection\",\n    booktitle = \"Proceedings of the 5th Swiss Text Analytics Conference (SwissText) \\& 16th Conference on Natural Language Processing (KONVENS)\",\n    address   = \"Zurich, Switzerland\",\n    year      = \"2020\",\n    month     = \"jun\",\n    url       = \"http://ceur-ws.org/Vol-2624/paper9.pdf\"\n}", "cardData": null, "siblings": [], "_id": "6284c29feac6d6ca13881998", "disabled": false, "gated": false, "likes": 1, "downloads": 69, "createdAt": "2022-05-18T09:55:43.000Z"}, {"id": "WorkInTheDark/FairytaleQA", "sha": "655b20b370f8ec6ef0cae5ac08f1c27ec6e72aaf", "lastModified": "2023-08-22T18:49:30.000Z", "tags": ["task_categories:question-answering", "task_categories:text-generation", "language:en", "license:apache-2.0", "education", "children education", "region:us"], "private": false, "author": "WorkInTheDark", "description": "FairytaleQA dataset, an open-source dataset focusing on comprehension of narratives, targeting students from kindergarten to eighth grade. The FairytaleQA dataset is annotated by education experts based on an evidence-based theoretical framework. It consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements or relations.", "citation": "@inproceedings{xu-etal-2022-fantastic,\n    title = \"Fantastic Questions and Where to Find Them: {F}airytale{QA} {--} An Authentic Dataset for Narrative Comprehension\",\n    author = \"Xu, Ying  and\n      Wang, Dakuo  and\n      Yu, Mo  and\n      Ritchie, Daniel  and\n      Yao, Bingsheng  and\n      Wu, Tongshuang  and\n      Zhang, Zheng  and\n      Li, Toby  and\n      Bradford, Nora  and\n      Sun, Branda  and\n      Hoang, Tran  and\n      Sang, Yisi  and\n      Hou, Yufang  and\n      Ma, Xiaojuan  and\n      Yang, Diyi  and\n      Peng, Nanyun  and\n      Yu, Zhou  and\n      Warschauer, Mark\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = may,\n    year = \"2022\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.acl-long.34\",\n    doi = \"10.18653/v1/2022.acl-long.34\",\n    pages = \"447--460\",\n    abstract = \"Question answering (QA) is a fundamental means to facilitate assessment and training of narrative comprehension skills for both machines and young children, yet there is scarcity of high-quality QA datasets carefully designed to serve this purpose. In particular, existing datasets rarely distinguish fine-grained reading skills, such as the understanding of varying narrative elements. Drawing on the reading education research, we introduce FairytaleQA, a dataset focusing on narrative comprehension of kindergarten to eighth-grade students. Generated by educational experts based on an evidence-based theoretical framework, FairytaleQA consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements or relations. Our dataset is valuable in two folds: First, we ran existing QA models on our dataset and confirmed that this annotation helps assess models{'} fine-grained learning skills. Second, the dataset supports question generation (QG) task in the education domain. Through benchmarking with QG models, we show that the QG model trained on FairytaleQA is capable of asking high-quality and more diverse questions.\",\n}", "cardData": null, "siblings": [], "_id": "628544c4e483e0d37b35bbf1", "disabled": false, "gated": false, "likes": 1, "downloads": 310, "createdAt": "2022-05-18T19:11:00.000Z"}, {"id": "strombergnlp/nlpcc-stance", "sha": "dca814e1ce04213a6600c4e490c0018b2c7004ac", "lastModified": "2022-10-25T21:47:26.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-analysis", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:zh", "license:cc-by-4.0", "stance-detection", "region:us"], "private": false, "author": "strombergnlp", "description": "This is a stance prediction dataset in Chinese.\nThe data is that from a shared task, stance detection in Chinese microblogs, in NLPCC-ICCPOL 2016. It covers Task A, a mandatory supervised task which detects stance towards five targets of interest with given labeled data.", "citation": "@incollection{xu2016overview,\n  title={Overview of nlpcc shared task 4: Stance detection in chinese microblogs},\n  author={Xu, Ruifeng and Zhou, Yu and Wu, Dongyin and Gui, Lin and Du, Jiachen and Xue, Yun},\n  booktitle={Natural language understanding and intelligent applications},\n  pages={907--916},\n  year={2016},\n  publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "628627b040423ef48fb5c784", "disabled": false, "gated": false, "likes": 4, "downloads": 25, "createdAt": "2022-05-19T11:19:12.000Z"}, {"id": "HuggingFaceM4/yttemporal180m", "sha": "1cc8db2ceb9edce8ff1bbbc3c7bb0b709eb6d745", "lastModified": "2022-05-24T12:25:22.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "YT-Temporal-180M, a large and diverse dataset of 6 million videos (spanning 180M extracted frames)\nthat covers diverse topics.", "citation": "@inproceedings{zellersluhessel2021merlot,\n  title={MERLOT: Multimodal Neural Script Knowledge Models},\n  author={Zellers, Rowan and Lu, Ximing and Hessel, Jack and Yu, Youngjae and Park, Jae Sung and Cao, Jize and Farhadi, Ali and Choi, Yejin},\n  booktitle={Advances in Neural Information Processing Systems 34},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "628637437cc3b7bc1b90739e", "disabled": false, "gated": false, "likes": 2, "downloads": 13, "createdAt": "2022-05-19T12:25:39.000Z"}, {"id": "GEM/FairytaleQA", "sha": "b6c76a77359f133f9ee087b65c52a686fada7c15", "lastModified": "2022-10-25T12:58:30.000Z", "tags": ["task_categories:other", "annotations_creators:expert-created", "language_creators:unknown", "multilinguality:unknown", "size_categories:unknown", "source_datasets:original", "language:en", "license:unknown", "question-generation", "arxiv:2203.13947", "region:us"], "private": false, "author": "GEM", "description": "\\\r\nThe FairytaleQA dataset focusing on narrative comprehension of kindergarten to eighth-grade students. Generated by educational experts based on an evidence-based theoretical framework, FairytaleQA consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements or relations. This is for the Question Generation Task of FairytaleQA.", "citation": "\\\r\n@inproceedings{xu2022fairytaleqa,\r\n    author={Xu, Ying and Wang, Dakuo and Yu, Mo and Ritchie, Daniel and Yao, Bingsheng and Wu, Tongshuang and Zhang, Zheng and Li, Toby Jia-Jun and Bradford, Nora and Sun, Branda and Hoang, Tran Bao and Sang, Yisi and Hou, Yufang and Ma, Xiaojuan and Yang, Diyi and Peng, Nanyun and Yu, Zhou and Warschauer, Mark},\r\n    title = {Fantastic Questions and Where to Find Them: Fairytale{QA} -- An Authentic Dataset for Narrative Comprehension},\r\n    publisher = {Association for Computational Linguistics},\r\n    year = {2022}\r\n}", "cardData": null, "siblings": [], "_id": "6286677440423ef48fb7b5ab", "disabled": false, "gated": false, "likes": 4, "downloads": 29, "createdAt": "2022-05-19T15:51:16.000Z"}, {"id": "mteb/tatoeba-bitext-mining", "sha": "ed9e4a974f867fd9736efcf222fc3a26487387a5", "lastModified": "2022-09-27T19:07:02.000Z", "tags": ["language:eng", "language:sqi", "language:fry", "language:kur", "language:tur", "language:deu", "language:nld", "language:ron", "language:ang", "language:ido", "language:jav", "language:isl", "language:slv", "language:cym", "language:kaz", "language:est", "language:heb", "language:gla", "language:mar", "language:lat", "language:bel", "language:pms", "language:gle", "language:pes", "language:nob", "language:bul", "language:cbk", "language:hun", "language:uig", "language:rus", "language:spa", "language:hye", "language:tel", "language:afr", "language:mon", "language:arz", "language:hrv", "language:nov", "language:gsw", "language:nds", "language:ukr", "language:uzb", "language:lit", "language:ina", "language:lfn", "language:zsm", "language:ita", "language:cmn", "language:lvs", "language:glg", "language:ceb", "language:bre", "language:ben", "language:swg", "language:arq", "language:kab", "language:fra", "language:por", "language:tat", "language:oci", "language:pol", "language:war", "language:aze", "language:vie", "language:nno", "language:cha", "language:mhr", "language:dan", "language:ell", "language:amh", "language:pam", "language:hsb", "language:srp", "language:epo", "language:kzj", "language:awa", "language:fao", "language:mal", "language:ile", "language:bos", "language:cor", "language:cat", "language:eus", "language:yue", "language:swe", "language:dtp", "language:kat", "language:jpn", "language:csb", "language:xho", "language:orv", "language:ind", "language:tuk", "language:max", "language:swh", "language:hin", "language:dsb", "language:ber", "language:tam", "language:slk", "language:tgl", "language:ast", "language:mkd", "language:khm", "language:ces", "language:tzl", "language:urd", "language:ara", "language:kor", "language:yid", "language:fin", "language:tha", "language:wuu", "region:us"], "private": false, "author": "mteb", "description": "        Tatoeba multilingual test set", "citation": null, "cardData": null, "siblings": [], "_id": "628693131d996488088919f3", "disabled": false, "gated": false, "likes": 3, "downloads": 10457, "createdAt": "2022-05-19T18:57:23.000Z"}, {"id": "mteb/bucc-bitext-mining", "sha": "d51519689f32196a32af33b075a01d0e7c51e252", "lastModified": "2022-09-22T14:17:13.000Z", "tags": ["multilinguality:monolingual", "multilinguality:multilingual", "language:de", "language:en", "language:fr", "language:ru", "language:zh", "license:cc-by-sa-4.0", "arxiv:2104.06893", "arxiv:2010.02573", "arxiv:2003.04807", "arxiv:2204.08582", "arxiv:2008.09335", "arxiv:2104.07081", "region:us"], "private": false, "author": "mteb", "description": "        BUCC 2018 Shared Task test dataset", "citation": null, "cardData": null, "siblings": [], "_id": "62869e18011a13fe5f871e05", "disabled": false, "gated": false, "likes": 0, "downloads": 1001, "createdAt": "2022-05-19T19:44:24.000Z"}, {"id": "strombergnlp/ans-stance", "sha": "41699cddcb0ce9849d476767b647f6d56aac52b1", "lastModified": "2022-10-25T21:45:09.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:apache-2.0", "stance-detection", "arxiv:2005.10410", "region:us"], "private": false, "author": "strombergnlp", "description": "The dataset is a collection of news titles in arabic along with paraphrased and corrupted titles. The stance prediction version is a 3-class classification task. Data contains three columns: s1, s2, stance.", "citation": "@inproceedings{,\n    title = \"Stance Prediction and Claim Verification: An {A}rabic Perspective\", \n    author = \"Khouja, Jude\",\n    booktitle = \"Proceedings of the Third Workshop on Fact Extraction and {VER}ification ({FEVER})\",\n    year = \"2020\",\n    address = \"Seattle, USA\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "628789d770af5d9106e3c5bf", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "createdAt": "2022-05-20T12:30:15.000Z"}, {"id": "ccdv/mediasum", "sha": "ee34247ae1e5c82e72e855a9d4f001112ccab46c", "lastModified": "2022-10-25T10:56:04.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "conditional-text-generation", "region:us"], "private": false, "author": "ccdv", "description": "MediaSum dataset for summarization.\n From paper: \"MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization\" by C. Zhu et al.\"", "citation": "    @article{zhu2021mediasum,\n  title={MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization},\n  author={Zhu, Chenguang and Liu, Yang and Mei, Jie and Zeng, Michael},\n  journal={arXiv preprint arXiv:2103.06410},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "6288db1fd2282d24e110fe46", "disabled": false, "gated": false, "likes": 5, "downloads": 726, "createdAt": "2022-05-21T12:29:19.000Z"}, {"id": "launch/gov_report", "sha": "32feeaede49fed993aef070bc4da09263fd0429a", "lastModified": "2022-11-09T01:58:24.000Z", "tags": ["task_categories:summarization", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "launch", "description": "GovReport long document summarization dataset.\n\nThere are three configs:\n  - plain_text: plain text document-to-summary pairs\n  - plain_text_with_recommendations: plain text doucment-summary pairs, with \"What GAO recommends\" included in the summary\n  - structure: data with section structure", "citation": "@inproceedings{huang-etal-2021-efficient,\n    title = \"Efficient Attentions for Long Document Summarization\",\n    author = \"Huang, Luyang  and\n        Cao, Shuyang  and\n        Parulian, Nikolaus  and\n        Ji, Heng  and\n        Wang, Lu\",\n    booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jun,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.naacl-main.112\",\n    doi = \"10.18653/v1/2021.naacl-main.112\",\n    pages = \"1419--1436\",\n    abstract = \"The quadratic computational and memory complexities of large Transformers have limited their scalability for long document summarization. In this paper, we propose Hepos, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source. We further conduct a systematic study of existing efficient self-attentions. Combined with Hepos, we are able to process ten times more tokens than existing models that use full attentions. For evaluation, we present a new dataset, GovReport, with significantly longer documents and summaries. Results show that our models produce significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on PubMed. Human evaluation also shows that our models generate more informative summaries with fewer unfaithful errors.\",\n}", "cardData": null, "siblings": [], "_id": "628a605f6a2a449b99a9244b", "disabled": false, "gated": false, "likes": 3, "downloads": 1045, "createdAt": "2022-05-22T16:10:07.000Z"}, {"id": "ekinakyurek/ftrace", "sha": "699143e74ee8fc20d035bcb95be5dc17b2147fba", "lastModified": "2022-10-23T05:56:05.000Z", "tags": ["task_ids:masked-language-modeling", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:TRex", "source_datasets:Lama", "language:en", "license:cc-by-sa-4.0", "license:cc-by-nc-4.0", "arxiv:2205.11482", "region:us"], "private": false, "author": "ekinakyurek", "description": "    Factual Tracing Dataset that contains queries and abstracts, and their corresponding ground truth.", "citation": "\\", "cardData": null, "siblings": [], "_id": "628b0e94042f83532f43b1d9", "disabled": false, "gated": false, "likes": 3, "downloads": 91, "createdAt": "2022-05-23T04:33:24.000Z"}, {"id": "GroNLP/divemt", "sha": "9abd1d1cea118ad7a9946e7f1f5a1a29c2a01762", "lastModified": "2023-02-10T11:04:33.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:it", "language:vi", "language:nl", "language:uk", "language:tr", "language:ar", "license:gpl-3.0", "arxiv:2205.12215", "region:us"], "private": false, "author": "GroNLP", "description": "DivEMT is the first publicly available post-editing study of Neural Machine Translation (NMT) over a typologically diverse set of target languages. Using a strictly controlled setup, 18 professional translators were instructed to translate or post-edit the same set of English documents into Arabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process, their edits, keystrokes, editing times, pauses, and perceived effort were logged, enabling an in-depth, cross-lingual evaluation of NMT quality and its post-editing process.", "citation": "@inproceedings{sarti-etal-2022-divemt,\n    title = \"{D}iv{EMT}: Neural Machine Translation Post-Editing Effort Across Typologically Diverse Languages\",\n    author = \"Sarti, Gabriele and Bisazza, Arianna and Guerberof Arenas, Ana and Toral, Antonio\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.emnlp-main.532\",\n    pages = \"7795--7816\",\n}", "cardData": null, "siblings": [], "_id": "628be7075f7c5912e46eb523", "disabled": false, "gated": false, "likes": 2, "downloads": 32, "createdAt": "2022-05-23T19:56:55.000Z"}, {"id": "taln-ls2n/pubmed", "sha": "061911863bb36ea787931d7f31588f8773218173", "lastModified": "2022-10-26T19:14:46.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:1k<n<10k", "language:en", "license:unknown", "keyphrase-generation", "keyphrase-extraction", "text-mining", "region:us"], "private": false, "author": "taln-ls2n", "description": "PubMed benchmark dataset for keyphrase extraction and generation.", "citation": "@MasterThesis{Schutz:2008,\n  author = {Alexander Thorsten Schutz}, \n  title = {Keyphrase Extraction from Single Documents in the Open Domain Exploiting Linguistic and Statistical Methods},\n  booktitle = {National University of Ireland},\n  year = {2008}\n}", "cardData": null, "siblings": [], "_id": "628c9880e6bf953d2e9bfc9f", "disabled": false, "gated": false, "likes": 1, "downloads": 31, "createdAt": "2022-05-24T08:34:08.000Z"}, {"id": "mteb/amazon_reviews_multi", "sha": "c379a6705fec24a2493fa68e011692605f44e119", "lastModified": "2022-09-27T19:10:01.000Z", "tags": ["language:de", "language:en", "language:es", "language:fr", "language:ja", "language:zh", "region:us"], "private": false, "author": "mteb", "description": "We provide an Amazon product reviews dataset for multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. \u2018books\u2019, \u2018appliances\u2019, etc.) The corpus is balanced across stars, so each star rating constitutes 20% of the reviews in each language.\nFor each language, there are 200,000, 5,000 and 5,000 reviews in the training, development and test sets respectively. The maximum number of reviews per reviewer is 20 and the maximum number of reviews per product is 20. All reviews are truncated after 2,000 characters, and all reviews are at least 20 characters long.\nNote that the language of a review does not necessarily match the language of its marketplace (e.g. reviews from amazon.de are primarily written in German, but could also be written in English, etc.). For this reason, we applied a language detection algorithm based on the work in Bojanowski et al. (2017) to determine the language of the review text and we removed reviews that were not written in the expected language.", "citation": "@inproceedings{marc_reviews,\n    title={The Multilingual Amazon Reviews Corpus},\n    author={Keung, Phillip and Lu, Yichao and Szarvas, Gy\u00f6rgy and Smith, Noah A.},\n    booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "628e820b9202a9acd20c9a48", "disabled": false, "gated": false, "likes": 5, "downloads": 2978, "createdAt": "2022-05-25T19:22:51.000Z"}, {"id": "taesiri/GamePhysics_Grand_Theft_Auto_V", "sha": "bd3505b16a7ae2f39998afa40c0cb80f3e20371c", "lastModified": "2022-05-26T06:00:19.000Z", "tags": ["region:us"], "private": false, "author": "taesiri", "description": "A test dataset for GamePhysics", "citation": "@article{taesiri2022clip,\n  title={CLIP meets GamePhysics: Towards bug identification in gameplay videos using zero-shot transfer learning},\n  author={Taesiri, Mohammad Reza and Macklon, Finlay and Bezemer, Cor-Paul},\n  journal={arXiv preprint arXiv:2203.11096},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "628f139fb4ca71ccc0f9355d", "disabled": false, "gated": false, "likes": 3, "downloads": 15, "createdAt": "2022-05-26T05:43:59.000Z"}, {"id": "sileod/movie_recommendation", "sha": "f0ad03e8c70dd3a3bff36b2ff1b29d2c1a8ce330", "lastModified": "2023-05-25T14:53:49.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:apache-2.0", "movie-recommendation", "collaborative-filtering", "movielens", "film", "doi:10.57967/hf/0257", "region:us"], "private": false, "author": "sileod", "description": "Movie recommendation task based on the Movielens dataset", "citation": "@InProceedings{sileodreclm22,\nauthor=\"Sileo, Damien\nand Vossen, Wout\nand Raymaekers, Robbe\",\neditor=\"Hagen, Matthias\nand Verberne, Suzan\nand Macdonald, Craig\nand Seifert, Christin\nand Balog, Krisztian\nand N{\\o}rv{\\aa}g, Kjetil\nand Setty, Vinay\",\ntitle=\"Zero-Shot Recommendation as\u00a0Language Modeling\",\nbooktitle=\"Advances in Information Retrieval\",\nyear=\"2022\",\npublisher=\"Springer International Publishing\",\naddress=\"Cham\",\npages=\"223--230\",\nabstract=\"Recommendation is the task of ranking items (e.g. movies or products) according to individual user needs. Current systems rely on collaborative filtering and content-based techniques, which both require structured training data. We propose a framework for recommendation with off-the-shelf pretrained language models (LM) that only used unstructured text corpora as training data. If a user u liked Matrix and Inception, we construct a textual prompt, e.g. ``Movies like Matrix, Inception, {\\$}{\\$}{\\{}<{\\}}m{\\{}>{\\}}{\\$}{\\$}<m>'' to estimate the affinity between u and m with LM likelihood. We motivate our idea with a corpus analysis, evaluate several prompt structures, and we compare LM-based recommendation with standard matrix factorization trained on different data regimes. The code for our experiments is publicly available (https://colab.research.google.com/drive/...?usp=sharing).\",\nisbn=\"978-3-030-99739-7\"\n}", "cardData": null, "siblings": [], "_id": "62908aef279de3b7209481e4", "disabled": false, "gated": false, "likes": 10, "downloads": 59, "createdAt": "2022-05-27T08:25:19.000Z"}, {"id": "silver/lccc", "sha": "5bd582fa28cd7143f2f9c852e08e23089d677c44", "lastModified": "2022-11-06T04:51:16.000Z", "tags": ["task_categories:conversational", "task_ids:dialogue-generation", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:zh", "license:mit", "dialogue-response-retrieval", "arxiv:2008.03946", "region:us"], "private": false, "author": "silver", "description": "LCCC: Large-scale Cleaned Chinese Conversation corpus (LCCC) is a large corpus of Chinese conversations.\nA rigorous data cleaning pipeline is designed to ensure the quality of the corpus.\nThis pipeline involves a set of rules and several classifier-based filters.\nNoises such as offensive or sensitive words, special symbols, emojis,\ngrammatically incorrect sentences, and incoherent conversations are filtered.", "citation": "@inproceedings{wang2020chinese,\ntitle={A Large-Scale Chinese Short-Text Conversation Dataset},\nauthor={Wang, Yida and Ke, Pei and Zheng, Yinhe and Huang, Kaili and Jiang, Yong and Zhu, Xiaoyan and Huang, Minlie},\nbooktitle={NLPCC},\nyear={2020},\nurl={https://arxiv.org/abs/2008.03946}\n}", "cardData": null, "siblings": [], "_id": "62933aa0dea3da4960c0f332", "disabled": false, "gated": false, "likes": 11, "downloads": 14, "createdAt": "2022-05-29T09:19:28.000Z"}, {"id": "juletxara/xquad_xtreme", "sha": "3b885e726812668096a44492a7dc506c4eb57aa9", "lastModified": "2022-10-12T08:43:41.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:extended|squad", "language:en", "language:es", "language:de", "language:el", "language:hi", "language:th", "language:ru", "language:tr", "language:ar", "language:vi", "language:zh", "language:ro", "license:cc-by-sa-4.0", "arxiv:1910.11856", "region:us"], "private": false, "author": "juletxara", "description": "XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering\nperformance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set\nof SQuAD v1.1 (Rajpurkar et al., 2016) together with their professional translations into ten languages: Spanish, German,\nGreek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and Romanian. Consequently, the dataset is entirely parallel\nacross 12 languages.\nWe also include \"translate-train\", \"translate-dev\", and \"translate-test\" splits for each non-English language from XTREME (Hu et al., 2020). These can be used to run XQuAD in the \"translate-train\" or \"translate-test\" settings.", "citation": "@article{Artetxe:etal:2019,\n      author    = {Mikel Artetxe and Sebastian Ruder and Dani Yogatama},\n      title     = {On the cross-lingual transferability of monolingual representations},\n      journal   = {CoRR},\n      volume    = {abs/1910.11856},\n      year      = {2019},\n      archivePrefix = {arXiv},\n      eprint    = {1910.11856}\n}", "cardData": null, "siblings": [], "_id": "6294a12d1e87ffbe5c042d3d", "disabled": false, "gated": false, "likes": 6, "downloads": 361, "paperswithcode_id": "xquad", "createdAt": "2022-05-30T10:49:17.000Z"}, {"id": "Lehrig/Monkey-Species-Collection", "sha": "dd3f3c25a869b077e5eac0ef0917ce7c33e45435", "lastModified": "2022-05-30T12:33:12.000Z", "tags": ["region:us"], "private": false, "author": "Lehrig", "description": "This dataset is intended as a test case for fine-grain classification tasks (10 different kinds of monkey species). The dataset consists of almost 1400 JPEG images grouped into two splits - training and validation. Each split contains 10 categories labeled as n0~n9, each corresponding a species from [Wikipedia's monkey cladogram](https://en.wikipedia.org/wiki/Monkey). Images were downloaded with help of the [googliser](https://github.com/teracow/googliser) open source code.\n\n\n| Label | Latin Name            | Common Name               | Train Images | Validation Images |\n| ----- | --------------------- | ------------------------- | ------------ | ----------------- |\n| n0    | alouatta_palliata     | mantled_howler            | 131          | 26                |\n| n1    | erythrocebus_patas    | patas_monkey              | 139          | 28                |\n| n2    | cacajao_calvus        | bald_uakari               | 137          | 27                |\n| n3    | macaca_fuscata        | japanese_macaque          | 152          | 30                |\n| n4    | cebuella_pygmea       | pygmy_marmoset            | 131          | 26                |\n| n5    | cebus_capucinus       | white_headed_capuchin     | 141          | 28                |\n| n6    | mico_argentatus       | silvery_marmoset          | 132          | 26                |\n| n7    | saimiri_sciureus      | common_squirrel_monkey    | 142          | 28                |\n| n8    | aotus_nigriceps       | black_headed_night_monkey | 133          | 27                |\n| n9    | trachypithecus_johnii | nilgiri_langur            | 132          | 26                |\n\n\nThis collection includes the following GTZAN variants:\n* original (images are 400x300 px or larger; ~550 MB)\n* downsized (images are downsized to 224x224 px; ~40 MB)", "citation": "@misc{kaggle-10-monkey-species,\n  title={Kaggle: 10 Monkey Species},\n  howpublished={\\\\url{https://www.kaggle.com/datasets/slothkong/10-monkey-species}},\n  note = {Accessed: 2022-05-30},\n}", "cardData": null, "siblings": [], "_id": "6294a70ca1e875b26e931321", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2022-05-30T11:14:20.000Z"}, {"id": "DFKI-SLT/wikitext_linked", "sha": "84c911c0541875191a4e87f16141cbd6cc99221d", "lastModified": "2022-07-04T06:09:56.000Z", "tags": ["task_categories:fill-mask", "task_categories:token-classification", "task_categories:text-classification", "task_ids:masked-language-modeling", "task_ids:named-entity-recognition", "task_ids:part-of-speech", "task_ids:lemmatization", "task_ids:parsing", "task_ids:entity-linking-classification", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:extended|wikitext", "language:en", "license:cc-by-sa-4.0", "arxiv:1609.07843", "region:us"], "private": false, "author": "DFKI-SLT", "description": " The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\n Good and Featured articles on Wikipedia. Dependency Relations, POS, NER tags are marked with trankit and\n entities are linked with entity-fishing.\n The dataset is available under the Creative Commons Attribution-ShareAlike License.", "citation": "@misc{merity2016pointer,\n      title={Pointer Sentinel Mixture Models},\n      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},\n      year={2016},\n      eprint={1609.07843},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@inproceedings{nguyen2021trankit,\n      title={Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing},\n      author={Nguyen, Minh Van and Lai, Viet Dac and Veyseh, Amir Pouran Ben and Nguyen, Thien Huu},\n      booktitle=\"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\n      year={2021}\n}\n\n@misc{entity-fishing,\n    title = {entity-fishing},\n    howpublished = {\\\\url{https://github.com/kermitt2/entity-fishing}},\n    publisher = {GitHub},\n    year = {2016--2022},\n    archivePrefix = {swh},\n    eprint = {1:dir:cb0ba3379413db12b0018b7c3af8d0d2d864139c}\n}", "cardData": null, "siblings": [], "_id": "6294d3fea1e875b26e93f01e", "disabled": false, "gated": false, "likes": 5, "downloads": 15, "createdAt": "2022-05-30T14:26:06.000Z"}, {"id": "mteb/sts22-crosslingual-sts", "sha": "2de6ce8c1921b71a755b262c6b57fef195dd7906", "lastModified": "2022-09-27T19:10:13.000Z", "tags": ["language:ar", "language:de", "language:en", "language:es", "language:fr", "language:it", "language:pl", "language:ru", "language:tr", "language:zh", "region:us"], "private": false, "author": "mteb", "description": "SemEval 2022 Task 8: Multilingual News Article Similarity", "citation": "\\", "cardData": null, "siblings": [], "_id": "629526b45f2097c17b84d5cd", "disabled": false, "gated": false, "likes": 4, "downloads": 12601, "createdAt": "2022-05-30T20:19:00.000Z"}, {"id": "arize-ai/ecommerce_reviews_with_language_drift", "sha": "fead71299eabef45c1fd2bf914c9c0ea724b6775", "lastModified": "2022-07-01T17:26:03.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|imdb", "language:en", "license:mit", "region:us"], "private": false, "author": "arize-ai", "description": "This dataset was crafted to be used in our tutorial [Link to the tutorial when\nready]. It consists on product reviews from an e-commerce store. The reviews\nare labeled on a scale from 1 to 5 (stars). The training & validation sets are\nfully composed by reviews written in english. However, the production set has\nsome reviews written in spanish. At Arize, we work to surface this issue and\nhelp you solve it.", "citation": "# @InProceedings{huggingface:dataset,\n# title = {A great new dataset},\n# author={huggingface, Inc.\n# },\n# year={2020}\n# }\n#", "cardData": null, "siblings": [], "_id": "6296a39bc2ec00620bfb4b0d", "disabled": false, "gated": false, "likes": 1, "downloads": 41, "createdAt": "2022-05-31T23:24:11.000Z"}, {"id": "enwik8", "sha": "a3d620ecedec0d39511d1dfdc3a27a69e648be84", "lastModified": "2023-04-06T14:14:17.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": null, "description": "The dataset is based on the Hutter Prize (http://prize.hutter1.net) and contains the first 10^8 bytes of English Wikipedia in 2006 in XML", "citation": null, "cardData": null, "siblings": [], "_id": "629771feb5a5a72ea2086280", "disabled": false, "gated": false, "likes": 4, "downloads": 6262, "createdAt": "2022-06-01T14:04:46.000Z"}, {"id": "lmqg/qg_squadshifts", "sha": "440df9079e95ce50f75fa69b3f6aed94900eca66", "lastModified": "2022-12-02T18:56:15.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:subjqa", "language:en", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "629907e8b58e71e2ac9f902c", "disabled": false, "gated": false, "likes": 1, "downloads": 61, "createdAt": "2022-06-02T18:56:40.000Z"}, {"id": "lmqg/qg_esquad", "sha": "7675f4bb4bd1510f97429f4038723d03ea9b64f7", "lastModified": "2022-12-02T18:52:05.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:squad_es", "language:es", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[SQuAD-es](https://huggingface.co/datasets/squad_es) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "62994a92ea8640d87e22da3d", "disabled": false, "gated": false, "likes": 0, "downloads": 101, "createdAt": "2022-06-02T23:41:06.000Z"}, {"id": "lmqg/qg_koquad", "sha": "49ad3eba360e4f6c40c0720e19be9d358dd893d0", "lastModified": "2022-12-02T18:53:42.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:squad_es", "language:ko", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[KorQuAD](https://huggingface.co/datasets/squad_kor_v1) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "62994add43898d5a4f805cf8", "disabled": false, "gated": false, "likes": 3, "downloads": 97, "createdAt": "2022-06-02T23:42:21.000Z"}, {"id": "lmqg/qg_ruquad", "sha": "1dc50f7e367ac8c1d78e0c69a889782d5b4177dd", "lastModified": "2022-12-02T18:55:01.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:deepset/germanquad", "language:ru", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[SberSQuAD](https://huggingface.co/datasets/sberquad) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "62994b767e4c5c435c7e3e47", "disabled": false, "gated": false, "likes": 2, "downloads": 92, "createdAt": "2022-06-02T23:44:54.000Z"}, {"id": "lmqg/qg_itquad", "sha": "d4e9a4ad68be3297bdd6854cdd57f0eaf9f99337", "lastModified": "2022-12-02T18:54:31.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:squad_es", "language:it", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[SQuAD-it](https://huggingface.co/datasets/squad_it) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "62994b8843e990340befafcb", "disabled": false, "gated": false, "likes": 1, "downloads": 66, "createdAt": "2022-06-02T23:45:12.000Z"}, {"id": "lmqg/qg_dequad", "sha": "55db14b1358c93bf9ed49af20ed06c36a7564386", "lastModified": "2022-12-02T18:53:57.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:deepset/germanquad", "language:de", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[GermanSQuAD](https://huggingface.co/datasets/deepset/germanquad) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "62994b9aea8640d87e22e10c", "disabled": false, "gated": false, "likes": 1, "downloads": 96, "createdAt": "2022-06-02T23:45:30.000Z"}, {"id": "carblacac/twitter-sentiment-analysis", "sha": "de6188e66fd45b975dfaef454eae6ba38e1c9f32", "lastModified": "2022-10-25T05:42:06.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "carblacac", "description": "The Twitter Sentiment Analysis Dataset contains 1,578,627 classified tweets, each row is marked as 1 for positive sentiment and 0 for negative sentiment.\nThe dataset is based on data from the following two sources:\n\nUniversity of Michigan Sentiment Analysis competition on Kaggle\nTwitter Sentiment Corpus by Niek Sanders\n\nFinally, I randomly selected a subset of them, applied a cleaning process, and divided them between the test and train subsets, keeping a balance between\nthe number of positive and negative tweets within each of these subsets.", "citation": "@InProceedings{thinknook:dataset,\ntitle = {Twitter Sentiment Analysis Training Corpus (Dataset)},\nauthor={Ibrahim Naji},\nyear={2012}\n}", "cardData": null, "siblings": [], "_id": "629ccaf85a13ba8233daff0f", "disabled": false, "gated": false, "likes": 11, "downloads": 7493, "paperswithcode_id": "other", "createdAt": "2022-06-05T15:25:44.000Z"}, {"id": "JeremyAlain/123_test", "sha": "40911c400822855a48328accb2f2b7688e290db3", "lastModified": "2022-10-25T10:29:11.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:zero-shot-classification", "task_categories:text2text-generation", "task_categories:table-question-answering", "task_categories:text-generation", "task_categories:text-classification", "task_categories:tabular-classification", "task_ids:multiple-choice-qa", "task_ids:extractive-qa", "task_ids:open-domain-qa", "task_ids:closed-domain-qa", "task_ids:closed-book-qa", "task_ids:open-book-qa", "task_ids:language-modeling", "task_ids:multi-class-classification", "task_ids:natural-language-inference", "task_ids:topic-classification", "task_ids:multi-label-classification", "task_ids:tabular-multi-class-classification", "task_ids:tabular-multi-label-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "JeremyAlain", "description": "The Fewshot Table dataset consists of tables that naturally occur on the web, that are formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. The dataset consists of approximately 413K tables that are extracted from the WDC Web Table Corpora 2015, which is released under the Apache-2.0 license. The WDC Web Table Corpora \"contains vast amounts of HTML tables. [...] The Web Data Commons project extracts relational Web tables from the Common Crawl, the largest and most up-to-date Web corpus that is currently available to the public.\"", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "629e031982153181b0714d63", "disabled": false, "gated": false, "likes": 2, "downloads": 716, "createdAt": "2022-06-06T13:37:29.000Z"}, {"id": "nlpaueb/multi_eurlex", "sha": "e18c6f4fc7555e7e2294070c77f9ff23215436a9", "lastModified": "2022-10-25T10:29:13.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|multi_eurlex", "language:en", "language:de", "language:fr", "language:el", "language:sk", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "nlpaueb", "description": "An non-parallel version of the MultiEURLEX datasets released by Chalkidis et al. (2021). \nMultiEURLEX comprises 65k EU laws in 23 official EU languages (some low-ish resource).\nEach EU law has been annotated with EUROVOC concepts (labels) by the Publication Office of EU.\nAs with the English EURLEX, the goal is to predict the relevant EUROVOC concepts (labels);\nthis is multi-label classification task (given the text, predict multiple labels).\nIn this version, MultiEURLEX comprises non-parallel documents across 5 languages (English, German, French, Greek, \nand Slovakian) including translations from English to the rest of the 4 available languages.", "citation": "@InProceedings{xenouleas-etal-2022-realistic-multieurlex,\n  author = {Xenouleas, Stratos\n                and Tsoukara, Alexia\n                and Panagiotakis, Giannis\n                and Chalkidis, Ilias\n                and Androutsopoulos, Ion},\n  title = {Realistic Zero-Shot Cross-Lingual Transfer in Legal Topic Classification},\n  booktitle = {Proceedings of 12th Hellenic Conference on Artificial Intelligence (SETN 2022)},\n  year = {2022},\n  publisher = {Association for Computer Machinery},\n  location = {Corfu, Greece},\n}", "cardData": null, "siblings": [], "_id": "629f28368483fd7f45eabfe7", "disabled": false, "gated": false, "likes": 4, "downloads": 45, "createdAt": "2022-06-07T10:28:06.000Z"}, {"id": "juletxara/tydiqa_xtreme", "sha": "cefa5bbe8262dcbd13ad8192c11a696fc06f6b1c", "lastModified": "2022-07-01T19:19:05.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:unknown", "source_datasets:extended|wikipedia", "language:en", "language:ar", "language:bn", "language:fi", "language:id", "language:ja", "language:sw", "language:ko", "language:ru", "language:te", "language:th", "license:apache-2.0", "arxiv:2003.11080", "region:us"], "private": false, "author": "juletxara", "description": "TyDi QA is a question answering dataset covering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology -- the set of linguistic features that each language\nexpresses -- such that we expect models performing well on this set to generalize across a large number of the languages\nin the world. It contains language phenomena that would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by people who want to know the answer, but\ndon\u2019t know the answer yet, (unlike SQuAD and its descendents) and the data is collected directly in each language without\nthe use of translation (unlike MLQA and XQuAD).\n\nWe also include \"translate-train\" and \"translate-test\" splits for each non-English languages from XTREME (Hu et al., 2020). These splits are the automatic translations from English to each target language used in the XTREME paper [https://arxiv.org/abs/2003.11080]. The \"translate-train\" split purposefully ignores the non-English TyDiQA-GoldP training data to simulate the transfer learning scenario where original-language data is not available and system builders must rely on labeled English data plus existing machine translation systems.", "citation": "@article{tydiqa,\ntitle   = {TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},\nauthor  = {Jonathan H. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki}\nyear    = {2020},\njournal = {Transactions of the Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "62a07d22ec41f255e3e2b03d", "disabled": false, "gated": false, "likes": 1, "downloads": 81, "paperswithcode_id": "tydi-qa", "createdAt": "2022-06-08T10:42:42.000Z"}, {"id": "truthful_qa", "sha": "e89fbc73ff8b063f0ab9c586b3dd1552ed0334f2", "lastModified": "2023-06-09T14:18:13.000Z", "tags": ["task_categories:multiple-choice", "task_categories:text-generation", "task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:language-modeling", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2109.07958", "region:us"], "private": false, "author": null, "description": "TruthfulQA is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.", "citation": "@misc{lin2021truthfulqa,\n    title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},\n    author={Stephanie Lin and Jacob Hilton and Owain Evans},\n    year={2021},\n    eprint={2109.07958},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "62a0b5b6d48dbca4bf369f45", "disabled": false, "gated": false, "likes": 84, "downloads": 1650503, "paperswithcode_id": "truthfulqa", "createdAt": "2022-06-08T14:44:06.000Z"}, {"id": "bigbench", "sha": "bc0c43d8b71c4216c18a03eee2431c7d87825e01", "lastModified": "2022-12-02T09:47:24.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:text-classification", "task_categories:text-generation", "task_categories:zero-shot-classification", "task_categories:other", "task_ids:multiple-choice-qa", "task_ids:extractive-qa", "task_ids:open-domain-qa", "task_ids:closed-domain-qa", "task_ids:fact-checking", "task_ids:acceptability-classification", "task_ids:intent-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:text-scoring", "task_ids:hate-speech-detection", "task_ids:language-modeling", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:machine-generated", "language_creators:other", "multilinguality:multilingual", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2206.04615", "region:us"], "private": false, "author": null, "description": "The Beyond the Imitation Game Benchmark (BIG-bench) is a collaborative benchmark intended to\nprobe large language models, and extrapolate their future capabilities.", "citation": "@misc{https://doi.org/10.48550/arxiv.2206.04615,\n  doi = {10.48550/ARXIV.2206.04615},\n  url = {https://arxiv.org/abs/2206.04615},\n  author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri\u00e0 and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Slone, Ambrose and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Madotto, Andrea and Santilli, Andrea and Stuhlm\u00fcller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karaka\u015f, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bart\u0142omiej and \u00d6zyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ram\u00edrez, C\u00e9sar Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and Gonz\u00e1lez, Daniel Mosegu\u00ed and Perszyk, Danielle and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Mart\u00ednez-Plumed, Fernando and Happ\u00e9, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and de Melo, Gerard and Kruszewski, Germ\u00e1n and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-L\u00f3pez, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Sch\u00fctze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fern\u00e1ndez and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Koco\u0144, Jan and Thompson, Jana and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Berant, Jonathan and Frohberg, J\u00f6rg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Col\u00f3n, Luis Oliveros and Metz, Luke and \u015eenel, L\u00fctfi Kerem and Bosma, Maarten and Sap, Maarten and ter Hoeve, Maartje and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ram\u00edrez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, M\u00e1ty\u00e1s and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Sw\u0119drowski, Micha\u0142 and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Mi\u0142kowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Delgado, Ram\u00f3n Risco and Milli\u00e8re, Rapha\u00ebl and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima,  and {Debnath} and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Th\u00e9o and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Telleen-Lawton, Timothy and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Zhao, Xinran and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi},\n  title = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}", "cardData": null, "siblings": [], "_id": "62a0dd4ebe7fa896d2ba113e", "disabled": false, "gated": false, "likes": 34, "downloads": 1007, "createdAt": "2022-06-08T17:33:02.000Z"}, {"id": "quickdraw", "sha": "83b2798ff72f7af66a4c0d255cf4549c9d33cb0e", "lastModified": "2023-06-26T12:09:26.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:machine-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:1704.03477", "region:us"], "private": false, "author": null, "description": "The Quick Draw Dataset is a collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!.\nThe drawings were captured as timestamped vectors, tagged with metadata including what the player was asked to draw and in which country the player was located.", "citation": "@article{DBLP:journals/corr/HaE17,\n  author    = {David Ha and\n               Douglas Eck},\n  title     = {A Neural Representation of Sketch Drawings},\n  journal   = {CoRR},\n  volume    = {abs/1704.03477},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.03477},\n  archivePrefix = {arXiv},\n  eprint    = {1704.03477},\n  timestamp = {Mon, 13 Aug 2018 16:48:30 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/HaE17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "62a1c3db6679492ca5ca0dc2", "disabled": false, "gated": false, "likes": 8, "downloads": 42, "paperswithcode_id": "quick-draw-dataset", "createdAt": "2022-06-09T09:56:43.000Z"}, {"id": "sil-ai/bloom-speech", "sha": "660956f28b0c98cf634d693dfb25156fceeef638", "lastModified": "2023-02-15T13:28:59.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ajz", "language:bam", "language:bi", "language:bis", "language:bjn", "language:bm", "language:boz", "language:bze", "language:bzi", "language:cak", "language:ceb", "language:chd", "language:chp", "language:clo", "language:csw", "language:en", "language:eng", "language:es", "language:fli", "language:fr", "language:fra", "language:gu", "language:guj", "language:hbb", "language:hi", "language:hin", "language:id", "language:ind", "language:jmx", "language:jra", "language:kan", "language:kbq", "language:kek", "language:kjb", "language:kmu", "language:kn", "language:kqr", "language:kwu", "language:loh", "language:mai", "language:mal", "language:mam", "language:mar", "language:ml", "language:mle", "language:mr", "language:my", "language:mya", "language:myk", "language:nas", "language:nsk", "language:nsn", "language:oj", "language:oji", "language:omw", "language:por", "language:pt", "language:quc", "language:sdk", "language:snk", "language:spa", "language:stk", "language:ta", "language:taj", "language:tam", "language:tbj", "language:tdc", "language:tgl", "language:tl", "language:tpi", "language:tuz", "language:tzj", "license:cc-by-nc-4.0", "license:cc-by-sa-4.0", "license:cc-by-nc-nd-4.0", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "sil-ai", "description": "Bloom-speech is a dataset of text aligned speech from bloomlibrary.org. This dataset contains over 50 languages including many low-resource languages. This dataset should be useful for training and/or testing speech-to-text or text-to-speech/ASR models.", "citation": "@InProceedings{huggingface:bloom-speech,\ntitle = {bloom-speech},\nauthor={Joshua Nemecek, Colin Leong, and Daniel Whitenack\n},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "62a1e2cc496d92f3521d72bf", "disabled": false, "gated": "auto", "likes": 16, "downloads": 70, "createdAt": "2022-06-09T12:08:44.000Z"}, {"id": "speechcolab/gigaspeech", "sha": "13eadc735ff81c0e0537276f729f2f391e594bb8", "lastModified": "2023-11-23T14:08:34.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "task_categories:text-to-audio", "multilinguality:monolingual", "language:en", "license:apache-2.0", "arxiv:2106.06909", "region:us"], "private": false, "author": "speechcolab", "description": "GigaSpeech is an evolving, multi-domain English speech recognition corpus with 10,000 hours of high quality\nlabeled audio suitable for supervised training, and 40,000 hours of total audio suitable for semi-supervised\nand unsupervised training. Around 40,000 hours of transcribed audio is first collected from audiobooks, podcasts\nand YouTube, covering both read and spontaneous speaking styles, and a variety of topics, such as arts, science,\nsports, etc. A new forced alignment and segmentation pipeline is proposed to create sentence segments suitable\nfor speech recognition training, and to filter out segments with low-quality transcription. For system training,\nGigaSpeech provides five subsets of different sizes, 10h, 250h, 1000h, 2500h, and 10000h.\nFor our 10,000-hour XL training subset, we cap the word error rate at 4% during the filtering/validation stage,\nand for all our other smaller training subsets, we cap it at 0%. The DEV and TEST evaluation sets, on the other hand,\nare re-processed by professional human transcribers to ensure high transcription quality.", "citation": "@article{DBLP:journals/corr/abs-2106-06909,\n  author    = {Guoguo Chen and\n               Shuzhou Chai and\n               Guanbo Wang and\n               Jiayu Du and\n               Wei{-}Qiang Zhang and\n               Chao Weng and\n               Dan Su and\n               Daniel Povey and\n               Jan Trmal and\n               Junbo Zhang and\n               Mingjie Jin and\n               Sanjeev Khudanpur and\n               Shinji Watanabe and\n               Shuaijiang Zhao and\n               Wei Zou and\n               Xiangang Li and\n               Xuchen Yao and\n               Yongqing Wang and\n               Yujun Wang and\n               Zhao You and\n               Zhiyong Yan},\n  title     = {GigaSpeech: An Evolving, Multi-domain {ASR} Corpus with 10, 000 Hours\n               of Transcribed Audio},\n  journal   = {CoRR},\n  volume    = {abs/2106.06909},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2106.06909},\n  eprinttype = {arXiv},\n  eprint    = {2106.06909},\n  timestamp = {Wed, 29 Dec 2021 14:29:26 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06909.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "62a2090e467d335eba288b8a", "disabled": false, "gated": "auto", "likes": 36, "downloads": 2942, "createdAt": "2022-06-09T14:51:58.000Z"}, {"id": "Theivaprakasham/wildreceipt", "sha": "05f68a2dbe784d24da08c4f35fda61a86a21d2e6", "lastModified": "2022-06-10T21:46:37.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Theivaprakasham", "description": "WildReceipt is a collection of receipts. It contains, for each photo, a list of OCRs - with the bounding box, text, and class. It contains 1765 photos, with 25 classes, and 50000 text boxes. The goal is to benchmark \"key information extraction\" - extracting key information from documents\nhttps://arxiv.org/abs/2103.14470", "citation": "@article{Sun2021SpatialDG,\n  title={Spatial Dual-Modality Graph Reasoning for Key Information Extraction},\n  author={Hongbin Sun and Zhanghui Kuang and Xiaoyu Yue and Chenhao Lin and Wayne Zhang},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2103.14470}\n}", "cardData": null, "siblings": [], "_id": "62a386f8c3608a37063ced20", "disabled": false, "gated": false, "likes": 5, "downloads": 35, "createdAt": "2022-06-10T18:01:28.000Z"}, {"id": "sagot/lefff_morpho", "sha": "9f599f415567235036fe3355b3f96c93f254d043", "lastModified": "2022-07-23T15:52:46.000Z", "tags": ["license:lgpl-lr", "region:us"], "private": false, "author": "sagot", "description": "The lefff-morpho dataset gives access to the morphological information, in both its original format and the UniMorph format.", "citation": "@inproceedings{sagot:inria-00521242,\n  TITLE = {{The Lefff, a freely available and large-coverage morphological and syntactic lexicon for French}},\n  AUTHOR = {Sagot, Beno{\\^i}t},\n  URL = {https://hal.inria.fr/inria-00521242},\n  BOOKTITLE = {{7th international conference on Language Resources and Evaluation (LREC 2010)}},\n  ADDRESS = {Valletta, Malta},\n  YEAR = {2010},\n  MONTH = May,\n  PDF = {https://hal.inria.fr/inria-00521242/file/lrec10lefff.pdf},\n  HAL_ID = {inria-00521242},\n  HAL_VERSION = {v1},\n}", "cardData": null, "siblings": [], "_id": "62a63c55c83b6f0409a2dce6", "disabled": false, "gated": false, "likes": 0, "downloads": 101, "createdAt": "2022-06-12T19:19:49.000Z"}, {"id": "sst2", "sha": "f295b0d3d80e030d59a3e1c6101166a274b64fac", "lastModified": "2023-05-02T12:53:26.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": null, "description": "The Stanford Sentiment Treebank consists of sentences from movie reviews and\nhuman annotations of their sentiment. The task is to predict the sentiment of a\ngiven sentence. We use the two-way (positive/negative) class split, and use only\nsentence-level labels.", "citation": "@inproceedings{socher2013recursive,\n  title={Recursive deep models for semantic compositionality over a sentiment treebank},\n  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew and Potts, Christopher},\n  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},\n  pages={1631--1642},\n  year={2013}\n}", "cardData": null, "siblings": [], "_id": "62a7434b8780c6d7291f6774", "disabled": false, "gated": false, "likes": 33, "downloads": 59683, "paperswithcode_id": "sst", "createdAt": "2022-06-13T14:01:47.000Z"}, {"id": "PiC/phrase_retrieval", "sha": "17dd9ee9f25a6d4c64be14e32af198cac68f6638", "lastModified": "2023-01-20T16:32:55.000Z", "tags": ["task_categories:text-retrieval", "annotations_creators:expert-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "PiC", "description": "Phrase in Context is a curated benchmark for phrase understanding and semantic search, consisting of three tasks of increasing difficulty: Phrase Similarity (PS), Phrase Retrieval (PR) and Phrase Sense Disambiguation (PSD). The datasets are annotated by 13 linguistic experts on Upwork and verified by two groups: ~1000 AMT crowdworkers and another set of 5 linguistic experts. PiC benchmark is distributed under CC-BY-NC 4.0.", "citation": "@article{pham2022PiC,\n  title={PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search},\n  author={Pham, Thang M and Yoon, Seunghyun and Bui, Trung and Nguyen, Anh},\n  journal={arXiv preprint arXiv:2207.09068},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "62a7a510a1065b904ec97219", "disabled": false, "gated": false, "likes": 5, "downloads": 52, "paperswithcode_id": "phrase-in-context", "createdAt": "2022-06-13T20:58:56.000Z"}, {"id": "taskydata/tasky_or_not", "sha": "45024356cf5bb984bedfe87b57ace5dca350c73b", "lastModified": "2023-05-31T03:30:14.000Z", "tags": ["task_categories:text-classification", "size_categories:10M<n<100M", "language:en", "license:mit", "region:us"], "private": false, "author": "taskydata", "description": "This dataset is a collection of prompted examples from P3, NI, RST, BigBench, FLAN & StackExchange, \nand examples from C4. The C4 examples are labeled \"not-task-like\" and the P3, NI, RST, BigBench, FLAN,\nStackExchange & UnNatural Instructions examples are \"task-like\". Examples were sampled from C4 so that \nthe distribution of example lengths is similar for C4, and P3, NI, RST, BigBench, FLAN, StackExchange \n& UnNatural Instructions examples. Some datasets from P3 were ignored because their examples were too \nlong. Some datasets from P3, BigBench, FLAN, StackExchange & UnNatural Instructions are held out for \nvalidation. The datasets from the train split of Natural Instuctions were used for creating the train \nset  of the tasky data while those from the test split were used in creating the validation set. \nNon-tasky validation data was gathered from C4 without intentionally matching the length distribution. \nTasky validation data was gathered from the validation set of certain held-out datasets from P3, NI, \nBigBench, FLAN, StackExchange & UnNatural Instructions.", "citation": null, "cardData": null, "siblings": [], "_id": "62a8ac5e4380c2dc3af8d127", "disabled": false, "gated": false, "likes": 0, "downloads": 92, "createdAt": "2022-06-14T15:42:22.000Z"}, {"id": "codeparrot/apps", "sha": "21e74ddf8de1a21436da12e3e653065c5213e9d1", "lastModified": "2022-10-20T15:00:15.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "language:code", "license:mit", "arxiv:2105.09938", "arxiv:2203.07814", "region:us"], "private": false, "author": "codeparrot", "description": "APPS is a benchmark for Python code generation, it includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges, for more details please refer to this paper: https://arxiv.org/pdf/2105.09938.pdf.", "citation": "@article{hendrycksapps2021,\n  title={Measuring Coding Challenge Competence With APPS},\n  author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},\n  journal={NeurIPS},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "62a9dc9a471f7e0783124b0d", "disabled": false, "gated": false, "likes": 56, "downloads": 23087, "createdAt": "2022-06-15T13:20:26.000Z"}, {"id": "fmplaza/offendes", "sha": "8c267a38fcde91dacc7edc0d39b7d632ac8a784b", "lastModified": "2023-03-27T08:19:06.000Z", "tags": ["language:es", "license:apache-2.0", "region:us"], "private": false, "author": "fmplaza", "description": "Focusing on young influencers from the well-known social platforms of Twitter, Instagram, and YouTube, \nwe have collected the corpus OffendES which is composed of Spanish comments manually labeled on offensive pre-defined categories. From the total corpus, we selected 30,416 \nposts to be publicly published, they correspond to the ones used in the MeOffendES competition at IberLEF 2021.", "citation": "@inproceedings{plaza-del-arco-etal-2021-offendes, \n\t\t\t\ttitle = \"{O}ffend{ES}: A New Corpus in {S}panish for Offensive Language Research\", \n\t\t\t\tauthor = \"{Plaza-del-Arco}, Flor Miriam and Montejo-R{'a}ez, \n\t\t\t\t\t\t  Arturo and Ure{~n}a-L{'o}pez, L. Alfonso and Mart\u00edn-Valdivia, \n\t\t\t\t\t\t  Mar\u00eda-Teresa\", \n\t\t\t\tbooktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\", \n\t\t\t\tmonth = sep, \n\t\t\t\tyear = \"2021\", \n\t\t\t\taddress = \"Held Online\",\n\t\t\t\tlanguage = \"English\", \n\t\t\t\tpages = \"1096--1108\" }", "cardData": null, "siblings": [], "_id": "62ab3ee30a9f695086a10144", "disabled": false, "gated": "auto", "likes": 8, "downloads": 94, "createdAt": "2022-06-16T14:32:03.000Z"}, {"id": "vesteinn/sosialurin-faroese-pos", "sha": "d530faa01d7d9be759260f752810691437473a25", "lastModified": "2022-06-16T15:49:46.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "vesteinn", "description": "The corpus that has been created consists of ca. 100.000 words of text from the [Faroese] newspaper Sosialurin. Each word is tagged with grammatical information (word class, gender, number etc.)", "citation": "@misc{sosialurin-pos,\n title = {Marking av teldut\u00f8kum tekstsavn},\n author = {Zakaris Svabo Hansen, Heini Justinussen, and Mortan\n\u00d3lason},\n url = {http://ark.axeltra.com/index.php?type=person&lng=en&id=18},\n year = {2004} }", "cardData": null, "siblings": [], "_id": "62ab4fd9d690953376df56ef", "disabled": false, "gated": false, "likes": 1, "downloads": 44, "createdAt": "2022-06-16T15:44:25.000Z"}, {"id": "vadis/sv-ident", "sha": "a5994401ede160334e601cf243bb5b632f2d1e32", "lastModified": "2022-11-07T20:51:06.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:semantic-similarity-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:de", "license:mit", "region:us"], "private": false, "author": "vadis", "description": "The SV-Ident corpus (version 0.3) is a collection of 4,248 expert-annotated English\nand German sentences from social science publications, supporting the task of\nmulti-label text classification.", "citation": "@misc{sv-ident,\n    author={vadis-project},\n    title={SV-Ident},\n    year={2022},\n    url={https://github.com/vadis-project/sv-ident},\n    }", "cardData": null, "siblings": [], "_id": "62ac3c40c35bb36ff0786bbb", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "paperswithcode_id": "sv-ident", "createdAt": "2022-06-17T08:33:04.000Z"}, {"id": "facebook/pmd", "sha": "decdb164025b593b707d36db2c9f79929ea66134", "lastModified": "2022-08-09T23:51:39.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:cc-by-4.0", "arxiv:2112.04482", "arxiv:2111.11431", "region:us"], "private": false, "author": "facebook", "description": "Introduced in FLAVA paper, Public Multimodal Dataset (PMD) is a collection of publicly-available image-text pairs datasets. PMD in total contains 70M image-text pairs with 68M unique images. The dataset contains pairs from Conceptual Captions, Conceptual Captions 12M, WIT, Localized Narratives, RedCaps, COCO, SBU Captions, Visual Genome and a subset of YFCC100M dataset.", "citation": "@inproceedings{singh2022flava,\n  title={Flava: A foundational language and vision alignment model},\n  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={15638--15650},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "62afc4df59823f71d7fa2c4d", "disabled": false, "gated": "auto", "likes": 28, "downloads": 102, "paperswithcode_id": "pmd", "createdAt": "2022-06-20T00:52:47.000Z"}, {"id": "JulesBelveze/tldr_news", "sha": "8fa2b4ee823448830f62d48cd0cd21357bede874", "lastModified": "2022-08-05T12:17:50.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "task_categories:text-generation", "task_ids:news-articles-headline-generation", "task_ids:text-simplification", "task_ids:language-modeling", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "region:us"], "private": false, "author": "JulesBelveze", "description": "The `tldr_news` dataset was constructed by collecting a daily tech newsletter (available at \nhttps://tldr.tech/newsletter). Then for every piece of news, the \"headline\" and its corresponding \"content\" were \ncollected. Such a dataset can be used to train a model to generate a headline from a input piece of text.", "citation": null, "cardData": null, "siblings": [], "_id": "62b1d7366a5435fd9a5f43bb", "disabled": false, "gated": false, "likes": 12, "downloads": 1088, "createdAt": "2022-06-21T14:35:34.000Z"}, {"id": "HuggingFaceM4/VQAv2", "sha": "4b98c864262e9db184eb039e85e97e6630825b6a", "lastModified": "2022-06-30T13:15:04.000Z", "tags": ["region:us"], "private": false, "author": "HuggingFaceM4", "description": "VQA is a new dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer.", "citation": "@InProceedings{VQA,\nauthor = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},\ntitle = {VQA: Visual Question Answering},\nbooktitle = {International Conference on Computer Vision (ICCV)},\nyear = {2015},\n}", "cardData": null, "siblings": [], "_id": "62b5c84ae8e8cdbd2a8850a7", "disabled": false, "gated": false, "likes": 8, "downloads": 2888, "createdAt": "2022-06-24T14:20:58.000Z"}, {"id": "launch/open_question_type", "sha": "1cf33ab60b1855c636eed32ca381dbac55116571", "lastModified": "2022-11-09T01:58:10.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "launch", "description": "Open-ended question type annotated dataset.", "citation": "@inproceedings{cao-wang-2021-controllable,\n    title = \"Controllable Open-ended Question Generation with A New Question Type Ontology\",\n    author = \"Cao, Shuyang  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.acl-long.502\",\n    doi = \"10.18653/v1/2021.acl-long.502\",\n    pages = \"6424--6439\",\n    abstract = \"We investigate the less-explored task of generating open-ended questions that are typically answered by multiple sentences. We first define a new question type ontology which differentiates the nuanced nature of questions better than widely used question words. A new dataset with 4,959 questions is labeled based on the new ontology. We then propose a novel question type-aware question generation framework, augmented by a semantic graph representation, to jointly predict question focuses and produce the question. Based on this framework, we further use both exemplars and automatically generated templates to improve controllability and diversity. Experiments on two newly collected large-scale datasets show that our model improves question quality over competitive comparisons based on automatic metrics. Human judges also rate our model outputs highly in answerability, coverage of scope, and overall quality. Finally, our model variants with templates can produce questions with enhanced controllability and diversity.\",\n}", "cardData": null, "siblings": [], "_id": "62bb6ade1295c3b9161c3abd", "disabled": false, "gated": false, "likes": 1, "downloads": 46, "createdAt": "2022-06-28T20:55:58.000Z"}, {"id": "ThierryZhou/test", "sha": "948743fa83750fa766c62a131ffa015d6cf990c9", "lastModified": "2022-08-22T02:13:10.000Z", "tags": ["task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:found", "language_creators:found", "source_datasets:original", "language:en", "arxiv:2111.11431", "region:us"], "private": false, "author": "ThierryZhou", "description": "Test (https://super.gluebenchmark.com/) is a new benchmark styled after\nGLUE with a new set of more difficult language understanding tasks, improved\nresources, and a new public leaderboard.", "citation": "@article{wang2019Test,\n  title={Test: A Stickier Benchmark for General-Purpose Language Understanding Systems},\n  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},\n  journal={arXiv preprint arXiv:1905.00537},\n  year={2019}\n}\nNote that each Test dataset has its own citation. Please see the source to\nget the correct citation for each contained dataset.", "cardData": null, "siblings": [], "_id": "62bbb991d8dda329d4c77c78", "disabled": false, "gated": false, "likes": 0, "downloads": 26, "paperswithcode_id": "test", "createdAt": "2022-06-29T02:31:45.000Z"}, {"id": "projecte-aina/catalanqa", "sha": "0888b80fd0a0f678cce1c6520ddd13e928e49442", "lastModified": "2023-11-25T04:47:38.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:ca", "license:cc-by-sa-4.0", "arxiv:1606.05250", "region:us"], "private": false, "author": "projecte-aina", "description": "CatalanQA: an extractive QA dataset from original Catalan Sources: Wikipedia and VilaWeb newswire.\n\n It is an aggregation and balancing of 2 previous datasets: VilaQUAD and ViquiQUAD, which were described in \n\nThis dataset can be used to build extractive-QA and Language Models.\n\nSplts have been balanced by kind of question, and unlike other datasets like SQUAD, it only contains, per record, one question and one answer for each context, although the contexts can repeat multiple times.\n\n- test.json \tcontains 2135 question/answer pairs\n\n- train.json \tcontains\t 17135 question/answer pairs\n\n- dev.json contains 2157 question/answer pairs\n\nFunded by the Generalitat de Catalunya, Departament de Pol\u00edtiques Digitals i Administraci\u00f3 P\u00fablica (AINA),\n and Plan de Impulso de las Tecnolog\u00edas del Lenguaje (Plan TL).", "citation": "None", "cardData": null, "siblings": [], "_id": "62bc6012d2c8a6542f40584e", "disabled": false, "gated": false, "likes": 1, "downloads": 205, "createdAt": "2022-06-29T14:22:10.000Z"}, {"id": "kensho/spgispeech", "sha": "94d6f34624770580411a759a1994bd437daf36d3", "lastModified": "2022-10-21T14:46:30.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:other", "arxiv:2104.02014", "region:us"], "private": false, "author": "kensho", "description": "The SPGISpeech corpus is derived from company earnings calls manually transcribed by S&P Global, Inc. according to a pro- fessional style guide detailing conventions for capitalization, punctuation, denormalization of non-standard words and tran- scription of disfluencies in spontaneous speech. The basic unit of SPGISpeech is a pair consisting of a 5 to 15 second long 16 bit, 16kHz mono wav audio file and its transcription..", "citation": "@ARTICLE{2021arXiv210402014O,\n       author = {{O'Neill}, Patrick K. and {Lavrukhin}, Vitaly and {Majumdar}, Somshubra and {Noroozi}, Vahid and {Zhang}, Yuekai and {Kuchaiev}, Oleksii and {Balam}, Jagadeesh and {Dovzhenko}, Yuliya and {Freyberg}, Keenan and {Shulman}, Michael D. and {Ginsburg}, Boris and {Watanabe}, Shinji and {Kucsko}, Georg},\n        title = \"{SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition}\",\n      journal = {arXiv e-prints},\n     keywords = {Computer Science - Computation and Language, Electrical Engineering and Systems Science - Audio and Speech Processing},\n         year = 2021,\n        month = apr,\n          eid = {arXiv:2104.02014},\n        pages = {arXiv:2104.02014},\narchivePrefix = {arXiv},\n       eprint = {2104.02014},\n primaryClass = {cs.CL},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210402014O},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}", "cardData": null, "siblings": [], "_id": "62bc7920966a5fcbfbf18efd", "disabled": false, "gated": "auto", "likes": 20, "downloads": 482, "createdAt": "2022-06-29T16:09:04.000Z"}, {"id": "codeparrot/github-code-clean", "sha": "c48d40f9e70f0196f8236901ee35807f7d6c44c0", "lastModified": "2022-07-05T09:35:14.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "codeparrot", "description": "The GitHub Code clean dataset in a more filtered version of codeparrot/github-code dataset, it consists of 115M code files from GitHub in 32 programming languages with 60 extensions totaling in almost 1TB of text data.", "citation": null, "cardData": null, "siblings": [], "_id": "62bcdb618d752f69a96e34eb", "disabled": false, "gated": false, "likes": 62, "downloads": 1914, "createdAt": "2022-06-29T23:08:17.000Z"}, {"id": "PolyAI/evi", "sha": "2e5f8d3dc550028d9ae1dbbb94476a6ae282134b", "lastModified": "2022-10-25T10:39:33.000Z", "tags": ["annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "language:en", "language:fr", "language:pl", "license:cc-by-4.0", "arxiv:2204.13496", "region:us"], "private": false, "author": "PolyAI", "description": "EVI is a challenging spoken multilingual dataset with 5,506 dialogues in English, Polish, and French \nthat can be used for benchmarking and developing knowledge-based enrolment, identification, and identification \nfor spoken dialogue systems.", "citation": "@inproceedings{Spithourakis2022evi,\n    author      = {Georgios P. Spithourakis and Ivan Vuli\\'{c} and Micha\\l{} Lis and I\\~{n}igo Casanueva and Pawe\\l{} Budzianowski},\n    title       = {{EVI}: Multilingual Spoken Dialogue Tasks and Dataset for Knowledge-Based Enrolment, Verification, and Identification},\n    year        = {2022},\n    note        = {Data available at https://github.com/PolyAI-LDN/evi-paper},\n    url         = {https://arxiv.org/abs/2204.13496},\n    booktitle   = {Findings of NAACL (publication pending)}\n}", "cardData": null, "siblings": [], "_id": "62bd8c35b01ce3b6a34ece64", "disabled": false, "gated": false, "likes": 2, "downloads": 20, "paperswithcode_id": "evi-multilingual-spoken-dialogue-tasks-and-1", "createdAt": "2022-06-30T11:42:45.000Z"}, {"id": "benschill/brain-tumor-collection", "sha": "fe18ffc594c9e8bade2ea0049f90d2e7d25ed7f7", "lastModified": "2022-07-04T08:26:59.000Z", "tags": ["license:pddl", "region:us"], "private": false, "author": "benschill", "description": "This dataset is intended as a test case for classification tasks (4 different kinds of brain xrays). The dataset consists of almost 1400 JPEG images grouped into two splits - training and validation. Each split contains 4 categories labeled as n0~n3, each corresponding to a cancer result of the mrt.\n\n\n| Label | Xray Category         | Train Images | Validation Images |\n| ----- | --------------------- | ------------ | ----------------- |\n| n0    | glioma_tumor          | 826          | 100               |\n| n1    | meningioma_tumor      | 822          | 115               |\n| n2    | pituitary_tumor       | 827          | 74                |\n| n3    | no_tumor              | 395          | 105               |", "citation": "@misc{kaggle-brain-tumor-classification,\n  title={Kaggle: Brain Tumor Classification (MRI)},\n  howpublished={\\\\url{https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri?resource=download}},\n  note = {Accessed: 2022-06-30},\n}", "cardData": null, "siblings": [], "_id": "62bec89b3aff257639ce23fd", "disabled": false, "gated": false, "likes": 1, "downloads": 18, "createdAt": "2022-07-01T10:12:43.000Z"}, {"id": "bigbio/scitail", "sha": "7b34cb148522a73022791027f729cc9518da2a05", "lastModified": "2023-03-31T02:11:26.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "bigbio", "description": "The SciTail dataset is an entailment dataset created from multiple-choice science exams and\nweb sentences. Each question and the correct answer choice are converted into an assertive\nstatement to form the hypothesis. We use information retrieval to obtain relevant text from\na large text corpus of web sentences, and use these sentences as a premise P. We crowdsource\nthe annotation of such premise-hypothesis pair as supports (entails) or not (neutral), in order\nto create the SciTail dataset. The dataset contains 27,026 examples with 10,101 examples with\nentails label and 16,925 examples with neutral label.", "citation": "@article{\n    Khot_Sabharwal_Clark_2018,\n    title={SciTaiL: A Textual Entailment Dataset from Science Question Answering},\n    volume={32},\n    url={https://ojs.aaai.org/index.php/AAAI/article/view/12022}, DOI={10.1609/aaai.v32i1.12022},\n    abstractNote={ &lt;p&gt; We present a new dataset and model for textual entailment, derived from treating multiple-choice question-answering as an entailment problem. SciTail is the first entailment set that is created solely from natural sentences that already exist independently ``in the wild\u2019\u2019 rather than sentences authored specifically for the entailment task. Different from existing entailment datasets, we create hypotheses from science questions and the corresponding answer candidates,\u00a0and premises from relevant web sentences retrieved from a large corpus. These sentences are often linguistically challenging. This, combined with the high lexical similarity of premise and hypothesis for both entailed and non-entailed pairs, makes this new entailment task particularly difficult.\u00a0The resulting challenge is evidenced by state-of-the-art textual entailment systems achieving mediocre performance on SciTail, especially in comparison to a simple majority class baseline. As a step forward, we demonstrate that one can improve accuracy on SciTail by 5% using a new neural model that exploits linguistic structure. &lt;/p&gt; },\n    number={1},\n    journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n    author={Khot, Tushar and Sabharwal, Ashish and Clark, Peter},\n    year={2018},\n    month={Apr.}\n}", "cardData": null, "siblings": [], "_id": "62c0b0543e7b8a5067d2749a", "disabled": false, "gated": false, "likes": 1, "downloads": 74, "paperswithcode_id": "scitail", "createdAt": "2022-07-02T20:53:40.000Z"}, {"id": "MicPie/unpredictable_mmo-champion-com", "sha": "85aaa66a7843304692990eea17bc3b89ef99aac5", "lastModified": "2022-08-04T20:09:49.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:zero-shot-classification", "task_categories:text2text-generation", "task_categories:table-question-answering", "task_categories:text-generation", "task_categories:text-classification", "task_categories:tabular-classification", "task_ids:multiple-choice-qa", "task_ids:extractive-qa", "task_ids:open-domain-qa", "task_ids:closed-domain-qa", "task_ids:closed-book-qa", "task_ids:open-book-qa", "task_ids:language-modeling", "task_ids:multi-class-classification", "task_ids:natural-language-inference", "task_ids:topic-classification", "task_ids:multi-label-classification", "task_ids:tabular-multi-class-classification", "task_ids:tabular-multi-label-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:apache-2.0", "arxiv:2208.01009", "region:us"], "private": false, "author": "MicPie", "description": "The UnpredicTable dataset consists of web tables formatted as few-shot tasks for fine-tuning language models to improve their few-shot performance. For more details please see the accompanying dataset card.", "citation": "@misc{chan2022few,\n  author = {Chan, Jun Shern and Pieler, Michael and Jao, Jonathan and Scheurer, J\u00e9r\u00e9my and Perez, Ethan},\n  title = {Few-shot Adaptation Works with UnpredicTable Data},\n  publisher={arXiv},\n  year = {2022},\n  url = {https://arxiv.org/abs/2208.01009}\n}", "cardData": null, "siblings": [], "_id": "62c1502a033f0c24127649bf", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2022-07-03T08:15:38.000Z"}, {"id": "BDas/Turkish-Dataset", "sha": "4d23111fad1b11390bf0ac0124e54c8f125e0dc9", "lastModified": "2022-09-16T07:34:57.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:tr", "license:other", "region:us"], "private": false, "author": "BDas", "description": "The dataset, prepared in Turkish, includes 53.000 tests, 53.000 validations and 160600 train data.\nThe data is composed of customer comments and created from e-commerce sites.", "citation": "----Turkish Data----", "cardData": null, "siblings": [], "_id": "62c343bec0b38d33090bec56", "disabled": false, "gated": false, "likes": 4, "downloads": 18, "createdAt": "2022-07-04T19:47:10.000Z"}, {"id": "SocialGrep/one-year-of-tsla-on-reddit", "sha": "574793eff62a8c25e1effd4edc0a6984f4ab40ad", "lastModified": "2022-07-07T18:54:18.000Z", "tags": ["annotations_creators:lexyr", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "SocialGrep", "description": "This dataset contains all the posts and comments mentioning the term \"TSLA\", spanning from July 5th, 2021 to July 4th, 2022.", "citation": null, "cardData": null, "siblings": [], "_id": "62c71685ef5c696df8889ead", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2022-07-07T17:23:17.000Z"}, {"id": "Heriot-WattUniversity/dialog_babi", "sha": "bbbbe1058950bad355118b9db17521683f12b0d2", "lastModified": "2022-07-12T08:27:12.000Z", "tags": ["arxiv:1605.07683", "arxiv:1502.05698", "region:us"], "private": false, "author": "Heriot-WattUniversity", "description": "This section presents the set of 6 tasks for testing end-to-end dialog systems in the restaurant domain described in the paper:\n\nAntoine Bordes, Y-Lan Boureau, Jason Weston, Learning End-to-End Goal-Oriented Dialog, arxiv:1605.07683.\n\nEach task tests a unique aspect of dialog. Tasks are designed to complement the set of 20 bAbI tasks for story understanding of the previous section.\n\nFor each task, there are 1000 dialogs for training, 1000 for development and 1000 for testing. For tasks 1-5, we also include a second test set (with suffix -OOV.txt) that contains dialogs including entities not present in training and development sets.", "citation": "@article{bordes2016learning,\n  title={Learning end-to-end goal-oriented dialog},\n  author={Bordes, Antoine and Boureau, Y-Lan and Weston, Jason},\n  journal={arXiv preprint arXiv:1605.07683},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "62c94b300011ffa7b3487706", "disabled": false, "gated": false, "likes": 2, "downloads": 13, "createdAt": "2022-07-09T09:32:32.000Z"}, {"id": "chenz16/curriculum_benchmark", "sha": "93689a9a52b0d0ecc12126b258a16f597150f230", "lastModified": "2022-07-11T01:51:34.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "chenz16", "description": "We introduce Curriculum as a new format of NLI benchmark for evaluation of broad-coverage linguistic phenomena. \nCurriculum contains a collection of datasets that covers 36 types of major linguistic phenomena and an evaluation procedure \nfor diagnosing how well a language model captures reasoning skills for distinct types of linguistic phenomena. \nWe show that this linguistic-phenomena-driven benchmark can serve as an effective tool for diagnosing \nmodel behavior and verifying model learning quality.", "citation": "@misc{https://doi.org/10.48550/arxiv.2204.06283,\n  doi = {10.48550/ARXIV.2204.06283},\n  url = {https://arxiv.org/abs/2204.06283},\n  author = {Chen, Zeming and Gao, Qiyue},\n  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "62cb81ffb189b6164d303efe", "disabled": false, "gated": false, "likes": 0, "downloads": 63, "createdAt": "2022-07-11T01:50:55.000Z"}, {"id": "biglam/brill_iconclass", "sha": "1c44bf464035180fe923b8837652ac79536214cf", "lastModified": "2023-07-25T13:38:02.000Z", "tags": ["task_categories:image-classification", "task_categories:image-to-text", "task_categories:feature-extraction", "task_ids:multi-class-image-classification", "task_ids:multi-label-image-classification", "task_ids:image-captioning", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:other-iconclass-metadata", "size_categories:10K<n<100K", "license:cc0-1.0", "lam", "art", "region:us"], "private": false, "author": "biglam", "description": "A dataset for applying machine learning to collections described with the Iconclass classification system.", "citation": "@MISC{iconclass,\ntitle = {Brill Iconclass AI Test Set},\nauthor={Etienne Posthumus},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "62cc22a902e7a64f33a05e52", "disabled": false, "gated": false, "likes": 6, "downloads": 28, "createdAt": "2022-07-11T13:16:25.000Z"}, {"id": "biglam/atypical_animacy", "sha": "46abc30ea992972e8838b5b42c386536c47c0054", "lastModified": "2022-07-22T17:29:12.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:intent-classification", "annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc0-1.0", "arxiv:2005.11140", "region:us"], "private": false, "author": "biglam", "description": "Atypical animacy detection dataset, based on nineteenth-century sentences in English extracted from an open dataset of nineteenth-century books digitized by the British Library (available via https://doi.org/10.21250/db14, British Library Labs, 2014). \nThis dataset contains 598 sentences containing mentions of machines. Each sentence has been annotated according to the animacy and humanness of the machine in the sentence.", "citation": "@article{DBLP:journals/corr/abs-2005-11140,\n  author    = {Mariona Coll Ardanuy and\n               Federico Nanni and\n               Kaspar Beelen and\n               Kasra Hosseini and\n               Ruth Ahnert and\n               Jon Lawrence and\n               Katherine McDonough and\n               Giorgia Tolfo and\n               Daniel C. S. Wilson and\n               Barbara McGillivray},\n  title     = {Living Machines: {A} study of atypical animacy},\n  journal   = {CoRR},\n  volume    = {abs/2005.11140},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2005.11140},\n  eprinttype = {arXiv},\n  eprint    = {2005.11140},\n  timestamp = {Sat, 23 Jan 2021 01:12:25 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-11140.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "62cc9713abd6e726e425e006", "disabled": false, "gated": false, "likes": 3, "downloads": 20, "createdAt": "2022-07-11T21:33:07.000Z"}, {"id": "codeparrot/xlcost-text-to-code", "sha": "60c5c133f043a5cffe162f9de1c62b9d88f309cf", "lastModified": "2022-10-25T09:30:47.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "language:code", "license:cc-by-sa-4.0", "arxiv:2206.08474", "region:us"], "private": false, "author": "codeparrot", "description": " XLCoST is a machine learning benchmark dataset that contains fine-grained parallel data in 7 commonly used programming languages (C++, Java, Python, C#, Javascript, PHP, C), and natural language (English).", "citation": "@misc{zhu2022xlcost,\n     title = {XLCoST: A Benchmark Dataset for Cross-lingual Code Intelligence},\n     url = {https://arxiv.org/abs/2206.08474},\n     author = {Zhu, Ming and Jain, Aneesh and Suresh, Karthik and Ravindran, Roshan and Tipirneni, Sindhu and Reddy, Chandan K.},\n     year = {2022},\n     eprint={2206.08474},\n     archivePrefix={arXiv}\n}", "cardData": null, "siblings": [], "_id": "62cf0b3da3a23014acaa227a", "disabled": false, "gated": false, "likes": 25, "downloads": 634, "createdAt": "2022-07-13T18:13:17.000Z"}, {"id": "facebook/flores", "sha": "80dc3040d19756742c9a18267ab30f54fb8e226b", "lastModified": "2022-08-09T20:27:39.000Z", "tags": ["annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|flores", "language:ace", "language:acm", "language:acq", "language:aeb", "language:af", "language:ajp", "language:ak", "language:als", "language:am", "language:apc", "language:ar", "language:ars", "language:ary", "language:arz", "language:as", "language:ast", "language:awa", "language:ayr", "language:azb", "language:azj", "language:ba", "language:bm", "language:ban", "language:be", "language:bem", "language:bn", "language:bho", "language:bjn", "language:bo", "language:bs", "language:bug", "language:bg", "language:ca", "language:ceb", "language:cs", "language:cjk", "language:ckb", "language:crh", "language:cy", "language:da", "language:de", "language:dik", "language:dyu", "language:dz", "language:el", "language:en", "language:eo", "language:et", "language:eu", "language:ee", "language:fo", "language:fj", "language:fi", "language:fon", "language:fr", "language:fur", "language:fuv", "language:gaz", "language:gd", "language:ga", "language:gl", "language:gn", "language:gu", "language:ht", "language:ha", "language:he", "language:hi", "language:hne", "language:hr", "language:hu", "language:hy", "language:ig", "language:ilo", "language:id", "language:is", "language:it", "language:jv", "language:ja", "language:kab", "language:kac", "language:kam", "language:kn", "language:ks", "language:ka", "language:kk", "language:kbp", "language:kea", "language:khk", "language:km", "language:ki", "language:rw", "language:ky", "language:kmb", "language:kmr", "language:knc", "language:kg", "language:ko", "language:lo", "language:lij", "language:li", "language:ln", "language:lt", "language:lmo", "language:ltg", "language:lb", "language:lua", "language:lg", "language:luo", "language:lus", "language:lvs", "language:mag", "language:mai", "language:ml", "language:mar", "language:min", "language:mk", "language:mt", "language:mni", "language:mos", "language:mi", "language:my", "language:nl", "language:nn", "language:nb", "language:npi", "language:nso", "language:nus", "language:ny", "language:oc", "language:ory", "language:pag", "language:pa", "language:pap", "language:pbt", "language:pes", "language:plt", "language:pl", "language:pt", "language:prs", "language:quy", "language:ro", "language:rn", "language:ru", "language:sg", "language:sa", "language:sat", "language:scn", "language:shn", "language:si", "language:sk", "language:sl", "language:sm", "language:sn", "language:sd", "language:so", "language:st", "language:es", "language:sc", "language:sr", "language:ss", "language:su", "language:sv", "language:swh", "language:szl", "language:ta", "language:taq", "language:tt", "language:te", "language:tg", "language:tl", "language:th", "language:ti", "language:tpi", "language:tn", "language:ts", "language:tk", "language:tum", "language:tr", "language:tw", "language:tzm", "language:ug", "language:uk", "language:umb", "language:ur", "language:uzn", "language:vec", "language:vi", "language:war", "language:wo", "language:xh", "language:ydd", "language:yo", "language:yue", "language:zh", "language:zsm", "language:zu", "license:cc-by-sa-4.0", "arxiv:2207.04672", "region:us"], "private": false, "author": "facebook", "description": "The creation of FLORES-200 doubles the existing language coverage of FLORES-101. \nGiven the nature of the new languages, which have less standardization and require \nmore specialized professional translations, the verification process became more complex. \nThis required modifications to the translation workflow. FLORES-200 has several languages \nwhich were not translated from English. Specifically, several languages were translated \nfrom Spanish, French, Russian and Modern Standard Arabic. Moreover, FLORES-200 also \nincludes two script alternatives for four languages. FLORES-200 consists of translations \nfrom 842 distinct web articles, totaling 3001 sentences. These sentences are divided \ninto three splits: dev, devtest, and test (hidden). On average, sentences are approximately \n21 words long.", "citation": "@article{nllb2022,\n  author    = {NLLB Team, Marta R. Costa-juss\u00e0, James Cross, Onur \u00c7elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm\u00e1n, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\n  year      = {2022}\n}\n\n@inproceedings{,\n  title={The FLORES-101  Evaluation Benchmark for Low-Resource and Multilingual Machine Translation},\n  author={Goyal, Naman and Gao, Cynthia and Chaudhary, Vishrav and Chen, Peng-Jen and Wenzek, Guillaume and Ju, Da and Krishnan, Sanjana and Ranzato, Marc'Aurelio and Guzm\\'{a}n, Francisco and Fan, Angela},\n  year={2021}\n}\n\n@inproceedings{,\n  title={Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English},\n  author={Guzm\\'{a}n, Francisco and Chen, Peng-Jen and Ott, Myle and Pino, Juan and Lample, Guillaume and Koehn, Philipp and Chaudhary, Vishrav and Ranzato, Marc'Aurelio},\n  journal={arXiv preprint arXiv:1902.01382},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "62cf350a180d2ba1cd013ead", "disabled": false, "gated": false, "likes": 28, "downloads": 86540, "paperswithcode_id": "flores", "createdAt": "2022-07-13T21:11:38.000Z"}, {"id": "demelin/moral_stories", "sha": "b830cf56eb00bc4edd1860dd544a192216eb3587", "lastModified": "2022-07-17T15:29:10.000Z", "tags": ["task_categories:multiple-choice", "task_categories:text-generation", "task_categories:text-classification", "task_ids:multiple-choice-qa", "task_ids:language-modeling", "task_ids:text-scoring", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:mit", "region:us"], "private": false, "author": "demelin", "description": "Moral Stories is a crowd-sourced dataset of structured, branching narratives for the study of grounded, goal-oriented \nsocial reasoning. For detailed information, see https://aclanthology.org/2021.emnlp-main.54.pdf.", "citation": "@article{Emelin2021MoralSS,\n  title={Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences},\n  author={Denis Emelin and Ronan Le Bras and Jena D. Hwang and Maxwell Forbes and Yejin Choi},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2012.15738}\n}", "cardData": null, "siblings": [], "_id": "62cffbd84b3e8dc1e32eabe8", "disabled": false, "gated": false, "likes": 12, "downloads": 299, "createdAt": "2022-07-14T11:19:52.000Z"}, {"id": "demelin/wino_x", "sha": "79a0451ac1f2e0b1512e25f1a56839e4eb941c48", "lastModified": "2022-07-15T22:28:18.000Z", "tags": ["task_categories:translation", "task_ids:multiple-choice-qa", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:de", "language:fr", "language:ru", "license:mit", "region:us"], "private": false, "author": "demelin", "description": "Wino-X is a parallel dataset of German, French, and Russian Winograd schemas, aligned with their English \ncounterparts, used to examine whether neural machine translation models can perform coreference resolution that \nrequires commonsense knowledge and whether multilingual language models are capable of commonsense reasoning across \nmultiple languages.", "citation": "@inproceedings{Emelin2021WinoXMW,\n  title={Wino-X: Multilingual Winograd Schemas for Commonsense Reasoning and Coreference Resolution},\n  author={Denis Emelin and Rico Sennrich},\n  booktitle={EMNLP},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "62cffc333c54a34d508c027d", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "createdAt": "2022-07-14T11:21:23.000Z"}, {"id": "ArthurBaia/squad_v1_pt_br", "sha": "3221702053e2bb473803a6fc25db782035951405", "lastModified": "2022-11-09T15:34:43.000Z", "tags": ["region:us"], "private": false, "author": "ArthurBaia", "description": "This dataset was translated by Deep Learning Brazil", "citation": "@article{2016arXiv160605250R,\n       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n                 Konstantin and {Liang}, Percy},\n        title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n      journal = {arXiv e-prints},\n         year = 2016,\n          eid = {arXiv:1606.05250},\n        pages = {arXiv:1606.05250},\narchivePrefix = {arXiv},\n       eprint = {1606.05250},\n}", "cardData": null, "siblings": [], "_id": "62d0749c485856cd710ee34a", "disabled": false, "gated": false, "likes": 3, "downloads": 101, "createdAt": "2022-07-14T19:55:08.000Z"}, {"id": "colbertv2/lotte", "sha": "1a87807da631e4197d77f7e720c38941abcf26d1", "lastModified": "2022-08-04T17:55:59.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2112.01488", "region:us"], "private": false, "author": "colbertv2", "description": "LoTTE Passages Dataset for ColBERTv2", "citation": "@inproceedings{santhanam-etal-2022-colbertv2,\n    title = \"{C}ol{BERT}v2: Effective and Efficient Retrieval via Lightweight Late Interaction\",\n    author = \"Santhanam, Keshav  and\n      Khattab, Omar  and\n      Saad-Falcon, Jon  and\n      Potts, Christopher  and\n      Zaharia, Matei\",\n    booktitle = \"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jul,\n    year = \"2022\",\n    address = \"Seattle, United States\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.naacl-main.272\",\n    pages = \"3715--3734\",\n    abstract = \"Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce Maize, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate Maize across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 6{--}10x.\",\n}", "cardData": null, "siblings": [], "_id": "62d0949bcf3a93c9335760ab", "disabled": false, "gated": false, "likes": 1, "downloads": 441, "createdAt": "2022-07-14T22:11:39.000Z"}, {"id": "nbroad/mediasum", "sha": "bcbcef7de3b4e702e526352d825a4ff06de2becb", "lastModified": "2022-10-25T10:40:11.000Z", "tags": ["task_categories:summarization", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:cc-by-nc-sa-4.0", "arxiv:2103.06410", "region:us"], "private": false, "author": "nbroad", "description": "This large-scale media interview dataset contains 463.6K transcripts with abstractive summaries, \ncollected from interview transcripts and overview / topic descriptions from NPR and CNN.", "citation": "@article{zhu2021mediasum,\n  title={MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization},\n  author={Zhu, Chenguang and Liu, Yang and Mei, Jie and Zeng, Michael},\n  journal={arXiv preprint arXiv:2103.06410},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "62d1df5bc58f969c152900bb", "disabled": false, "gated": false, "likes": 1, "downloads": 16, "createdAt": "2022-07-15T21:42:51.000Z"}, {"id": "tner/conll2003", "sha": "b18612dee0007b1f7129731dbf2f5f2ed4039ad3", "lastModified": "2022-07-18T00:43:28.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:other", "region:us"], "private": false, "author": "tner", "description": "[CoNLL 2003 NER dataset](https://aclanthology.org/W03-0419/)", "citation": "@inproceedings{tjong-kim-sang-de-meulder-2003-introduction,\n    title = \"Introduction to the {C}o{NLL}-2003 Shared Task: Language-Independent Named Entity Recognition\",\n    author = \"Tjong Kim Sang, Erik F.  and De Meulder, Fien\",\n    booktitle = \"Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003\",\n    year = \"2003\",\n    url = \"https://www.aclweb.org/anthology/W03-0419\",\n    pages = \"142--147\",\n}", "cardData": null, "siblings": [], "_id": "62d2954d7e2b9b625ef0a0bd", "disabled": false, "gated": false, "likes": 1, "downloads": 21, "createdAt": "2022-07-16T10:39:09.000Z"}, {"id": "tner/wnut2017", "sha": "068c8163eee17ea24bdc86211efeaa9001b57c33", "lastModified": "2022-08-06T23:30:30.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "multilinguality:monolingual", "size_categories:1k<10K", "language:en", "license:other", "region:us"], "private": false, "author": "tner", "description": "[WNUT 2017 NER dataset](https://aclanthology.org/W17-4418/)", "citation": "@inproceedings{derczynski-etal-2017-results,\n    title = \"Results of the {WNUT}2017 Shared Task on Novel and Emerging Entity Recognition\",\n    author = \"Derczynski, Leon  and\n      Nichols, Eric  and\n      van Erp, Marieke  and\n      Limsopatham, Nut\",\n    booktitle = \"Proceedings of the 3rd Workshop on Noisy User-generated Text\",\n    month = sep,\n    year = \"2017\",\n    address = \"Copenhagen, Denmark\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W17-4418\",\n    doi = \"10.18653/v1/W17-4418\",\n    pages = \"140--147\",\n    abstract = \"This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. Named entities form the basis of many modern approaches to other tasks (like event clustering and summarization), but recall on them is a real problem in noisy text - even among annotators. This drop tends to be due to novel entities and surface forms. Take for example the tweet {``}so.. kktny in 30 mins?!{''} {--} even human experts find the entity {`}kktny{'} hard to detect and resolve. The goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these entities. The task as described in this paper evaluated the ability of participating entries to detect and classify novel and emerging named entities in noisy text.\",\n}", "cardData": null, "siblings": [], "_id": "62d29c2826213de379a05ae3", "disabled": false, "gated": false, "likes": 0, "downloads": 84, "createdAt": "2022-07-16T11:08:24.000Z"}, {"id": "tner/bc5cdr", "sha": "f68cdc7db924369241e7868656f583072acd4e90", "lastModified": "2022-07-18T00:43:04.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:other", "region:us"], "private": false, "author": "tner", "description": "[Bio Creative 5 CDR NER dataset](https://academic.oup.com/database/article/doi/10.1093/database/baw032/2630271?login=true)", "citation": "@article{wei2016assessing,\n  title={Assessing the state of the art in biomedical relation extraction: overview of the BioCreative V chemical-disease relation (CDR) task},\n  author={Wei, Chih-Hsuan and Peng, Yifan and Leaman, Robert and Davis, Allan Peter and Mattingly, Carolyn J and Li, Jiao and Wiegers, Thomas C and Lu, Zhiyong},\n  journal={Database},\n  volume={2016},\n  year={2016},\n  publisher={Oxford Academic}\n}", "cardData": null, "siblings": [], "_id": "62d29c5c498762ed5f3acfdf", "disabled": false, "gated": false, "likes": 1, "downloads": 958, "createdAt": "2022-07-16T11:09:16.000Z"}, {"id": "Muennighoff/flores200", "sha": "79801d1422b50e686bd8303bfe6ccb2248e0884f", "lastModified": "2023-10-05T14:56:26.000Z", "tags": ["task_categories:text2text-generation", "task_categories:translation", "annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|flores", "license:cc-by-sa-4.0", "conditional-text-generation", "arxiv:2207.04672", "region:us"], "private": false, "author": "Muennighoff", "description": ">The creation of FLORES200 doubles the existing language coverage of FLORES-101. \nGiven the nature of the new languages, which have less standardization and require \nmore specialized professional translations, the verification process became more complex. \nThis required modifications to the translation workflow. FLORES-200 has several languages \nwhich were not translated from English. Specifically, several languages were translated \nfrom Spanish, French, Russian and Modern Standard Arabic. Moreover, FLORES-200 also \nincludes two script alternatives for four languages. FLORES-200 consists of translations \nfrom 842 distinct web articles, totaling 3001 sentences. These sentences are divided \ninto three splits: dev, devtest, and test (hidden). On average, sentences are approximately \n21 words long.", "citation": "@article{nllb2022,\n  author    = {NLLB Team, Marta R. Costa-juss\u00e0, James Cross, Onur \u00c7elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm\u00e1n, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\n  year      = {2022}\n}", "cardData": null, "siblings": [], "_id": "62d3c44a24a626ee94747a43", "disabled": false, "gated": false, "likes": 4, "downloads": 59784, "paperswithcode_id": "flores", "createdAt": "2022-07-17T08:11:54.000Z"}, {"id": "Muennighoff/xwinograd", "sha": "e98b9216f60fc8dbabfe766e014534a08ff01949", "lastModified": "2023-07-07T08:27:03.000Z", "tags": ["language:en", "language:fr", "language:ja", "language:pt", "language:ru", "language:zh", "license:cc-by-4.0", "arxiv:2211.01786", "arxiv:2106.12066", "region:us"], "private": false, "author": "Muennighoff", "description": "A multilingual collection of Winograd Schemas in six languages that can be used for evaluation of cross-lingual commonsense reasoning capabilities.", "citation": "@misc{muennighoff2022crosslingual,\n      title={Crosslingual Generalization through Multitask Finetuning}, \n      author={Niklas Muennighoff and Thomas Wang and Lintang Sutawika and Adam Roberts and Stella Biderman and Teven Le Scao and M Saiful Bari and Sheng Shen and Zheng-Xin Yong and Hailey Schoelkopf and Xiangru Tang and Dragomir Radev and Alham Fikri Aji and Khalid Almubarak and Samuel Albanie and Zaid Alyafeai and Albert Webson and Edward Raff and Colin Raffel},\n      year={2022},\n      eprint={2211.01786},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@misc{tikhonov2021heads,\n    title={It's All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual Transfer in Commonsense Reasoning},\n    author={Alexey Tikhonov and Max Ryabinin},\n    year={2021},\n    eprint={2106.12066},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "62d428a997ab9eb0875c2af3", "disabled": false, "gated": false, "likes": 4, "downloads": 15190, "createdAt": "2022-07-17T15:20:09.000Z"}, {"id": "pyronear/openfire", "sha": "787af29673533c61886956a44fb0093850abed52", "lastModified": "2022-12-11T22:25:43.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "size_categories:1K<n<10K", "source_datasets:original", "license:apache-2.0", "region:us"], "private": false, "author": "pyronear", "description": "OpenFire is an image classification dataset for wildfire detection, collected\nfrom web searches.", "citation": "@software{Pyronear_PyroVision_2019,\n    title={Pyrovision: wildfire early detection},\n    author={Pyronear contributors},\n    year={2019},\n    month={October},\n    publisher = {GitHub},\n    url = {https://github.com/pyronear/pyro-vision}\n}", "cardData": null, "siblings": [], "_id": "62d434aac8d5db57902a33ad", "disabled": false, "gated": false, "likes": 2, "downloads": 131, "createdAt": "2022-07-17T16:11:22.000Z"}, {"id": "biglam/clmet_3_1", "sha": "3f8fe90b59fe1958fe39583b5d74e398d882f1ed", "lastModified": "2022-07-18T02:14:38.000Z", "tags": ["task_categories:text-classification", "task_categories:fill-mask", "task_ids:multi-label-classification", "task_ids:masked-language-modeling", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "biglam", "description": "The Corpus of Late Modern English Texts, version 3.1 (CLMET3.1) has been created by Hendrik De Smet, \nSusanne Flach, Hans-J\u00fcrgen Diller and Jukka Tyrkk\u00f6, as an offshoot of a bigger project developing a database of text \ndescriptors (Diller, De Smet & Tyrkk\u00f6 2011). CLMET3.1 is a principled collection of public domain texts drawn from \nvarious online archiving projects. This dataset can be used for part-of-speech tagging, NER and text classification", "citation": "@article{de2015corpus,\n  title={Corpus of Late Modern English texts (version 3.1)},\n  author={De Smet, Hendrik and Flach, Susanne and Tyrkk{\\\"o}, Jukka and Diller, Hans-J{\\\"u}rgen},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "62d49ac8c8d5db57902eafc2", "disabled": false, "gated": false, "likes": 0, "downloads": 46, "createdAt": "2022-07-17T23:27:04.000Z"}, {"id": "frgfm/imagenette", "sha": "a8a496123b40fa739da2acf9b0dae339d30c7bae", "lastModified": "2022-12-11T22:26:06.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "size_categories:1K<n<10K", "source_datasets:extended", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "frgfm", "description": "Imagenette is a subset of 10 easily classified classes from Imagenet\n(tench, English springer, cassette player, chain saw, church, French\nhorn, garbage truck, gas pump, golf ball, parachute).", "citation": "@software{Howard_Imagenette_2019,\n    title={Imagenette: A smaller subset of 10 easily classified classes from Imagenet},\n    author={Jeremy Howard},\n    year={2019},\n    month={March},\n    publisher = {GitHub},\n    url = {https://github.com/fastai/imagenette}\n}", "cardData": null, "siblings": [], "_id": "62d4a5afd5943ccb471b5494", "disabled": false, "gated": false, "likes": 7, "downloads": 1368, "paperswithcode_id": "imagenette", "createdAt": "2022-07-18T00:13:35.000Z"}, {"id": "allenai/mslr2022", "sha": "a3c510486e8715aeb27ffb9e3846d2a6ca0f3500", "lastModified": "2022-11-18T21:16:10.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other-MS^2", "source_datasets:extended|other-Cochrane", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "allenai", "description": "The Multidocument Summarization for Literature Review (MSLR) Shared Task aims to study how medical\nevidence from different clinical studies are summarized in literature reviews. Reviews provide the\nhighest quality of evidence for clinical care, but are expensive to produce manually.\n(Semi-)automation via NLP may facilitate faster evidence synthesis without sacrificing rigor.\nThe MSLR shared task uses two datasets to assess the current state of multidocument summarization\nfor this task, and to encourage the development of modeling contributions, scaffolding tasks, methods\nfor model interpretability, and improved automated evaluation methods in this domain.", "citation": "@inproceedings{DeYoung2021MS2MS,\n    title        = {MS\u02c62: Multi-Document Summarization of Medical Studies},\n    author       = {Jay DeYoung and Iz Beltagy and Madeleine van Zuylen and Bailey Kuehl and Lucy Lu Wang},\n    booktitle    = {EMNLP},\n    year         = {2021}\n}\n@article{Wallace2020GeneratingN,\n    title        = {Generating (Factual?) Narrative Summaries of RCTs: Experiments with Neural Multi-Document Summarization},\n    author       = {Byron C. Wallace and Sayantani Saha and Frank Soboczenski and Iain James Marshall},\n    year         = 2020,\n    journal      = {AMIA Annual Symposium},\n    volume       = {abs/2008.11293}\n}", "cardData": null, "siblings": [], "_id": "62d589381fa3e4e7ae37e8e1", "disabled": false, "gated": false, "likes": 6, "downloads": 1850, "paperswithcode_id": "multi-document-summarization", "createdAt": "2022-07-18T16:24:24.000Z"}, {"id": "Muennighoff/mbpp", "sha": "d81b8291e5998f5726ab7f35a0a557e761532aac", "lastModified": "2022-10-20T19:43:58.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-4.0", "code-generation", "arxiv:2108.07732", "region:us"], "private": false, "author": "Muennighoff", "description": "The MBPP (Mostly Basic Python Problems) dataset consists of around 1,000 crowd-sourced Python\nprogramming problems, designed to be solvable by entry level programmers, covering programming\nfundamentals, standard library functionality, and so on. Each problem consists of a task\ndescription, code solution and 3 automated test cases.", "citation": "@article{austin2021program,\n  title={Program Synthesis with Large Language Models},\n  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},\n  journal={arXiv preprint arXiv:2108.07732},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "62d5aef15c29ac61fecb03ca", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-07-18T19:05:21.000Z"}, {"id": "biglam/lampeter_corpus", "sha": "24b7cc19e0ca633cccf49ad39a42e8feca1ac4d1", "lastModified": "2022-09-15T15:52:46.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:multi-class-classification", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "biglam", "description": "The Lampeter Corpus of Early Modern English Tracts is a collection of texts on\n various subject matter published between 1640 and 1740 \u2013 a time that is marked by the rise of mass \n publication, the development of a public discourse in many areas of everyday life \n and, last but not least, the standardisation of British English.", "citation": "@misc{20.500.12024/3193,\n title = {The Lampeter Corpus of Early Modern English Tracts},\n url = {http://hdl.handle.net/20.500.12024/3193},\n note = {Oxford Text Archive},\n copyright = {Distributed by the University of Oxford under a Creative Commons Attribution-{ShareAlike} 3.0 Unported License},", "cardData": null, "siblings": [], "_id": "62d5d1994d766e27a46f3e7c", "disabled": false, "gated": false, "likes": 1, "downloads": 25, "createdAt": "2022-07-18T21:33:13.000Z"}, {"id": "breakend/nllb-multi-domain", "sha": "017c5c5cada61bfacf5431573b0d054d7a9ce6c6", "lastModified": "2022-08-09T20:44:23.000Z", "tags": ["annotations_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:unknown", "source_datasets:extended|flores", "language:en", "language:ru", "language:ayr", "language:bho", "language:dyu", "language:fur", "language:wol", "license:cc-by-sa-4.0", "arxiv:2207.04672", "region:us"], "private": false, "author": "breakend", "description": "NLLB Multi Domain is a set of professionally-translated sentences in News, Unscripted informal speech, and Health domains. It is designed to enable assessment of out-of-domain performance and to study domain adaptation for machine translation. Each domain has approximately 3000 sentences.", "citation": "@article{nllb2022,\n  author    = {NLLB Team, Marta R. Costa-juss\u00e0, James Cross, Onur \u00c7elebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzm\u00e1n, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\n  year      = {2022}\n}", "cardData": null, "siblings": [], "_id": "62d5e661b6ced8fbf39a9668", "disabled": false, "gated": false, "likes": 1, "downloads": 29, "paperswithcode_id": "flores", "createdAt": "2022-07-18T23:01:53.000Z"}, {"id": "LanceaKing/asvspoof2019", "sha": "9e3c700a884eb823b3b6c9bd993f3197cdfdacb6", "lastModified": "2022-11-11T08:41:54.000Z", "tags": ["task_categories:audio-classification", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|vctk", "language:en", "license:odc-by", "voice-anti-spoofing", "arxiv:1911.01601", "region:us"], "private": false, "author": "LanceaKing", "description": "This is a database used for the Third Automatic Speaker Verification Spoofing\nand Countermeasuers Challenge, for short, ASVspoof 2019 (http://www.asvspoof.org)\norganized by Junichi Yamagishi, Massimiliano Todisco, Md Sahidullah, H\u00e9ctor\nDelgado, Xin Wang, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Ville Vestman,\nand Andreas Nautsch in 2019.", "citation": "@InProceedings{Todisco2019,\n  Title     = {{ASV}spoof 2019: {F}uture {H}orizons in {S}poofed and {F}ake {A}udio {D}etection},\n  Author    = {Todisco, Massimiliano and\n               Wang, Xin and\n               Sahidullah, Md and\n               Delgado, H \u0301ector and\n               Nautsch, Andreas and\n               Yamagishi, Junichi and\n               Evans, Nicholas and\n               Kinnunen, Tomi and\n               Lee, Kong Aik},\n  booktitle = {Proc. of Interspeech 2019},\n  Year      = {2019}\n}", "cardData": null, "siblings": [], "_id": "62d7bcf4102d144db4b26df9", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2022-07-20T08:29:40.000Z"}, {"id": "kietzmannlab/ecoset", "sha": "a2a878b269bf7b93d5bc1c6a234539ba9f4b60c1", "lastModified": "2023-10-14T20:10:10.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-classification", "task_ids:multi-class-image-classification", "source_datasets:original", "license:cc", "other-image-classification", "image-classification", "region:us"], "private": false, "author": "kietzmannlab", "description": "Tired of all the dogs in ImageNet (ILSVRC)? Then ecoset is here for you. 1.5m images \nfrom 565 basic level categories, chosen to be both (i) frequent in linguistic usage, \nand (ii) rated by human observers as concrete (e.g. \u2018table\u2019 is concrete, \u2018romance\u2019 \nis not). Here we collect resources associated with ecoset. This includes the dataset,\ntrained deep neural network models, code to interact with them, and published papers \nusing it.", "citation": "@article{mehrer2021ecologically,\n  title={An ecologically motivated image dataset for deep learning yields better models of human vision},\n  author={Mehrer, Johannes and Spoerer, Courtney J and Jones, Emer C and Kriegeskorte, Nikolaus and Kietzmann, Tim C},\n  journal={Proceedings of the National Academy of Sciences},\n  volume={118},\n  number={8},\n  year={2021},\n  publisher={National Acad Sciences}\n}", "cardData": null, "siblings": [], "_id": "62d9015e9a5353eef9d7691d", "disabled": false, "gated": false, "likes": 7, "downloads": 83, "paperswithcode_id": "ecoset", "createdAt": "2022-07-21T07:33:50.000Z"}, {"id": "biglam/hansard_speech", "sha": "ef655a3bfc18d977bb7d657ab87a6de404c883fc", "lastModified": "2022-07-27T12:30:30.000Z", "tags": ["task_categories:text-classification", "task_categories:text-generation", "task_ids:multi-class-classification", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:en", "license:cc-by-4.0", "speeches", "politics", "parliament", "British", "region:us"], "private": false, "author": "biglam", "description": "A dataset containing every speech in the House of Commons from May 1979-July 2020.", "citation": "@misc{odell, evan_2021, \ntitle={Hansard Speeches 1979-2021: Version 3.1.0}, \nDOI={10.5281/zenodo.4843485}, \nabstractNote={<p>Full details are available at <a href=\"https://evanodell.com/projects/datasets/hansard-data\">https://evanodell.com/projects/datasets/hansard-data</a></p> <p><strong>Version 3.1.0 contains the following changes:</strong></p> <p>- Coverage up to the end of April 2021</p>}, \nnote={This release is an update of previously released datasets. See full documentation for details.}, \npublisher={Zenodo}, \nauthor={Odell, Evan}, \nyear={2021}, \nmonth={May} }", "cardData": null, "siblings": [], "_id": "62db1d67802660b80df5eb7b", "disabled": false, "gated": false, "likes": 2, "downloads": 13, "createdAt": "2022-07-22T21:57:59.000Z"}, {"id": "muibk/wmt19_metrics_task", "sha": "8078e27c5ff4c52d5b85572ed45d36c712a3c423", "lastModified": "2022-07-26T10:06:23.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:found", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:100K<n<1M", "license:unknown", "region:us"], "private": false, "author": "muibk", "description": "This shared task will examine automatic evaluation metrics for machine translation. We will provide\nyou with all of the translations produced in the translation task along with the human reference translations.\nYou will return your automatic metric scores for translations at the system-level and/or at the sentence-level.\nWe will calculate the system-level and sentence-level correlations of your scores with WMT19 human judgements\nonce the manual evaluation has been completed.", "citation": "@inproceedings{ma-etal-2019-results,\n    title = {Results of the WMT19 Metrics Shared Task: Segment-Level and Strong MT Systems Pose Big Challenges},\n    author = {Ma, Qingsong and Wei, Johnny and Bojar, Ond\u0159ej and Graham, Yvette},\n    booktitle = {Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)},\n    month = {aug},\n    year = {2019},\n    address = {Florence, Italy},\n    publisher = {Association for Computational Linguistics},\n    url = {https://aclanthology.org/W19-5302},\n    doi = {10.18653/v1/W19-5302},\n    pages = {62--90}\n}", "cardData": null, "siblings": [], "_id": "62df95f8b38832b792ae1772", "disabled": false, "gated": false, "likes": 0, "downloads": 26, "createdAt": "2022-07-26T07:21:28.000Z"}, {"id": "frgfm/imagewoof", "sha": "8dc1bdb0cbe71fea85bb3a4f14c2c1b57c61d88f", "lastModified": "2022-12-11T22:26:18.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "size_categories:1K<n<10K", "source_datasets:extended", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "frgfm", "description": "Imagewoof is a subset of 10 classes from Imagenet that aren't so \neasy to classify, since they're all dog breeds. The breeds are: \nAustralian terrier, Border terrier, Samoyed, Beagle, Shih-Tzu, \nEnglish foxhound, Rhodesian ridgeback, Dingo, Golden retriever, \nOld English sheepdog.", "citation": "@software{Howard_Imagewoof_2019,\n    title={Imagewoof: a subset of 10 classes from Imagenet that aren't so easy to classify},\n    author={Jeremy Howard},\n    year={2019},\n    month={March},\n    publisher = {GitHub},\n    url = {https://github.com/fastai/imagenette#imagewoof}\n}", "cardData": null, "siblings": [], "_id": "62e00694c6a1003ca26cd0a5", "disabled": false, "gated": false, "likes": 2, "downloads": 48, "paperswithcode_id": "imagewoof", "createdAt": "2022-07-26T15:21:56.000Z"}, {"id": "tarteel-ai/quranqa", "sha": "88b10b40e3197c83f2995771e057515f584ecd27", "lastModified": "2022-07-27T02:28:31.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "size_categories:1K<n<10K", "source_datasets:original", "language:ar", "license:cc-by-nd-4.0", "quran", "qa", "region:us"], "private": false, "author": "tarteel-ai", "description": "The absence of publicly available reusable test collections for Arabic question answering on the Holy Qur\u2019an has impeded the possibility of fairly comparing the performance of systems in that domain. In this article, we introduce AyaTEC, a reusable test collection for verse-based question answering on the Holy Qur\u2019an, which serves as a common experimental testbed for this task. AyaTEC includes 207 questions (with their corresponding 1,762 answers) covering 11 topic categories of the Holy Qur\u2019an that target the information needs of both curious and skeptical users. To the best of our effort, the answers to the questions (each represented as a sequence of verses) in AyaTEC were exhaustive\u2014that is, all qur\u2019anic verses that directly answered the questions were exhaustively extracted and annotated. To facilitate the use of AyaTEC in evaluating the systems designed for that task, we propose several evaluation measures to support the different types of questions and the nature of verse-based answers while integrating the concept of partial matching of answers in the evaluation.", "citation": "@article{malhas2020ayatec,\n    author = {Malhas, Rana and Elsayed, Tamer},\n    title = {AyaTEC: Building a Reusable Verse-Based Test Collection for Arabic Question Answering on the Holy Qur\u2019an},\n    year = {2020},\n    issue_date = {November 2020},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    volume = {19},\n    number = {6},\n    issn = {2375-4699},\n    url = {https://doi.org/10.1145/3400396},\n    doi = {10.1145/3400396},\n    journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},\n    month = {oct},\n    articleno = {78},\n    numpages = {21},\n    keywords = {evaluation, Classical Arabic}\n}", "cardData": null, "siblings": [], "_id": "62e048f673c43298f18d4eb8", "disabled": false, "gated": false, "likes": 8, "downloads": 274, "createdAt": "2022-07-26T20:05:10.000Z"}, {"id": "biglam/contentious_contexts", "sha": "794edc666ccae9f296d033a99a826a3f41f34385", "lastModified": "2022-08-01T17:02:11.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-scoring", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:nl", "license:cc-by-2.0", "newspapers", "historic", "dutch", "problematic", "ConConCor", "region:us"], "private": false, "author": "biglam", "description": "This dataset contains extracts from historical Dutch newspapers which have been containing keywords of potentially contentious words (according to present-day sensibilities). \nThe dataset contains multiple annotations per instance, given the option to quantify agreement scores for annotations. This dataset can be used to track how words and their meanings have changed over time", "citation": "@misc{ContentiousContextsCorpus2021,\n  author = {Cultural AI},\n  title = {Contentious Contexts Corpus},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\\\url{https://github.com/cultural-ai/ConConCor}},\n}", "cardData": null, "siblings": [], "_id": "62e065b44736b5a4156924a2", "disabled": false, "gated": false, "likes": 2, "downloads": 11, "createdAt": "2022-07-26T22:07:48.000Z"}, {"id": "chintagunta85/bc2gm_test", "sha": "e24270fa1657929a060d81dc258fee812b3905f6", "lastModified": "2022-07-28T14:16:43.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": "chintagunta85", "description": "Nineteen teams presented results for the Gene Mention Task at the BioCreative II Workshop.\nIn this task participants designed systems to identify substrings in sentences corresponding to gene name mentions.\nA variety of different methods were used and the results varied with a highest achieved F1 score of 0.8721.\nHere we present brief descriptions of all the methods used and a statistical analysis of the results.\nWe also demonstrate that, by combining the results from all submissions, an F score of 0.9066 is feasible,\nand furthermore that the best result makes use of the lowest scoring submissions.\nFor more details, see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2559986/\nThe original dataset can be downloaded from: https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-ii-corpus/\nThis dataset has been converted to CoNLL format for NER using the following tool: https://github.com/spyysalo/standoff2conll", "citation": "@article{smith2008overview,\n        title={Overview of BioCreative II gene mention recognition},\n        author={Smith, Larry and Tanabe, Lorraine K and nee Ando, Rie Johnson and Kuo, Cheng-Ju and Chung, I-Fang and Hsu, Chun-Nan and Lin, Yu-Shi and Klinger, Roman and Friedrich, Christoph M and Ganchev, Kuzman and others},\n        journal={Genome biology},\n        volume={9},\n        number={S2},\n        pages={S2},\n        year={2008},\n        publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "62e12d8202a6c13e467560b7", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2022-07-27T12:20:18.000Z"}, {"id": "kiddothe2b/contract-nli", "sha": "059927b91122a6827e7dbb4f296f6da8f5dcee1c", "lastModified": "2022-07-27T13:07:52.000Z", "tags": ["license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "kiddothe2b", "description": "ContractNLI: A Benchmark Dataset for ContractNLI in English", "citation": " @inproceedings{koreeda-manning-2021-contractnli-dataset,\n    title = \"{C}ontract{NLI}: A Dataset for Document-level Natural Language Inference for Contracts\",\n    author = \"Koreeda, Yuta  and\n      Manning, Christopher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2021\",\n    month = nov,\n    year = \"2021\",\n    address = \"Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.findings-emnlp.164\",\n    doi = \"10.18653/v1/2021.findings-emnlp.164\",\n    pages = \"1907--1919\",\n}", "cardData": null, "siblings": [], "_id": "62e13147cb1f164f2cb0d3b7", "disabled": false, "gated": false, "likes": 1, "downloads": 38, "createdAt": "2022-07-27T12:36:23.000Z"}, {"id": "jordiae/exebench", "sha": "093085f8558cfd53de8e2c8f4ccc7b9e73dc22ae", "lastModified": "2023-03-09T16:06:06.000Z", "tags": ["region:us"], "private": false, "author": "jordiae", "description": "An ML-scale dataset of executable C functions", "citation": "@inproceedings{10.1145/3520312.3534867,\nauthor = {Armengol-Estap\\'{e}, Jordi and Woodruff, Jackson and Brauckmann, Alexander and Magalh\\~{a}es, Jos\\'{e} Wesley de Souza and O'Boyle, Michael F. P.},\ntitle = {ExeBench: An ML-Scale Dataset of Executable C Functions},\nyear = {2022},\nisbn = {9781450392730},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3520312.3534867},\ndoi = {10.1145/3520312.3534867},\nabstract = {Machine-learning promises to transform compilation and software engineering, yet is frequently limited by the scope of available datasets. In particular, there is a lack of runnable, real-world datasets required for a range of tasks ranging from neural program synthesis to machine learning-guided program optimization. We introduce a new dataset, ExeBench, which attempts to address this. It tackles two key issues with real-world code: references to external types and functions and scalable generation of IO examples. ExeBench is the first publicly available dataset that pairs real-world C code taken from GitHub with IO examples that allow these programs to be run. We develop a toolchain that scrapes GitHub, analyzes the code, and generates runnable snippets of code. We analyze our benchmark suite using several metrics, and show it is representative of real-world code. ExeBench contains 4.5M compilable and 700k executable C functions. This scale of executable, real functions will enable the next generation of machine learning-based programming tasks.},\nbooktitle = {Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},\npages = {50\u201359},\nnumpages = {10},\nkeywords = {Code Dataset, Program Synthesis, Mining Software Repositories, C, Machine Learning for Code, Compilers},\nlocation = {San Diego, CA, USA},\nseries = {MAPS 2022}\n}", "cardData": null, "siblings": [], "_id": "62e58f6aea4ab596196064b8", "disabled": false, "gated": false, "likes": 1, "downloads": 1461, "createdAt": "2022-07-30T20:07:06.000Z"}, {"id": "bigscience/xP3all", "sha": "d2bde405fafdd53aa4f92ddf03b14a7e7533d660", "lastModified": "2023-05-30T15:51:40.000Z", "tags": ["task_categories:other", "annotations_creators:expert-generated", "annotations_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100M<n<1B", "language:ak", "language:ar", "language:as", "language:bm", "language:bn", "language:ca", "language:code", "language:en", "language:es", "language:eu", "language:fon", "language:fr", "language:gu", "language:hi", "language:id", "language:ig", "language:ki", "language:kn", "language:lg", "language:ln", "language:ml", "language:mr", "language:ne", "language:nso", "language:ny", "language:or", "language:pa", "language:pt", "language:rn", "language:rw", "language:sn", "language:st", "language:sw", "language:ta", "language:te", "language:tn", "language:ts", "language:tum", "language:tw", "language:ur", "language:vi", "language:wo", "language:xh", "language:yo", "language:zh", "language:zu", "license:apache-2.0", "arxiv:2211.01786", "region:us"], "private": false, "author": "bigscience", "description": "xP3 (Crosslingual Public Pool of Prompts) is a collection of prompts & datasets across 46 of languages & 16 NLP tasks. It is used for the training of BLOOMZ and mT0, multilingual language models capable of following human instructions in dozens of languages zero-shot.", "citation": "@misc{muennighoff2022crosslingual,\n      title={Crosslingual Generalization through Multitask Finetuning}, \n      author={Niklas Muennighoff and Thomas Wang and Lintang Sutawika and Adam Roberts and Stella Biderman and Teven Le Scao and M Saiful Bari and Sheng Shen and Zheng-Xin Yong and Hailey Schoelkopf and Xiangru Tang and Dragomir Radev and Alham Fikri Aji and Khalid Almubarak and Samuel Albanie and Zaid Alyafeai and Albert Webson and Edward Raff and Colin Raffel},\n      year={2022},\n      eprint={2211.01786},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "62e59cfea944e2a56cd7c743", "disabled": false, "gated": false, "likes": 17, "downloads": 215, "createdAt": "2022-07-30T21:05:02.000Z"}, {"id": "joelniklaus/lextreme", "sha": "8de79b42002a6e7ab7e713787f4c427d122a269f", "lastModified": "2023-04-29T07:02:17.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "task_ids:topic-classification", "task_ids:named-entity-recognition", "annotations_creators:other", "language_creators:found", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:cc-by-4.0", "arxiv:2301.13126", "region:us"], "private": false, "author": "joelniklaus", "description": "The LEXTREME Benchmark is a collection of multilingual datasets for evaluating model performance \nacross a diverse set of legal NLU tasks.", "citation": "@misc{niklaus2023lextreme,\n    title={LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain},\n    author={Joel Niklaus and Veton Matoshi and Pooja Rani and Andrea Galassi and Matthias St\u00fcrmer and Ilias Chalkidis},\n    year={2023},\n    eprint={2301.13126},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "62e791d30f686ef922a0eb31", "disabled": false, "gated": false, "likes": 16, "downloads": 227, "createdAt": "2022-08-01T08:41:55.000Z"}, {"id": "allenai/multi_lexsum", "sha": "afda465737e77099473336b4caf60b70fe969dcc", "lastModified": "2023-05-18T21:41:22.000Z", "tags": ["task_categories:summarization", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:odc-by", "arxiv:2206.10883", "region:us"], "private": false, "author": "allenai", "description": "Multi-LexSum is a multi-doc summarization dataset for civil rights litigation lawsuits with summaries of three granularities.", "citation": "@article{Shen2022MultiLexSum,\n    author    = {Zejiang Shen and\n                Kyle Lo and\n                Lauren Yu and\n                Nathan Dahlberg and\n                Margo Schlanger and\n                Doug Downey},\n    title     = {Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple Granularities},\n    journal   = {CoRR},\n    volume    = {abs/2206.10883},\n    year      = {2022},\n    url       = {https://doi.org/10.48550/arXiv.2206.10883},\n    doi       = {10.48550/arXiv.2206.10883}\n}", "cardData": null, "siblings": [], "_id": "62ea996e762e33d4e823aaf4", "disabled": false, "gated": false, "likes": 13, "downloads": 260, "createdAt": "2022-08-03T15:51:10.000Z"}, {"id": "tau/sled", "sha": "e6a474f5ff4133338b4b9b5e393bad65e787b152", "lastModified": "2022-10-25T07:33:44.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-generation", "task_ids:multiple-choice-qa", "task_ids:natural-language-inference", "language:en", "license:mit", "multi-hop-question-answering", "query-based-summarization", "long-texts", "arxiv:2208.00748", "arxiv:2201.03533", "arxiv:2104.02112", "arxiv:2104.07091", "arxiv:2104.05938", "arxiv:1712.07040", "arxiv:2105.03011", "arxiv:2112.08608", "arxiv:2110.01799", "arxiv:1606.05250", "arxiv:1809.09600", "region:us"], "private": false, "author": "tau", "description": "Efficient Long-Text Understanding with Short-Text Models.\nOur SLiding-Encoder and Decoder uses any pretrained encoder-decoder model, to independtly encode overlapping chunks of \nthe inputs, and perform fusion-in-decoder to achieve linear-memory requirment for long-range natural language understanding.", "citation": "@inproceedings{Ivgi2022EfficientLU,\n  title={Efficient Long-Text Understanding with Short-Text Models},\n  author={Maor Ivgi and Uri Shaham and Jonathan Berant},\n  year={2022}\n}\nNote that each SLED dataset has its own citation. Please see the source to\nget the correct citation for each contained dataset (and also cite the SCROLLS dataset on which it is based).", "cardData": null, "siblings": [], "_id": "62ecdabfb8764c7738ef661b", "disabled": false, "gated": false, "likes": 7, "downloads": 21207, "createdAt": "2022-08-05T08:54:23.000Z"}, {"id": "NbAiLab/norwegian-paws-x", "sha": "b59d979a9ee1e04ae424a714479df4baa273396e", "lastModified": "2023-08-18T11:26:40.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "task_ids:multi-input-text-classification", "annotations_creators:expert-generated", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:extended|other-paws", "language:nb", "language:nn", "license:cc-by-4.0", "region:us"], "private": false, "author": "NbAiLab", "description": "Norwegian PAWS-X, Bokmaal and Nynorsk machine-translated versions of PAWS-X.\n\nPAWS-X, a multilingual version of PAWS (Paraphrase Adversaries from Word Scrambling) for six languages.\n\nThis dataset contains 23,659 human translated PAWS evaluation pairs and 296,406 machine\ntranslated training pairs in six typologically distinct languages: French, Spanish, German,\nChinese, Japanese, and Korean. English language is available by default. All translated\npairs are sourced from examples in PAWS-Wiki.\n\nFor further details, see the accompanying paper: PAWS-X: A Cross-lingual Adversarial Dataset\nfor Paraphrase Identification (https://arxiv.org/abs/1908.11828)\n\nNOTE: There might be some missing or wrong labels in the dataset and we have replaced them with -1.", "citation": "@InProceedings{pawsx2019emnlp,\n  title = {{PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification}},\n  author = {Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},\n  booktitle = {Proc. of EMNLP},\n  year = {2019}\n}", "cardData": null, "siblings": [], "_id": "62ecf6289680db511dafdb22", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2022-08-05T10:51:20.000Z"}, {"id": "jakartaresearch/google-play-review", "sha": "4030949b0360722d8853eb01d407393de0b40bad", "lastModified": "2022-08-06T16:24:49.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:id", "license:cc-by-4.0", "sentiment", "google-play", "indonesian", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built as a playground for beginner to make a use case for creating sentiment analysis model.", "citation": null, "cardData": null, "siblings": [], "_id": "62edf5700effdbb913830149", "disabled": false, "gated": false, "likes": 4, "downloads": 142, "createdAt": "2022-08-06T05:00:32.000Z"}, {"id": "dali-does/clevr-math", "sha": "6a30110f887edd7edbad033275aa853ddd8c4a26", "lastModified": "2022-10-31T11:28:31.000Z", "tags": ["task_categories:visual-question-answering", "task_ids:visual-question-answering", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "source_datasets:clevr", "language:en", "license:cc-by-4.0", "reasoning", "neuro-symbolic", "multimodal", "arxiv:2208.05358", "region:us"], "private": false, "author": "dali-does", "description": "CLEVR-Math is a dataset for compositional language, visual and mathematical reasoning. CLEVR-Math poses questions about mathematical operations on visual scenes using subtraction and addition, such as \"Remove all large red cylinders. How many objects are left?\". There are also adversarial (e.g. \"Remove all blue cubes. How many cylinders are left?\") and multihop questions (e.g. \"Remove all blue cubes. Remove all small purple spheres. How many objects are left?\").", "citation": "@misc{https://doi.org/10.48550/arxiv.2208.05358,\n  doi = {10.48550/ARXIV.2208.05358},\n  url = {https://arxiv.org/abs/2208.05358},\n  author = {Lindstr\u00f6m, Adam Dahlgren and Abraham, Savitha Sam},\n  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.7; I.2.10; I.2.6; I.4.8; I.1.4},\n  title = {CLEVR-Math: A Dataset for Compositional Language, Visual, and Mathematical Reasoning},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "62ee5a0395a10fd0d62d54c0", "disabled": false, "gated": false, "likes": 5, "downloads": 469, "createdAt": "2022-08-06T12:09:39.000Z"}, {"id": "hoskinson-center/proof-pile", "sha": "490b980249446f2f3bd2df3a8cf085d0f2de240a", "lastModified": "2023-08-19T03:24:11.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "language:en", "license:apache-2.0", "math", "mathematics", "formal-mathematics", "region:us"], "private": false, "author": "hoskinson-center", "description": "A dataset of high quality mathematical text.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {proof-pile},\nauthor={Zhangir Azerbayev, Edward Ayers, Bartosz Piotrowski\n},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "62f178d43e0991a8ab14c6af", "disabled": false, "gated": false, "likes": 33, "downloads": 51, "createdAt": "2022-08-08T20:57:56.000Z"}, {"id": "google/cvss", "sha": "206b001828fb8532e569701519dac19d048fbf09", "lastModified": "2022-08-27T23:19:14.000Z", "tags": ["license:cc-by-4.0", "arxiv:2201.03713", "region:us"], "private": false, "author": "google", "description": "CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\ncovering sentence-level parallel speech-to-speech translation pairs from 21\nlanguages into English.", "citation": "@inproceedings{jia2022cvss,\n    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},\n    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},\n    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},\n    pages={6691--6703},\n    year={2022}\n}", "cardData": null, "siblings": [], "_id": "62f4535ed6ba2ee266553478", "disabled": false, "gated": false, "likes": 8, "downloads": 116, "createdAt": "2022-08-11T00:54:54.000Z"}, {"id": "juletxara/visual-spatial-reasoning", "sha": "a07bec7a6b1cbf4b5ca3a68bf744e854982b72bd", "lastModified": "2022-08-11T20:11:21.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2205.00363", "arxiv:1908.03557", "arxiv:1908.07490", "arxiv:2102.03334", "region:us"], "private": false, "author": "juletxara", "description": "The Visual Spatial Reasoning (VSR) corpus is a collection of caption-image pairs with true/false labels. Each caption describes the spatial relation of two individual objects in the image, and a vision-language model (VLM) needs to judge whether the caption is correctly describing the image (True) or not (False).", "citation": "@article{Liu2022VisualSR,\n  title={Visual Spatial Reasoning},\n  author={Fangyu Liu and Guy Edward Toh Emerson and Nigel Collier},\n  journal={ArXiv},\n  year={2022},\n  volume={abs/2205.00363}\n}", "cardData": null, "siblings": [], "_id": "62f4fc9a2873214eb5f003e1", "disabled": false, "gated": false, "likes": 3, "downloads": 11, "createdAt": "2022-08-11T12:56:58.000Z"}, {"id": "jakartaresearch/news-title-gen", "sha": "12c12ebe27cf9cac7ad6c1244f6022cf7ae41d12", "lastModified": "2022-08-13T06:32:12.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "license:cc-by-4.0", "newspapers", "title", "news", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built for generating text for news title.", "citation": null, "cardData": null, "siblings": [], "_id": "62f700cec3372328414f3c42", "disabled": false, "gated": false, "likes": 1, "downloads": 23, "createdAt": "2022-08-13T01:39:26.000Z"}, {"id": "galatolo/TeTIm-Eval", "sha": "00069d7da55dcca7b4e3743111b9caa3918460ee", "lastModified": "2022-12-15T14:58:24.000Z", "tags": ["task_categories:text-to-image", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc", "curated", "high-quality", "text-to-image", "evaluation", "validation", "region:us"], "private": false, "author": "galatolo", "description": "Text To Image Evaluation (TeTIm-Eval)", "citation": "TODO", "cardData": null, "siblings": [], "_id": "62f774a0b9fda55613c89891", "disabled": false, "gated": false, "likes": 1, "downloads": 173, "createdAt": "2022-08-13T09:53:36.000Z"}, {"id": "jakartaresearch/indoqa", "sha": "7d1910e1d4224fc239757dc96fa4ad41e2130a62", "lastModified": "2022-12-17T06:07:27.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:id", "license:cc-by-nd-4.0", "indoqa", "qa", "question-answering", "indonesian", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built for question answering task.", "citation": null, "cardData": null, "siblings": [], "_id": "62f782d047d782a6e283a11f", "disabled": false, "gated": false, "likes": 1, "downloads": 35, "createdAt": "2022-08-13T10:54:08.000Z"}, {"id": "m3/multi_domain_document_classification", "sha": "bb7727c857ab980682dee6aece71abfdcf248095", "lastModified": "2022-08-25T11:25:30.000Z", "tags": ["region:us"], "private": false, "author": "m3", "description": "Multi domain document classification dataset used in [https://arxiv.org/pdf/2004.10964.pdf](https://arxiv.org/pdf/2004.10964.pdf)", "citation": "@inproceedings{dontstoppretraining2020,\n author = {Suchin Gururangan and Ana Marasovi\u0107 and Swabha Swayamdipta and Kyle Lo and Iz Beltagy and Doug Downey and Noah A. Smith},\n title = {Don't Stop Pretraining: Adapt Language Models to Domains and Tasks},\n year = {2020},\n booktitle = {Proceedings of ACL},\n}", "cardData": null, "siblings": [], "_id": "62f82acf3b991129e943b4ec", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2022-08-13T22:50:55.000Z"}, {"id": "jakartaresearch/semeval-absa", "sha": "60e03f1f98b19e519c271891caea6d1e020095f4", "lastModified": "2022-08-14T05:38:21.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "aspect-based-sentiment-analysis", "semeval", "semeval2015", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built as a playground for aspect-based sentiment analysis.", "citation": null, "cardData": null, "siblings": [], "_id": "62f889a704de855c35e65ffb", "disabled": false, "gated": false, "likes": 1, "downloads": 90, "createdAt": "2022-08-14T05:35:35.000Z"}, {"id": "jonathanli/echr", "sha": "a8ea5b9fe8851acd50fc14b5ab54cca61a4dbf04", "lastModified": "2022-08-21T23:29:28.000Z", "tags": ["license:cc-by-nc-sa-4.0", "arxiv:1906.02059", "region:us"], "private": false, "author": "jonathanli", "description": "The ECHR Cases dataset is designed for experimentation of neural judgment prediction, as in the original 2019 ACL paper \"Neural Legal Judgment Prediction in English\".", "citation": "@inproceedings{chalkidis-etal-2019-neural,\n    title = \"Neural Legal Judgment Prediction in {E}nglish\",\n    author = \"Chalkidis, Ilias  and\n      Androutsopoulos, Ion  and\n      Aletras, Nikolaos\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P19-1424\",\n    doi = \"10.18653/v1/P19-1424\",\n    pages = \"4317--4323\",\n}", "cardData": null, "siblings": [], "_id": "62f9a2d4c727e26ef721bed6", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2022-08-15T01:35:16.000Z"}, {"id": "cjvt/sentinews", "sha": "a5b444f752b9be3f66feda3720cc0344a1593d20", "lastModified": "2022-08-17T06:28:13.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:sl", "license:cc-by-sa-4.0", "slovenian sentiment", "news articles", "region:us"], "private": false, "author": "cjvt", "description": "SentiNews is a Slovenian sentiment classification dataset, consisting of news articles manually annotated with their \nsentiment by between 2 and 6 annotators. The news articles contain political, business, economic and financial content \nfrom the Slovenian news portals 24ur, Dnevnik, Finance, Rtvslo, and \u017durnal24. The texts were annotated using the \nfive-level Lickert scale (1 \u2013 very negative, 2 \u2013 negative, 3 \u2013 neutral, 4 \u2013 positive, and 5 \u2013 very positive) on three \nlevels of granularity, i.e. on the document, paragraph, and sentence level. The final sentiment is determined using \nthe following criterion: negative (if average of scores \u2264 2.4); neutral (if average of scores is between 2.4 and 3.6); \npositive (average of annotated scores \u2265 3.6).", "citation": "@article{buvcar2018annotated, \n        title={Annotated news corpora and a lexicon for sentiment analysis in Slovene}, \n        author={Bu{\\v{c}}ar, Jo{\\v{z}}e and {\\v{Z}}nidar{\\v{s}}i{\\v{c}}, Martin and Povh, Janez}, \n        journal={Language Resources and Evaluation}, \n        volume={52}, \n        number={3}, \n        pages={895--919}, \n        year={2018}, \n        publisher={Springer}\n}", "cardData": null, "siblings": [], "_id": "62fa049eefd2de85492b338b", "disabled": false, "gated": false, "likes": 1, "downloads": 47, "createdAt": "2022-08-15T08:32:30.000Z"}, {"id": "jakartaresearch/indo-movie-subtitle", "sha": "61aadced13e6afdad929ff7473e2c7c3060e5cef", "lastModified": "2022-08-16T13:20:23.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "license:cc-by-4.0", "movie", "subtitle", "indonesian", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built as a playground for analyzing text on movie subtitle", "citation": null, "cardData": null, "siblings": [], "_id": "62fb972da80632fbd4792b33", "disabled": false, "gated": false, "likes": 1, "downloads": 23, "createdAt": "2022-08-16T13:10:05.000Z"}, {"id": "MLCommons/peoples_speech", "sha": "9f8157c032dfa4ca4c99b83fc152f2922d2ac88d", "lastModified": "2023-05-16T16:11:10.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1T<n", "source_datasets:original", "language:en", "license:cc-by-2.0", "license:cc-by-2.5", "license:cc-by-3.0", "license:cc-by-4.0", "license:cc-by-sa-3.0", "license:cc-by-sa-4.0", "robust-speech-recognition", "noisy-speech-recognition", "speech-recognition", "arxiv:2111.09344", "region:us"], "private": false, "author": "MLCommons", "description": "The People's Speech is a free-to-download 30,000-hour and growing supervised \nconversational English speech recognition dataset licensed for academic and \ncommercial usage under CC-BY-SA (with a CC-BY subset).", "citation": "@article{DBLP:journals/corr/abs-2111-09344,\n  author    = {Daniel Galvez and\n               Greg Diamos and\n               Juan Ciro and\n               Juan Felipe Ceron and\n               Keith Achorn and\n               Anjali Gopi and\n               David Kanter and\n               Maximilian Lam and\n               Mark Mazumder and\n               Vijay Janapa Reddi},\n  title     = {The People's Speech: A Large-Scale Diverse English Speech Recognition\n               Dataset for Commercial Usage},\n  journal   = {CoRR},\n  volume    = {abs/2111.09344},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2111.09344},\n  eprinttype = {arXiv},\n  eprint    = {2111.09344},\n  timestamp = {Mon, 22 Nov 2021 16:44:07 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-09344.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "62fba7fda80632fbd479aa60", "disabled": false, "gated": false, "likes": 30, "downloads": 278, "createdAt": "2022-08-16T14:21:49.000Z"}, {"id": "yhavinga/cnn_dailymail_dutch", "sha": "320d19aa562db0561143c3dce198be5d5e50a66f", "lastModified": "2022-08-20T12:39:20.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:nl", "license:apache-2.0", "region:us"], "private": false, "author": "yhavinga", "description": "CNN/DailyMail non-anonymized summarization dataset, translated to Dutch with ccmatrix.\nThere are two features:\n  - article: text of news article, used as the document to be summarized\n  - highlights: joined text of highlights with <s> and </s> around each\n    highlight, which is the target summary", "citation": "@article{DBLP:journals/corr/SeeLM17,\n  author    = {Abigail See and\n               Peter J. Liu and\n               Christopher D. Manning},\n  title     = {Get To The Point: Summarization with Pointer-Generator Networks},\n  journal   = {CoRR},\n  volume    = {abs/1704.04368},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1704.04368},\n  archivePrefix = {arXiv},\n  eprint    = {1704.04368},\n  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n@inproceedings{hermann2015teaching,\n  title={Teaching machines to read and comprehend},\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n  booktitle={Advances in neural information processing systems},\n  pages={1693--1701},\n  year={2015}\n}", "cardData": null, "siblings": [], "_id": "62fbe102fcce44435d825e55", "disabled": false, "gated": false, "likes": 1, "downloads": 31, "paperswithcode_id": "cnn-daily-mail-1", "createdAt": "2022-08-16T18:25:06.000Z"}, {"id": "spacemanidol/cc-stories", "sha": "6c8113e72a5aed919dbf615ed37723d393e7b27b", "lastModified": "2023-05-02T11:48:55.000Z", "tags": ["region:us"], "private": false, "author": "spacemanidol", "description": "CC-Stories (or STORIES) is a dataset for common sense reasoning and language modeling. It was constructed by aggregating documents from the CommonCrawl dataset that has the most overlapping n-grams with the questions in commonsense reasoning tasks. The top 1.0% of highest ranked documents is chosen as the new training corpus.", "citation": "@article{Trinh2018ASM,\n  title={A Simple Method for Commonsense Reasoning},\n  author={Trieu H. Trinh and Quoc V. Le},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1806.02847}\n}", "cardData": null, "siblings": [], "_id": "62fc0d8fce54be18b09aca95", "disabled": false, "gated": false, "likes": 7, "downloads": 17, "createdAt": "2022-08-16T21:35:11.000Z"}, {"id": "SLPL/naab", "sha": "c0ffda60b8b5a0e9ec63360548be8d53f955246f", "lastModified": "2022-11-03T06:33:48.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "multilinguality:monolingual", "size_categories:100M<n<1B", "language:fa", "license:mit", "arxiv:2208.13486", "region:us"], "private": false, "author": "SLPL", "description": "Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word \u0646\u0627\u0628 which means pure and high-grade.", "citation": "@misc{https://doi.org/10.48550/arxiv.2208.13486,\n  doi = {10.48550/ARXIV.2208.13486},\n  url = {https://arxiv.org/abs/2208.13486},\n  author = {Sabouri, Sadra and Rahmati, Elnaz and Gooran, Soroush and Sameti, Hossein},\n  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {naab: A ready-to-use plug-and-play corpus for Farsi},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "62fe42fc029f73cec276f393", "disabled": false, "gated": false, "likes": 27, "downloads": 64, "createdAt": "2022-08-18T13:47:40.000Z"}, {"id": "SLPL/naab-raw", "sha": "447ead3773dc665d37157e84483e5235f8aeb4ad", "lastModified": "2022-11-03T06:34:28.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:language-modeling", "task_ids:masked-language-modeling", "multilinguality:monolingual", "language:fa", "license:mit", "arxiv:2208.13486", "region:us"], "private": false, "author": "SLPL", "description": "Huge corpora of textual data are always known to be a crucial need for training deep models such as transformer-based ones. This issue is emerging more in lower resource languages - like Farsi. We propose naab, the biggest cleaned and ready-to-use open-source textual corpus in Farsi. It contains about 130GB of data, 250 million paragraphs, and 15 billion words. The project name is derived from the Farsi word \u0646\u0627\u0628 which means pure and high-grade. This corpus contains the raw (uncleaned) version of it.", "citation": "@misc{https://doi.org/10.48550/arxiv.2208.13486,\n  doi = {10.48550/ARXIV.2208.13486},\n  url = {https://arxiv.org/abs/2208.13486},\n  author = {Sabouri, Sadra and Rahmati, Elnaz and Gooran, Soroush and Sameti, Hossein},\n  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {naab: A ready-to-use plug-and-play corpus for Farsi},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "62fe49738cdcc5d80bc7b956", "disabled": false, "gated": false, "likes": 6, "downloads": 18, "createdAt": "2022-08-18T14:15:15.000Z"}, {"id": "projecte-aina/WikiCAT_ca", "sha": "9b06ad6e84c3677ced03405e98400668afb061cc", "lastModified": "2023-11-25T06:02:26.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:auromatically-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:ca", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "projecte-aina", "description": "WikiCAT: Text Classification Catalan dataset from the Viquipedia", "citation": "", "cardData": null, "siblings": [], "_id": "62fe4cae594a7b92e674424e", "disabled": false, "gated": false, "likes": 1, "downloads": 25, "createdAt": "2022-08-18T14:29:02.000Z"}, {"id": "jakartaresearch/inglish", "sha": "460772fb9f8ebdea9a826a863f8d08f398ecca89", "lastModified": "2022-08-19T15:23:15.000Z", "tags": ["task_categories:translation", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:original", "language:id", "language:en", "license:cc-by-4.0", "indonesian", "english", "translation", "region:us"], "private": false, "author": "jakartaresearch", "description": "This dataset is built as a playground for beginner to make a translation model for Indonesian and English.", "citation": null, "cardData": null, "siblings": [], "_id": "62ffa6d659b9ff1ccb54dc50", "disabled": false, "gated": false, "likes": 0, "downloads": 158, "createdAt": "2022-08-19T15:05:58.000Z"}, {"id": "csebuetnlp/BanglaNMT", "sha": "bb866b91ea96935b3f2ba1746fd62d0c136015e8", "lastModified": "2023-02-24T14:46:55.000Z", "tags": ["task_categories:translation", "annotations_creators:other", "language_creators:found", "multilinguality:translation", "size_categories:1M<n<10M", "language:bn", "language:en", "license:cc-by-nc-sa-4.0", "bengali", "BanglaNMT", "region:us"], "private": false, "author": "csebuetnlp", "description": "This is the largest Machine Translation (MT) dataset for Bengali-English, introduced in the paper\n`Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation`.", "citation": "@inproceedings{hasan-etal-2020-low,\n    title = \"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for {B}engali-{E}nglish Machine Translation\",\n    author = \"Hasan, Tahmid  and\n      Bhattacharjee, Abhik  and\n      Samin, Kazi  and\n      Hasan, Masum  and\n      Basak, Madhusudan  and\n      Rahman, M. Sohel  and\n      Shahriyar, Rifat\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.emnlp-main.207\",\n    doi = \"10.18653/v1/2020.emnlp-main.207\",\n    pages = \"2612--2623\",\n    abstract = \"Despite being the seventh most widely spoken language in the world, Bengali has received much less attention in machine translation literature due to being low in resources. Most publicly available parallel corpora for Bengali are not large enough; and have rather poor quality, mostly because of incorrect sentence alignments resulting from erroneous sentence segmentation, and also because of a high volume of noise present in them. In this work, we build a customized sentence segmenter for Bengali and propose two novel methods for parallel corpus creation on low-resource setups: aligner ensembling and batch filtering. With the segmenter and the two methods combined, we compile a high-quality Bengali-English parallel corpus comprising of 2.75 million sentence pairs, more than 2 million of which were not available before. Training on neural models, we achieve an improvement of more than 9 BLEU score over previous approaches to Bengali-English machine translation. We also evaluate on a new test set of 1000 pairs made with extensive quality control. We release the segmenter, parallel corpus, and the evaluation set, thus elevating Bengali from its low-resource status. To the best of our knowledge, this is the first ever large scale study on Bengali-English machine translation. We believe our study will pave the way for future research on Bengali-English machine translation as well as other low-resource languages. Our data and code are available at https://github.com/csebuetnlp/banglanmt.\",\n}", "cardData": null, "siblings": [], "_id": "630232352a9eff96143543d3", "disabled": false, "gated": false, "likes": 0, "downloads": 225, "createdAt": "2022-08-21T13:25:09.000Z"}, {"id": "yhavinga/xsum_dutch", "sha": "89ffbee82a31a0a741d56de24a55918ce0d6d2ea", "lastModified": "2022-08-21T20:50:08.000Z", "tags": ["task_categories:summarization", "task_ids:news-articles-summarization", "language:nl", "region:us"], "private": false, "author": "yhavinga", "description": "Extreme Summarization (XSum) Dataset.\nThere are three features:\n  - document: Input news article.\n  - summary: One sentence summary of the article.\n  - id: BBC ID of the article.", "citation": "@article{Narayan2018DontGM,\n  title={Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},\n  author={Shashi Narayan and Shay B. Cohen and Mirella Lapata},\n  journal={ArXiv},\n  year={2018},\n  volume={abs/1808.08745}\n}", "cardData": null, "siblings": [], "_id": "630295b72db53f7d9f3914fd", "disabled": false, "gated": false, "likes": 0, "downloads": 111, "paperswithcode_id": "xsum_dutch", "createdAt": "2022-08-21T20:29:43.000Z"}, {"id": "masakhane/mafand", "sha": "b215cd3c701dd16e447a0a2132fb73181acd6c53", "lastModified": "2023-09-11T18:01:53.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:fr", "language:am", "language:bm", "language:bbj", "language:ee", "language:fon", "language:ha", "language:ig", "language:lg", "language:mos", "language:ny", "language:pcm", "language:rw", "language:sn", "language:sw", "language:tn", "language:tw", "language:wo", "language:xh", "language:yo", "language:zu", "license:cc-by-nc-4.0", "news, mafand, masakhane", "region:us"], "private": false, "author": "masakhane", "description": "MAFAND-MT is the largest MT benchmark for African languages in the news domain, covering 21 languages. The languages covered are:\n- Amharic\n- Bambara\n- Ghomala\n- Ewe\n- Fon\n- Hausa\n- Igbo\n- Kinyarwanda\n- Luganda\n- Luo\n- Mossi\n- Nigerian-Pidgin\n- Chichewa\n- Shona\n- Swahili\n- Setswana\n- Twi\n- Wolof\n- Xhosa\n- Yoruba\n- Zulu\n\nThe train/validation/test sets are available for 16 languages, and validation/test set for amh, kin, nya, sna, and xho\n\nFor more details see https://aclanthology.org/2022.naacl-main.223/", "citation": "@inproceedings{adelani-etal-2022-thousand,\n    title = \"A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models for {A}frican News Translation\",\n    author = \"Adelani, David  and\n      Alabi, Jesujoba  and\n      Fan, Angela  and\n      Kreutzer, Julia  and\n      Shen, Xiaoyu  and\n      Reid, Machel  and\n      Ruiter, Dana  and\n      Klakow, Dietrich  and\n      Nabende, Peter  and\n      Chang, Ernie  and\n      Gwadabe, Tajuddeen  and\n      Sackey, Freshia  and\n      Dossou, Bonaventure F. P.  and\n      Emezue, Chris  and\n      Leong, Colin  and\n      Beukman, Michael  and\n      Muhammad, Shamsuddeen  and\n      Jarso, Guyo  and\n      Yousuf, Oreen  and\n      Niyongabo Rubungo, Andre  and\n      Hacheme, Gilles  and\n      Wairagala, Eric Peter  and\n      Nasir, Muhammad Umair  and\n      Ajibade, Benjamin  and\n      Ajayi, Tunde  and\n      Gitau, Yvonne  and\n      Abbott, Jade  and\n      Ahmed, Mohamed  and\n      Ochieng, Millicent  and\n      Aremu, Anuoluwapo  and\n      Ogayo, Perez  and\n      Mukiibi, Jonathan  and\n      Ouoba Kabore, Fatoumata  and\n      Kalipe, Godson  and\n      Mbaye, Derguene  and\n      Tapo, Allahsera Auguste  and\n      Memdjokam Koagne, Victoire  and\n      Munkoh-Buabeng, Edwin  and\n      Wagner, Valencia  and\n      Abdulmumin, Idris  and\n      Awokoya, Ayodele  and\n      Buzaaba, Happy  and\n      Sibanda, Blessing  and\n      Bukula, Andiswa  and\n      Manthalu, Sam\",\n    booktitle = \"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jul,\n    year = \"2022\",\n    address = \"Seattle, United States\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.naacl-main.223\",\n    doi = \"10.18653/v1/2022.naacl-main.223\",\n    pages = \"3053--3070\",\n    abstract = \"Recent advances in the pre-training for language models leverage large-scale datasets to create multilingual models. However, low-resource languages are mostly left out in these datasets. This is primarily because many widely spoken languages that are not well represented on the web and therefore excluded from the large-scale crawls for datasets. Furthermore, downstream users of these models are restricted to the selection of languages originally chosen for pre-training. This work investigates how to optimally leverage existing pre-trained models to create low-resource translation systems for 16 African languages. We focus on two questions: 1) How can pre-trained models be used for languages not included in the initial pretraining? and 2) How can the resulting translation models effectively transfer to new domains? To answer these questions, we create a novel African news corpus covering 16 languages, of which eight languages are not part of any existing evaluation dataset. We demonstrate that the most effective strategy for transferring both additional languages and additional domains is to leverage small quantities of high-quality translation data to fine-tune large pre-trained models.\",\n}", "cardData": null, "siblings": [], "_id": "63034c5de1e7f0e03a5e77c5", "disabled": false, "gated": false, "likes": 6, "downloads": 70, "createdAt": "2022-08-22T09:29:01.000Z"}, {"id": "RCC-MSU/collection3", "sha": "18841ce4c41a94aaed0041342c6a7cb0c59cfcfe", "lastModified": "2023-01-31T09:47:58.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:other", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:ru", "license:other", "region:us"], "private": false, "author": "RCC-MSU", "description": "Collection3 is a Russian dataset for named entity recognition annotated with LOC (location), PER (person), and ORG (organization) tags.\n\nDataset is based on collection Persons-1000 originally containing 1000 news documents labeled only with names of persons.\nAdditional labels were added by Valerie Mozharova and Natalia Loukachevitch.\nConversion to the IOB2 format and splitting into train, validation and test sets was done by DeepPavlov team.\n\nFor more details see https://ieeexplore.ieee.org/document/7584769 and http://labinform.ru/pub/named_entities/index.htm", "citation": "@inproceedings{mozharova-loukachevitch-2016-two-stage-russian-ner,\n  author={Mozharova, Valerie and Loukachevitch, Natalia},\n  booktitle={2016 International FRUCT Conference on Intelligence, Social Media and Web (ISMW FRUCT)},\n  title={Two-stage approach in Russian named entity recognition},\n  year={2016},\n  pages={1-6},\n  doi={10.1109/FRUCT.2016.7584769}}", "cardData": null, "siblings": [], "_id": "6304de16eb6d777a838fdfb1", "disabled": false, "gated": false, "likes": 4, "downloads": 92, "createdAt": "2022-08-23T14:03:02.000Z"}, {"id": "OxAISH-AL-LLM/wiki_toxic", "sha": "872656a156f32e4058307e50e234a44a727a9503", "lastModified": "2022-09-19T15:53:19.000Z", "tags": ["task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other", "language:en", "license:cc0-1.0", "wikipedia", "toxicity", "toxic comments", "region:us"], "private": false, "author": "OxAISH-AL-LLM", "description": "Jigsaw Toxic Comment Challenge dataset. This dataset was the basis of a Kaggle competition run by Jigsaw", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "63077220fd156a1d624e336c", "disabled": false, "gated": false, "likes": 11, "downloads": 386, "createdAt": "2022-08-25T12:59:12.000Z"}, {"id": "angelolab/ark_example", "sha": "99fbd44d13896b03ac3c29acead55243de944070", "lastModified": "2023-10-30T23:57:27.000Z", "tags": ["task_categories:image-segmentation", "task_ids:instance-segmentation", "annotations_creators:no-annotation", "size_categories:n<1K", "source_datasets:original", "license:apache-2.0", "MIBI", "Multiplexed-Imaging", "region:us"], "private": false, "author": "angelolab", "description": "This dataset contains 11 Field of Views (FOVs), each with 22 channels.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Ark Analysis Example Dataset},\nauthor={Angelo Lab},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "63080285161cfe1383a5c5c6", "disabled": false, "gated": false, "likes": 0, "downloads": 7492, "createdAt": "2022-08-25T23:15:17.000Z"}, {"id": "BDas/ArabicNLPDataset", "sha": "322604b436887a56f8cbcdd4ed3ecf2e60a2a488", "lastModified": "2022-09-26T18:52:01.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ar", "license:other", "region:us"], "private": false, "author": "BDas", "description": "The dataset, prepared in Arabic, includes 10.000 tests, 10.000 validations and 80000 train data.\nThe data is composed of customer comments and created from e-commerce sites.", "citation": "----ArabicNLPDataset----", "cardData": null, "siblings": [], "_id": "63093c241a8d77fa3191ad45", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2022-08-26T21:33:24.000Z"}, {"id": "BDas/EnglishNLPDataset", "sha": "a3692ff6d4f7958e6eea80025ac7ae9f4472cfe0", "lastModified": "2022-08-27T11:13:01.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:other", "region:us"], "private": false, "author": "BDas", "description": "The dataset, prepared in English, includes 10.000 tests, 10.000 validations and 80000 train data.\nThe data is composed of customer comments and created from e-commerce sites.", "citation": "----EnglishNLPDataset----", "cardData": null, "siblings": [], "_id": "6309f8ce2ff113e0fb29f06d", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-08-27T10:58:22.000Z"}, {"id": "jamescalam/unsplash-25k-photos", "sha": "ae9e759dd31d60479354cc06e4f4291c0c27bbca", "lastModified": "2022-09-13T13:02:46.000Z", "tags": ["task_categories:image-to-image", "task_categories:image-classification", "task_categories:image-to-text", "task_categories:text-to-image", "task_categories:zero-shot-image-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "images", "unsplash", "photos", "region:us"], "private": false, "author": "jamescalam", "description": "This is a dataset that streams photos data from the Unsplash 25K servers.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Unsplash Lite Dataset 1.2.0 Photos},\nauthor={Unsplash},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "630a94259df54451d91f9d5c", "disabled": false, "gated": false, "likes": 31, "downloads": 74, "createdAt": "2022-08-27T22:01:09.000Z"}, {"id": "alexandrainst/scandi-qa", "sha": "0bfc5269714a8861f29c1253bf89e6465eae8ab9", "lastModified": "2023-01-16T13:51:25.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:mkqa", "source_datasets:natural_questions", "language:da", "language:sv", "language:no", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "alexandrainst", "description": "ScandiQA is a dataset of questions and answers in the Danish, Norwegian, and Swedish\nlanguages. All samples come from the Natural Questions (NQ) dataset, which is a large\nquestion answering dataset from Google searches. The Scandinavian questions and answers\ncome from the MKQA dataset, where 10,000 NQ samples were manually translated into,\namong others, Danish, Norwegian, and Swedish. However, this did not include a\ntranslated context, hindering the training of extractive question answering models.\n\nWe merged the NQ dataset with the MKQA dataset, and extracted contexts as either \"long\nanswers\" from the NQ dataset, being the paragraph in which the answer was found, or\notherwise we extract the context by locating the paragraphs which have the largest\ncosine similarity to the question, and which contains the desired answer.\n\nFurther, many answers in the MKQA dataset were \"language normalised\": for instance, all\ndate answers were converted to the format \"YYYY-MM-DD\", meaning that in most cases\nthese answers are not appearing in any paragraphs. We solve this by extending the MKQA\nanswers with plausible \"answer candidates\", being slight perturbations or translations\nof the answer.\n\nWith the contexts extracted, we translated these to Danish, Swedish and Norwegian using\nthe DeepL translation service for Danish and Swedish, and the Google Translation\nservice for Norwegian. After translation we ensured that the Scandinavian answers do\nindeed occur in the translated contexts.\n\nAs we are filtering the MKQA samples at both the \"merging stage\" and the \"translation\nstage\", we are not able to fully convert the 10,000 samples to the Scandinavian\nlanguages, and instead get roughly 8,000 samples per language. These have further been\nsplit into a training, validation and test split, with the former two containing\nroughly 750 samples. The splits have been created in such a way that the proportion of\nsamples without an answer is roughly the same in each split.", "citation": "# @InProceedings{huggingface:dataset,\n# title = {ScandiQA: A Scandinavian Question Answering Dataset},\n# author={Dan Saattrup Nielsen},\n# year={2022}\n# }\n#", "cardData": null, "siblings": [], "_id": "630ddc93f6f6d700f50682bd", "disabled": false, "gated": false, "likes": 7, "downloads": 13, "createdAt": "2022-08-30T09:46:59.000Z"}, {"id": "opus/liv4ever", "sha": "548923f1122a84ce3de8ae3bd972922fd01afb9d", "lastModified": "2022-09-02T19:00:53.000Z", "tags": ["region:us"], "private": false, "author": "opus", "description": "This is the Livonian 4-lingual parallel corpus. Livonian is a Uralic / Finnic language with just about 20 fluent\nspeakers and no native speakers (as of 2021). The texts and translations in this corpus were collected from all the\ndigital text resources that could be found by the authors; scanned and printed materials are left for future work.", "citation": null, "cardData": null, "siblings": [], "_id": "631252825beb528b5c111f2d", "disabled": false, "gated": false, "likes": 0, "downloads": 152, "createdAt": "2022-09-02T18:59:14.000Z"}, {"id": "jamescalam/image-text-demo", "sha": "93edd1bca752c19f2cf64a5b24e2f3cf3a1e7fb1", "lastModified": "2023-02-06T05:29:49.000Z", "tags": ["region:us"], "private": false, "author": "jamescalam", "description": "Demo dataset for testing or showing image-text capabilities.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Small image-text set},\nauthor={James Briggs},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "63145c2f4d923ec747e76ee4", "disabled": false, "gated": false, "likes": 0, "downloads": 466, "createdAt": "2022-09-04T08:05:03.000Z"}, {"id": "bigbio/biosses", "sha": "f1e5518e824f5eaddfe81377a58ea18c329abb55", "lastModified": "2022-12-22T15:32:58.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": "bigbio", "description": "BIOSSES computes similarity of biomedical sentences by utilizing WordNet as the\ngeneral domain ontology and UMLS as the biomedical domain specific ontology.\nThe original paper outlines the approaches with respect to using annotator\nscore as golden standard. Source view will return all annotator score\nindividually whereas the Bigbio view will return the mean of the annotator\nscore.", "citation": "@article{souganciouglu2017biosses,\n  title={BIOSSES: a semantic sentence similarity estimation system for the biomedical domain},\n  author={So\u011fanc\u0131o\u011flu, Gizem, Hakime \u00d6zt\u00fcrk, and Arzucan \u00d6zg\u00fcr},\n  journal={Bioinformatics},\n  volume={33},\n  number={14},\n  pages={i49--i58},\n  year={2017},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "63169e74550b00d37dbce7b7", "disabled": false, "gated": false, "likes": 1, "downloads": 51, "createdAt": "2022-09-06T01:12:20.000Z"}, {"id": "eraldoluis/faquad", "sha": "e0ec01c52f1ebc2be766493eca5f571b4e20474b", "lastModified": "2023-01-23T08:45:41.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:extended|wikipedia", "language:pt", "license:cc-by-4.0", "region:us"], "private": false, "author": "eraldoluis", "description": "Academic secretaries and faculty members of higher education institutions face a common problem: \n  the abundance of questions sent by academics \n  whose answers are found in available institutional documents. \nThe official documents produced by Brazilian public universities are vast and disperse, \n  which discourage students to further search for answers in such sources.\nIn order to lessen this problem, we present FaQuAD: \n  a novel machine reading comprehension dataset \n  in the domain of Brazilian higher education institutions. \nFaQuAD follows the format of SQuAD (Stanford Question Answering Dataset) [Rajpurkar et al. 2016]. \nIt comprises 900 questions about 249 reading passages (paragraphs), \n  which were taken from 18 official documents of a computer science college \n  from a Brazilian federal university \n  and 21 Wikipedia articles related to Brazilian higher education system. \nAs far as we know, this is the first Portuguese reading comprehension dataset in this format.", "citation": "@INPROCEEDINGS{\n    8923668,\n    author={Sayama, H\u00e9lio Fonseca and Araujo, Anderson Vi\u00e7oso and Fernandes, Eraldo Rezende},\n    booktitle={2019 8th Brazilian Conference on Intelligent Systems (BRACIS)},\n    title={FaQuAD: Reading Comprehension Dataset in the Domain of Brazilian Higher Education},\n    year={2019},\n    volume={},\n    number={},\n    pages={443-448},\n    doi={10.1109/BRACIS.2019.00084}\n}", "cardData": null, "siblings": [], "_id": "6317295dcd0254f8026bddf7", "disabled": false, "gated": false, "likes": 6, "downloads": 186, "createdAt": "2022-09-06T11:05:01.000Z"}, {"id": "cjvt/solar3", "sha": "a77ffb4773b694d03c805d80ea128b44e5c709f3", "lastModified": "2022-10-21T07:35:45.000Z", "tags": ["task_categories:text2text-generation", "task_categories:other", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:1K<n<10K", "source_datasets:original", "language:sl", "license:cc-by-nc-sa-4.0", "grammatical-error-correction", "other-token-classification-of-text-errors", "region:us"], "private": false, "author": "cjvt", "description": "\u0160olar is a developmental corpus of 5485 school texts (e.g., essays), written by students in Slovenian secondary schools \n(age 15-19) and pupils in the 7th-9th grade of primary school (13-15), with a small percentage also from the 6th grade. \nPart of the corpus (1516 texts) is annotated with teachers' corrections using a system of labels described in the \ndocument available at https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1589/Smernice-za-oznacevanje-korpusa-Solar_V1.1.pdf (in Slovenian).", "citation": "@misc{solar3.0,\n    title = {Developmental corpus {\\v S}olar 3.0},\n    author = {Arhar Holdt, {\\v S}pela and Rozman, Tadeja and Stritar Ku{\\v c}uk, Mojca and Krek, Simon and Krap{\\v s} Vodopivec, Irena and Stabej, Marko and Pori, Eva and Goli, Teja and Lavri{\\v c}, Polona and Laskowski, Cyprian and Kocjan{\\v c}i{\\v c}, Polonca and Klemenc, Bojan and Krsnik, Luka and Kosem, Iztok},\n    url = {http://hdl.handle.net/11356/1589},\n    note = {Slovenian language resource repository {CLARIN}.{SI}},\n    year = {2022}\n}", "cardData": null, "siblings": [], "_id": "6318616773e9e4aa51dc18e4", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2022-09-07T09:16:23.000Z"}, {"id": "cannlytics/cannabis_tests", "sha": "671cdca3749b70e3e3b4f23e36428f1b1890ab70", "lastModified": "2023-02-22T15:48:43.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:expert-generated", "size_categories:1K<n<10K", "source_datasets:original", "license:cc-by-4.0", "cannabis", "lab results", "tests", "region:us"], "private": false, "author": "cannlytics", "description": "Cannabis lab test results (https://cannlytics.com/data/results) is a\ndataset of curated cannabis lab test results.", "citation": "@inproceedings{cannlytics2022cannabis_tests,\n  author    = {Skeate, Keegan and O'Sullivan-Sutherland, Candace},\n  title     = {Cannabis Tests: Curated Cannabis Lab Test Results},\n  booktitle = {Cannabis Data Science},\n  month     = {September},\n  year      = {2022},\n  address   = {United States of America},\n  publisher = {Cannlytics}\n}", "cardData": null, "siblings": [], "_id": "631cc15471f8e7137df4d6e9", "disabled": false, "gated": false, "likes": 6, "downloads": 32, "createdAt": "2022-09-10T16:54:44.000Z"}, {"id": "neulab/conala", "sha": "fbc749f1c537e5c3834e93b15784302e331debe2", "lastModified": "2022-10-20T20:25:00.000Z", "tags": ["task_categories:text2text-generation", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:mit", "code-generation", "arxiv:1805.08949", "region:us"], "private": false, "author": "neulab", "description": "CoNaLa is a dataset of code and natural language pairs crawled from Stack Overflow, for more details please refer to this paper: https://arxiv.org/pdf/1805.08949.pdf or the dataset page https://conala-corpus.github.io/.", "citation": "@inproceedings{yin2018learning,\n  title={Learning to mine aligned code and natural language pairs from stack overflow},\n  author={Yin, Pengcheng and Deng, Bowen and Chen, Edgar and Vasilescu, Bogdan and Neubig, Graham},\n  booktitle={2018 IEEE/ACM 15th international conference on mining software repositories (MSR)},\n  pages={476--486},\n  year={2018},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "63222bfce4399dd6139aa41a", "disabled": false, "gated": false, "likes": 45, "downloads": 504, "createdAt": "2022-09-14T19:31:08.000Z"}, {"id": "codesue/kelly", "sha": "a99cdd9ebcda07905cf2d6c5cdf58b70c43cce8e", "lastModified": "2022-12-18T22:06:55.000Z", "tags": ["task_categories:text-classification", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:sv", "license:cc-by-4.0", "lexicon", "swedish", "CEFR", "region:us"], "private": false, "author": "codesue", "description": "The Swedish Kelly list is a freely available frequency-based vocabulary list that comprises general-purpose language of modern Swedish. The list was generated from a large web-acquired corpus (SweWaC) of 114 million words dating from the 2010s. It is adapted to the needs of language learners and contains 8,425 most frequent lemmas that cover 80% of SweWaC.\\", "citation": "@article{Kilgarriff2013,\ndoi = {10.1007/s10579-013-9251-2},\nurl = {https://doi.org/10.1007/s10579-013-9251-2},\nyear = {2013},\nmonth = sep,\npublisher = {Springer Science and Business Media {LLC}},\nvolume = {48},\nnumber = {1},\npages = {121--163},\nauthor = {Adam Kilgarriff and Frieda Charalabopoulou and Maria Gavrilidou and Janne Bondi Johannessen and Saussan Khalil and Sofie Johansson Kokkinakis and Robert Lew and Serge Sharoff and Ravikiran Vadlapudi and Elena Volodina},\ntitle = {Corpus-based vocabulary lists for language learners for nine languages},\njournal = {Language Resources and Evaluation}\n}", "cardData": null, "siblings": [], "_id": "6323dce83259cbaadbcde970", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2022-09-16T02:18:16.000Z"}, {"id": "PlanTL-GOB-ES/wnli-es", "sha": "6ca3d7b3c4711e6f9df5d73ee70958c2750f925c", "lastModified": "2022-11-18T12:03:25.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:extended|glue", "language:es", "license:cc-by-4.0", "region:us"], "private": false, "author": "PlanTL-GOB-ES", "description": "professional translation into Spanish of Winograd NLI dataset as published in GLUE Benchmark.\n               The Winograd NLI dataset presents 855 sentence pairs, \n               in which the first sentence contains an ambiguity and the second one a possible interpretation of it. \n               The label indicates if the interpretation is correct (1) or not (0).", "citation": "ADD CITATION", "cardData": null, "siblings": [], "_id": "63247f7160ff5fbf36e94f24", "disabled": false, "gated": false, "likes": 2, "downloads": 52, "createdAt": "2022-09-16T13:51:45.000Z"}, {"id": "anton-l/earnings22_baseline_5_gram", "sha": "deb6287d02a3b1465a6ea16f6a99f04bac73b348", "lastModified": "2022-10-17T18:35:04.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "anton-l", "description": "\\nThe Earnings 22 dataset ( also referred to as earnings22 ) is a 119-hour corpus of English-language earnings calls collected from global companies. \nThe primary purpose is to serve as a benchmark for industrial and academic automatic speech recognition (ASR) models on real-world accented speech.", "citation": "\\n@misc{https://doi.org/10.48550/arxiv.2203.15591,\n  doi = {10.48550/ARXIV.2203.15591},\n  url = {https://arxiv.org/abs/2203.15591},\n  author = {Del Rio, Miguel and Ha, Peter and McNamara, Quinten and Miller, Corey and Chandra, Shipra},\n  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {Earnings-22: A Practical Benchmark for Accents in the Wild},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "6325e86b4f4f4ea5a860a5ba", "disabled": false, "gated": false, "likes": 1, "downloads": 16, "createdAt": "2022-09-17T15:31:55.000Z"}, {"id": "skytnt/fbanimehq", "sha": "493d1d86e7977892b60f8eeb901a10fe84fd1fc7", "lastModified": "2022-10-23T14:02:23.000Z", "tags": ["task_categories:unconditional-image-generation", "size_categories:100K<n<1M", "source_datasets:original", "license:cc0-1.0", "region:us"], "private": false, "author": "skytnt", "description": "FBAnimeHQ is a dataset with high-quality full-body anime girl images in a resolution of 1024 \u00d7 512.", "citation": null, "cardData": null, "siblings": [], "_id": "63266df72a0af3bd45271f3a", "disabled": false, "gated": false, "likes": 9, "downloads": 14, "createdAt": "2022-09-18T01:01:43.000Z"}, {"id": "asapp/slue", "sha": "e804f0ad5054f08cd6dd5641fab37d22f162234b", "lastModified": "2022-09-26T23:08:10.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_categories:text-classification", "task_categories:token-classification", "task_ids:sentiment-analysis", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc0-1.0", "license:cc-by-4.0", "arxiv:2111.10367", "region:us"], "private": false, "author": "asapp", "description": "Spoken Language Understanding Evaluation (SLUE) benchmark. There are two subsets: (i) SLUE-VoxPopuli which has ASR and NER tasks and (ii) SLUE-VoxCeleb which has ASR and SA tasks.", "citation": "@inproceedings{shon2022slue,\n  title={Slue: New benchmark tasks for spoken language understanding evaluation on natural speech},\n  author={Shon, Suwon and Pasad, Ankita and Wu, Felix and Brusco, Pablo and Artzi, Yoav and Livescu, Karen and Han, Kyu J},\n  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n  pages={7927--7931},\n  year={2022},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "6328afff76bcaa47f6445619", "disabled": false, "gated": false, "likes": 2, "downloads": 135, "paperswithcode_id": "slue", "createdAt": "2022-09-19T18:07:59.000Z"}, {"id": "THUDM/humaneval-x", "sha": "62c78627f3072a1454fa0cb0184737cafe5e4198", "lastModified": "2022-10-25T06:08:38.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:unknown", "language:code", "license:apache-2.0", "region:us"], "private": false, "author": "THUDM", "description": "HumanEval-X is a benchmark for the evaluation of the multilingual ability of code generative models. It consists of 820 high-quality human-crafted data samples (each with test cases) in Python, C++, Java, JavaScript, and Go, and can be used for various tasks.", "citation": null, "cardData": null, "siblings": [], "_id": "6329e91915a8aeac601ddfeb", "disabled": false, "gated": false, "likes": 49, "downloads": 863, "createdAt": "2022-09-20T16:23:53.000Z"}, {"id": "nlphuji/winogavil", "sha": "51e1265fc8118bc9273550c3ade7ee4e546e0bb9", "lastModified": "2022-11-26T19:56:27.000Z", "tags": ["annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-4.0", "commonsense-reasoning", "visual-reasoning", "arxiv:2207.12576", "region:us"], "private": false, "author": "nlphuji", "description": "WinoGAViL is a challenging dataset for evaluating vision-and-language commonsense reasoning abilities. Given a set of images, a cue, and a number K, the task is to select the K images that best fits the association. This dataset was collected via the WinoGAViL online game to collect vision-and-language associations, (e.g., werewolves to a full moon). Inspired by the popular card game Codenames, a spymaster gives a textual cue related to several visual candidates, and another player has to identify them. Human players are rewarded for creating associations that are challenging for a rival AI model but still solvable by other human players. We evaluate several state-of-the-art vision-and-language models, finding that they are intuitive for humans (>90% Jaccard index) but challenging for state-of-the-art AI models, where the best model (ViLT) achieves a score of 52%, succeeding mostly where the cue is visually salient. Our analysis as well as the feedback we collect from players indicate that the collected associations require diverse reasoning skills, including general knowledge, common sense, abstraction, and more.", "citation": "@article{bitton2022winogavil,\n  title={WinoGAViL: Gamified Association Benchmark to Challenge Vision-and-Language Models},\n  author={Bitton, Yonatan and Guetta, Nitzan Bitton and Yosef, Ron and Elovici, Yuval and Bansal, Mohit and Stanovsky, Gabriel and Schwartz, Roy},\n  journal={arXiv preprint arXiv:2207.12576},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "632e08a13519dfea2bd5bc0b", "disabled": false, "gated": false, "likes": 0, "downloads": 608, "paperswithcode_id": "winogavil", "createdAt": "2022-09-23T19:27:29.000Z"}, {"id": "HuggingFaceM4/cm4-synthetic-testing", "sha": "c53614789f63256d057d584d40c10e2fc29212b1", "lastModified": "2022-11-22T16:24:24.000Z", "tags": ["license:bigscience-openrail-m", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "This dataset is designed to be used in testing. It's derived from cm4-10k dataset", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Multimodal synthetic dataset for testing},\nauthor={HuggingFace, Inc.},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "632e6d6f02890f64f52e6b53", "disabled": false, "gated": false, "likes": 3, "downloads": 46004, "createdAt": "2022-09-24T02:37:35.000Z"}, {"id": "bigbio/mednli", "sha": "21f3313de37d60d45fb67a276d63ace9c4a0ac7d", "lastModified": "2022-12-22T15:24:43.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "State of the art models using deep neural networks have become very good in learning an accurate\nmapping from inputs to outputs. However, they still lack generalization capabilities in conditions\nthat differ from the ones encountered during training. This is even more challenging in specialized,\nand knowledge intensive domains, where training data is limited. To address this gap, we introduce\nMedNLI - a dataset annotated by doctors, performing a natural language inference task (NLI),\ngrounded in the medical history of patients. As the source of premise sentences, we used the\nMIMIC-III. More specifically, to minimize the risks to patient privacy, we worked with clinical\nnotes corresponding to the deceased patients. The clinicians in our team suggested the Past Medical\nHistory to be the most informative section of a clinical note, from which useful inferences can be\ndrawn about the patient.", "citation": "@misc{https://doi.org/10.13026/c2rs98,\n    title        = {MedNLI \u2014 A Natural Language Inference Dataset For The Clinical Domain},\n    author       = {Shivade,  Chaitanya},\n    year         = 2017,\n    publisher    = {physionet.org},\n    doi          = {10.13026/C2RS98},\n    url          = {https://physionet.org/content/mednli/}\n}", "cardData": null, "siblings": [], "_id": "633117a0bc39fc78a4caceaa", "disabled": false, "gated": false, "likes": 5, "downloads": 37, "paperswithcode_id": "mednli", "createdAt": "2022-09-26T03:08:16.000Z"}, {"id": "bigbio/gad", "sha": "8950f534f8012eef317e1b90b2a8b13fbec8746d", "lastModified": "2022-12-22T15:25:28.000Z", "tags": ["multilinguality:momolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "A corpus identifying associations between genes and diseases by a semi-automatic\nannotation procedure based on the Genetic Association Database", "citation": "@article{Bravo2015,\n  doi = {10.1186/s12859-015-0472-9},\n  url = {https://doi.org/10.1186/s12859-015-0472-9},\n  year = {2015},\n  month = feb,\n  publisher = {Springer Science and Business Media {LLC}},\n  volume = {16},\n  number = {1},\n  author = {{\\`{A}}lex Bravo and Janet Pi{\\~{n}}ero and N{\\'{u}}ria Queralt-Rosinach and Michael Rautschka and Laura I Furlong},\n  title = {Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research},\n  journal = {{BMC} Bioinformatics}\n}", "cardData": null, "siblings": [], "_id": "63311e402ef32331612a1363", "disabled": false, "gated": false, "likes": 1, "downloads": 154, "paperswithcode_id": "gad", "createdAt": "2022-09-26T03:36:32.000Z"}, {"id": "bigbio/bioasq_task_b", "sha": "e0ca639ce1a5f1267ada3f8fae2fdad79737887c", "lastModified": "2022-12-22T15:41:12.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The data are intended to be used as training and development data for BioASQ\n10, which will take place during 2022. There is one file containing the data:\n - training10b.json\n\nThe file contains the data of the first nine editions of the challenge: 4234\nquestions [1] with their relevant documents, snippets, concepts and RDF\ntriples, exact and ideal answers.\n\nDifferences with BioASQ-training9b.json\n- 492 new questions added from BioASQ9\n    - The question with id 56c1f01eef6e394741000046 had identical body with\n    602498cb1cb411341a00009e. All relevant elements from both questions\n    are available in the merged question with id 602498cb1cb411341a00009e.\n    - The question with id 5c7039207c78d69471000065 had identical body with\n    601c317a1cb411341a000014. All relevant elements from both questions\n    are available in the merged question with id 601c317a1cb411341a000014.\n\t- The question with id 5e4b540b6d0a27794100001c had identical body with\n    602828b11cb411341a0000fc. All relevant elements from both questions\n    are available in the merged question with id 602828b11cb411341a0000fc.\n    - The question with id 5fdb42fba43ad31278000027 had identical body with\n    5d35eb01b3a638076300000f. All relevant elements from both questions\n    are available in the merged question with id 5d35eb01b3a638076300000f.\n    - The question with id 601d76311cb411341a000045 had identical body with\n    6060732b94d57fd87900003d. All relevant elements from both questions\n    are available in the merged question with id 6060732b94d57fd87900003d.\n\n[1] 4234 questions : 1252 factoid, 1148 yesno, 1018 summary, 816 list", "citation": "@article{tsatsaronis2015overview,\n\ttitle        = {\n\t\tAn overview of the BIOASQ large-scale biomedical semantic indexing and\n\t\tquestion answering competition\n\t},\n\tauthor       = {\n\t\tTsatsaronis, George and Balikas, Georgios and Malakasiotis, Prodromos\n        and Partalas, Ioannis and Zschunke, Matthias and Alvers, Michael R and\n\t\tWeissenborn, Dirk and Krithara, Anastasia and Petridis, Sergios and\n\t\tPolychronopoulos, Dimitris and others\n\t},\n\tyear         = 2015,\n\tjournal      = {BMC bioinformatics},\n\tpublisher    = {BioMed Central Ltd},\n\tvolume       = 16,\n\tnumber       = 1,\n\tpages        = 138\n}", "cardData": null, "siblings": [], "_id": "633125082ef32331612a4271", "disabled": false, "gated": false, "likes": 3, "downloads": 94, "createdAt": "2022-09-26T04:05:28.000Z"}, {"id": "joelniklaus/Multi_Legal_Pile", "sha": "d91ed159caa61392ba939202717dbbcd5f23949f", "lastModified": "2023-10-18T20:39:36.000Z", "tags": ["task_categories:fill-mask", "annotations_creators:other", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:cc-by-nc-sa-4.0", "arxiv:2306.02069", "region:us"], "private": false, "author": "joelniklaus", "description": "Multi Legal Pile is a dataset of legal documents in the 24 EU languages.", "citation": "", "cardData": null, "siblings": [], "_id": "63317eb64bd187e9ce055cfe", "disabled": false, "gated": false, "likes": 30, "downloads": 51, "createdAt": "2022-09-26T10:28:06.000Z"}, {"id": "EMBO/sd-nlp-v2", "sha": "6b7cdd494e42ae91bea2ac6aceeeed38132b12cd", "lastModified": "2022-09-26T12:47:16.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "EMBO", "description": "    This dataset is based on the SourceData database and is intended to facilitate training of NLP tasks in the cell and molecualr biology domain.", "citation": "    @Unpublished{\n        huggingface: dataset,\n        title = {SourceData NLP},\n        authors={Thomas Lemberger & Jorge Abreu-Vicente, EMBO},\n        year={2021}\n    }", "cardData": null, "siblings": [], "_id": "63319d439d77091830d1db9e", "disabled": false, "gated": false, "likes": 0, "downloads": 34, "createdAt": "2022-09-26T12:38:27.000Z"}, {"id": "DFKI-SLT/tacred", "sha": "c801dc186b40a532c5820b4662570390da90431b", "lastModified": "2023-05-17T12:55:00.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other", "language:en", "license:other", "relation extraction", "arxiv:2104.08398", "region:us"], "private": false, "author": "DFKI-SLT", "description": "TACRED is a large-scale relation extraction dataset with 106,264 examples built over newswire\n and web text from the corpus used in the yearly TAC Knowledge Base Population (TAC KBP) challenges.\n Examples in TACRED cover 41 relation types as used in the TAC KBP challenges (e.g., per:schools_attended\n and org:members) or are labeled as no_relation if no defined relation is held. These examples are created\n by combining available human annotations from the TAC KBP challenges and crowdsourcing.\n\n Please see our EMNLP paper, or our EMNLP slides for full details.\n\nNote: There is currently a label-corrected version of the TACRED dataset, which you should consider using instead of\nthe original version released in 2017. For more details on this new version, see the TACRED Revisited paper\npublished at ACL 2020.\n\nNote 2: This Datasetreader changes the offsets of the following fields, to conform with standard Python usage (see\n#_generate_examples()):\n- subj_end to subj_end + 1 (make end offset exclusive)\n- obj_end to obj_end + 1 (make end offset exclusive)\n- stanford_head to stanford_head - 1 (make head offsets 0-based)", "citation": "@inproceedings{zhang-etal-2017-position,\n    title = \"Position-aware Attention and Supervised Data Improve Slot Filling\",\n    author = \"Zhang, Yuhao  and\n      Zhong, Victor  and\n      Chen, Danqi  and\n      Angeli, Gabor  and\n      Manning, Christopher D.\",\n    booktitle = \"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing\",\n    month = sep,\n    year = \"2017\",\n    address = \"Copenhagen, Denmark\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D17-1004\",\n    doi = \"10.18653/v1/D17-1004\",\n    pages = \"35--45\",\n}\n\n@inproceedings{alt-etal-2020-tacred,\n    title = \"{TACRED} Revisited: A Thorough Evaluation of the {TACRED} Relation Extraction Task\",\n    author = \"Alt, Christoph  and\n      Gabryszak, Aleksandra  and\n      Hennig, Leonhard\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.142\",\n    doi = \"10.18653/v1/2020.acl-main.142\",\n    pages = \"1558--1569\",\n}\n\n@article{stoica2021re,\n  author    = {George Stoica and\n               Emmanouil Antonios Platanios and\n               Barnab{\\'{a}}s P{\\'{o}}czos},\n  title     = {Re-TACRED: Addressing Shortcomings of the {TACRED} Dataset},\n  journal   = {CoRR},\n  volume    = {abs/2104.08398},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2104.08398},\n  eprinttype = {arXiv},\n  eprint    = {2104.08398},\n  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08398.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63341bbadf7fd24fb072815d", "disabled": false, "gated": false, "likes": 4, "downloads": 1266, "createdAt": "2022-09-28T10:02:34.000Z"}, {"id": "nuprl/MultiPL-E", "sha": "d23b094346c5dbda1080a74bb2a24c18adbf7409", "lastModified": "2023-06-16T00:08:57.000Z", "tags": ["annotations_creators:machine-generated", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|openai_humaneval", "source_datasets:extended|mbpp", "language:en", "license:mit", "region:us"], "private": false, "author": "nuprl", "description": "MultiPL-E is a dataset for evaluating large language models for code generation that supports 18 programming languages. It takes the OpenAI \"HumanEval\" and the MBPP Python benchmarks and uses little compilers to translate them to other languages. It is easy to add support for new languages and benchmarks.", "citation": "@article{cassano:multipl-e,\n  author = {Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and\n            Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and\n            Anderson, Carolyn Jane and Feldman, Molly Q and Guha, Arjun and\n            Greenberg, Michael and Jangda, Abhinav},\n  title = {{MultiPL-E}: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation},\n  journal = \"{IEEE} Transactions of Software Engineering (TSE)\",\n  year = 2023\n}", "cardData": null, "siblings": [], "_id": "63349e67495073b88705fd76", "disabled": false, "gated": false, "likes": 17, "downloads": 27087, "createdAt": "2022-09-28T19:20:07.000Z"}, {"id": "cannlytics/cannabis_licenses", "sha": "5c9e80ea311d9ab56264265b77ed06a1d32bcef0", "lastModified": "2023-09-30T14:23:05.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:expert-generated", "license:cc-by-4.0", "cannabis", "licenses", "region:us"], "private": false, "author": "cannlytics", "description": "Cannabis Licenses is a dataset of curated cannabis license data. The dataset consists of sub-datasets for each state with permitted adult-use cannabis, as well as a sub-dataset that includes all licenses.", "citation": "@inproceedings{cannlytics2023cannabis_licenses,\n  author    = {Skeate, Keegan and O'Sullivan-Sutherland, Candace},\n  title     = {Cannabis Licenses},\n  booktitle = {Cannabis Data Science},\n  month     = {August},\n  year      = {2023},\n  address   = {United States of America},\n  publisher = {Cannlytics}\n}", "cardData": null, "siblings": [], "_id": "6334a5f7c3cb9eda932ab38d", "disabled": false, "gated": false, "likes": 3, "downloads": 77, "createdAt": "2022-09-28T19:52:23.000Z"}, {"id": "skytnt/anime-segmentation", "sha": "6685505e1e3c02ac0483398e633922b31de89fb0", "lastModified": "2022-10-03T01:35:40.000Z", "tags": ["task_categories:image-segmentation", "task_ids:semantic-segmentation", "size_categories:10K<n<100K", "source_datasets:original", "license:cc0-1.0", "region:us"], "private": false, "author": "skytnt", "description": "A segmentation dataset for anime character", "citation": null, "cardData": null, "siblings": [], "_id": "63367e2a38e33ddc2659e336", "disabled": false, "gated": false, "likes": 21, "downloads": 132, "createdAt": "2022-09-30T05:27:06.000Z"}, {"id": "DFKI-SLT/multitacred", "sha": "a53e7be7c5dcc3b5e9880f8d037cd1450f3325e9", "lastModified": "2023-11-06T12:19:37.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "language_creators:found", "size_categories:100K<n<1M", "source_datasets:DFKI-NLP/tacred", "language:ar", "language:de", "language:es", "language:fi", "language:fr", "language:hi", "language:hu", "language:ja", "language:pl", "language:ru", "language:tr", "language:zh", "license:other", "relation extraction", "arxiv:2305.04582", "region:us"], "private": false, "author": "DFKI-SLT", "description": "MultiTACRED is a multilingual version of the large-scale TAC Relation Extraction Dataset \n(https://nlp.stanford.edu/projects/tacred). It covers 12 typologically diverse languages from 9 language families, \nand was created by the Speech & Language Technology group of DFKI (https://www.dfki.de/slt) by machine-translating the\ninstances of the original TACRED dataset and automatically projecting their entity annotations. For details of the \noriginal TACRED's data collection and annotation process, see the Stanford paper (https://aclanthology.org/D17-1004/). \nTranslations are syntactically validated by checking the correctness of the XML tag markup. Any translations with an \ninvalid tag structure, e.g. missing or invalid head or tail tag pairs, are discarded (on average, 2.3% of the \ninstances).\n\nLanguages covered are: Arabic, Chinese, Finnish, French, German, Hindi, Hungarian, Japanese, Polish,\n Russian, Spanish, Turkish. Intended use is supervised relation classification. Audience - researchers.\n\n Please see our ACL paper (https://arxiv.org/abs/2305.04582) for full details.\n\nNOTE: This Datasetreader supports a reduced version of the original TACRED JSON format with the following changes:\n- Removed fields: stanford_pos, stanford_ner, stanford_head, stanford_deprel, docid\nThe motivation for this is that we want to support additional languages, for which these fields were not required\nor available. The reader expects the specification of a language-specific configuration specifying the variant\n(original, revisited or retacred) and the language (as a two-letter iso code).\n\nThe DatasetReader changes the offsets of the following fields, to conform with standard Python usage (see\n_generate_examples()):\n- subj_end to subj_end + 1 (make end offset exclusive)\n- obj_end to obj_end + 1 (make end offset exclusive)\n\nNOTE 2: The MultiTACRED dataset offers an additional 'split', namely the backtranslated test data (translated to a\ntarget language and then back to English). To access this split, use dataset['backtranslated_test'].\n\nYou can find the TACRED dataset reader for the English version of the dataset at \nhttps://huggingface.co/datasets/DFKI-SLT/tacred.", "citation": "@inproceedings{hennig-etal-2023-multitacred,\n    title = \"MultiTACRED: A Multilingual Version of the TAC Relation Extraction Dataset\",\n    author = \"Hennig, Leonhard and Thomas, Philippe and M\u00f6ller, Sebastian\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Online and Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n}\n\n@inproceedings{zhang-etal-2017-position,\n    title = \"Position-aware Attention and Supervised Data Improve Slot Filling\",\n    author = \"Zhang, Yuhao  and\n      Zhong, Victor  and\n      Chen, Danqi  and\n      Angeli, Gabor  and\n      Manning, Christopher D.\",\n    booktitle = \"Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing\",\n    month = sep,\n    year = \"2017\",\n    address = \"Copenhagen, Denmark\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D17-1004\",\n    doi = \"10.18653/v1/D17-1004\",\n    pages = \"35--45\",\n}\n\n@inproceedings{alt-etal-2020-tacred,\n    title = \"{TACRED} Revisited: A Thorough Evaluation of the {TACRED} Relation Extraction Task\",\n    author = \"Alt, Christoph  and\n      Gabryszak, Aleksandra  and\n      Hennig, Leonhard\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.142\",\n    doi = \"10.18653/v1/2020.acl-main.142\",\n    pages = \"1558--1569\",\n}\n\n@inproceedings{DBLP:conf/aaai/StoicaPP21,\n  author       = {George Stoica and\n                  Emmanouil Antonios Platanios and\n                  Barnab{\\'{a}}s P{\\'{o}}czos},\n  title        = {Re-TACRED: Addressing Shortcomings of the {TACRED} Dataset},\n  booktitle    = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI}\n                  2021, Thirty-Third Conference on Innovative Applications of Artificial\n                  Intelligence, {IAAI} 2021, The Eleventh Symposium on Educational Advances\n                  in Artificial Intelligence, {EAAI} 2021, Virtual Event, February 2-9,\n                  2021},\n  pages        = {13843--13850},\n  publisher    = {{AAAI} Press},\n  year         = {2021},\n  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/17631},\n}", "cardData": null, "siblings": [], "_id": "6336d393ecdc9400b2ba6c26", "disabled": false, "gated": false, "likes": 1, "downloads": 127, "paperswithcode_id": "multitacred", "createdAt": "2022-09-30T11:31:31.000Z"}, {"id": "alkzar90/NIH-Chest-X-ray-dataset", "sha": "3655d3cbaad4028f787282b2ada55967aabac9c1", "lastModified": "2022-11-22T20:10:52.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:machine-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:unknown", "arxiv:1705.02315", "region:us"], "private": false, "author": "alkzar90", "description": "The NIH Chest X-ray dataset consists of 100,000 de-identified images of chest x-rays. The images are in PNG format.\n\nThe data is provided by the NIH Clinical Center and is available through the NIH download site: https://nihcc.app.box.com/v/ChestXray-NIHCC", "citation": "@inproceedings{Wang_2017,\n\tdoi = {10.1109/cvpr.2017.369},\n\turl = {https://doi.org/10.1109%2Fcvpr.2017.369},\n\tyear = 2017,\n\tmonth = {jul},\n\tpublisher = {{IEEE}\n},\n\tauthor = {Xiaosong Wang and Yifan Peng and Le Lu and Zhiyong Lu and Mohammadhadi Bagheri and Ronald M. Summers},\n\ttitle = {{ChestX}-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},\n\tbooktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})}\n}", "cardData": null, "siblings": [], "_id": "6336e500970187a00a99b015", "disabled": false, "gated": false, "likes": 19, "downloads": 1021, "paperswithcode_id": "chestx-ray14", "createdAt": "2022-09-30T12:45:52.000Z"}, {"id": "TurkuNLP/xlsum-fi", "sha": "aa33b87297442d3bf9aa64ac8db2f1f14bd76b4f", "lastModified": "2022-10-25T06:30:19.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "annotations_creators:found", "language_creators:machine translated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:xlsum", "language:fi", "license:cc-by-nc-sa-4.0", "conditional-text-generation", "region:us"], "private": false, "author": "TurkuNLP", "description": "This dataset is a DeepL -based machine translation of a part of the English section of the XLSum dataset:[https://github.com/csebuetnlp/xl-sum](https://github.com/csebuetnlp/xl-sum) In the present version, only examples where the full version is at most 10x the summary in length are included. We might translate more later.", "citation": "\nPlease cite the article and also acknowledge Filip Ginter / TurkuNLP for the machine translated version\n\n@inproceedings{hasan-etal-2021-xl,\n    title = \"{XL}-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\",\n    author = \"Hasan, Tahmid  and\n      Bhattacharjee, Abhik  and\n      Islam, Md. Saiful  and\n      Mubasshir, Kazi  and\n      Li, Yuan-Fang  and\n      Kang, Yong-Bin  and\n      Rahman, M. Sohel  and\n      Shahriyar, Rifat\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\n    month = aug,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.findings-acl.413\",\n    pages = \"4693--4703\",\n}", "cardData": null, "siblings": [], "_id": "6336eaad31efcb5647f239c0", "disabled": false, "gated": false, "likes": 0, "downloads": 29, "createdAt": "2022-09-30T13:10:05.000Z"}, {"id": "bigbio/blurb", "sha": "f6e0fcd3a4171e2a9a2656f58cb50b9aba5fbba5", "lastModified": "2022-12-22T15:27:48.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The BioCreative II Gene Mention task. The training corpus for the current task consists mainly of the training and testing corpora (text collections) from the BCI task, and the testing corpus for the current task consists of an additional 5,000 sentences that were held 'in reserve' from the previous task. In the current corpus, tokenization is not provided; instead participants are asked to identify a gene mention in a sentence by giving its start and end characters. As before, the training set consists of a set of sentences, and for each sentence a set of gene mentions (GENE annotations).\n\n- Homepage: https://biocreative.bioinformatics.udel.edu/tasks/biocreative-ii/task-1a-gene-mention-tagging/\n- Repository: https://github.com/cambridgeltl/MTL-Bioinformatics-2016/raw/master/data/\n- Paper: Overview of BioCreative II gene mention recognition\n         https://link.springer.com/article/10.1186/gb-2008-9-s2-s2", "citation": "@article{gu2021domain,\n    title = {\n        Domain-specific language model pretraining for biomedical natural\n        language processing\n    },\n    author = {\n        Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and\n        Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao,\n        Jianfeng and Poon, Hoifung\n    },\n    year = 2021,\n    journal = {ACM Transactions on Computing for Healthcare (HEALTH)},\n    publisher = {ACM New York, NY},\n    volume = 3,\n    number = 1,\n    pages = {1--23}\n}", "cardData": null, "siblings": [], "_id": "633a7f0ea4a8f33508dcd529", "disabled": false, "gated": false, "likes": 1, "downloads": 184, "createdAt": "2022-10-03T06:19:58.000Z"}, {"id": "Drewd/lex_fridman_podcast_transcripts", "sha": "a60d8420a2e5ec790b23d3a6349f6cdb9a1b7934", "lastModified": "2022-10-05T01:41:30.000Z", "tags": ["annotations_creators:found", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:n<1K", "language:en", "podcast", "ai", "interviews", "region:us"], "private": false, "author": "Drewd", "description": "This new dataset is meant to fine tune a model on how lex would talk. It's meant \nto support Q+A style models as well as encoders.", "citation": null, "cardData": null, "siblings": [], "_id": "633babbf0d68f86e2d9aaba7", "disabled": false, "gated": false, "likes": 0, "downloads": 14, "createdAt": "2022-10-04T03:42:55.000Z"}, {"id": "loubnabnl/humaneval_infilling", "sha": "ad46002f24b153968a3d0949e6fa9576780530ba", "lastModified": "2022-10-21T10:37:13.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "source_datasets:original", "language:code", "license:mit", "code-generation", "arxiv:2207.14255", "region:us"], "private": false, "author": "loubnabnl", "description": "An evaluation benchamrk for infilling tasks on HumanEval dataset for code generation.", "citation": "@article{bavarian2022efficient,\n  title={Efficient Training of Language Models to Fill in the Middle},\n  author={Bavarian, Mohammad and Jun, Heewoo and Tezak, Nikolas and Schulman, John and McLeavey, Christine and Tworek, Jerry and Chen, Mark},\n  journal={arXiv preprint arXiv:2207.14255},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "633f068529fea7381b985a8c", "disabled": false, "gated": false, "likes": 0, "downloads": 62, "createdAt": "2022-10-06T16:47:01.000Z"}, {"id": "HuggingFaceM4/general-pmd-synthetic-testing", "sha": "dd044471323012a872f4230be412a4b9e0900f11", "lastModified": "2022-10-07T03:12:13.000Z", "tags": ["license:bigscience-openrail-m", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "This dataset is designed to be used in testing. It's derived from general-pmd-10k dataset", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Multimodal synthetic dataset for testing / general PMD},\nauthor={HuggingFace, Inc.},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "633f7bcc905131c8f5327340", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2022-10-07T01:07:24.000Z"}, {"id": "dennlinger/eur-lex-sum", "sha": "dab944b274fe6e047f0cc6b8dc5e0ca68f4dcd36", "lastModified": "2022-11-11T14:25:06.000Z", "tags": ["task_categories:translation", "task_categories:summarization", "annotations_creators:found", "annotations_creators:expert-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:bg", "language:hr", "language:cs", "language:da", "language:nl", "language:en", "language:et", "language:fi", "language:fr", "language:de", "language:el", "language:hu", "language:ga", "language:it", "language:lv", "language:lt", "language:mt", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:es", "language:sv", "license:cc-by-4.0", "legal", "eur-lex", "expert summary", "parallel corpus", "multilingual", "arxiv:2210.13448", "region:us"], "private": false, "author": "dennlinger", "description": "The EUR-Lex-Sum dataset is a multilingual resource intended for text summarization in the legal domain.\nIt is based on human-written summaries of legal acts issued by the European Union.\nIt distinguishes itself by introducing a smaller set of high-quality human-written samples,\neach of which have much longer references (and summaries!) than comparable datasets.\nAdditionally, the underlying legal acts provide a challenging domain-specific application to legal texts,\nwhich are so far underrepresented in non-English languages.\nFor each legal act, the sample can be available in up to 24 languages\n(the officially recognized languages in the European Union);\nthe validation and test samples consist entirely of samples available in all languages,\nand are aligned across all languages at the paragraph level.", "citation": "@article{aumiller-etal-2022-eur,\nauthor = {Aumiller, Dennis and Chouhan, Ashish and Gertz, Michael},\ntitle = {{EUR-Lex-Sum: A Multi- and Cross-lingual Dataset for Long-form Summarization in the Legal Domain}},\njournal = {CoRR},\nvolume = {abs/2210.13448},\neprinttype = {arXiv},\neprint = {2210.13448},\nurl = {https://arxiv.org/abs/2210.13448}\n}", "cardData": null, "siblings": [], "_id": "6343d2c9e7fd9848ef9d14b6", "disabled": false, "gated": false, "likes": 23, "downloads": 717, "createdAt": "2022-10-10T08:07:37.000Z"}, {"id": "arpelarpe/nota", "sha": "b37f50217a7522a07f588121ecb6c6b06a6a4133", "lastModified": "2022-10-11T07:56:49.000Z", "tags": ["task_categories:automatic-speech-recognition", "multilinguality:monolingual", "language:da", "license:cc0-1.0", "region:us"], "private": false, "author": "arpelarpe", "description": "Nota lyd- og tekstdata\nDatas\u00e6ttet indeholder b\u00e5de tekst- og taledata fra udvalgte dele af Nota's lydbogsbiblotek. Datas\u00e6ttet best\u00e5r af \nover 500 timers opl\u00e6sninger og medf\u00f8lgende transkriptioner p\u00e5 dansk. Al lyddata er i .wav-format, mens tekstdata \ner i .txt-format.\n\nI data indg\u00e5r indl\u00e6sninger af Notas eget blad \"Inspiration\" og \"Radio/TV\", som er udgivet i perioden 2007 til 2022.\nNota krediteres for arbejdet med at strukturere data, s\u00e5ledes at tekst og lyd stemmer overens.\n\nNota er en institution under Kulturministeriet, der g\u00f8r trykte tekster tilg\u00e6ngelige i digitale formater til personer \nmed synshandicap og l\u00e6sevanskeligheder, fx via produktion af lydb\u00f8ger og opl\u00e6sning af aviser, magasiner, mv.", "citation": null, "cardData": null, "siblings": [], "_id": "63450f369ad67b3d069d24a4", "disabled": false, "gated": false, "likes": 2, "downloads": 72, "createdAt": "2022-10-11T06:37:42.000Z"}, {"id": "RussianNLP/tape", "sha": "eaf4532306a3a31fbfa975b45abd80d0b4b759d6", "lastModified": "2023-07-14T19:31:49.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:multiple-choice", "size_categories:1K<n<10K", "language:ru", "license:apache-2.0", "benchmark", "ethics", "question-answering", "reasoning", "arxiv:2210.12813", "region:us"], "private": false, "author": "RussianNLP", "description": "The Winograd schema challenge composes tasks with syntactic ambiguity,\nwhich can be resolved with logic and reasoning (Levesque et al., 2012).\n\nThe texts for the Winograd schema problem are obtained using a semi-automatic \npipeline. First, lists of 11 typical grammatical structures with syntactic \nhomonymy (mainly case) are compiled. For example, two noun phrases with a \ncomplex subordinate: 'A trinket from Pompeii that has survived the centuries'.\nRequests corresponding to these constructions are submitted in search of the \nRussian National Corpus, or rather its sub-corpus with removed homonymy. In the \nresulting 2+k examples, homonymy is removed automatically with manual validation\nafterward. Each original sentence is split into multiple examples in the binary \nclassification format, indicating whether the homonymy is resolved correctly or\nnot.", "citation": "@article{taktasheva2022tape,\n  title={TAPE: Assessing Few-shot Russian Language Understanding},\n  author={Taktasheva, Ekaterina and Shavrina, Tatiana and Fenogenova, Alena and Shevelev, Denis and Katricheva, Nadezhda and Tikhonova, Maria and Akhmetgareeva, Albina and Zinkevich, Oleg and Bashmakova, Anastasiia and Iordanskaia, Svetlana and others},\n  journal={arXiv preprint arXiv:2210.12813},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6346cf839db2aaaf470f2473", "disabled": false, "gated": false, "likes": 5, "downloads": 149, "createdAt": "2022-10-12T14:30:27.000Z"}, {"id": "sled-umich/TRIP", "sha": "e8034abd1a23f948dc6bc68e1bceaa47d7e966c2", "lastModified": "2022-10-14T19:17:29.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "region:us"], "private": false, "author": "sled-umich", "description": "We introduce Tiered Reasoning for Intuitive Physics (TRIP), a novel commonsense reasoning dataset with dense annotations that enable multi-tiered evaluation of machines\u2019 reasoning process.", "citation": "@misc{storks2021tiered,\n      title={Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding}, \n      author={Shane Storks and Qiaozi Gao and Yichi Zhang and Joyce Chai},\n      year={2021},\n      booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},\n      location={Punta Cana, Dominican Republic},\n      publisher={Association for Computational Linguistics},\n}", "cardData": null, "siblings": [], "_id": "63470611110621697cb8b859", "disabled": false, "gated": false, "likes": 0, "downloads": 65, "createdAt": "2022-10-12T18:23:13.000Z"}, {"id": "sled-umich/Action-Effect", "sha": "5e34c0587551f404f5a77198d74e06e6859bd75b", "lastModified": "2022-10-14T19:12:20.000Z", "tags": ["task_categories:image-classification", "task_categories:image-to-text", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:eng", "region:us"], "private": false, "author": "sled-umich", "description": "Despite recent advances in knowledge representation, automated reasoning, and machine learning, artificial agents still lack the ability to understand basic action-effect relations regarding the physical world, for example, the action of cutting a cucumber most likely leads to the state where the cucumber is broken apart into smaller pieces. If artificial agents (e.g., robots) ever become our partners in joint tasks, it is critical to empower them with such action-effect understanding so that they can reason about the state of the world and plan for actions. Towards this goal, this paper introduces a new task on naive physical action-effect prediction, which addresses the relations between concrete actions (expressed in the form of verb-noun pairs) and their effects on the state of the physical world as depicted by images. We collected a dataset for this task and developed an approach that harnesses web image data through distant supervision to facilitate learning for action-effect prediction. Our empirical results have shown that web data can be used to complement a small number of seed examples (e.g., three examples for each action) for model learning. This opens up possibilities for agents to learn physical action-effect relations for tasks at hand through communication with humans with a few examples.", "citation": "@inproceedings{gao-etal-2018-action,\n    title = \"What Action Causes This? Towards Naive Physical Action-Effect Prediction\",\n    author = \"Gao, Qiaozi  and\n      Yang, Shaohua  and\n      Chai, Joyce  and\n      Vanderwende, Lucy\",\n    booktitle = \"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2018\",\n    address = \"Melbourne, Australia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P18-1086\",\n    doi = \"10.18653/v1/P18-1086\",\n    pages = \"934--945\",\n}", "cardData": null, "siblings": [], "_id": "63471ea379e42766e20f5a65", "disabled": false, "gated": false, "likes": 1, "downloads": 149, "createdAt": "2022-10-12T20:08:03.000Z"}, {"id": "csebuetnlp/BanglaParaphrase", "sha": "55a7cf0a0b66ce56ba9c35e5a56bf52c88adfd30", "lastModified": "2022-11-14T15:39:43.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100k<n<1M", "source_datasets:original", "language:bn", "license:cc-by-nc-sa-4.0", "conditional-text-generation", "paraphrase-generation", "arxiv:2210.05109", "region:us"], "private": false, "author": "csebuetnlp", "description": "We present a high quality bangla paraphrase dataset containing about 466k paraphrase pairs. The paraphrases ensures high quality by being semantically coherent and syntactically diverse.", "citation": "to be added", "cardData": null, "siblings": [], "_id": "6348377db43761812152edf0", "disabled": false, "gated": false, "likes": 3, "downloads": 14, "createdAt": "2022-10-13T16:06:21.000Z"}, {"id": "elenanereiss/german-ler", "sha": "9d7a3960c7b4b1f6efb1e97bd4d469a217b46930", "lastModified": "2022-10-26T08:32:17.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:de", "license:cc-by-4.0", "ner, named entity recognition, legal ner, legal texts, label classification", "arxiv:2003.13016", "doi:10.57967/hf/0046", "region:us"], "private": false, "author": "elenanereiss", "description": "A dataset of Legal Documents from German federal court decisions for Named Entity Recognition. The dataset is human-annotated with 19 fine-grained entity classes. The dataset consists of approx. 67,000 sentences and contains 54,000 annotated entities.", "citation": "@misc{https://doi.org/10.48550/arxiv.2003.13016,\n  doi = {10.48550/ARXIV.2003.13016},\n  \n  url = {https://arxiv.org/abs/2003.13016},\n  \n  author = {Leitner, Elena and Rehm, Georg and Moreno-Schneider, Juli\u00e1n},\n  \n  keywords = {Computation and Language (cs.CL), Information Retrieval (cs.IR), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {A Dataset of German Legal Documents for Named Entity Recognition},\n  \n  publisher = {arXiv},\n  \n  year = {2020},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}", "cardData": null, "siblings": [], "_id": "634e89a8d049354d7ee1da53", "disabled": false, "gated": false, "likes": 9, "downloads": 61, "paperswithcode_id": "dataset-of-legal-documents", "createdAt": "2022-10-18T11:10:32.000Z"}, {"id": "tomasg25/scientific_lay_summarisation", "sha": "159aa1a67eac7dd85527e218b2e68a30ebbc2ccd", "lastModified": "2022-10-26T11:11:33.000Z", "tags": ["task_categories:summarization", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:unknown", "abstractive-summarization", "scientific-papers", "lay-summarization", "PLOS", "eLife", "arxiv:2210.09932", "region:us"], "private": false, "author": "tomasg25", "description": "This repository contains the PLOS and eLife datasets, introduced in the EMNLP 2022 paper \"[Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature\n](https://arxiv.org/abs/2210.09932)\". \nEach dataset contains full biomedical research articles paired with expert-written lay summaries (i.e., non-technical summaries). PLOS articles are derived from various journals published by [the Public Library of Science (PLOS)](https://plos.org/), whereas eLife articles are derived from the [eLife](https://elifesciences.org/) journal. More details/anlaysis on the content of each dataset are provided in the paper.\n\nBoth \"elife\" and \"plos\" have 6 features:\n    - \"article\": the body of the document (including the abstract), sections seperated by \"/n\".\n    - \"section_headings\": the title of each section, seperated by \"/n\". \n    - \"keywords\": keywords describing the topic of the article, seperated by \"/n\".\n    - \"title\" : the title of the article.\n    - \"year\" : the year the article was published.\n    - \"summary\": the lay summary of the document.", "citation": "@misc{Goldsack_2022,\n  doi = {10.48550/ARXIV.2210.09932},\n  url = {https://arxiv.org/abs/2210.09932},\n  author = {Goldsack, Tomas and Zhang, Zhihao and Lin, Chenghua and Scarton, Carolina},\n  title = {Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}", "cardData": null, "siblings": [], "_id": "63500ddccfefce6e577ab9f9", "disabled": false, "gated": false, "likes": 12, "downloads": 510, "createdAt": "2022-10-19T14:46:52.000Z"}, {"id": "projecte-aina/Parafraseja", "sha": "c03ad050756db3748209f1a51ba4b8afc8dcefcb", "lastModified": "2023-11-25T06:09:20.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-input-text-classification", "annotations_creators:CLiC-UB", "language_creators:found", "multilinguality:monolingual", "language:ca", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": "projecte-aina", "description": "Parafraseja is a dataset of 16,584 pairs of sentences with a label that indicates if they are paraphrases or not. The original sentences were collected from TE-ca and STS-ca. For each sentence, an annotator wrote a sentence that was a paraphrase and another that was not. The guidelines of this annotation are available.", "citation": "", "cardData": null, "siblings": [], "_id": "635660e21c93c1ef4e9ffdab", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2022-10-24T09:54:42.000Z"}, {"id": "poloclub/diffusiondb", "sha": "4de7acd1878f82cc474f4bc432e27f4b3e363ad7", "lastModified": "2023-05-09T19:00:45.000Z", "tags": ["task_categories:text-to-image", "task_categories:image-to-text", "task_ids:image-captioning", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:n>1T", "source_datasets:original", "language:en", "license:cc0-1.0", "stable diffusion", "prompt engineering", "prompts", "research paper", "arxiv:2210.14896", "region:us"], "private": false, "author": "poloclub", "description": "DiffusionDB is the first large-scale text-to-image prompt dataset. It contains 2\nmillion images generated by Stable Diffusion using prompts and hyperparameters\nspecified by real users. The unprecedented scale and diversity of this\nhuman-actuated dataset provide exciting research opportunities in understanding\nthe interplay between prompts and generative models, detecting deepfakes, and\ndesigning human-AI interaction tools to help users more easily use these models.", "citation": "@article{wangDiffusionDBLargescalePrompt2022,\n  title = {{{DiffusionDB}}: {{A}} Large-Scale Prompt Gallery Dataset for Text-to-Image Generative Models},\n  author = {Wang, Zijie J. and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},\n  year = {2022},\n  journal = {arXiv:2210.14896 [cs]},\n  url = {https://arxiv.org/abs/2210.14896}\n}", "cardData": null, "siblings": [], "_id": "63574918d5389a0786004892", "disabled": false, "gated": false, "likes": 332, "downloads": 956879, "createdAt": "2022-10-25T02:25:28.000Z"}, {"id": "feradauto/MoralExceptQA", "sha": "def71b74159a8460ce977fc2ace42e32947fb3fa", "lastModified": "2022-10-27T15:42:04.000Z", "tags": ["task_categories:text-classification", "arxiv:2210.01478", "region:us"], "private": false, "author": "feradauto", "description": "We present a novel challenge set consisting of moral exception question answering (MoralExceptQA) of cases that involve potentially permissible moral exceptions.", "citation": "@misc{https://doi.org/10.48550/arxiv.2210.01478,\n  doi = {10.48550/ARXIV.2210.01478},\n  \n  url = {https://arxiv.org/abs/2210.01478},\n  \n  author = {Jin, Zhijing and Levine, Sydney and Gonzalez, Fernando and Kamal, Ojasv and Sap, Maarten and Sachan, Mrinmaya and Mihalcea, Rada and Tenenbaum, Josh and Sch\u00f6lkopf, Bernhard},\n  \n  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  \n  title = {When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment},\n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {Creative Commons Attribution Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "63587e9f99234d37903097da", "disabled": false, "gated": false, "likes": 1, "downloads": 665, "createdAt": "2022-10-26T00:26:07.000Z"}, {"id": "taln-ls2n/kpbiomed", "sha": "209818b23654f0057dbac7bb86b6bba4c95d82d1", "lastModified": "2022-12-01T10:52:09.000Z", "tags": ["task_categories:text-generation", "annotations_creators:unknown", "language_creators:unknown", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:en", "license:cc-by-nc-4.0", "arxiv:2211.12124", "region:us"], "private": false, "author": "taln-ls2n", "description": "KPBiomed benchmark dataset for keyphrase extraction an generation.", "citation": "\\", "cardData": null, "siblings": [], "_id": "635938ed6a61954080831960", "disabled": false, "gated": false, "likes": 3, "downloads": 18, "createdAt": "2022-10-26T13:41:01.000Z"}, {"id": "RaphaelOlivier/whisper_adversarial_examples", "sha": "fd3366545ad353723966836cc25f1ed10b7ef355", "lastModified": "2022-11-03T21:48:16.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "RaphaelOlivier", "description": "Adversarial examples fooling whisper models", "citation": null, "cardData": null, "siblings": [], "_id": "635998b77d959cab632c6619", "disabled": false, "gated": false, "likes": 1, "downloads": 47, "createdAt": "2022-10-26T20:29:43.000Z"}, {"id": "AmazonScience/mintaka", "sha": "4788cd2a26eae8a1e6534d87b1bfbad82c3a9dc2", "lastModified": "2022-10-28T10:55:50.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:ar", "multilinguality:de", "multilinguality:ja", "multilinguality:hi", "multilinguality:pt", "multilinguality:en", "multilinguality:es", "multilinguality:it", "multilinguality:fr", "size_categories:100K<n<1M", "source_datasets:original", "license:cc-by-4.0", "region:us"], "private": false, "author": "AmazonScience", "description": "         Mintaka is a complex, natural, and multilingual dataset designed for experimenting with end-to-end\n         question-answering models. Mintaka is composed of 20,000 question-answer pairs collected in English,\n         annotated with Wikidata entities, and translated into Arabic, French, German, Hindi, Italian,\n         Japanese, Portuguese, and Spanish for a total of 180,000 samples.\n         Mintaka includes 8 types of complex questions, including superlative, intersection, and multi-hop questions, \n         which were naturally elicited from crowd workers.", "citation": "        @inproceedings{sen-etal-2022-mintaka,\n            title = \"Mintaka: A Complex, Natural, and Multilingual Dataset for End-to-End Question Answering\",\n            author = \"Sen, Priyanka and Aji, Alham Fikri and Saffari, Amir\",\n            booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n            month = oct,\n            year = \"2022\",\n            address = \"Gyeongju, Republic of Korea\",\n            publisher = \"International Committee on Computational Linguistics\",\n            url = \"https://aclanthology.org/2022.coling-1.138\",\n            pages = \"1604--1619\"\n        }", "cardData": null, "siblings": [], "_id": "635ad026f9a004065f31ba02", "disabled": false, "gated": false, "likes": 7, "downloads": 94, "paperswithcode_id": "mintaka", "createdAt": "2022-10-27T18:38:30.000Z"}, {"id": "KETI-AIR/aihub_dialog_summarization", "sha": "d861d01d303d7a171b319d0e8dc01ff87ac3b2e0", "lastModified": "2022-10-31T06:10:39.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "KETI-AIR", "description": "# \ud55c\uad6d\uc5b4 \ub300\ud654 \uc694\uc57d\n\n## \uc18c\uac1c\n\uc77c\uc0c1 \ub300\ud654, \ud1a0\ub860 \ub4f1 \ub2e4\uc591\ud55c \uc720\ud615\uc758 \ud55c\uad6d\uc5b4 \ub300\ud654 \uc6d0\ubb38 \ud14d\uc2a4\ud2b8 \ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \ud55c\uad6d\uc5b4 \ub300\ud654 \uc694\uc57d AI \uae30\uc220 \uac1c\ubc1c\uc744 \uc704\ud55c \ud55c\uad6d\uc5b4 \ub300\ud654 \uc694\uc57d \ud14d\uc2a4\ud2b8 \ub370\uc774\ud130\n## \uad6c\ucd95\ubaa9\uc801\n\ub274\uc2a4, \uae30\uc0ac \ub4f1\uc758 \ubb38\uc5b4\uccb4\uc5d0 \ube44\ud574 \uc0dd\ub7b5\uc774\ub098 \ubcc0\ud615\uc774 \ub9ce\uace0, \ub300\ud654\uc758 \ubb38\ub9e5\uc744 \uace0\ub824\ud574\uc57c \ud558\ub294 \ud2b9\uc218\uc131\uc774 \uc788\ub294 \ub300\ud654 \uc694\uc57d \uae30\uc220 \uac1c\ubc1c\uc744 \uc704\ud55c \ud55c\uad6d\uc5b4 \ud559\uc2b5 \ub370\uc774\ud130 \uad6c\ucd95\n\n\n## Usage\n```python\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\n                \"aihub_dialog_summarization.py\", \n                \"roberta_prepended_single_punct\",\n                cache_dir=\"huggingface_datasets\", \n                data_dir=\"data\",\n                ignore_verifications=True,\n            )\n\ndataset_train = raw_datasets[\"train\"]\n\nfor item in dataset_train:\n    print(item)\n    exit()\n```\n\n## \ub370\uc774\ud130 \uad00\ub828 \ubb38\uc758\ucc98\n| \ub2f4\ub2f9\uc790\uba85 | \uc804\ud654\ubc88\ud638 | \uc774\uba54\uc77c |\n| ------------- | ------------- | ------------- |\n| \uae40\uc218\uacbd(\ubc14\uc774\ube0c\ucef4\ud37c\ub2c8) | 02-565-0531 | ckaskan@vaiv.kr |\n\n## Copyright\n\n### \ub370\uc774\ud130 \uc18c\uac1c\nAI \ud5c8\ube0c\uc5d0\uc11c \uc81c\uacf5\ub418\ub294 \uc778\uacf5\uc9c0\ub2a5 \ud559\uc2b5\uc6a9 \ub370\uc774\ud130(\uc774\ud558 \u2018AI\ub370\uc774\ud130\u2019\ub77c\uace0 \ud568)\ub294 \uacfc\ud559\uae30\uc220\uc815\ubcf4\ud1b5\uc2e0\ubd80\uc640 \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc758 \u300c\uc9c0\ub2a5\uc815\ubcf4\uc0b0\uc5c5 \uc778\ud504\ub77c \uc870\uc131\u300d \uc0ac\uc5c5\uc758 \uc77c\ud658\uc73c\ub85c \uad6c\ucd95\ub418\uc5c8\uc73c\uba70, \ubcf8 \uc0ac\uc5c5\uc758 \uc720\u2027\ubb34\ud615\uc801 \uacb0\uacfc\ubb3c\uc778 \ub370\uc774\ud130, AI \uc751\uc6a9\ubaa8\ub378 \ubc0f \ub370\uc774\ud130 \uc800\uc791\ub3c4\uad6c\uc758 \uc18c\uc2a4, \uac01\uc885 \ub9e4\ub274\uc5bc \ub4f1(\uc774\ud558 \u2018AI\ub370\uc774\ud130 \ub4f1\u2019)\uc5d0 \ub300\ud55c \uc77c\uccb4\uc758 \uad8c\ub9ac\ub294 AI\ub370\uc774\ud130 \ub4f1\uc758 \uad6c\ucd95 \uc218\ud589\uae30\uad00 \ubc0f \ucc38\uc5ec\uae30\uad00(\uc774\ud558 \u2018\uc218\ud589\uae30\uad00 \ub4f1\u2019)\uacfc \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc5d0 \uc788\uc2b5\ub2c8\ub2e4.\n\ubcf8 AI\ub370\uc774\ud130 \ub4f1\uc740 \uc778\uacf5\uc9c0\ub2a5 \uae30\uc220 \ubc0f \uc81c\ud488\u00b7\uc11c\ube44\uc2a4 \ubc1c\uc804\uc744 \uc704\ud558\uc5ec \uad6c\ucd95\ud558\uc600\uc73c\uba70, \uc9c0\ub2a5\ud615 \uc81c\ud488\u30fb\uc11c\ube44\uc2a4, \ucc57\ubd07 \ub4f1 \ub2e4\uc591\ud55c \ubd84\uc57c\uc5d0\uc11c \uc601\ub9ac\uc801\u30fb\ube44\uc601\ub9ac\uc801 \uc5f0\uad6c\u30fb\uac1c\ubc1c \ubaa9\uc801\uc73c\ub85c \ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n### \ub370\uc774\ud130 \uc774\uc6a9\uc815\ucc45\n- \ubcf8 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc774\uc6a9\ud558\uae30 \uc704\ud574\uc11c \ub2e4\uc74c \uc0ac\ud56d\uc5d0 \ub3d9\uc758\ud558\uba70 \uc900\uc218\ud574\uc57c \ud568\uc744 \uace0\uc9c0\ud569\ub2c8\ub2e4.\n\n1. \ubcf8 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc774\uc6a9\ud560 \ub54c\uc5d0\ub294 \ubc18\ub4dc\uc2dc \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc758 \uc0ac\uc5c5\uacb0\uacfc\uc784\uc744 \ubc1d\ud600\uc57c \ud558\uba70, \ubcf8 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc774\uc6a9\ud55c 2\ucc28\uc801 \uc800\uc791\ubb3c\uc5d0\ub3c4 \ub3d9\uc77c\ud558\uac8c \ubc1d\ud600\uc57c \ud569\ub2c8\ub2e4.\n2. \uad6d\uc678\uc5d0 \uc18c\uc7ac\ud558\ub294 \ubc95\uc778, \ub2e8\uccb4 \ub610\ub294 \uac1c\uc778\uc774 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc774\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc218\ud589\uae30\uad00 \ub4f1 \ubc0f \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uacfc \ubcc4\ub3c4\ub85c \ud569\uc758\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n3. \ubcf8 AI\ub370\uc774\ud130 \ub4f1\uc758 \uad6d\uc678 \ubc18\ucd9c\uc744 \uc704\ud574\uc11c\ub294 \uc218\ud589\uae30\uad00 \ub4f1 \ubc0f \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uacfc \ubcc4\ub3c4\ub85c \ud569\uc758\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n4. \ubcf8 AI\ub370\uc774\ud130\ub294 \uc778\uacf5\uc9c0\ub2a5 \ud559\uc2b5\ubaa8\ub378\uc758 \ud559\uc2b5\uc6a9\uc73c\ub85c\ub9cc \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc740 AI\ub370\uc774\ud130 \ub4f1\uc758 \uc774\uc6a9\uc758 \ubaa9\uc801\uc774\ub098 \ubc29\ubc95, \ub0b4\uc6a9 \ub4f1\uc774 \uc704\ubc95\ud558\uac70\ub098 \ubd80\uc801\ud569\ud558\ub2e4\uace0 \ud310\ub2e8\ub420 \uacbd\uc6b0 \uc81c\uacf5\uc744 \uac70\ubd80\ud560 \uc218 \uc788\uc73c\uba70, \uc774\ubbf8 \uc81c\uacf5\ud55c \uacbd\uc6b0 \uc774\uc6a9\uc758 \uc911\uc9c0\uc640 AI \ub370\uc774\ud130 \ub4f1\uc758 \ud658\uc218, \ud3d0\uae30 \ub4f1\uc744 \uc694\uad6c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n5. \uc81c\uacf5 \ubc1b\uc740 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc218\ud589\uae30\uad00 \ub4f1\uacfc \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc758 \uc2b9\uc778\uc744 \ubc1b\uc9c0 \uc54a\uc740 \ub2e4\ub978 \ubc95\uc778, \ub2e8\uccb4 \ub610\ub294 \uac1c\uc778\uc5d0\uac8c \uc5f4\ub78c\ud558\uac8c \ud558\uac70\ub098 \uc81c\uacf5, \uc591\ub3c4, \ub300\uc5ec, \ud310\ub9e4\ud558\uc5ec\uc11c\ub294 \uc548\ub429\ub2c8\ub2e4.\n6. AI\ub370\uc774\ud130 \ub4f1\uc5d0 \ub300\ud574\uc11c \uc81c 4\ud56d\uc5d0 \ub530\ub978 \ubaa9\uc801 \uc678 \uc774\uc6a9, \uc81c5\ud56d\uc5d0 \ub530\ub978 \ubb34\ub2e8 \uc5f4\ub78c, \uc81c\uacf5, \uc591\ub3c4, \ub300\uc5ec, \ud310\ub9e4 \ub4f1\uc758 \uacb0\uacfc\ub85c \uc778\ud558\uc5ec \ubc1c\uc0dd\ud558\ub294 \ubaa8\ub4e0 \ubbfc\u30fb\ud615\uc0ac \uc0c1\uc758 \ucc45\uc784\uc740 AI\ub370\uc774\ud130 \ub4f1\uc744 \uc774\uc6a9\ud55c \ubc95\uc778, \ub2e8\uccb4 \ub610\ub294 \uac1c\uc778\uc5d0\uac8c \uc788\uc2b5\ub2c8\ub2e4.\n7. \uc774\uc6a9\uc790\ub294 AI \ud5c8\ube0c \uc81c\uacf5 \ub370\uc774\ud130\uc14b \ub0b4\uc5d0 \uac1c\uc778\uc815\ubcf4 \ub4f1\uc774 \ud3ec\ud568\ub41c \uac83\uc774 \ubc1c\uacac\ub41c \uacbd\uc6b0, \uc989\uc2dc AI \ud5c8\ube0c\uc5d0 \ud574\ub2f9 \uc0ac\uc2e4\uc744 \uc2e0\uace0\ud558\uace0 \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc740 \ub370\uc774\ud130\uc14b\uc744 \uc0ad\uc81c\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4.\n8. AI \ud5c8\ube0c\ub85c\ubd80\ud130 \uc81c\uacf5\ubc1b\uc740 \ube44\uc2dd\ubcc4 \uc815\ubcf4(\uc7ac\ud604\uc815\ubcf4 \ud3ec\ud568)\ub97c \uc778\uacf5\uc9c0\ub2a5 \uc11c\ube44\uc2a4 \uac1c\ubc1c \ub4f1\uc758 \ubaa9\uc801\uc73c\ub85c \uc548\uc804\ud558\uac8c \uc774\uc6a9\ud558\uc5ec\uc57c \ud558\uba70, \uc774\ub97c \uc774\uc6a9\ud574\uc11c \uac1c\uc778\uc744 \uc7ac\uc2dd\ubcc4\ud558\uae30 \uc704\ud55c \uc5b4\ub5a0\ud55c \ud589\uc704\ub3c4 \ud558\uc5ec\uc11c\ub294 \uc548\ub429\ub2c8\ub2e4.\n9. \ud5a5\ud6c4 \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc5d0\uc11c \ud65c\uc6a9\uc0ac\ub840\u30fb\uc131\uacfc \ub4f1\uc5d0 \uad00\ud55c \uc2e4\ud0dc\uc870\uc0ac\ub97c \uc218\ud589 \ud560 \uacbd\uc6b0 \uc774\uc5d0 \uc131\uc2e4\ud558\uac8c \uc784\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4.\n\n### \ub370\uc774\ud130 \ub2e4\uc6b4\ub85c\ub4dc \uc2e0\uccad\ubc29\ubc95\n1. AI \ud5c8\ube0c\ub97c \ud1b5\ud574 \uc81c\uacf5 \uc911\uc778 AI\ub370\uc774\ud130 \ub4f1\uc744 \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uae30 \uc704\ud574\uc11c\ub294 \ubcc4\ub3c4\uc758 \uc2e0\uccad\uc790 \ubcf8\uc778 \ud655\uc778\uacfc \uc815\ubcf4 \uc81c\uacf5, \ubaa9\uc801\uc744 \ubc1d\ud788\ub294 \uc808\ucc28\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n2. AI\ub370\uc774\ud130\ub97c \uc81c\uc678\ud55c \ub370\uc774\ud130 \uc124\uba85, \uc800\uc791 \ub3c4\uad6c \ub4f1\uc740 \ubcc4\ub3c4\uc758 \uc2e0\uccad \uc808\ucc28\ub098 \ub85c\uadf8\uc778 \uc5c6\uc774 \uc774\uc6a9\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n3. \ud55c\uad6d\uc9c0\ub2a5\uc815\ubcf4\uc0ac\ud68c\uc9c4\ud765\uc6d0\uc774 \uad8c\ub9ac\uc790\uac00 \uc544\ub2cc AI\ub370\uc774\ud130 \ub4f1\uc740 \ud574\ub2f9 \uae30\uad00\uc758 \uc774\uc6a9\uc815\ucc45\uacfc \ub2e4\uc6b4\ub85c\ub4dc \uc808\ucc28\ub97c \ub530\ub77c\uc57c \ud558\uba70 \uc774\ub294 AI \ud5c8\ube0c\uc640 \uad00\ub828\uc774 \uc5c6\uc74c\uc744 \uc54c\ub824 \ub4dc\ub9bd\ub2c8\ub2e4.", "citation": "There is no citation information", "cardData": null, "siblings": [], "_id": "635bbfa9e1e7ef214267bf43", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-10-28T11:40:25.000Z"}, {"id": "society-ethics/lila_camera_traps", "sha": "339ce0d6a41439bac7b42fd71405e68253ed1dbf", "lastModified": "2023-03-07T20:14:40.000Z", "tags": ["task_categories:image-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:en", "license:other", "biodiversity", "camera trap data", "wildlife monitoring", "region:us"], "private": false, "author": "society-ethics", "description": "LILA Camera Traps is an aggregate data set of images taken by camera traps, which are devices that automatically (e.g. via motion detection) capture images of wild animals to help ecological research.\n\nThis data set is the first time when disparate camera trap data sets have been aggregated into a single training environment with a single taxonomy.\n\nThis data set consists of only camera trap image data sets, whereas the broader LILA website also has other data sets related to biology and conservation, intended as a resource for both machine learning (ML) researchers and those that want to harness ML for this topic.", "citation": null, "cardData": null, "siblings": [], "_id": "635efbf599aae2b15f232767", "disabled": false, "gated": false, "likes": 5, "downloads": 37, "createdAt": "2022-10-30T22:34:29.000Z"}, {"id": "nbtpj/BioNLP2021", "sha": "a189a9d3742ff9a42941b536305cd77221d3262b", "lastModified": "2023-01-02T02:11:44.000Z", "tags": ["region:us"], "private": false, "author": "nbtpj", "description": "MEDIQA @ NAACL-BioNLP 2021 -- Task 2: Multi-answer summarization\nhttps://sites.google.com/view/mediqa2021\nBiomedical Summarization Data\nThe MEDIQA-AnS Dataset could be used for training.", "citation": null, "cardData": null, "siblings": [], "_id": "63607bb5ddb99167138f1462", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-01T01:51:49.000Z"}, {"id": "qanastek/HoC", "sha": "6f8ce801f8cf4cc9d58c08f61f3424ad612f2f67", "lastModified": "2022-11-01T15:03:11.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:machine-generated", "annotations_creators:expert-generated", "language_creators:found", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "region:us"], "private": false, "author": "qanastek", "description": "The Hallmarks of Cancer Corpus for text classification\n\nThe Hallmarks of Cancer (HOC) Corpus consists of 1852 PubMed\npublication abstracts manually annotated by experts according\nto a taxonomy. The taxonomy consists of 37 classes in a\nhierarchy. Zero or more class labels are assigned to each\nsentence in the corpus. The labels are found under the \"labels\"\ndirectory, while the tokenized text can be found under \"text\"\ndirectory. The filenames are the corresponding PubMed IDs (PMID).\n\nIn addition to the HOC corpus, we also have the\n[Cancer Hallmarks Analytics Tool](http://chat.lionproject.net/)\nwhich classifes all of PubMed according to the HoC taxonomy.", "citation": "@article{baker2015automatic,\n  title={Automatic semantic classification of scientific literature according to the hallmarks of cancer},\n  author={Baker, Simon and Silins, Ilona and Guo, Yufan and Ali, Imran and H{\\\"o}gberg, Johan and Stenius, Ulla and Korhonen, Anna},\n  journal={Bioinformatics},\n  volume={32},\n  number={3},\n  pages={432--440},\n  year={2015},\n  publisher={Oxford University Press}\n}\n\n@article{baker2017cancer,\n  title={Cancer Hallmarks Analytics Tool (CHAT): a text mining approach to organize and evaluate scientific literature on cancer},\n  author={Baker, Simon and Ali, Imran and Silins, Ilona and Pyysalo, Sampo and Guo, Yufan and H{\\\"o}gberg, Johan and Stenius, Ulla and Korhonen, Anna},\n  journal={Bioinformatics},\n  volume={33},\n  number={24},\n  pages={3973--3981},\n  year={2017},\n  publisher={Oxford University Press}\n}\n\n@article{baker2017cancer,\n  title={Cancer hallmark text classification using convolutional neural networks},\n  author={Baker, Simon and Korhonen, Anna-Leena and Pyysalo, Sampo},\n  year={2016}\n}\n\n@article{baker2017initializing,\n  title={Initializing neural networks for hierarchical multi-label text classification},\n  author={Baker, Simon and Korhonen, Anna},\n  journal={BioNLP 2017},\n  pages={307--315},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "6360f9d0472131c3bc506759", "disabled": false, "gated": false, "likes": 1, "downloads": 82, "createdAt": "2022-11-01T10:49:52.000Z"}, {"id": "GEM/TaTA", "sha": "8df0b33afd830cd72656e23c6b1cedec2b285b37", "lastModified": "2022-11-03T14:23:59.000Z", "tags": ["task_categories:table-to-text", "annotations_creators:none", "language_creators:unknown", "multilinguality:yes", "size_categories:unknown", "source_datasets:original", "language:ar", "language:en", "language:fr", "language:ha", "language:ig", "language:pt", "language:ru", "language:sw", "language:yo", "license:cc-by-sa-4.0", "data-to-text", "arxiv:2211.00142", "arxiv:2112.12870", "region:us"], "private": false, "author": "GEM", "description": "Dataset loader for TaTA: A Multilingual Table-to-Text Dataset for African Languages", "citation": "@misc{gehrmann2022TaTA,\nAuthor = {Sebastian Gehrmann and Sebastian Ruder and Vitaly Nikolaev and Jan A. Botha and Michael Chavinda and Ankur Parikh and Clara Rivera},\nTitle = {TaTa: A Multilingual Table-to-Text Dataset for African Languages},\nYear = {2022},\nEprint = {arXiv:2211.00142},\n}", "cardData": null, "siblings": [], "_id": "63626ef1d3be91534c2c7011", "disabled": false, "gated": false, "likes": 0, "downloads": 90, "createdAt": "2022-11-02T13:21:53.000Z"}, {"id": "allenai/csabstruct", "sha": "82e266d8effde67520d50532587b5f000237b50a", "lastModified": "2022-11-02T17:54:38.000Z", "tags": ["license:apache-2.0", "arxiv:1909.04054", "region:us"], "private": false, "author": "allenai", "description": "As a step toward better document-level understanding, we explore classification of a sequence of sentences into their corresponding categories, a task that requires understanding sentences in context of the document. Recent successful models for this task have used hierarchical models to contextualize sentence representations, and Conditional Random Fields (CRFs) to incorporate dependencies between subsequent labels. In this work, we show that pretrained language models, BERT (Devlin et al., 2018) in particular, can be used for this task to capture contextual dependencies without the need for hierarchical encoding nor a CRF. Specifically, we construct a joint sentence representation that allows BERT Transformer layers to directly utilize contextual information from all words in all sentences. Our approach achieves state-of-the-art results on four datasets, including a new dataset of structured scientific abstracts.", "citation": "@inproceedings{Cohan2019EMNLP,\n  title={Pretrained Language Models for Sequential Sentence Classification},\n  author={Arman Cohan, Iz Beltagy, Daniel King, Bhavana Dalvi, Dan Weld},\n  year={2019},\n  booktitle={EMNLP},\n}", "cardData": null, "siblings": [], "_id": "6362a5c98f43a912fc713b93", "disabled": false, "gated": false, "likes": 3, "downloads": 79, "createdAt": "2022-11-02T17:15:53.000Z"}, {"id": "shunk031/cocostuff", "sha": "e3dc6d24c7d76a0c9d1c20b6c838abbc918a36b0", "lastModified": "2022-12-09T04:29:27.000Z", "tags": ["language:en", "license:cc-by-4.0", "computer-vision", "object-detection", "ms-coco", "arxiv:1612.03716", "region:us"], "private": false, "author": "shunk031", "description": "COCO-Stuff augments all 164K images of the popular COCO dataset with pixel-level stuff annotations. These annotations can be used for scene understanding tasks like semantic segmentation, object detection and image captioning.", "citation": "@INPROCEEDINGS{caesar2018cvpr,\n  title={COCO-Stuff: Thing and stuff classes in context},\n  author={Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},\n  booktitle={Computer vision and pattern recognition (CVPR), 2018 IEEE conference on},\n  organization={IEEE},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "6362ad2f20addea5130bf094", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2022-11-02T17:47:27.000Z"}, {"id": "sileod/probability_words_nli", "sha": "4162853a87a970f96bdb689dcdc35732d8aaa854", "lastModified": "2023-09-06T14:56:43.000Z", "tags": ["task_categories:text-classification", "task_categories:multiple-choice", "task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:multiple-choice-qa", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:apache-2.0", "wep", "words of estimative probability", "probability", "logical reasoning", "soft logic", "nli", "verbal probabilities", "natural-language-inference", "reasoning", "logic", "arxiv:2211.03358", "region:us"], "private": false, "author": "sileod", "description": "Probing neural language models for understanding of words of estimative probability", "citation": "@inproceedings{sileo-moens-2023-probing,\n    title = \"Probing neural language models for understanding of words of estimative probability\",\n    author = \"Sileo, Damien  and\n      Moens, Marie-francine\",\n    booktitle = \"Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.starsem-1.41\",\n    doi = \"10.18653/v1/2023.starsem-1.41\",\n    pages = \"469--476\",\n}", "cardData": null, "siblings": [], "_id": "6363ce5a969bdae89e0f9223", "disabled": false, "gated": false, "likes": 4, "downloads": 30, "createdAt": "2022-11-03T14:21:14.000Z"}, {"id": "lmqg/qa_squadshifts", "sha": "7b8b77e8fdeb334e3550d1fb6167d4cc92dc6957", "lastModified": "2022-11-05T05:10:26.000Z", "tags": ["task_categories:question-answering", "task_ids:extractive-qa", "multilinguality:monolingual", "size_categories:1k<n<10k", "source_datasets:extended|wikipedia", "language:en", "license:cc-by-4.0", "arxiv:2004.14444", "region:us"], "private": false, "author": "lmqg", "description": "[SQuAD Shifts](https://modestyachts.github.io/squadshifts-website/index.html) dataset for question answering task with custom split.", "citation": "@inproceedings{miller2020effect,\n  title={The effect of natural distribution shift on question answering models},\n  author={Miller, John and Krauth, Karl and Recht, Benjamin and Schmidt, Ludwig},\n  booktitle={International Conference on Machine Learning},\n  pages={6905--6916},\n  year={2020},\n  organization={PMLR}\n}", "cardData": null, "siblings": [], "_id": "6365cdc712188d67e65e72fc", "disabled": false, "gated": false, "likes": 0, "downloads": 388, "createdAt": "2022-11-05T02:43:19.000Z"}, {"id": "alkzar90/cell_benchmark", "sha": "95ab4109b2ce39ef0f9370c8d9c6ee3ab015464f", "lastModified": "2023-01-23T21:36:52.000Z", "tags": ["region:us"], "private": false, "author": "alkzar90", "description": "A segmentation dataset for [TODO: complete...]", "citation": null, "cardData": null, "siblings": [], "_id": "6368148e5bb06007ea0dcf59", "disabled": false, "gated": false, "likes": 0, "downloads": 106, "createdAt": "2022-11-06T20:09:50.000Z"}, {"id": "Conrad747/lg-ner", "sha": "97db70c4efab8fd8f8a367f471fe24335ce03fae", "lastModified": "2023-03-30T13:44:30.000Z", "tags": ["region:us"], "private": false, "author": "Conrad747", "description": "LugandaPII is a named entity dataset consisting of PERSON, ORG, LOCATION, NORP, USERID and DATE entities.\nThe train/validation/test sets are available for the Luganda language.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Luganda Ner Dataset},\nauthor={many authors\n},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "636b627ccde3707d10988671", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2022-11-09T08:19:08.000Z"}, {"id": "KETI-AIR/vqa", "sha": "4085d8bad777532784546b4043dfd175537a6085", "lastModified": "2022-11-10T09:59:21.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "KETI-AIR", "description": "# VQA\n\n## What is VQA?\nVQA is a new dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer.\n- 265,016 images (COCO and abstract scenes)\n- At least 3 questions (5.4 questions on average) per image\n- 10 ground truth answers per question\n- 3 plausible (but likely incorrect) answers per question\n- Automatic evaluation metric\n\n## Dataset\nDetails on downloading the latest dataset may be found on the [download webpage](https://visualqa.org/download.html).\n\n## Usage\n```python\nfrom datasets import load_dataset\n\nraw_datasets = load_dataset(\n                \"vqa.py\", \n                \"base\",\n                cache_dir=\"huggingface_datasets\", \n                data_dir=\"data\",\n                ignore_verifications=True,\n            )\n\ndataset_train = raw_datasets[\"train\"]\n\nfor item in dataset_train:\n    print(item)\n    exit()\n```\n\nv2 = v2.real + v2.abstract (v2.abstract == v1.abstract)\nv1 = v1.real + v1.abstract\nv2.abstract.balanced.bin", "citation": "```\n@InProceedings{balanced_vqa_v2,\nauthor = {Yash Goyal and Tejas Khot and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},\ntitle = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding in {V}isual {Q}uestion {A}nswering},\nbooktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear = {2017},\n}\n```\n\n```\n@InProceedings{balanced_binary_vqa,\nauthor = {Peng Zhang and Yash Goyal and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},\ntitle = {{Y}in and {Y}ang: Balancing and Answering Binary Visual Questions},\nbooktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear = {2016},\n}\n```\n\n```\n@InProceedings{{VQA},\nauthor = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},\ntitle = {{VQA}: {V}isual {Q}uestion {A}nswering},\nbooktitle = {International Conference on Computer Vision (ICCV)},\nyear = {2015},\n}\n```", "cardData": null, "siblings": [], "_id": "636ccb62cfb49b46821ec074", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2022-11-10T09:58:58.000Z"}, {"id": "Genius1237/TyDiP", "sha": "dfc63068215c270ac0f6702228fd80ea2ae170a5", "lastModified": "2023-10-15T05:14:26.000Z", "tags": ["task_categories:text-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "language:en", "language:hi", "language:ko", "language:es", "language:ta", "language:fr", "language:vi", "language:ru", "language:af", "language:hu", "license:cc-by-4.0", "politeness", "wikipedia", "multilingual", "region:us"], "private": false, "author": "Genius1237", "description": "The TyDiP dataset is a dataset of requests in conversations between wikipedia editors\nthat have been annotated for politeness. The splits available below consists of only\nrequests from the top 25 percentile (polite) and bottom 25 percentile (impolite) of\npoliteness scores. The English train set and English test set that are\nadapted from the Stanford Politeness Corpus, and test data in 9 more languages\n(Hindi, Korean, Spanish, Tamil, French, Vietnamese, Russian, Afrikaans, Hungarian) \nwas annotated by us.", "citation": "@inproceedings{srinivasan-choi-2022-tydip,\n    title = \"{T}y{D}i{P}: A Dataset for Politeness Classification in Nine Typologically Diverse Languages\",\n    author = \"Srinivasan, Anirudh  and\n      Choi, Eunsol\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.findings-emnlp.420\",\n    pages = \"5723--5738\",\n}", "cardData": null, "siblings": [], "_id": "636da0a85aaed143cd6bed06", "disabled": false, "gated": false, "likes": 0, "downloads": 61, "createdAt": "2022-11-11T01:08:56.000Z"}, {"id": "lmqg/qag_tweetqa", "sha": "f807452b98a80d2daf6b7e84f4a8a55bec9b0d16", "lastModified": "2022-12-02T19:16:46.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:1k<n<10K", "source_datasets:tweet_qa", "language:en", "license:cc-by-sa-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "Question & answer generation dataset based on [TweetQA](https://huggingface.co/datasets/tweet_qa).", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "636e2dddb0ebc0488812daad", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-11-11T11:11:25.000Z"}, {"id": "lmqg/qag_squad", "sha": "d1f2a4184134247fa0fbd5db8d7324ef8792c6f8", "lastModified": "2022-12-18T07:39:03.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:1k<n<10K", "source_datasets:lmqg/qg_squad", "language:en", "license:cc-by-sa-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "Question & answer generation dataset based on SQuAD.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "636e584e44a18bc3c011660e", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-11T14:12:30.000Z"}, {"id": "101arrowz/vox_celeb", "sha": "27a66f55dd29709710c2f2eb415b192f50639526", "lastModified": "2023-08-20T03:04:07.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_categories:image-classification", "task_ids:speaker-identification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "license:cc-by-4.0", "region:us"], "private": false, "author": "101arrowz", "description": "VoxCeleb is an audio-visual dataset consisting of short clips of human speech, extracted from interview videos uploaded to YouTube", "citation": "@Article{Nagrani19,\n    author = \"Arsha Nagrani and Joon~Son Chung and Weidi Xie and Andrew Zisserman\",\n    title = \"Voxceleb: Large-scale speaker verification in the wild\",\n    journal = \"Computer Science and Language\",\n    year = \"2019\",\n    publisher = \"Elsevier\",\n}\n\n@InProceedings{Chung18b,\n    author = \"Chung, J.~S. and Nagrani, A. and Zisserman, A.\",\n    title = \"VoxCeleb2: Deep Speaker Recognition\",\n    booktitle = \"INTERSPEECH\",\n    year = \"2018\",\n}\n\n@InProceedings{Nagrani17,\n    author = \"Nagrani, A. and Chung, J.~S. and Zisserman, A.\",\n    title = \"VoxCeleb: a large-scale speaker identification dataset\",\n    booktitle = \"INTERSPEECH\",\n    year = \"2017\",\n}", "cardData": null, "siblings": [], "_id": "63704bd26cd69d9a36098b96", "disabled": false, "gated": false, "likes": 1, "downloads": 43, "createdAt": "2022-11-13T01:43:46.000Z"}, {"id": "lawcompany/KLAID", "sha": "cc77aedcfe59f728c64449bf35522d0201c49e7f", "lastModified": "2022-11-17T07:09:10.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "multilinguality:monolingual", "language:ko", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": "lawcompany", "description": "KLAID (Korean Legal Artificial Intelligence Datasets) is a dataset for the development of Korean legal artificial intelligence technology. This time we offer 1 task, which is legal judgment prediction(LJP).", "citation": null, "cardData": null, "siblings": [], "_id": "63707ec19633c0fb6ff6187f", "disabled": false, "gated": false, "likes": 7, "downloads": 33, "createdAt": "2022-11-13T05:21:05.000Z"}, {"id": "bigbio/an_em", "sha": "e526476af6384a8c8c1b9baaa5b6e5717bac2980", "lastModified": "2022-12-22T15:43:14.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "bigbio", "description": "AnEM corpus is a domain- and species-independent resource manually annotated for anatomical\nentity mentions using a fine-grained classification system. The corpus consists of 500 documents\n(over 90,000 words) selected randomly from citation abstracts and full-text papers with\nthe aim of making the corpus representative of the entire available biomedical scientific\nliterature. The corpus annotation covers mentions of both healthy and pathological anatomical\nentities and contains over 3,000 annotated mentions.", "citation": "@inproceedings{ohta-etal-2012-open,\n  author    = {Ohta, Tomoko and Pyysalo, Sampo and Tsujii, Jun{'}ichi and Ananiadou, Sophia},\n  title     = {Open-domain Anatomical Entity Mention Detection},\n  journal   = {},\n  volume    = {W12-43},\n  year      = {2012},\n  url       = {https://aclanthology.org/W12-4304},\n  doi       = {},\n  biburl    = {},\n  bibsource = {},\n  publisher = {Association for Computational Linguistics}\n}", "cardData": null, "siblings": [], "_id": "637131d3967e405db1203035", "disabled": false, "gated": false, "likes": 1, "downloads": 57, "createdAt": "2022-11-13T18:05:07.000Z"}, {"id": "bigbio/anat_em", "sha": "c5aeeab2ea5865c7d9bafddcf1fbab5a230a6607", "lastModified": "2022-12-22T15:43:16.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The extended Anatomical Entity Mention corpus (AnatEM) consists of 1212 documents (approx. 250,000 words) manually annotated to identify over 13,000 mentions of anatomical entities. Each annotation is assigned one of 12 granularity-based types such as Cellular component, Tissue and Organ, defined with reference to the Common Anatomy Reference Ontology.", "citation": "@article{pyysalo2014anatomical,\n  title={Anatomical entity mention recognition at literature scale},\n  author={Pyysalo, Sampo and Ananiadou, Sophia},\n  journal={Bioinformatics},\n  volume={30},\n  number={6},\n  pages={868--875},\n  year={2014},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "637136bbffc0489ed7d06d62", "disabled": false, "gated": false, "likes": 0, "downloads": 163, "createdAt": "2022-11-13T18:26:03.000Z"}, {"id": "bigbio/bc5cdr", "sha": "4ef175418ad859b5414ec40c40c00f3c4781e8a1", "lastModified": "2022-12-22T15:43:20.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The BioCreative V Chemical Disease Relation (CDR) dataset is a large annotated text corpus of human annotations of all chemicals, diseases and their interactions in 1,500 PubMed articles.", "citation": "@article{DBLP:journals/biodb/LiSJSWLDMWL16,\n  author    = {Jiao Li and\n               Yueping Sun and\n               Robin J. Johnson and\n               Daniela Sciaky and\n               Chih{-}Hsuan Wei and\n               Robert Leaman and\n               Allan Peter Davis and\n               Carolyn J. Mattingly and\n               Thomas C. Wiegers and\n               Zhiyong Lu},\n  title     = {BioCreative {V} {CDR} task corpus: a resource for chemical disease\n               relation extraction},\n  journal   = {Database J. Biol. Databases Curation},\n  volume    = {2016},\n  year      = {2016},\n  url       = {https://doi.org/10.1093/database/baw068},\n  doi       = {10.1093/database/baw068},\n  timestamp = {Thu, 13 Aug 2020 12:41:41 +0200},\n  biburl    = {https://dblp.org/rec/journals/biodb/LiSJSWLDMWL16.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63716a5567cd0e88150491b9", "disabled": false, "gated": false, "likes": 1, "downloads": 687, "createdAt": "2022-11-13T22:06:13.000Z"}, {"id": "bigbio/bc7_litcovid", "sha": "4707df98cc3cc8f8f684ca1b42f19dbaf83b21c3", "lastModified": "2022-12-22T15:43:23.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "The training and development datasets contain the publicly-available text of over 30 thousand COVID-19-related articles and their metadata (e.g., title, abstract, journal). Articles in both datasets have been manually reviewed and articles annotated by in-house models.", "citation": "@inproceedings{chen2021overview,\n  title        = {\n    Overview of the BioCreative VII LitCovid Track: multi-label topic\n    classification for COVID-19 literature annotation\n  },\n  author       = {\n    Chen, Qingyu and Allot, Alexis and Leaman, Robert and Do{\\\\u{g}}an, Rezarta\n    Islamaj and Lu, Zhiyong\n  },\n  year         = 2021,\n  booktitle    = {Proceedings of the seventh BioCreative challenge evaluation workshop}\n}", "cardData": null, "siblings": [], "_id": "63716a59ffc0489ed7d29421", "disabled": false, "gated": false, "likes": 0, "downloads": 103, "createdAt": "2022-11-13T22:06:17.000Z"}, {"id": "bigbio/bioasq_2021_mesinesp", "sha": "16ef8e93b4fce968fa18d7d189353650d8ef2975", "lastModified": "2022-12-22T15:43:30.000Z", "tags": ["multilinguality:monolingual", "language:es", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The main aim of MESINESP2 is to promote the development of practically relevant semantic indexing tools for biomedical content in non-English language. We have generated a manually annotated corpus, where domain experts have labeled a set of scientific literature, clinical trials, and patent abstracts. All the documents were labeled with DeCS descriptors, which is a structured controlled vocabulary created by BIREME to index scientific publications on BvSalud, the largest database of scientific documents in Spanish, which hosts records from the databases LILACS, MEDLINE, IBECS, among others.\n\nMESINESP track at BioASQ9 explores the efficiency of systems for assigning DeCS to different types of biomedical documents. To that purpose, we have divided the task into three subtracks depending on the document type. Then, for each one we generated an annotated corpus which was provided to participating teams:\n\n- [Subtrack 1 corpus] MESINESP-L \u2013 Scientific Literature: It contains all   Spanish records from LILACS and IBECS databases at the Virtual Health Library   (VHL) with non-empty abstract written in Spanish.\n- [Subtrack 2 corpus] MESINESP-T- Clinical Trials contains records from Registro   Espa\u00f1ol de Estudios Cl\u00ednicos (REEC). REEC doesn't provide documents with the   structure title/abstract needed in BioASQ, for that reason we have built   artificial abstracts based on the content available in the data crawled using   the REEC API.\n- [Subtrack 3 corpus] MESINESP-P \u2013 Patents: This corpus includes patents in   Spanish extracted from Google Patents which have the IPC code \u201cA61P\u201d and   \u201cA61K31\u201d. In addition, we also provide a set of complementary data such as:   the DeCS terminology file, a silver standard with the participants' predictions   to the task background set and the entities of medications, diseases, symptoms   and medical procedures extracted from the BSC NERs documents.", "citation": "@conference {396,\n    title = {Overview of BioASQ 2021-MESINESP track. Evaluation of\n    advance hierarchical classification techniques for scientific\n    literature, patents and clinical trials.},\n    booktitle = {Proceedings of the 9th BioASQ Workshop\n    A challenge on large-scale biomedical semantic indexing\n    and question answering},\n    year = {2021},\n    url = {http://ceur-ws.org/Vol-2936/paper-11.pdf},\n    author = {Gasco, Luis and Nentidis, Anastasios and Krithara, Anastasia\n     and Estrada-Zavala, Darryl and Toshiyuki Murasaki, Renato and Primo-Pe{\\~n}a,\n     Elena and Bojo-Canales, Cristina and Paliouras, Georgios and Krallinger, Martin}\n}", "cardData": null, "siblings": [], "_id": "63716a64afbe42caa5a8d409", "disabled": false, "gated": false, "likes": 0, "downloads": 22, "createdAt": "2022-11-13T22:06:28.000Z"}, {"id": "bigbio/bioasq_task_c_2017", "sha": "85042e23931b6ad55b381e9eee785873a5966169", "lastModified": "2022-12-22T15:43:32.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The training data set for this task contains annotated biomedical articles\npublished in PubMed and corresponding full text from PMC. By annotated is meant\nthat GrantIDs and corresponding Grant Agencies have been identified in the full\ntext of articles", "citation": "@article{nentidis-etal-2017-results,\n  title        = {Results of the fifth edition of the {B}io{ASQ} Challenge},\n  author       = {\n    Nentidis, Anastasios  and Bougiatiotis, Konstantinos  and Krithara,\n    Anastasia  and Paliouras, Georgios  and Kakadiaris, Ioannis\n  },\n  year         = 2007,\n  journal      = {},\n  volume       = {BioNLP 2017},\n  doi          = {10.18653/v1/W17-2306},\n  url          = {https://aclanthology.org/W17-2306},\n  biburl       = {},\n  bibsource    = {https://aclanthology.org/W17-2306}\n}", "cardData": null, "siblings": [], "_id": "63716a6767cd0e8815049248", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-13T22:06:31.000Z"}, {"id": "bigbio/bioinfer", "sha": "7a5de43c8723091a36f549f8569f778fd86560b1", "lastModified": "2022-12-22T15:43:38.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-2.0", "region:us"], "private": false, "author": "bigbio", "description": "A corpus targeted at protein, gene, and RNA relationships which serves as a\nresource for the development of information extraction systems and their\ncomponents such as parsers and domain analyzers. Currently, the corpus contains\n1100 sentences from abstracts of biomedical research articles annotated for\nrelationships, named entities, as well as syntactic dependencies.", "citation": "@article{pyysalo2007bioinfer,\n  title        = {BioInfer: a corpus for information extraction in the biomedical domain},\n  author       = {\n    Pyysalo, Sampo and Ginter, Filip and Heimonen, Juho and Bj{\\\"o}rne, Jari\n    and Boberg, Jorma and J{\\\"a}rvinen, Jouni and Salakoski, Tapio\n  },\n  year         = 2007,\n  journal      = {BMC bioinformatics},\n  publisher    = {BioMed Central},\n  volume       = 8,\n  number       = 1,\n  pages        = {1--24}\n}", "cardData": null, "siblings": [], "_id": "63716a6bffc0489ed7d294e3", "disabled": false, "gated": false, "likes": 2, "downloads": 49, "createdAt": "2022-11-13T22:06:35.000Z"}, {"id": "bigbio/biology_how_why_corpus", "sha": "95cbfef08fc668490f91fba0d4163a7a4eb1ed7d", "lastModified": "2022-12-22T15:43:41.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "This dataset consists of 185 \"how\" and 193 \"why\" biology questions authored by a domain expert, with one or more gold \nanswer passages identified in an undergraduate textbook. The expert was not constrained in any way during the \nannotation process, so gold answers might be smaller than a paragraph or span multiple paragraphs. This dataset was \nused for the question-answering system described in the paper \u201cDiscourse Complements Lexical Semantics for Non-factoid \nAnswer Reranking\u201d (ACL 2014).", "citation": "@inproceedings{jansen-etal-2014-discourse,\n    title = \"Discourse Complements Lexical Semantics for Non-factoid Answer Reranking\",\n    author = \"Jansen, Peter  and\n      Surdeanu, Mihai  and\n      Clark, Peter\",\n    booktitle = \"Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jun,\n    year = \"2014\",\n    address = \"Baltimore, Maryland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P14-1092\",\n    doi = \"10.3115/v1/P14-1092\",\n    pages = \"977--986\",\n}", "cardData": null, "siblings": [], "_id": "63716a6e7a5e5d8efdc3f2f7", "disabled": false, "gated": false, "likes": 2, "downloads": 29, "createdAt": "2022-11-13T22:06:38.000Z"}, {"id": "bigbio/biomrc", "sha": "09938b2d42d6e4ecd4d5282657d0bb5f8791950b", "lastModified": "2022-12-22T15:43:44.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "We introduce BIOMRC, a large-scale cloze-style biomedical MRC dataset. Care was taken to reduce noise, compared to the\nprevious BIOREAD dataset of Pappas et al. (2018). Experiments show that simple heuristics do not perform well on the\nnew dataset and that two neural MRC models that had been tested on BIOREAD perform much better on BIOMRC, indicating\nthat the new dataset is indeed less noisy or at least that its task is more feasible. Non-expert human performance is\nalso higher on the new dataset compared to BIOREAD, and biomedical experts perform even better. We also introduce a new\nBERT-based MRC model, the best version of which substantially outperforms all other methods tested, reaching or\nsurpassing the accuracy of biomedical experts in some experiments. We make the new dataset available in three different\nsizes, also releasing our code, and providing a leaderboard.", "citation": "@inproceedings{pappas-etal-2020-biomrc,\n    title = \"{B}io{MRC}: A Dataset for Biomedical Machine Reading Comprehension\",\n    author = \"Pappas, Dimitris  and\n      Stavropoulos, Petros  and\n      Androutsopoulos, Ion  and\n      McDonald, Ryan\",\n    booktitle = \"Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.bionlp-1.15\",\n    pages = \"140--149\",\n}", "cardData": null, "siblings": [], "_id": "63716a72967e405db1228bfd", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2022-11-13T22:06:42.000Z"}, {"id": "bigbio/bionlp_shared_task_2009", "sha": "6482ae67be1476804b35ca417915952d7806852a", "lastModified": "2022-12-22T15:43:48.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The BioNLP Shared Task 2009 was organized by GENIA Project and its corpora were curated based\non the annotations of the publicly available GENIA Event corpus and an unreleased (blind) section\nof the GENIA Event corpus annotations, used for evaluation.", "citation": "@inproceedings{kim-etal-2009-overview,\n    title = \"Overview of {B}io{NLP}{'}09 Shared Task on Event Extraction\",\n    author = \"Kim, Jin-Dong  and\n      Ohta, Tomoko  and\n      Pyysalo, Sampo  and\n      Kano, Yoshinobu  and\n      Tsujii, Jun{'}ichi\",\n    booktitle = \"Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task\",\n    month = jun,\n    year = \"2009\",\n    address = \"Boulder, Colorado\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W09-1401\",\n    pages = \"1--9\",\n}", "cardData": null, "siblings": [], "_id": "63716a753d1bd47a4ec4279b", "disabled": false, "gated": false, "likes": 1, "downloads": 21, "createdAt": "2022-11-13T22:06:45.000Z"}, {"id": "bigbio/bionlp_st_2011_epi", "sha": "e70d21156918fd00eed1f61f6cdb19c91f258043", "lastModified": "2022-12-22T15:43:49.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The dataset of the Epigenetics and Post-translational Modifications (EPI) task\nof BioNLP Shared Task 2011.", "citation": "@inproceedings{ohta-etal-2011-overview,\n    title = \"Overview of the Epigenetics and Post-translational\n    Modifications ({EPI}) task of {B}io{NLP} Shared Task 2011\",\n    author = \"Ohta, Tomoko  and\n      Pyysalo, Sampo  and\n      Tsujii, Jun{'}ichi\",\n    booktitle = \"Proceedings of {B}io{NLP} Shared Task 2011 Workshop\",\n    month = jun,\n    year = \"2011\",\n    address = \"Portland, Oregon, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W11-1803\",\n    pages = \"16--25\",\n}", "cardData": null, "siblings": [], "_id": "63716a7991284164d1b8f81d", "disabled": false, "gated": false, "likes": 1, "downloads": 61, "createdAt": "2022-11-13T22:06:49.000Z"}, {"id": "bigbio/bionlp_st_2011_ge", "sha": "d390829665dd6f5038d1073ecdd10d32c50544ff", "lastModified": "2022-12-22T15:43:51.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The BioNLP-ST GE task has been promoting development of fine-grained information extraction (IE) from biomedical\ndocuments, since 2009. Particularly, it has focused on the domain of NFkB as a model domain of Biomedical IE.\nThe GENIA task aims at extracting events occurring upon genes or gene products, which are typed as \"Protein\"\nwithout differentiating genes from gene products. Other types of physical entities, e.g. cells, cell components,\nare not differentiated from each other, and their type is given as \"Entity\".", "citation": "@inproceedings{10.5555/2107691.2107693,\nauthor = {Kim, Jin-Dong and Wang, Yue and Takagi, Toshihisa and Yonezawa, Akinori},\ntitle = {Overview of Genia Event Task in BioNLP Shared Task 2011},\nyear = {2011},\nisbn = {9781937284091},\npublisher = {Association for Computational Linguistics},\naddress = {USA},\nabstract = {The Genia event task, a bio-molecular event extraction task,\nis arranged as one of the main tasks of BioNLP Shared Task 2011.\nAs its second time to be arranged for community-wide focused\nefforts, it aimed to measure the advance of the community since 2009,\nand to evaluate generalization of the technology to full text papers.\nAfter a 3-month system development period, 15 teams submitted their\nperformance results on test cases. The results show the community has\nmade a significant advancement in terms of both performance improvement\nand generalization.},\nbooktitle = {Proceedings of the BioNLP Shared Task 2011 Workshop},\npages = {7\u201315},\nnumpages = {9},\nlocation = {Portland, Oregon},\nseries = {BioNLP Shared Task '11}\n}", "cardData": null, "siblings": [], "_id": "63716a7c7a5e5d8efdc3f37f", "disabled": false, "gated": false, "likes": 0, "downloads": 17, "createdAt": "2022-11-13T22:06:52.000Z"}, {"id": "bigbio/bionlp_st_2011_id", "sha": "8687f2eb6ea7c3291ca64e38280c09bc81a8c644", "lastModified": "2022-12-22T15:43:52.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The dataset of the Infectious Diseases (ID) task of\nBioNLP Shared Task 2011.", "citation": "@inproceedings{pyysalo-etal-2011-overview,\n    title = \"Overview of the Infectious Diseases ({ID}) task of {B}io{NLP} Shared Task 2011\",\n    author = \"Pyysalo, Sampo  and\n      Ohta, Tomoko  and\n      Rak, Rafal  and\n      Sullivan, Dan  and\n      Mao, Chunhong  and\n      Wang, Chunxia  and\n      Sobral, Bruno  and\n      Tsujii, Jun{'}ichi  and\n      Ananiadou, Sophia\",\n    booktitle = \"Proceedings of {B}io{NLP} Shared Task 2011 Workshop\",\n    month = jun,\n    year = \"2011\",\n    address = \"Portland, Oregon, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W11-1804\",\n    pages = \"26--35\",\n}", "cardData": null, "siblings": [], "_id": "63716a807a5e5d8efdc3f3c6", "disabled": false, "gated": false, "likes": 1, "downloads": 18, "createdAt": "2022-11-13T22:06:56.000Z"}, {"id": "bigbio/bionlp_st_2011_rel", "sha": "f0e67fb59c3ef293c2bae36b5524d7825f22f815", "lastModified": "2022-12-22T15:43:54.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The Entity Relations (REL) task is a supporting task of the BioNLP Shared Task 2011.\nThe task concerns the extraction of two types of part-of relations between a\ngene/protein and an associated entity.", "citation": "@inproceedings{10.5555/2107691.2107703,\nauthor = {Pyysalo, Sampo and Ohta, Tomoko and Tsujii, Jun'ichi},\ntitle = {Overview of the Entity Relations (REL) Supporting Task of BioNLP Shared Task 2011},\nyear = {2011},\nisbn = {9781937284091},\npublisher = {Association for Computational Linguistics},\naddress = {USA},\nabstract = {This paper presents the Entity Relations (REL) task,\na supporting task of the BioNLP Shared Task 2011. The task concerns\nthe extraction of two types of part-of relations between a gene/protein\nand an associated entity. Four teams submitted final results for\nthe REL task, with the highest-performing system achieving 57.7%\nF-score. While experiments suggest use of the data can help improve\nevent extraction performance, the task data has so far received only\nlimited use in support of event extraction. The REL task continues\nas an open challenge, with all resources available from the shared\ntask website.},\nbooktitle = {Proceedings of the BioNLP Shared Task 2011 Workshop},\npages = {83\u201388},\nnumpages = {6},\nlocation = {Portland, Oregon},\nseries = {BioNLP Shared Task '11}\n}", "cardData": null, "siblings": [], "_id": "63716a83967e405db1228ca5", "disabled": false, "gated": false, "likes": 1, "downloads": 16, "createdAt": "2022-11-13T22:06:59.000Z"}, {"id": "bigbio/bionlp_st_2013_cg", "sha": "0a65caf6fb10c3bd6a0d032546109ce3ce3fb1ba", "lastModified": "2022-12-22T15:43:57.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "the Cancer Genetics (CG) is a event extraction task and a main task of the BioNLP Shared Task (ST) 2013.\nThe CG task is an information extraction task targeting the recognition of events in text,\nrepresented as structured n-ary associations of given physical entities. In addition to\naddressing the cancer domain, the CG task is differentiated from previous event extraction\ntasks in the BioNLP ST series in addressing a wide range of pathological processes and multiple\nlevels of biological organization, ranging from the molecular through the cellular and organ\nlevels up to whole organisms. Final test set submissions were accepted from six teams", "citation": "@inproceedings{pyysalo-etal-2013-overview,\n    title = \"Overview of the Cancer Genetics ({CG}) task of {B}io{NLP} Shared Task 2013\",\n    author = \"Pyysalo, Sampo  and\n      Ohta, Tomoko  and\n      Ananiadou, Sophia\",\n    booktitle = \"Proceedings of the {B}io{NLP} Shared Task 2013 Workshop\",\n    month = aug,\n    year = \"2013\",\n    address = \"Sofia, Bulgaria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W13-2008\",\n    pages = \"58--66\",\n}", "cardData": null, "siblings": [], "_id": "63716a8767cd0e881504936a", "disabled": false, "gated": false, "likes": 2, "downloads": 38, "createdAt": "2022-11-13T22:07:03.000Z"}, {"id": "bigbio/bionlp_st_2013_ge", "sha": "6ffdbf6b70599d3613e8122ce6a459d51e5de61a", "lastModified": "2022-12-22T15:43:59.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The BioNLP-ST GE task has been promoting development of fine-grained\ninformation extraction (IE) from biomedical\ndocuments, since 2009. Particularly, it has focused on the domain of\nNFkB as a model domain of Biomedical IE", "citation": "@inproceedings{kim-etal-2013-genia,\n    title = \"The {G}enia Event Extraction Shared Task, 2013 Edition - Overview\",\n    author = \"Kim, Jin-Dong  and\n      Wang, Yue  and\n      Yasunori, Yamamoto\",\n    booktitle = \"Proceedings of the {B}io{NLP} Shared Task 2013 Workshop\",\n    month = aug,\n    year = \"2013\",\n    address = \"Sofia, Bulgaria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W13-2002\",\n    pages = \"8--15\",\n}", "cardData": null, "siblings": [], "_id": "63716a8a7a5e5d8efdc3f423", "disabled": false, "gated": false, "likes": 1, "downloads": 45, "createdAt": "2022-11-13T22:07:06.000Z"}, {"id": "bigbio/bionlp_st_2013_gro", "sha": "1f8f9ba929e063e4ca55c03667a875183d83f50a", "lastModified": "2022-12-22T15:44:01.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "GRO Task: Populating the Gene Regulation Ontology with events and\nrelations. A data set from the bio NLP shared tasks competition from 2013", "citation": "@inproceedings{kim-etal-2013-gro,\n    title = \"{GRO} Task: Populating the Gene Regulation Ontology with events and relations\",\n    author = \"Kim, Jung-jae  and\n      Han, Xu  and\n      Lee, Vivian  and\n      Rebholz-Schuhmann, Dietrich\",\n    booktitle = \"Proceedings of the {B}io{NLP} Shared Task 2013 Workshop\",\n    month = aug,\n    year = \"2013\",\n    address = \"Sofia, Bulgaria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W13-2007\",\n    pages = \"50--57\",\n}", "cardData": null, "siblings": [], "_id": "63716a8e7a5e5d8efdc3f486", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "createdAt": "2022-11-13T22:07:10.000Z"}, {"id": "bigbio/bionlp_st_2013_pc", "sha": "57eacf12bd690e8490116a32d0463988c2313d47", "lastModified": "2022-12-22T15:44:03.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "the Pathway Curation (PC) task is a main event extraction task of the BioNLP shared task (ST) 2013.\nThe PC task concerns the automatic extraction of biomolecular reactions from text.\nThe task setting, representation and semantics are defined with respect to pathway\nmodel standards and ontologies (SBML, BioPAX, SBO) and documents selected by relevance\nto specific model reactions. Two BioNLP ST 2013 participants successfully completed\nthe PC task. The highest achieved F-score, 52.8%, indicates that event extraction is\na promising approach to supporting pathway curation efforts.", "citation": "@inproceedings{ohta-etal-2013-overview,\n    title = \"Overview of the Pathway Curation ({PC}) task of {B}io{NLP} Shared Task 2013\",\n    author = \"Ohta, Tomoko  and\n      Pyysalo, Sampo  and\n      Rak, Rafal  and\n      Rowley, Andrew  and\n      Chun, Hong-Woo  and\n      Jung, Sung-Jae  and\n      Choi, Sung-Pil  and\n      Ananiadou, Sophia  and\n      Tsujii, Jun{'}ichi\",\n    booktitle = \"Proceedings of the {B}io{NLP} Shared Task 2013 Workshop\",\n    month = aug,\n    year = \"2013\",\n    address = \"Sofia, Bulgaria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W13-2009\",\n    pages = \"67--75\",\n}", "cardData": null, "siblings": [], "_id": "63716a92789970f7bc6355cd", "disabled": false, "gated": false, "likes": 0, "downloads": 59, "createdAt": "2022-11-13T22:07:14.000Z"}, {"id": "bigbio/bionlp_st_2019_bb", "sha": "3b213bd304cc94a73174215c8b1a4548606da669", "lastModified": "2022-12-22T15:44:04.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "The task focuses on the extraction of the locations and phenotypes of\nmicroorganisms from PubMed abstracts and full-text excerpts, and the\ncharacterization of these entities with respect to reference knowledge\nsources (NCBI taxonomy, OntoBiotope ontology). The task is motivated by\nthe importance of the knowledge on biodiversity for fundamental research\nand applications in microbiology.", "citation": "@inproceedings{bossy-etal-2019-bacteria,\n    title = \"Bacteria Biotope at {B}io{NLP} Open Shared Tasks 2019\",\n    author = \"Bossy, Robert  and\n      Del{\\'e}ger, Louise  and\n      Chaix, Estelle  and\n      Ba, Mouhamadou  and\n      N{\\'e}dellec, Claire\",\n    booktitle = \"Proceedings of The 5th Workshop on BioNLP Open Shared Tasks\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D19-5719\",\n    doi = \"10.18653/v1/D19-5719\",\n    pages = \"121--131\",\n    abstract = \"This paper presents the fourth edition of the Bacteria\n    Biotope task at BioNLP Open Shared Tasks 2019. The task focuses on\n    the extraction of the locations and phenotypes of microorganisms\n    from PubMed abstracts and full-text excerpts, and the characterization\n    of these entities with respect to reference knowledge sources (NCBI\n    taxonomy, OntoBiotope ontology). The task is motivated by the importance\n    of the knowledge on biodiversity for fundamental research and applications\n    in microbiology. The paper describes the different proposed subtasks, the\n    corpus characteristics, and the challenge organization. We also provide an\n    analysis of the results obtained by participants, and inspect the evolution\n    of the results since the last edition in 2016.\",\n}", "cardData": null, "siblings": [], "_id": "63716a95f0fe906bdc587c72", "disabled": false, "gated": false, "likes": 1, "downloads": 107, "createdAt": "2022-11-13T22:07:17.000Z"}, {"id": "bigbio/biored", "sha": "276d3b7a02894b41649dd62541c1418e49deb7ee", "lastModified": "2023-01-12T05:54:49.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "arxiv:2204.04263", "region:us"], "private": false, "author": "bigbio", "description": "Relation Extraction corpus with multiple entity types (e.g., gene/protein,\ndisease, chemical) and relation pairs (e.g., gene-disease; chemical-chemical),\non a set of 600 PubMed articles", "citation": "@article{DBLP:journals/corr/abs-2204-04263,\n  author    = {Ling Luo and\n               Po{-}Ting Lai and\n               Chih{-}Hsuan Wei and\n               Cecilia N. Arighi and\n               Zhiyong Lu},\n  title     = {BioRED: {A} Comprehensive Biomedical Relation Extraction Dataset},\n  journal   = {CoRR},\n  volume    = {abs/2204.04263},\n  year      = {2022},\n  url       = {https://doi.org/10.48550/arXiv.2204.04263},\n  doi       = {10.48550/arXiv.2204.04263},\n  eprinttype = {arXiv},\n  eprint    = {2204.04263},\n  timestamp = {Wed, 11 May 2022 15:24:37 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2204-04263.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63716a99789970f7bc635614", "disabled": false, "gated": false, "likes": 1, "downloads": 565, "createdAt": "2022-11-13T22:07:21.000Z"}, {"id": "bigbio/biorelex", "sha": "1d8844cb1a265ef7037a65482d32b674ba8364fa", "lastModified": "2022-12-22T15:44:10.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "BioRelEx is a biological relation extraction dataset. Version 1.0 contains 2010\nannotated sentences that describe binding interactions between various\nbiological entities (proteins, chemicals, etc.). 1405 sentences are for\ntraining, another 201 sentences are for validation. They are publicly available\nat https://github.com/YerevaNN/BioRelEx/releases. Another 404 sentences are for\ntesting which are kept private for at this Codalab competition\nhttps://competitions.codalab.org/competitions/20468. All sentences contain words\n\"bind\", \"bound\" or \"binding\". For every sentence we provide: 1) Complete\nannotations of all biological entities that appear in the sentence 2) Entity\ntypes (32 types) and grounding information for most of the proteins and families\n(links to uniprot, interpro and other databases) 3) Coreference between entities\nin the same sentence (e.g. abbreviations and synonyms) 4) Binding interactions\nbetween the annotated entities 5) Binding interaction types: positive, negative\n(A does not bind B) and neutral (A may bind to B)", "citation": "@inproceedings{khachatrian2019biorelex,\n    title = \"{B}io{R}el{E}x 1.0: Biological Relation Extraction Benchmark\",\n    author = \"Khachatrian, Hrant  and\n      Nersisyan, Lilit  and\n      Hambardzumyan, Karen  and\n      Galstyan, Tigran  and\n      Hakobyan, Anna  and\n      Arakelyan, Arsen  and\n      Rzhetsky, Andrey  and\n      Galstyan, Aram\",\n    booktitle = \"Proceedings of the 18th BioNLP Workshop and Shared Task\",\n    month = aug,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W19-5019\",\n    doi = \"10.18653/v1/W19-5019\",\n    pages = \"176--190\"\n}", "cardData": null, "siblings": [], "_id": "63716a9c345f97d07b2b2c5d", "disabled": false, "gated": false, "likes": 2, "downloads": 68, "createdAt": "2022-11-13T22:07:24.000Z"}, {"id": "bigbio/bioscope", "sha": "43ba162359f01d6436590ba2a014421b6ad09621", "lastModified": "2022-12-22T15:44:13.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-2.0", "region:us"], "private": false, "author": "bigbio", "description": "The BioScope corpus consists of medical and biological texts annotated for\nnegation, speculation and their linguistic scope. This was done to allow a\ncomparison between the development of systems for negation/hedge detection and\nscope resolution. The BioScope corpus was annotated by two independent linguists\nfollowing the guidelines written by our linguist expert before the annotation of\nthe corpus was initiated.", "citation": "@article{vincze2008bioscope,\n  title={The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes},\n  author={Vincze, Veronika and Szarvas, Gy{\\\"o}rgy and Farkas, Rich{\\'a}rd and M{\\'o}ra, Gy{\\\"o}rgy and Csirik, J{\\'a}nos},\n  journal={BMC bioinformatics},\n  volume={9},\n  number={11},\n  pages={1--9},\n  year={2008},\n  publisher={BioMed Central}\n}", "cardData": null, "siblings": [], "_id": "63716aa0967e405db1228dab", "disabled": false, "gated": false, "likes": 0, "downloads": 32, "createdAt": "2022-11-13T22:07:28.000Z"}, {"id": "bigbio/cas", "sha": "7b45cb510fffc61d8ef750ae08dce3e242c38385", "lastModified": "2022-12-22T15:44:18.000Z", "tags": ["multilinguality:monolingual", "language:fr", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "We manually annotated two corpora from the biomedical field. The ESSAI corpus contains clinical trial protocols in French. They were mainly obtained from the National Cancer Institute The typical protocol consists of two parts: the summary of the trial, which indicates the purpose of the trial and the methods applied; and a detailed description of the trial with the inclusion and exclusion criteria. The CAS corpus contains clinical cases published in scientific literature and training material. They are published in different journals from French-speaking countries (France, Belgium, Switzerland, Canada, African countries, tropical countries) and are related to various medical specialties (cardiology, urology, oncology, obstetrics, pulmonology, gastro-enterology). The purpose of clinical cases is to describe clinical situations of patients. Hence, their content is close to the content of clinical narratives (description of diagnoses, treatments or procedures, evolution, family history, expected audience, etc.). In clinical cases, the negation is frequently used for describing the patient signs, symptoms, and diagnosis. Speculation is present as well but less frequently.\n\nThis version only contain the annotated CAS corpus", "citation": "@inproceedings{grabar-etal-2018-cas,\n  title        = {{CAS}: {F}rench Corpus with Clinical Cases},\n  author       = {Grabar, Natalia  and Claveau, Vincent  and Dalloux, Cl{\\'e}ment},\n  year         = 2018,\n  month        = oct,\n  booktitle    = {\n    Proceedings of the Ninth International Workshop on Health Text Mining and\n    Information Analysis\n  },\n  publisher    = {Association for Computational Linguistics},\n  address      = {Brussels, Belgium},\n  pages        = {122--128},\n  doi          = {10.18653/v1/W18-5614},\n  url          = {https://aclanthology.org/W18-5614},\n  abstract     = {\n    Textual corpora are extremely important for various NLP applications as\n    they provide information necessary for creating, setting and testing these\n    applications and the corresponding tools. They are also crucial for\n    designing reliable methods and reproducible results. Yet, in some areas,\n    such as the medical area, due to confidentiality or to ethical reasons, it\n    is complicated and even impossible to access textual data representative of\n    those produced in these areas. We propose the CAS corpus built with\n    clinical cases, such as they are reported in the published scientific\n    literature in French. We describe this corpus, currently containing over\n    397,000 word occurrences, and the existing linguistic and semantic\n    annotations.\n  }\n}", "cardData": null, "siblings": [], "_id": "63716aa7afbe42caa5a8d6ed", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-13T22:07:35.000Z"}, {"id": "bigbio/cellfinder", "sha": "6f0dbdfff00869acca7865a6defdefa1c63397bc", "lastModified": "2022-12-22T15:44:19.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The CellFinder project aims to create a stem cell data repository by linking information from existing public databases and by performing text mining on the research literature. The first version of the corpus is composed of 10 full text documents containing more than 2,100 sentences, 65,000 tokens and 5,200 annotations for entities. The corpus has been annotated with six types of entities (anatomical parts, cell components, cell lines, cell types, genes/protein and species) with an overall inter-annotator agreement around 80%.\n\nSee: https://www.informatik.hu-berlin.de/de/forschung/gebiete/wbi/resources/cellfinder/", "citation": "@inproceedings{neves2012annotating,\n  title        = {Annotating and evaluating text for stem cell research},\n  author       = {Neves, Mariana and Damaschun, Alexander and Kurtz, Andreas and Leser, Ulf},\n  year         = 2012,\n  booktitle    = {\n    Proceedings of the Third Workshop on Building and Evaluation Resources for\n    Biomedical Text Mining\\ (BioTxtM 2012) at Language Resources and Evaluation\n    (LREC). Istanbul, Turkey\n  },\n  pages        = {16--23},\n  organization = {Citeseer}\n}", "cardData": null, "siblings": [], "_id": "63716aab3d1bd47a4ec429d4", "disabled": false, "gated": false, "likes": 1, "downloads": 30, "createdAt": "2022-11-13T22:07:39.000Z"}, {"id": "bigbio/chebi_nactem", "sha": "1edad51fe17c6e0321a7aaebfefecda9347783c6", "lastModified": "2022-12-22T15:44:20.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The ChEBI corpus contains 199 annotated abstracts and 100 annotated full papers.\nAll documents in the corpus have been annotated for named entities and relations\nbetween these. In total, our corpus provides over 15000 named entity annotations\nand over 6,000 relations between entities.", "citation": "@inproceedings{Shardlow2018,\n  title        = {\n    A New Corpus to Support Text Mining for the Curation of Metabolites in the\n    {ChEBI} Database\n  },\n  author       = {\n    Shardlow, M J and Nguyen, N and Owen, G and O'Donovan, C and Leach, A and\n    McNaught, J and Turner, S and Ananiadou, S\n  },\n  year         = 2018,\n  month        = may,\n  booktitle    = {\n    Proceedings of the Eleventh International Conference on Language Resources\n    and Evaluation ({LREC} 2018)\n  },\n  location     = {Miyazaki, Japan},\n  pages        = {280--285},\n  conference   = {\n    Eleventh International Conference on Language Resources and Evaluation\n    (LREC 2018)\n  },\n  language     = {en}\n}", "cardData": null, "siblings": [], "_id": "63716aafafbe42caa5a8d728", "disabled": false, "gated": false, "likes": 0, "downloads": 120, "createdAt": "2022-11-13T22:07:43.000Z"}, {"id": "bigbio/chemdner", "sha": "4c4cf9abe6937e2063db3a5d331cc50a7af37f59", "lastModified": "2022-12-22T15:44:21.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "We present the CHEMDNER corpus, a collection of 10,000 PubMed abstracts that\ncontain a total of 84,355 chemical entity mentions labeled manually by expert\nchemistry literature curators, following annotation guidelines specifically\ndefined for this task. The abstracts of the CHEMDNER corpus were selected to be\nrepresentative for all major chemical disciplines. Each of the chemical entity\nmentions was manually labeled according to its structure-associated chemical\nentity mention (SACEM) class: abbreviation, family, formula, identifier,\nmultiple, systematic and trivial.", "citation": "@article{Krallinger2015,\n  title        = {The CHEMDNER corpus of chemicals and drugs and its annotation principles},\n  author       = {\n    Krallinger, Martin and Rabal, Obdulia and Leitner, Florian and Vazquez,\n    Miguel and Salgado, David and Lu, Zhiyong and Leaman, Robert and Lu, Yanan\n    and Ji, Donghong and Lowe, Daniel M. and Sayle, Roger A. and\n    Batista-Navarro, Riza Theresa and Rak, Rafal and Huber, Torsten and\n    Rockt{\\\"a}schel, Tim and Matos, S{\\'e}rgio and Campos, David and Tang,\n    Buzhou and Xu, Hua and Munkhdalai, Tsendsuren and Ryu, Keun Ho and Ramanan,\n    S. V. and Nathan, Senthil and {\\v{Z}}itnik, Slavko and Bajec, Marko and\n    Weber, Lutz and Irmer, Matthias and Akhondi, Saber A. and Kors, Jan A. and\n    Xu, Shuo and An, Xin and Sikdar, Utpal Kumar and Ekbal, Asif and Yoshioka,\n    Masaharu and Dieb, Thaer M. and Choi, Miji and Verspoor, Karin and Khabsa,\n    Madian and Giles, C. Lee and Liu, Hongfang and Ravikumar, Komandur\n    Elayavilli and Lamurias, Andre and Couto, Francisco M. and Dai, Hong-Jie\n    and Tsai, Richard Tzong-Han and Ata, Caglar and Can, Tolga and Usi{\\'e},\n    Anabel and Alves, Rui and Segura-Bedmar, Isabel and Mart{\\'i}nez, Paloma\n    and Oyarzabal, Julen and Valencia, Alfonso\n  },\n  year         = 2015,\n  month        = {Jan},\n  day          = 19,\n  journal      = {Journal of Cheminformatics},\n  volume       = 7,\n  number       = 1,\n  pages        = {S2},\n  doi          = {10.1186/1758-2946-7-S1-S2},\n  issn         = {1758-2946},\n  url          = {https://doi.org/10.1186/1758-2946-7-S1-S2},\n  abstract     = {\n    The automatic extraction of chemical information from text requires the\n    recognition of chemical entity mentions as one of its key steps. When\n    developing supervised named entity recognition (NER) systems, the\n    availability of a large, manually annotated text corpus is desirable.\n    Furthermore, large corpora permit the robust evaluation and comparison of\n    different approaches that detect chemicals in documents. We present the\n    CHEMDNER corpus, a collection of 10,000 PubMed abstracts that contain a\n    total of 84,355 chemical entity mentions labeled manually by expert\n    chemistry literature curators, following annotation guidelines specifically\n    defined for this task. The abstracts of the CHEMDNER corpus were selected\n    to be representative for all major chemical disciplines. Each of the\n    chemical entity mentions was manually labeled according to its\n    structure-associated chemical entity mention (SACEM) class: abbreviation,\n    family, formula, identifier, multiple, systematic and trivial. The\n    difficulty and consistency of tagging chemicals in text was measured using\n    an agreement study between annotators, obtaining a percentage agreement of\n    91. For a subset of the CHEMDNER corpus (the test set of 3,000 abstracts)\n    we provide not only the Gold Standard manual annotations, but also mentions\n    automatically detected by the 26 teams that participated in the BioCreative\n    IV CHEMDNER chemical mention recognition task. In addition, we release the\n    CHEMDNER silver standard corpus of automatically extracted mentions from\n    17,000 randomly selected PubMed abstracts. A version of the CHEMDNER corpus\n    in the BioC format has been generated as well. We propose a standard for\n    required minimum information about entity annotations for the construction\n    of domain specific corpora on chemical and drug entities. The CHEMDNER\n    corpus and annotation guidelines are available at:\n    ttp://www.biocreative.org/resources/biocreative-iv/chemdner-corpus/\n  }\n}", "cardData": null, "siblings": [], "_id": "63716ab2ffc0489ed7d297de", "disabled": false, "gated": false, "likes": 1, "downloads": 156, "createdAt": "2022-11-13T22:07:46.000Z"}, {"id": "bigbio/chemprot", "sha": "86afccf3ccc614f817a7fad0692bf62fbc5ce469", "lastModified": "2022-12-22T15:44:22.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The BioCreative VI Chemical-Protein interaction dataset identifies entities of\nchemicals and proteins and their likely relation to one other. Compounds are\ngenerally agonists (activators) or antagonists (inhibitors) of proteins.", "citation": "@article{DBLP:journals/biodb/LiSJSWLDMWL16,\n  author    = {Krallinger, M., Rabal, O., Louren\u00e7o, A.},\n  title     = {Overview of the BioCreative VI chemical-protein interaction Track},\n  journal   = {Proceedings of the BioCreative VI Workshop,},\n  volume    = {141-146},\n  year      = {2017},\n  url       = {https://biocreative.bioinformatics.udel.edu/tasks/biocreative-vi/track-5/},\n  doi       = {},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "63716ab6967e405db1228ead", "disabled": false, "gated": false, "likes": 1, "downloads": 454, "createdAt": "2022-11-13T22:07:50.000Z"}, {"id": "bigbio/chia", "sha": "36e5df0d60dfc5152cd22a807ade73f135105008", "lastModified": "2022-12-22T15:44:25.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "A large annotated corpus of patient eligibility criteria extracted from 1,000\ninterventional, Phase IV clinical trials registered in ClinicalTrials.gov. This\ndataset includes 12,409 annotated eligibility criteria, represented by 41,487\ndistinctive entities of 15 entity types and 25,017 relationships of 12\nrelationship types.", "citation": "@article{kury2020chia,\n  title        = {Chia, a large annotated corpus of clinical trial eligibility criteria},\n  author       = {\n    Kury, Fabr{\\'\\\\i}cio and Butler, Alex and Yuan, Chi and Fu, Li-heng and\n    Sun, Yingcheng and Liu, Hao and Sim, Ida and Carini, Simona and Weng,\n    Chunhua\n  },\n  year         = 2020,\n  journal      = {Scientific data},\n  publisher    = {Nature Publishing Group},\n  volume       = 7,\n  number       = 1,\n  pages        = {1--11}\n}", "cardData": null, "siblings": [], "_id": "63716ab967cd0e8815049529", "disabled": false, "gated": false, "likes": 1, "downloads": 91, "createdAt": "2022-11-13T22:07:53.000Z"}, {"id": "bigbio/codiesp", "sha": "a0ae1d2efa285d33084e35bbb25f56f28360aef6", "lastModified": "2022-12-22T15:44:28.000Z", "tags": ["multilinguality:monolingual", "language:es", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "Synthetic corpus of 1,000 manually selected clinical case studies in Spanish\nthat was designed for the Clinical Case Coding in Spanish Shared Task, as part\nof the CLEF 2020 conference.\n\nThe goal of the task was to automatically assign ICD10 codes (CIE-10, in\nSpanish) to clinical case documents, being evaluated against manually generated\nICD10 codifications. The CodiEsp corpus was selected manually by practicing\nphysicians and clinical documentalists and annotated by clinical coding\nprofessionals meeting strict quality criteria. They reached an inter-annotator\nagreement of 88.6% for diagnosis coding, 88.9% for procedure coding and 80.5%\nfor the textual reference annotation.\n\nThe final collection of 1,000 clinical cases that make up the corpus had a total\nof 16,504 sentences and 396,988 words. All documents are in Spanish language and\nCIE10 is the coding terminology (the Spanish version of ICD10-CM and ICD10-PCS).\nThe CodiEsp corpus has been randomly sampled into three subsets. The train set\ncontains 500 clinical cases, while the development and test sets have 250\nclinical cases each. In addition to these, a collection of 176,294 abstracts\nfrom Lilacs and Ibecs with the corresponding ICD10 codes (ICD10-CM and\nICD10-PCS) was provided by the task organizers. Every abstract has at least one\nassociated code, with an average of 2.5 ICD10 codes per abstract.\n\nThe CodiEsp track was divided into three sub-tracks (2 main and 1 exploratory):\n\n- CodiEsp-D: The Diagnosis Coding sub-task, which requires automatic ICD10-CM\n  [CIE10-Diagn\u00f3stico] code assignment.\n- CodiEsp-P: The Procedure Coding sub-task, which requires automatic ICD10-PCS\n  [CIE10-Procedimiento] code assignment.\n- CodiEsp-X: The Explainable AI exploratory sub-task, which requires to submit\n  the reference to the predicted codes (both ICD10-CM and ICD10-PCS). The goal \n  of this novel task was not only to predict the correct codes but also to \n  present the reference in the text that supports the code predictions.\n\nFor further information, please visit https://temu.bsc.es/codiesp or send an\nemail to encargo-pln-life@bsc.es", "citation": "@article{miranda2020overview,\n  title={Overview of Automatic Clinical Coding: Annotations, Guidelines, and Solutions for non-English Clinical Cases at CodiEsp Track of CLEF eHealth 2020.},\n  author={Miranda-Escalada, Antonio and Gonzalez-Agirre, Aitor and Armengol-Estap{\\'e}, Jordi and Krallinger, Martin},\n  journal={CLEF (Working Notes)},\n  volume={2020},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "63716ac167cd0e8815049566", "disabled": false, "gated": false, "likes": 0, "downloads": 44, "createdAt": "2022-11-13T22:08:01.000Z"}, {"id": "bigbio/ctebmsp", "sha": "07eabc59f1564280eedc8992b62ed6a8f456e4d2", "lastModified": "2022-12-22T15:44:30.000Z", "tags": ["multilinguality:monolingual", "language:es", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The \"abstracts\" subset of the Clinical Trials for Evidence-Based Medicine in Spanish\n(CT-EBM-SP) corpus contains 500 abstracts of clinical trial studies in Spanish,\npublished in journals with a Creative Commons license. Most were downloaded from\nthe SciELO repository and free abstracts in PubMed.\n\nAbstracts were retrieved with the query:\nClinical Trial[ptyp] AND \u201cloattrfree full text\u201d[sb] AND \u201cspanish\u201d[la].\n\n(Information collected from 10.1186/s12911-021-01395-z)", "citation": "@article{CampillosLlanos2021,\n  author    = {Leonardo Campillos-Llanos and\n               Ana Valverde-Mateos and\n               Adri{\\'{a}}n Capllonch-Carri{\\'{o}}n and\n               Antonio Moreno-Sandoval},\n  title     = {A clinical trials corpus annotated with {UMLS}\n               entities to enhance the access to evidence-based medicine},\n  journal   = {{BMC} Medical Informatics and Decision Making},\n  volume    = {21},\n  year      = {2021},\n  url       = {https://doi.org/10.1186/s12911-021-01395-z},\n  doi       = {10.1186/s12911-021-01395-z},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "63716ac467cd0e881504957f", "disabled": false, "gated": false, "likes": 0, "downloads": 40, "createdAt": "2022-11-13T22:08:04.000Z"}, {"id": "bigbio/ddi_corpus", "sha": "da8e94986a0c689095b22bed134248b11f9311c7", "lastModified": "2022-12-22T15:44:31.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The DDI corpus has been manually annotated with drugs and pharmacokinetics and pharmacodynamics interactions. It contains 1025 documents from two different sources: DrugBank database and MedLine.", "citation": "@article{HERREROZAZO2013914,\n  title        = {\n    The DDI corpus: An annotated corpus with pharmacological substances and\n    drug-drug interactions\n  },\n  author       = {\n    Mar\u00eda Herrero-Zazo and Isabel Segura-Bedmar and Paloma Mart\u00ednez and Thierry\n    Declerck\n  },\n  year         = 2013,\n  journal      = {Journal of Biomedical Informatics},\n  volume       = 46,\n  number       = 5,\n  pages        = {914--920},\n  doi          = {https://doi.org/10.1016/j.jbi.2013.07.011},\n  issn         = {1532-0464},\n  url          = {https://www.sciencedirect.com/science/article/pii/S1532046413001123},\n  keywords     = {Biomedical corpora, Drug interaction, Information extraction}\n}", "cardData": null, "siblings": [], "_id": "63716ac891284164d1b8fb27", "disabled": false, "gated": false, "likes": 2, "downloads": 357, "createdAt": "2022-11-13T22:08:08.000Z"}, {"id": "bigbio/distemist", "sha": "fcf2be22093d904d325634943912bd0739cacdb1", "lastModified": "2023-04-01T16:51:57.000Z", "tags": ["multilinguality:monolingual", "language:es", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The DisTEMIST corpus is a collection of 1000 clinical cases with disease annotations linked with Snomed-CT concepts.\nAll documents are released in the context of the BioASQ DisTEMIST track for CLEF 2022.", "citation": "@article{miranda2022overview,\ntitle={Overview of DisTEMIST at BioASQ: Automatic detection and normalization of diseases\n    from clinical texts: results, methods, evaluation and multilingual resources},\nauthor={Miranda-Escalada, Antonio and Gasc\u00f3, Luis and Lima-L\u00f3pez, Salvador and Farr\u00e9-Maduell,\n    Eul\u00e0lia and Estrada, Darryl and Nentidis, Anastasios and Krithara, Anastasia and Katsimpras,\n    Georgios and Paliouras, Georgios and Krallinger, Martin},\nbooktitle={Working Notes of Conference and Labs of the Evaluation (CLEF) Forum.\n    CEUR Workshop Proceedings},\nyear={2022}\n}", "cardData": null, "siblings": [], "_id": "63716acb7a5e5d8efdc3f6ba", "disabled": false, "gated": false, "likes": 3, "downloads": 57, "createdAt": "2022-11-13T22:08:11.000Z"}, {"id": "bigbio/ebm_pico", "sha": "0d5ce09f87c6d144b107438c5ce2b70a9f0b2800", "lastModified": "2022-12-22T15:44:33.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "This corpus release contains 4,993 abstracts annotated with (P)articipants,\n(I)nterventions, and (O)utcomes. Training labels are sourced from AMT workers and\naggregated to reduce noise. Test labels are collected from medical professionals.", "citation": "@inproceedings{nye-etal-2018-corpus,\n    title = \"A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature\",\n    author = \"Nye, Benjamin  and\n      Li, Junyi Jessy  and\n      Patel, Roma  and\n      Yang, Yinfei  and\n      Marshall, Iain  and\n      Nenkova, Ani  and\n      Wallace, Byron\",\n    booktitle = \"Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2018\",\n    address = \"Melbourne, Australia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P18-1019\",\n    doi = \"10.18653/v1/P18-1019\",\n    pages = \"197--207\",\n}", "cardData": null, "siblings": [], "_id": "63716acf789970f7bc63582d", "disabled": false, "gated": false, "likes": 0, "downloads": 410, "createdAt": "2022-11-13T22:08:15.000Z"}, {"id": "bigbio/euadr", "sha": "da142461b82afb73b7bad03695c61d61a412de4f", "lastModified": "2022-12-22T15:44:36.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "Corpora with specific entities and relationships annotated are essential to train and evaluate text-mining systems that are developed to extract specific structured information from a large corpus. In this paper we describe an approach where a named-entity recognition system produces a first annotation and annotators revise this annotation using a web-based interface. The agreement figures achieved show that the inter-annotator agreement is much better than the agreement with the system provided annotations. The corpus has been annotated for drugs, disorders, genes and their inter-relationships. For each of the drug-disorder, drug-target, and target-disorder relations three experts have annotated a set of 100 abstracts. These annotated relationships will be used to train and evaluate text-mining software to capture these relationships in texts.", "citation": "@article{VANMULLIGEN2012879,\ntitle = {The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships},\njournal = {Journal of Biomedical Informatics},\nvolume = {45},\nnumber = {5},\npages = {879-884},\nyear = {2012},\nnote = {Text Mining and Natural Language Processing in Pharmacogenomics},\nissn = {1532-0464},\ndoi = {https://doi.org/10.1016/j.jbi.2012.04.004},\nurl = {https://www.sciencedirect.com/science/article/pii/S1532046412000573},\nauthor = {Erik M. {van Mulligen} and Annie Fourrier-Reglat and David Gurwitz and Mariam Molokhia and Ainhoa Nieto and Gianluca Trifiro and Jan A. Kors and Laura I. Furlong},\nkeywords = {Text mining, Corpus development, Machine learning, Adverse drug reactions},\nabstract = {Corpora with specific entities and relationships annotated are essential to train and evaluate text-mining systems that are developed to extract specific structured information from a large corpus. In this paper we describe an approach where a named-entity recognition system produces a first annotation and annotators revise this annotation using a web-based interface. The agreement figures achieved show that the inter-annotator agreement is much better than the agreement with the system provided annotations. The corpus has been annotated for drugs, disorders, genes and their inter-relationships. For each of the drug\u2013disorder, drug\u2013target, and target\u2013disorder relations three experts have annotated a set of 100 abstracts. These annotated relationships will be used to train and evaluate text-mining software to capture these relationships in texts.}\n}", "cardData": null, "siblings": [], "_id": "63716ad991284164d1b8fc49", "disabled": false, "gated": false, "likes": 2, "downloads": 79, "createdAt": "2022-11-13T22:08:25.000Z"}, {"id": "bigbio/evidence_inference", "sha": "35dce6aba1b3eb9eb9af9bdc38ebeda73dad15b9", "lastModified": "2022-12-22T15:44:37.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:mit", "region:us"], "private": false, "author": "bigbio", "description": "The dataset consists of biomedical articles describing randomized control trials (RCTs) that compare multiple\ntreatments. Each of these articles will have multiple questions, or 'prompts' associated with them.\nThese prompts will ask about the relationship between an intervention and comparator with respect to an outcome,\nas reported in the trial. For example, a prompt may ask about the reported effects of aspirin as compared\nto placebo on the duration of headaches. For the sake of this task, we assume that a particular article\nwill report that the intervention of interest either significantly increased, significantly decreased\nor had significant effect on the outcome, relative to the comparator.", "citation": "@inproceedings{deyoung-etal-2020-evidence,\n    title = \"Evidence Inference 2.0: More Data, Better Models\",\n    author = \"DeYoung, Jay  and\n      Lehman, Eric  and\n      Nye, Benjamin  and\n      Marshall, Iain  and\n      Wallace, Byron C.\",\n    booktitle = \"Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.bionlp-1.13\",\n    pages = \"123--132\",\n}", "cardData": null, "siblings": [], "_id": "63716addafbe42caa5a8d98e", "disabled": false, "gated": false, "likes": 1, "downloads": 29, "createdAt": "2022-11-13T22:08:29.000Z"}, {"id": "bigbio/genetag", "sha": "664a5e5007c3a4e51d244c289f211013d529658d", "lastModified": "2022-12-22T15:44:38.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "Named entity recognition (NER) is an important first step for text mining the biomedical literature.\nEvaluating the performance of biomedical NER systems is impossible without a standardized test corpus.\nThe annotation of such a corpus for gene/protein name NER is a difficult process due to the complexity\nof gene/protein names. We describe the construction and annotation of GENETAG, a corpus of 20K MEDLINE\u00ae\nsentences for gene/protein NER. 15K GENETAG sentences were used for the BioCreAtIvE Task 1A Competition..", "citation": "@article{Tanabe2005,\n  author    = {Lorraine Tanabe and Natalie Xie and Lynne H Thom and Wayne Matten and W John Wilbur},\n  title     = {{GENETAG}: a tagged corpus for gene/protein named entity recognition},\n  journal   = {{BMC} Bioinformatics},\n  volume    = {6},\n  year      = {2005},\n  url       = {https://doi.org/10.1186/1471-2105-6-S1-S3},\n  doi       = {10.1186/1471-2105-6-s1-s3},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "63716ae0afbe42caa5a8d9e5", "disabled": false, "gated": false, "likes": 2, "downloads": 25, "createdAt": "2022-11-13T22:08:32.000Z"}, {"id": "bigbio/genia_ptm_event_corpus", "sha": "3e15094fc56ec0b1feced8aa228eff3c55c54740", "lastModified": "2022-12-22T15:44:39.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "Post-translational-modi\ufb01cations (PTM), amino acid modi\ufb01cations of proteins after translation, are one of the posterior processes of protein biosynthesis for many proteins, and they are critical for determining protein function such as its activity state, localization, turnover and interactions with other biomolecules. While there have been many studies of information extraction targeting individual PTM types, there was until recently little effort to address extraction of multiple PTM types at once in a unified framework.", "citation": "@inproceedings{ohta-etal-2010-event,\n    title = \"Event Extraction for Post-Translational Modifications\",\n    author = \"Ohta, Tomoko  and\n      Pyysalo, Sampo  and\n      Miwa, Makoto  and\n      Kim, Jin-Dong  and\n      Tsujii, Jun{'}ichi\",\n    booktitle = \"Proceedings of the 2010 Workshop on Biomedical Natural Language Processing\",\n    month = jul,\n    year = \"2010\",\n    address = \"Uppsala, Sweden\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W10-1903\",\n    pages = \"19--27\",\n}", "cardData": null, "siblings": [], "_id": "63716ae43434f2764ceafcaf", "disabled": false, "gated": false, "likes": 1, "downloads": 40, "createdAt": "2022-11-13T22:08:36.000Z"}, {"id": "bigbio/genia_relation_corpus", "sha": "03ed6ae9c7ea27ae2b430f71ea7a74853bd2fb5e", "lastModified": "2022-12-22T15:44:40.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The extraction of various relations stated to hold between biomolecular entities is one of the most frequently\naddressed information extraction tasks in domain studies. Typical relation extraction targets involve protein-protein\ninteractions or gene regulatory relations. However, in the GENIA corpus, such associations involving change in the\nstate or properties of biomolecules are captured in the event annotation.\n\nThe GENIA corpus relation annotation aims to complement the event annotation of the corpus by capturing (primarily)\nstatic relations, relations such as part-of that hold between entities without (necessarily) involving change.", "citation": "@inproceedings{pyysalo-etal-2009-static,\n    title = \"Static Relations: a Piece in the Biomedical Information Extraction Puzzle\",\n    author = \"Pyysalo, Sampo  and\n      Ohta, Tomoko  and\n      Kim, Jin-Dong  and\n      Tsujii, Jun{'}ichi\",\n    booktitle = \"Proceedings of the {B}io{NLP} 2009 Workshop\",\n    month = jun,\n    year = \"2009\",\n    address = \"Boulder, Colorado\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W09-1301\",\n    pages = \"1--9\",\n}\n\n@article{article,\nauthor = {Ohta, Tomoko and Pyysalo, Sampo and Kim, Jin-Dong and Tsujii, Jun'ichi},\nyear = {2010},\nmonth = {10},\npages = {917-28},\ntitle = {A reevaluation of biomedical named entity - term relations},\nvolume = {8},\njournal = {Journal of bioinformatics and computational biology},\ndoi = {10.1142/S0219720010005014}\n}\n\n@MISC{Hoehndorf_applyingontology,\n    author = {Robert Hoehndorf and Axel-cyrille Ngonga Ngomo and Sampo Pyysalo and Tomoko Ohta and Anika Oellrich and\n    Dietrich Rebholz-schuhmann},\n    title = {Applying ontology design patterns to the implementation of relations in GENIA},\n    year = {}\n}", "cardData": null, "siblings": [], "_id": "63716ae7afbe42caa5a8da4e", "disabled": false, "gated": false, "likes": 1, "downloads": 30, "createdAt": "2022-11-13T22:08:39.000Z"}, {"id": "bigbio/genia_term_corpus", "sha": "c556529b5f8b5e4ffe2c10f23209e70c4390f3e1", "lastModified": "2022-12-22T15:44:41.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The identification of linguistic expressions referring to entities of interest in molecular biology such as proteins,\ngenes and cells is a fundamental task in biomolecular text mining. The GENIA technical term annotation covers the\nidentification of  physical biological entities as well as other important terms. The corpus annotation covers the full\n1,999 abstracts of the primary GENIA corpus.", "citation": "@inproceedings{10.5555/1289189.1289260,\nauthor = {Ohta, Tomoko and Tateisi, Yuka and Kim, Jin-Dong},\ntitle = {The GENIA Corpus: An Annotated Research Abstract Corpus in Molecular Biology Domain},\nyear = {2002},\npublisher = {Morgan Kaufmann Publishers Inc.},\naddress = {San Francisco, CA, USA},\nbooktitle = {Proceedings of the Second International Conference on Human Language Technology Research},\npages = {82\u201386},\nnumpages = {5},\nlocation = {San Diego, California},\nseries = {HLT '02}\n}\n\n@article{Kim2003GENIAC,\n  title={GENIA corpus - a semantically annotated corpus for bio-textmining},\n  author={Jin-Dong Kim and Tomoko Ohta and Yuka Tateisi and Junichi Tsujii},\n  journal={Bioinformatics},\n  year={2003},\n  volume={19 Suppl 1},\n  pages={\n          i180-2\n        }\n}\n\n@inproceedings{10.5555/1567594.1567610,\nauthor = {Kim, Jin-Dong and Ohta, Tomoko and Tsuruoka, Yoshimasa and Tateisi, Yuka and Collier, Nigel},\ntitle = {Introduction to the Bio-Entity Recognition Task at JNLPBA},\nyear = {2004},\npublisher = {Association for Computational Linguistics},\naddress = {USA},\nbooktitle = {Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and Its\nApplications},\npages = {70\u201375},\nnumpages = {6},\nlocation = {Geneva, Switzerland},\nseries = {JNLPBA '04}\n}", "cardData": null, "siblings": [], "_id": "63716aebffc0489ed7d29b20", "disabled": false, "gated": false, "likes": 1, "downloads": 65, "createdAt": "2022-11-13T22:08:43.000Z"}, {"id": "bigbio/geokhoj_v1", "sha": "5256724fced919bd69ec2f9d6f2e7822a59b5f81", "lastModified": "2022-12-22T15:44:42.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-nc-4.0", "region:us"], "private": false, "author": "bigbio", "description": "GEOKhoj v1 is a annotated corpus of control/perturbation labels for 30,000 samples\nfrom Microarray, Transcriptomics and Single cell experiments which are available on\nthe GEO (Gene Expression Omnibus) database", "citation": "@misc{geokhoj_v1,\n  author = {Elucidata, Inc.},\n  title = {GEOKhoj v1},\n  howpublished = {\\\\url{https://github.com/ElucidataInc/GEOKhoj-datasets/tree/main/geokhoj_v1}},\n}", "cardData": null, "siblings": [], "_id": "63716aee3d1bd47a4ec42d99", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-11-13T22:08:46.000Z"}, {"id": "bigbio/gnormplus", "sha": "0be64eff331d4951c8d04347c711bca08c715f39", "lastModified": "2023-02-17T14:55:04.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "We re-annotated two existing gene corpora. The BioCreative II GN corpus is a widely used data set for benchmarking GN\ntools and includes document-level annotations for a total of 543 articles (281 in its training set; and 262 in test).\nThe Citation GIA Test Collection was recently created for gene indexing at the NLM and includes 151 PubMed abstracts\nwith both mention-level and document-level annotations. They are selected because both have a focus on human genes.\nFor both corpora, we added annotations of gene families and protein domains. For the BioCreative GN corpus, we also\nadded mention-level gene annotations. As a result, in our new corpus, there are a total of 694 PubMed articles.\nPubTator was used as our annotation tool along with BioC formats.", "citation": "@Article{Wei2015,\nauthor={Wei, Chih-Hsuan and Kao, Hung-Yu and Lu, Zhiyong},\ntitle={GNormPlus: An Integrative Approach for Tagging Genes, Gene Families, and Protein Domains},\njournal={BioMed Research International},\nyear={2015},\nmonth={Aug},\nday={25},\npublisher={Hindawi Publishing Corporation},\nvolume={2015},\npages={918710},\nissn={2314-6133},\ndoi={10.1155/2015/918710},\nurl={https://doi.org/10.1155/2015/918710}\n}", "cardData": null, "siblings": [], "_id": "63716af23d1bd47a4ec42dea", "disabled": false, "gated": false, "likes": 2, "downloads": 128, "createdAt": "2022-11-13T22:08:50.000Z"}, {"id": "bigbio/hallmarks_of_cancer", "sha": "5177d3fb0681f27af37431f46617fea31d50bdc3", "lastModified": "2022-12-22T15:44:44.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The Hallmarks of Cancer (HOC) Corpus consists of 1852 PubMed publication\nabstracts manually annotated by experts according to a taxonomy. The taxonomy\nconsists of 37 classes in a hierarchy. Zero or more class labels are assigned\nto each sentence in the corpus. The labels are found under the \"labels\"\ndirectory, while the tokenized text can be found under \"text\" directory.\nThe filenames are the corresponding PubMed IDs (PMID).", "citation": "@article{DBLP:journals/bioinformatics/BakerSGAHSK16,\n  author    = {Simon Baker and\n               Ilona Silins and\n               Yufan Guo and\n               Imran Ali and\n               Johan H{\\\"{o}}gberg and\n               Ulla Stenius and\n               Anna Korhonen},\n  title     = {Automatic semantic classification of scientific literature\n               according to the hallmarks of cancer},\n  journal   = {Bioinform.},\n  volume    = {32},\n  number    = {3},\n  pages     = {432--440},\n  year      = {2016},\n  url       = {https://doi.org/10.1093/bioinformatics/btv585},\n  doi       = {10.1093/bioinformatics/btv585},\n  timestamp = {Thu, 14 Oct 2021 08:57:44 +0200},\n  biburl    = {https://dblp.org/rec/journals/bioinformatics/BakerSGAHSK16.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63716af5afbe42caa5a8db7c", "disabled": false, "gated": false, "likes": 1, "downloads": 463, "createdAt": "2022-11-13T22:08:53.000Z"}, {"id": "bigbio/hprd50", "sha": "12192d76a4d1cf1fbad39f119df56135bd206e5b", "lastModified": "2022-12-22T15:44:46.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "HPRD50 is a dataset of randomly selected, hand-annotated abstracts of biomedical papers\nreferenced by the Human Protein Reference Database (HPRD). It is parsed in XML format,\nsplitting each abstract into sentences, and in each sentence there may be entities and\ninteractions between those entities. In this particular dataset, entities are all\nproteins and interactions are thus protein-protein interactions.\n\nMoreover, all entities are normalized to the HPRD database. These normalized terms are\nstored in each entity's 'type' attribute in the source XML. This means the dataset can\ndetermine e.g. that \"Janus kinase 2\" and \"Jak2\" are referencing the same normalized\nentity.\n\nBecause the dataset contains entities and relations, it is suitable for Named Entity\nRecognition and Relation Extraction.", "citation": "@article{fundel2007relex,\n  title={RelEx\u2014Relation extraction using dependency parse trees},\n  author={Fundel, Katrin and K{\\\"u}ffner, Robert and Zimmer, Ralf},\n  journal={Bioinformatics},\n  volume={23},\n  number={3},\n  pages={365--371},\n  year={2007},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "63716af93434f2764ceafe5d", "disabled": false, "gated": false, "likes": 1, "downloads": 71, "createdAt": "2022-11-13T22:08:57.000Z"}, {"id": "bigbio/iepa", "sha": "26c3374dd37305fd8ad410ded80fb9cd0db7fde8", "lastModified": "2022-12-22T15:44:47.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "The IEPA benchmark PPI corpus is designed for relation extraction. It was created from 303 PubMed abstracts, each of which contains a specific pair of co-occurring chemicals.", "citation": "@ARTICLE{ding2001mining,\n  title    = \"Mining {MEDLINE}: abstracts, sentences, or phrases?\",\n  author   = \"Ding, J and Berleant, D and Nettleton, D and Wurtele, E\",\n  journal  = \"Pac Symp Biocomput\",\n  pages    = \"326--337\",\n  year     =  2002,\n  address  = \"United States\",\n  language = \"en\"\n}", "cardData": null, "siblings": [], "_id": "63716afcffc0489ed7d29c71", "disabled": false, "gated": false, "likes": 1, "downloads": 17, "createdAt": "2022-11-13T22:09:00.000Z"}, {"id": "bigbio/linnaeus", "sha": "296f506a445246476178df0d6e749a04cb29aafd", "lastModified": "2022-12-22T15:44:50.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "Linnaeus is a novel corpus of full-text documents manually annotated for species mentions.", "citation": "@Article{gerner2010linnaeus,\ntitle={LINNAEUS: a species name identification system for biomedical literature},\nauthor={Gerner, Martin and Nenadic, Goran and Bergman, Casey M},\njournal={BMC bioinformatics},\nvolume={11},\nnumber={1},\npages={1--17},\nyear={2010},\npublisher={BioMed Central}\n}", "cardData": null, "siblings": [], "_id": "63716b03789970f7bc635b8a", "disabled": false, "gated": false, "likes": 1, "downloads": 75, "createdAt": "2022-11-13T22:09:07.000Z"}, {"id": "bigbio/lll", "sha": "cbcbb30006c80d35bcb380bc9f4b79b36c5123e1", "lastModified": "2022-12-22T15:44:52.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "The LLL05 challenge task is to learn rules to extract protein/gene interactions from biology abstracts from the Medline\nbibliography database. The goal of the challenge is to test the ability of the participating IE systems to identify the\ninteractions and the gene/proteins that interact. The participants will test their IE patterns on a test set with the\naim of extracting the correct agent and target.The challenge focuses on information extraction of gene interactions in\nBacillus subtilis. Extracting gene interaction is the most popular event IE task in biology. Bacillus subtilis (Bs) is\na model bacterium and many papers have been published on direct gene interactions involved in sporulation. The gene\ninteractions are generally mentioned in the abstract and the full text of the paper is not needed. Extracting gene\ninteraction means, extracting the agent (proteins) and the target (genes) of all couples of genic interactions from\nsentences.", "citation": "    @article{article,\n    author = {N\u00e9dellec, C.},\n    year = {2005},\n    month = {01},\n    pages = {},\n    title = {Learning Language in Logic - Genic Interaction Extraction Challenge},\n    journal = {Proceedings of the Learning Language in Logic 2005 Workshop at the         International Conference on Machine Learning}\n}", "cardData": null, "siblings": [], "_id": "63716b07afbe42caa5a8dc0c", "disabled": false, "gated": false, "likes": 2, "downloads": 11, "createdAt": "2022-11-13T22:09:11.000Z"}, {"id": "bigbio/med_qa", "sha": "9212ff85ce1e6de4cf7418a8fabd21a9350b96f2", "lastModified": "2023-09-26T13:00:32.000Z", "tags": ["multilinguality:multilingual", "language:en", "language:zh", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "In this work, we present the first free-form multiple-choice OpenQA dataset for solving medical problems, MedQA,\ncollected from the professional medical board exams. It covers three languages: English, simplified Chinese, and\ntraditional Chinese, and contains 12,723, 34,251, and 14,123 questions for the three languages, respectively. Together\nwith the question data, we also collect and release a large-scale corpus from medical textbooks from which the reading\ncomprehension models can obtain necessary knowledge for answering the questions.", "citation": "@article{jin2021disease,\n  title={What disease does this patient have? a large-scale open domain question answering dataset from medical exams},\n  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},\n  journal={Applied Sciences},\n  volume={11},\n  number={14},\n  pages={6421},\n  year={2021},\n  publisher={MDPI}\n}", "cardData": null, "siblings": [], "_id": "63716b0e15aafbe231370ab4", "disabled": false, "gated": false, "likes": 22, "downloads": 2239, "createdAt": "2022-11-13T22:09:18.000Z"}, {"id": "bigbio/medical_data", "sha": "a3a37bb61b661bcbc72ca1833836d0c128c26474", "lastModified": "2022-12-22T15:45:28.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "    This dataset is designed to do multiclass classification on medical drugs", "citation": "@misc{ask9medicaldata,\n  author    = {Khan, Arbaaz},\n  title     = {Sentiment Analysis for Medical Drugs},\n  year      = {2019},\n  url       = {https://www.kaggle.com/datasets/arbazkhan971/analyticvidhyadatasetsentiment},\n}", "cardData": null, "siblings": [], "_id": "63716b1ff0fe906bdc588307", "disabled": false, "gated": false, "likes": 2, "downloads": 16, "createdAt": "2022-11-13T22:09:35.000Z"}, {"id": "bigbio/mediqa_nli", "sha": "5a442c8e2f1a5ef0979930c16944d0cfa89b05f9", "lastModified": "2022-12-22T15:45:31.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "Natural Language Inference (NLI) is the task of determining whether a given hypothesis can be\ninferred from a given premise. Also known as Recognizing Textual Entailment (RTE), this task has\nenjoyed popularity among researchers for some time. However, almost all datasets for this task\nfocused on open domain data such as as news texts, blogs, and so on. To address this gap, the MedNLI\ndataset was created for language inference in the medical domain. MedNLI is a derived dataset with\ndata sourced from MIMIC-III v1.4. In order to stimulate research for this problem, a shared task on\nMedical Inference and Question Answering (MEDIQA) was organized at the workshop for biomedical\nnatural language processing (BioNLP) 2019. The dataset provided herein is a test set of 405 premise\nhypothesis pairs for the NLI challenge in the MEDIQA shared task. Participants of the shared task\nare expected to use the MedNLI data for development of their models and this dataset was used as an\nunseen dataset for scoring each participant submission.", "citation": "@misc{https://doi.org/10.13026/gtv4-g455,\n    title        = {MedNLI for Shared Task at ACL BioNLP 2019},\n    author       = {Shivade,  Chaitanya},\n    year         = 2019,\n    publisher    = {physionet.org},\n    doi          = {10.13026/GTV4-G455},\n    url          = {https://physionet.org/content/mednli-bionlp19/}\n}", "cardData": null, "siblings": [], "_id": "63716b237a5e5d8efdc3fb2a", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-13T22:09:39.000Z"}, {"id": "bigbio/medmentions", "sha": "c8de447c7fb7241ef37538644107a6a5e1d95e43", "lastModified": "2022-12-22T15:45:34.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc0-1.0", "arxiv:1902.09476", "region:us"], "private": false, "author": "bigbio", "description": "MedMentions is a new manually annotated resource for the recognition of biomedical concepts.\nWhat distinguishes MedMentions from other annotated biomedical corpora is its size (over 4,000\nabstracts and over 350,000 linked mentions), as well as the size of the concept ontology (over\n3 million concepts from UMLS 2017) and its broad coverage of biomedical disciplines.\n\nCorpus: The MedMentions corpus consists of 4,392 papers (Titles and Abstracts) randomly selected\nfrom among papers released on PubMed in 2016, that were in the biomedical field, published in\nthe English language, and had both a Title and an Abstract.\n\nAnnotators: We recruited a team of professional annotators with rich experience in biomedical\ncontent curation to exhaustively annotate all UMLS\u00ae (2017AA full version) entity mentions in\nthese papers.\n\nAnnotation quality: We did not collect stringent IAA (Inter-annotator agreement) data. To gain\ninsight on the annotation quality of MedMentions, we randomly selected eight papers from the\nannotated corpus, containing a total of 469 concepts. Two biologists ('Reviewer') who did not\nparticipate in the annotation task then each reviewed four papers. The agreement between\nReviewers and Annotators, an estimate of the Precision of the annotations, was 97.3%.", "citation": "@misc{mohan2019medmentions,\n      title={MedMentions: A Large Biomedical Corpus Annotated with UMLS Concepts},\n      author={Sunil Mohan and Donghui Li},\n      year={2019},\n      eprint={1902.09476},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "63716b2d3434f2764ceb0035", "disabled": false, "gated": false, "likes": 4, "downloads": 367, "createdAt": "2022-11-13T22:09:49.000Z"}, {"id": "bigbio/meqsum", "sha": "fe726c698a3fed11a9871dab00de553682808bd9", "lastModified": "2022-12-22T15:45:35.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "Dataset for medical question summarization introduced in the ACL 2019 paper \"On the Summarization of Consumer Health\nQuestions\". Question understanding is one of the main challenges in question answering. In real world applications,\nusers often submit natural language questions that are longer than needed and include peripheral information that\nincreases the complexity of the question, leading to substantially more false positives in answer retrieval. In this\npaper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000\nsummarized consumer health questions.", "citation": "@inproceedings{ben-abacha-demner-fushman-2019-summarization,\n    title = \"On the Summarization of Consumer Health Questions\",\n    author = \"Ben Abacha, Asma  and\n      Demner-Fushman, Dina\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/P19-1215\",\n    doi = \"10.18653/v1/P19-1215\",\n    pages = \"2228--2234\",\n    abstract = \"Question understanding is one of the main challenges in question answering. In real world applications, users often submit natural language questions that are longer than needed and include peripheral information that increases the complexity of the question, leading to substantially more false positives in answer retrieval. In this paper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000 summarized consumer health questions. We explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this new task. In particular, we show that semantic augmentation from question datasets improves the overall performance, and that pointer-generator networks outperform sequence-to-sequence attentional models on this task, with a ROUGE-1 score of 44.16{\\%}. We also present a detailed error analysis and discuss directions for improvement that are specific to question summarization.\",\n}", "cardData": null, "siblings": [], "_id": "63716b31789970f7bc635ce6", "disabled": false, "gated": false, "likes": 0, "downloads": 24, "createdAt": "2022-11-13T22:09:53.000Z"}, {"id": "bigbio/mirna", "sha": "c4d7318c6392e85e034f40fd2f5aa37832509446", "lastModified": "2022-12-22T15:45:38.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-nc-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The corpus consists of 301 Medline citations. The documents were screened for\nmentions of miRNA in the abstract text. Gene, disease and miRNA entities were manually\nannotated. The corpus comprises of two separate files, a train and a test set, coming\nfrom 201 and 100 documents respectively.", "citation": "@Article{Bagewadi2014,\nauthor={Bagewadi, Shweta\nand Bobi{\\'{c}}, Tamara\nand Hofmann-Apitius, Martin\nand Fluck, Juliane\nand Klinger, Roman},\ntitle={Detecting miRNA Mentions and Relations in Biomedical Literature},\njournal={F1000Research},\nyear={2014},\nmonth={Aug},\nday={28},\npublisher={F1000Research},\nvolume={3},\npages={205-205},\nkeywords={MicroRNAs; corpus; prediction algorithms},\nabstract={\n    INTRODUCTION: MicroRNAs (miRNAs) have demonstrated their potential as post-transcriptional\n    gene expression regulators, participating in a wide spectrum of regulatory events such as\n    apoptosis, differentiation, and stress response. Apart from the role of miRNAs in normal\n    physiology, their dysregulation is implicated in a vast array of diseases. Dissection of\n    miRNA-related associations are valuable for contemplating their mechanism in diseases,\n    leading to the discovery of novel miRNAs for disease prognosis, diagnosis, and therapy.\n    MOTIVATION: Apart from databases and prediction tools, miRNA-related information is largely\n    available as unstructured text. Manual retrieval of these associations can be labor-intensive\n    due to steadily growing number of publications. Additionally, most of the published miRNA\n    entity recognition methods are keyword based, further subjected to manual inspection for\n    retrieval of relations. Despite the fact that several databases host miRNA-associations\n    derived from text, lower sensitivity and lack of published details for miRNA entity\n    recognition and associated relations identification has motivated the need for developing\n    comprehensive methods that are freely available for the scientific community. Additionally,\n    the lack of a standard corpus for miRNA-relations has caused difficulty in evaluating the\n    available systems. We propose methods to automatically extract mentions of miRNAs, species,\n    genes/proteins, disease, and relations from scientific literature. Our generated corpora,\n    along with dictionaries, and miRNA regular expression are freely available for academic\n    purposes. To our knowledge, these resources are the most comprehensive developed so far.\n    RESULTS: The identification of specific miRNA mentions reaches a recall of 0.94 and\n    precision of 0.93. Extraction of miRNA-disease and miRNA-gene relations lead to an\n    F1 score of up to 0.76. A comparison of the information extracted by our approach to\n    the databases miR2Disease and miRSel for the extraction of Alzheimer's disease\n    related relations shows the capability of our proposed methods in identifying correct\n    relations with improved sensitivity. The published resources and described methods can\n    help the researchers for maximal retrieval of miRNA-relations and generation of\n    miRNA-regulatory networks. AVAILABILITY: The training and test corpora, annotation\n    guidelines, developed dictionaries, and supplementary files are available at\n    http://www.scai.fraunhofer.de/mirna-corpora.html.\n},\nnote={26535109[pmid]},\nnote={PMC4602280[pmcid]},\nissn={2046-1402},\nurl={https://pubmed.ncbi.nlm.nih.gov/26535109},\nlanguage={eng}\n}", "cardData": null, "siblings": [], "_id": "63716b38ffc0489ed7d29e6b", "disabled": false, "gated": false, "likes": 1, "downloads": 43, "createdAt": "2022-11-13T22:10:00.000Z"}, {"id": "bigbio/mlee", "sha": "e83ef1dba6092f84581c3d6a57b72bcec86811ac", "lastModified": "2022-12-22T15:45:39.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-nc-sa-3.0", "region:us"], "private": false, "author": "bigbio", "description": "MLEE is an event extraction corpus consisting of manually annotated abstracts of papers\non angiogenesis. It contains annotations for entities, relations, events and coreferences\nThe annotations span molecular, cellular, tissue, and organ-level processes.", "citation": "@article{pyysalo2012event,\n  title={Event extraction across multiple levels of biological organization},\n  author={Pyysalo, Sampo and Ohta, Tomoko and Miwa, Makoto and Cho, Han-Cheol and Tsujii, Jun'ichi and Ananiadou, Sophia},\n  journal={Bioinformatics},\n  volume={28},\n  number={18},\n  pages={i575--i581},\n  year={2012},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "63716b3b15aafbe231370c4f", "disabled": false, "gated": false, "likes": 1, "downloads": 44, "createdAt": "2022-11-13T22:10:03.000Z"}, {"id": "bigbio/mqp", "sha": "408873bbb53acf9c97a578dc7e8faabed48f4ca2", "lastModified": "2022-12-22T15:45:40.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "Medical Question Pairs dataset by McCreery et al (2020) contains pairs of medical questions and paraphrased versions of \nthe question prepared by medical professional. Paraphrased versions were labelled as similar (syntactically dissimilar \nbut contextually similar ) or dissimilar (syntactically may look similar but contextually dissimilar). Labels 1: similar, 0: dissimilar", "citation": "@article{DBLP:journals/biodb/LiSJSWLDMWL16,\n  author    = {Krallinger, M., Rabal, O., Louren\u00e7o, A.},\n  title     = {Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs},\n  journal   = {KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining},\n  volume    = {3458\u20133465},\n  year      = {2020},\n  url       = {https://github.com/curai/medical-question-pair-dataset},\n  doi       = {},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "63716b3f345f97d07b2b3468", "disabled": false, "gated": false, "likes": 0, "downloads": 140, "createdAt": "2022-11-13T22:10:07.000Z"}, {"id": "bigbio/msh_wsd", "sha": "b88df31cef04a90eae9e512d1de2b58104659252", "lastModified": "2022-12-22T15:45:41.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "Evaluation of Word Sense Disambiguation methods (WSD) in the biomedical domain is difficult because the available\nresources are either too small or too focused on specific types of entities (e.g. diseases or genes). We have\ndeveloped a method that can be used to automatically develop a WSD test collection using the Unified Medical Language\nSystem (UMLS) Metathesaurus and the manual MeSH indexing of MEDLINE. The resulting dataset is called MSH WSD and\nconsists of 106 ambiguous abbreviations, 88 ambiguous terms and 9 which are a combination of both, for a total of 203\nambiguous words. Each instance containing the ambiguous word was assigned a CUI from the 2009AB version of the UMLS.\nFor each ambiguous term/abbreviation, the data set contains a maximum of 100 instances per sense obtained from\nMEDLINE; totaling 37,888 ambiguity cases in 37,090 MEDLINE citations.", "citation": "@article{jimeno2011exploiting,\n  title={Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation},\n  author={Jimeno-Yepes, Antonio J and McInnes, Bridget T and Aronson, Alan R},\n  journal={BMC bioinformatics},\n  volume={12},\n  number={1},\n  pages={1--14},\n  year={2011},\n  publisher={BioMed Central}\n}", "cardData": null, "siblings": [], "_id": "63716b43967e405db122952a", "disabled": false, "gated": false, "likes": 1, "downloads": 11, "createdAt": "2022-11-13T22:10:11.000Z"}, {"id": "bigbio/n2c2_2008", "sha": "494533b7efb87d7cd57fc3b26e8acc6bfccafa3b", "lastModified": "2022-12-22T15:45:48.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The data for the n2c2 2008 obesity challenge consisted of discharge summaries from\nthe Partners HealthCare Research Patient Data Repository. These data were chosen \nfrom the discharge summaries of patients who were overweight or diabetic and had \nbeen hospitalized for obesity or diabetes sometime since 12/1/04. De-identification\nwas performed semi-automatically. All private health information was replaced with\nsynthetic identifiers.\n\nThe data for the challenge were annotated by two obesity experts from the \nMassachusetts General Hospital Weight Center. The experts were given a textual task, \nwhich asked them to classify each disease (see list of diseases above) as Present, \nAbsent, Questionable, or Unmentioned based on explicitly documented information in \nthe discharge summaries, e.g., the statement \u201cthe patient is obese\u201d. The experts were \nalso given an intuitive task, which asked them to classify each disease as Present, \nAbsent, or Questionable by applying their intuition and judgment to information in \nthe discharge summaries.", "citation": "@article{uzuner2009recognizing,\n    author = {\n        Uzuner, Ozlem\n    },\n    title     = {Recognizing Obesity and Comorbidities in Sparse Data},\n    journal   = {Journal of the American Medical Informatics Association},\n    volume    = {16},\n    number    = {4},\n    pages     = {561-570},\n    year      = {2009},\n    month     = {07},\n    url       = {https://doi.org/10.1197/jamia.M3115},\n    doi       = {10.1197/jamia.M3115},\n    eprint    = {https://academic.oup.com/jamia/article-pdf/16/4/561/2302602/16-4-561.pdf}\n}", "cardData": null, "siblings": [], "_id": "63716b54ffc0489ed7d29fa4", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2022-11-13T22:10:28.000Z"}, {"id": "bigbio/n2c2_2018_track1", "sha": "023597b2861ba80c0077b9d36cc2c3c296d707cb", "lastModified": "2022-12-22T15:45:59.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "Track 1 of the 2018 National NLP Clinical Challenges shared tasks focused\non identifying which patients in a corpus of longitudinal medical records\nmeet and do not meet identified selection criteria.\n\nThis shared task aimed to determine whether NLP systems could be trained to identify if patients met or did not meet\na set of selection criteria taken from real clinical trials. The selected criteria required measurement detection (\n\u201cAny HbA1c value between 6.5 and 9.5%\u201d), inference (\u201cUse of aspirin to prevent myocardial infarction\u201d),\ntemporal reasoning (\u201cDiagnosis of ketoacidosis in the past year\u201d), and expert judgment to assess (\u201cMajor\ndiabetes-related complication\u201d). For the corpus, we used the dataset of American English, longitudinal clinical\nnarratives from the 2014 i2b2/UTHealth shared task 4.\n\nThe final selected 13 selection criteria are as follows:\n1. DRUG-ABUSE: Drug abuse, current or past\n2. ALCOHOL-ABUSE: Current alcohol use over weekly recommended limits\n3. ENGLISH: Patient must speak English\n4. MAKES-DECISIONS: Patient must make their own medical decisions\n5. ABDOMINAL: History of intra-abdominal surgery, small or large intestine\nresection, or small bowel obstruction.\n6. MAJOR-DIABETES: Major diabetes-related complication. For the purposes of\nthis annotation, we define \u201cmajor complication\u201d (as opposed to \u201cminor complication\u201d)\nas any of the following that are a result of (or strongly correlated with) uncontrolled diabetes:\n    a. Amputation\n    b. Kidney damage\n    c. Skin conditions\n    d. Retinopathy\n    e. nephropathy\n    f. neuropathy\n7. ADVANCED-CAD: Advanced cardiovascular disease (CAD).\nFor the purposes of this annotation, we define \u201cadvanced\u201d as having 2 or more of the following:\n    a. Taking 2 or more medications to treat CAD\n    b. History of myocardial infarction (MI)\n    c. Currently experiencing angina\n    d. Ischemia, past or present\n8. MI-6MOS: MI in the past 6 months\n9. KETO-1YR: Diagnosis of ketoacidosis in the past year\n10. DIETSUPP-2MOS: Taken a dietary supplement (excluding vitamin D) in the past 2 months\n11. ASP-FOR-MI: Use of aspirin to prevent MI\n12. HBA1C: Any hemoglobin A1c (HbA1c) value between 6.5% and 9.5%\n13. CREATININE: Serum creatinine > upper limit of normal\n\nThe training consists of 202 patient records with document-level annotations, 10 records\nwith textual spans indicating annotator\u2019s evidence for their annotations while test set contains 86.\n\nNote:\n* The inter-annotator average agreement is 84.9%\n* Whereabouts of 10 records with textual spans indicating annotator\u2019s evidence are unknown.\nHowever, author did a simple script based validation to check if any of the tags contained any text\nin any of the training set and they do not, which confirms that atleast train and test do not\n have any evidence tagged alongside corresponding tags.", "citation": "@article{DBLP:journals/jamia/StubbsFSHU19,\n  author    = {\n                Amber Stubbs and\n                Michele Filannino and\n                Ergin Soysal and\n                Samuel Henry and\n                Ozlem Uzuner\n               },\n  title     = {Cohort selection for clinical trials: n2c2 2018 shared task track 1},\n  journal   = {J. Am. Medical Informatics Assoc.},\n  volume    = {26},\n  number    = {11},\n  pages     = {1163--1171},\n  year      = {2019},\n  url       = {https://doi.org/10.1093/jamia/ocz163},\n  doi       = {10.1093/jamia/ocz163},\n  timestamp = {Mon, 15 Jun 2020 16:56:11 +0200},\n  biburl    = {https://dblp.org/rec/journals/jamia/StubbsFSHU19.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63716b65afbe42caa5a8dfb7", "disabled": false, "gated": false, "likes": 1, "downloads": 87, "createdAt": "2022-11-13T22:10:45.000Z"}, {"id": "bigbio/n2c2_2018_track2", "sha": "d03afd823088e16689cf7e5060f769fc12458681", "lastModified": "2022-12-22T15:46:01.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The National NLP Clinical Challenges (n2c2), organized in 2018, continued the\nlegacy of i2b2 (Informatics for Biology and the Bedside), adding 2 new tracks and 2\nnew sets of data to the shared tasks organized since 2006. Track 2 of 2018\nn2c2 shared tasks focused on the extraction of medications, with their signature\ninformation, and adverse drug events (ADEs) from clinical narratives.\nThis track built on our previous medication challenge, but added a special focus on ADEs.\n\nADEs are injuries resulting from a medical intervention related to a drugs and\ncan include allergic reactions, drug interactions, overdoses, and medication errors.\nCollectively, ADEs are estimated to account for 30% of all hospital adverse\nevents; however, ADEs are preventable. Identifying potential drug interactions,\noverdoses, allergies, and errors at the point of care and alerting the caregivers of\npotential ADEs can improve health delivery, reduce the risk of ADEs, and improve health\noutcomes.\n\nA step in this direction requires processing narratives of clinical records\nthat often elaborate on the medications given to a patient, as well as the known\nallergies, reactions, and adverse events of the patient. Extraction of this information\nfrom narratives complements the structured medication information that can be\nobtained from prescriptions, allowing a more thorough assessment of potential ADEs\nbefore they happen.\n\nThe 2018 n2c2 shared task Track 2, hereon referred to as the ADE track,\ntackled these natural language processing tasks in 3 different steps,\nwhich we refer to as tasks:\n1. Concept Extraction: identification of concepts related to medications,\ntheir signature information, and ADEs\n2. Relation Classification: linking the previously mentioned concepts to\ntheir medication  by identifying relations on gold standard concepts\n3. End-to-End: building end-to-end systems that process raw narrative text\nto discover concepts and find relations of those concepts to their medications\n\nShared tasks provide a venue for head-to-head comparison of systems developed\nfor the same task and on the same data, allowing researchers to identify the state\nof the art in a particular task, learn from it, and build on it.", "citation": "@article{DBLP:journals/jamia/HenryBFSU20,\n  author    = {\n                Sam Henry and\n                Kevin Buchan and\n                Michele Filannino and\n                Amber Stubbs and\n                Ozlem Uzuner\n               },\n  title     = {2018 n2c2 shared task on adverse drug events and medication extraction\n               in electronic health records},\n  journal   = {J. Am. Medical Informatics Assoc.},\n  volume    = {27},\n  number    = {1},\n  pages     = {3--12},\n  year      = {2020},\n  url       = {https://doi.org/10.1093/jamia/ocz166},\n  doi       = {10.1093/jamia/ocz166},\n  timestamp = {Sat, 30 May 2020 19:53:56 +0200},\n  biburl    = {https://dblp.org/rec/journals/jamia/HenryBFSU20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63716b69afbe42caa5a8dfd5", "disabled": false, "gated": false, "likes": 3, "downloads": 29, "createdAt": "2022-11-13T22:10:49.000Z"}, {"id": "bigbio/ncbi_disease", "sha": "b96b632b1c1c245b5cb21faaeec8bdac3b67553e", "lastModified": "2023-01-14T03:24:56.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "bigbio", "description": "The NCBI disease corpus is fully annotated at the mention and concept level to serve as a research\nresource for the biomedical natural language processing community.", "citation": "@article{Dogan2014NCBIDC,\n    title        = {NCBI disease corpus: A resource for disease name recognition and concept normalization},\n    author       = {Rezarta Islamaj Dogan and Robert Leaman and Zhiyong Lu},\n    year         = 2014,\n    journal      = {Journal of biomedical informatics},\n    volume       = 47,\n    pages        = {1--10}\n}", "cardData": null, "siblings": [], "_id": "63716b6d7a5e5d8efdc3fe8a", "disabled": false, "gated": false, "likes": 1, "downloads": 843, "createdAt": "2022-11-13T22:10:53.000Z"}, {"id": "bigbio/nlm_gene", "sha": "c03750c25daa63162664ac6e92b6b0ca59bebf6e", "lastModified": "2023-03-31T02:10:39.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "bigbio", "description": "NLM-Gene consists of 550 PubMed articles, from 156 journals, and contains more than 15 thousand unique gene names, corresponding to more than five thousand gene identifiers (NCBI Gene taxonomy). This corpus contains gene annotation data from 28 organisms. The annotated articles contain on average 29 gene names, and 10 gene identifiers per article. These characteristics demonstrate that this article set is an important benchmark dataset to test the accuracy of gene recognition algorithms both on multi-species and ambiguous data. The NLM-Gene corpus will be invaluable for advancing text-mining techniques for gene identification tasks in biomedical text.", "citation": "@article{islamaj2021nlm,\n  title        = {\n    NLM-Gene, a richly annotated gold standard dataset for gene entities that\n    addresses ambiguity and multi-species gene recognition\n  },\n  author       = {\n    Islamaj, Rezarta and Wei, Chih-Hsuan and Cissel, David and Miliaras,\n    Nicholas and Printseva, Olga and Rodionov, Oleg and Sekiya, Keiko and Ward,\n    Janice and Lu, Zhiyong\n  },\n  year         = 2021,\n  journal      = {Journal of Biomedical Informatics},\n  publisher    = {Elsevier},\n  volume       = 118,\n  pages        = 103779\n}", "cardData": null, "siblings": [], "_id": "63716b70967e405db1229747", "disabled": false, "gated": false, "likes": 1, "downloads": 200, "createdAt": "2022-11-13T22:10:56.000Z"}, {"id": "bigbio/nlmchem", "sha": "3ea16ec31a629659cef520c116b17a08db7f3764", "lastModified": "2022-12-22T15:46:07.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "bigbio", "description": "NLM-Chem corpus consists of 150 full-text articles from the PubMed Central Open Access dataset,\ncomprising 67 different chemical journals, aiming to cover a general distribution of usage of chemical\nnames in the biomedical literature.\nArticles were selected so that human annotation was most valuable (meaning that they were rich in bio-entities,\nand current state-of-the-art named entity recognition systems disagreed on bio-entity recognition.", "citation": "@Article{islamaj2021nlm,\ntitle={NLM-Chem, a new resource for chemical entity recognition in PubMed full text literature},\nauthor={Islamaj, Rezarta and Leaman, Robert and Kim, Sun and Kwon, Dongseop and Wei, Chih-Hsuan and Comeau, Donald C and Peng, Yifan and Cissel, David and Coss, Cathleen and Fisher, Carol and others},\njournal={Scientific Data},\nvolume={8},\nnumber={1},\npages={1--12},\nyear={2021},\npublisher={Nature Publishing Group}\n}", "cardData": null, "siblings": [], "_id": "63716b773d1bd47a4ec43325", "disabled": false, "gated": false, "likes": 1, "downloads": 108, "createdAt": "2022-11-13T22:11:03.000Z"}, {"id": "bigbio/ntcir_13_medweb", "sha": "cb4244c51ecfd387150463d1ad2e1c7dbaad83f4", "lastModified": "2022-12-22T15:46:09.000Z", "tags": ["multilinguality:multilingual", "language:en", "language:zh", "language:ja", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "NTCIR-13 MedWeb (Medical Natural Language Processing for Web Document) task requires\nto perform a multi-label classification that labels for eight diseases/symptoms must\nbe assigned to each tweet. Given pseudo-tweets, the output are Positive:p or Negative:n\nlabels for eight diseases/symptoms. The achievements of this task can almost be\ndirectly applied to a fundamental engine for actual applications.\n\nThis task provides pseudo-Twitter messages in a cross-language and multi-label corpus,\ncovering three languages (Japanese, English, and Chinese), and annotated with eight\nlabels such as influenza, diarrhea/stomachache, hay fever, cough/sore throat, headache,\nfever, runny nose, and cold.\n\nFor more information, see:\nhttp://research.nii.ac.jp/ntcir/permission/ntcir-13/perm-en-MedWeb.html\n\nAs this dataset also provides a parallel corpus of pseudo-tweets for english,\njapanese and chinese it can also be used to train translation models between\nthese three languages.", "citation": "@article{wakamiya2017overview,\n  author    = {Shoko Wakamiya, Mizuki Morita, Yoshinobu Kano, Tomoko Ohkuma and Eiji Aramaki},\n  title     = {Overview of the NTCIR-13 MedWeb Task},\n  journal   = {Proceedings of the 13th NTCIR Conference on Evaluation of Information Access Technologies (NTCIR-13)},\n  year      = {2017},\n  url       = {\n    http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/pdf/ntcir/01-NTCIR13-OV-MEDWEB-WakamiyaS.pdf\n  },\n}", "cardData": null, "siblings": [], "_id": "63716b7a789970f7bc635ff0", "disabled": false, "gated": false, "likes": 0, "downloads": 19, "createdAt": "2022-11-13T22:11:06.000Z"}, {"id": "bigbio/osiris", "sha": "91785db603fcfebc28a3bb9b52df62968528ad8e", "lastModified": "2022-12-22T15:46:10.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-3.0", "region:us"], "private": false, "author": "bigbio", "description": "The OSIRIS corpus is a set of MEDLINE abstracts manually annotated\nwith human variation mentions. The corpus is distributed under the terms\nof the Creative Commons Attribution License\nCreative Commons Attribution 3.0 Unported License,\nwhich permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work is properly cited (Furlong et al, BMC Bioinformatics 2008, 9:84).", "citation": "@ARTICLE{Furlong2008,\n  author = {Laura I Furlong and Holger Dach and Martin Hofmann-Apitius and Ferran Sanz},\n  title = {OSIRISv1.2: a named entity recognition system for sequence variants\n  of genes in biomedical literature.},\n  journal = {BMC Bioinformatics},\n  year = {2008},\n  volume = {9},\n  pages = {84},\n  doi = {10.1186/1471-2105-9-84},\n  pii = {1471-2105-9-84},\n  pmid = {18251998},\n  timestamp = {2013.01.15},\n  url = {http://dx.doi.org/10.1186/1471-2105-9-84}\n}", "cardData": null, "siblings": [], "_id": "63716b7eafbe42caa5a8e0c1", "disabled": false, "gated": false, "likes": 1, "downloads": 46, "createdAt": "2022-11-13T22:11:10.000Z"}, {"id": "bigbio/paramed", "sha": "02d51cfe956add9301e00b2fe894d21ad961aaec", "lastModified": "2022-12-22T15:46:11.000Z", "tags": ["multilinguality:multilingual", "language:en", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "NEJM is a Chinese-English parallel corpus crawled from the New England Journal of Medicine website. \nEnglish articles are distributed through https://www.nejm.org/ and Chinese articles are distributed through \nhttp://nejmqianyan.cn/. The corpus contains all article pairs (around 2000 pairs) since 2011.", "citation": "@article{liu2021paramed,\n  author    = {Liu, Boxiang and Huang, Liang},\n  title     = {ParaMed: a parallel corpus for English\u2013Chinese translation in the biomedical domain},\n  journal   = {BMC Medical Informatics and Decision Making},\n  volume    = {21},\n  year      = {2021},\n  url       = {https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-021-01621-8},\n  doi       = {10.1186/s12911-021-01621-8}\n}", "cardData": null, "siblings": [], "_id": "63716b81afbe42caa5a8e11d", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "createdAt": "2022-11-13T22:11:13.000Z"}, {"id": "bigbio/pdr", "sha": "c06541eebe286b1f4dd4b967be7ab5598857757c", "lastModified": "2022-12-22T15:46:14.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "The corpus of plant-disease relation consists of plants and diseases and their relation to PubMed abstract.\nThe corpus consists of about 2400 plant and disease entities and 300 annotated relations from 179 abstracts.", "citation": "@article{kim2019corpus,\n  title={A corpus of plant--disease relations in the biomedical domain},\n  author={Kim, Baeksoo and Choi, Wonjun and Lee, Hyunju},\n  journal={PLoS One},\n  volume={14},\n  number={8},\n  pages={e0221582},\n  year={2019},\n  publisher={Public Library of Science San Francisco, CA USA}\n}", "cardData": null, "siblings": [], "_id": "63716b88789970f7bc6360ab", "disabled": false, "gated": false, "likes": 1, "downloads": 45, "createdAt": "2022-11-13T22:11:20.000Z"}, {"id": "bigbio/pharmaconer", "sha": "bcfd7ed4cefb5cc157e2495d558ca7f01920963c", "lastModified": "2022-12-22T15:46:15.000Z", "tags": ["multilinguality:monolingual", "language:es", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "PharmaCoNER: Pharmacological Substances, Compounds and Proteins Named Entity Recognition track\n\nThis dataset is designed for the PharmaCoNER task, sponsored by Plan de Impulso de las Tecnolog\u00edas del Lenguaje.\n\nIt is a manually classified collection of clinical case studies derived from the Spanish Clinical Case Corpus (SPACCC), an open access electronic library that gathers Spanish medical publications from SciELO (Scientific Electronic Library Online).\n\nThe annotation of the entire set of entity mentions was carried out by medicinal chemistry experts and it includes the following 4 entity types: NORMALIZABLES, NO_NORMALIZABLES, PROTEINAS and UNCLEAR.\n\nThe PharmaCoNER corpus contains a total of 396,988 words and 1,000 clinical cases that have been randomly sampled into 3 subsets. The training set contains 500 clinical cases, while the development and test sets contain 250 clinical cases each.\n\nFor further information, please visit https://temu.bsc.es/pharmaconer/ or send an email to encargo-pln-life@bsc.es", "citation": "@inproceedings{gonzalez2019pharmaconer,\n    title = \"PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track\",\n    author = \"Gonzalez-Agirre, Aitor  and\n      Marimon, Montserrat  and\n      Intxaurrondo, Ander  and\n      Rabal, Obdulia  and\n      Villegas, Marta  and\n      Krallinger, Martin\",\n    booktitle = \"Proceedings of The 5th Workshop on BioNLP Open Shared Tasks\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D19-5701\",\n    doi = \"10.18653/v1/D19-5701\",\n    pages = \"1--10\",\n}", "cardData": null, "siblings": [], "_id": "63716b8c91284164d1b904bd", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2022-11-13T22:11:24.000Z"}, {"id": "bigbio/pico_extraction", "sha": "5490315822791dbbda39931348a2d16a7c360c60", "lastModified": "2022-12-22T15:46:16.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "This dataset contains annotations for Participants, Interventions, and Outcomes (referred to as PICO task).\nFor 423 sentences, annotations collected by 3 medical experts are available.\nTo get the final annotations, we perform the majority voting.", "citation": "@inproceedings{zlabinger-etal-2020-effective,\n    title = \"Effective Crowd-Annotation of Participants, Interventions, and Outcomes in the Text of Clinical Trial Reports\",\n    author = {Zlabinger, Markus  and\n      Sabou, Marta  and\n      Hofst{\\\"a}tter, Sebastian  and\n      Hanbury, Allan},\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2020\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.findings-emnlp.274\",\n    doi = \"10.18653/v1/2020.findings-emnlp.274\",\n    pages = \"3064--3074\",\n}", "cardData": null, "siblings": [], "_id": "63716b8f345f97d07b2b3826", "disabled": false, "gated": false, "likes": 1, "downloads": 37, "createdAt": "2022-11-13T22:11:27.000Z"}, {"id": "bigbio/progene", "sha": "fff51281b7936536de98ff763003ab8b7f700f7a", "lastModified": "2022-12-22T15:46:19.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The Protein/Gene corpus was developed at the JULIE Lab Jena under supervision of Prof. Udo Hahn.\nThe executing scientist was Dr. Joachim Wermter.\nThe main annotator was Dr. Rico Pusch who is an expert in biology.\nThe corpus was developed in the context of the StemNet project (http://www.stemnet.de/).", "citation": "@inproceedings{faessler-etal-2020-progene,\n    title = \"{P}ro{G}ene - A Large-scale, High-Quality Protein-Gene Annotated Benchmark Corpus\",\n    author = \"Faessler, Erik  and\n      Modersohn, Luise  and\n      Lohr, Christina  and\n      Hahn, Udo\",\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.lrec-1.564\",\n    pages = \"4585--4596\",\n    abstract = \"Genes and proteins constitute the fundamental entities of molecular genetics. We here introduce ProGene (formerly called FSU-PRGE), a corpus that reflects our efforts to cope with this important class of named entities within the framework of a long-lasting large-scale annotation campaign at the Jena University Language {\\&} Information Engineering (JULIE) Lab. We assembled the entire corpus from 11 subcorpora covering various biological domains to achieve an overall subdomain-independent corpus. It consists of 3,308 MEDLINE abstracts with over 36k sentences and more than 960k tokens annotated with nearly 60k named entity mentions. Two annotators strove for carefully assigning entity mentions to classes of genes/proteins as well as families/groups, complexes, variants and enumerations of those where genes and proteins are represented by a single class. The main purpose of the corpus is to provide a large body of consistent and reliable annotations for supervised training and evaluation of machine learning algorithms in this relevant domain. Furthermore, we provide an evaluation of two state-of-the-art baseline systems {---} BioBert and flair {---} on the ProGene corpus. We make the evaluation datasets and the trained models available to encourage comparable evaluations of new methods in the future.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "63716b973434f2764ceb0576", "disabled": false, "gated": false, "likes": 2, "downloads": 30, "createdAt": "2022-11-13T22:11:35.000Z"}, {"id": "bigbio/psytar", "sha": "6dad2a16b2aa5d83677440fa8b9f0c9764a58a6d", "lastModified": "2022-12-22T15:46:20.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The \"Psychiatric Treatment Adverse Reactions\" (PsyTAR) dataset contains 891 drugs\nreviews posted by patients on \"askapatient.com\", about the effectiveness and adverse\ndrug events associated with Zoloft, Lexapro, Cymbalta, and Effexor XR.\n\nThis dataset can be used for (multi-label) sentence classification of Adverse Drug\nReaction (ADR), Withdrawal Symptoms (WDs), Sign/Symptoms/Illness (SSIs), Drug\nIndications (DIs), Drug Effectiveness (EF), Drug Infectiveness (INF) and Others, as well\nas for recognition of 5 different types of named entity (in the categories ADRs, WDs,\nSSIs and DIs)", "citation": "@article{Zolnoori2019,\n  author    = {Maryam Zolnoori and\n               Kin Wah Fung and\n               Timothy B. Patrick and\n               Paul Fontelo and\n               Hadi Kharrazi and\n               Anthony Faiola and\n               Yi Shuan Shirley Wu and\n               Christina E. Eldredge and\n               Jake Luo and\n               Mike Conway and\n               Jiaxi Zhu and\n               Soo Kyung Park and\n               Kelly Xu and\n               Hamideh Moayyed and\n               Somaieh Goudarzvand},\n  title     = {A systematic approach for developing a corpus of patient                reported adverse drug events: A case study for {SSRI} and {SNRI} medications},\n  journal   = {Journal of Biomedical Informatics},\n  volume    = {90},\n  year      = {2019},\n  url       = {https://doi.org/10.1016/j.jbi.2018.12.005},\n  doi       = {10.1016/j.jbi.2018.12.005},\n}", "cardData": null, "siblings": [], "_id": "63716b9affc0489ed7d2a333", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2022-11-13T22:11:38.000Z"}, {"id": "bigbio/pubmed_qa", "sha": "21aa9affd1564464684c73b8476aa3f9e0ccbeb7", "lastModified": "2022-12-22T15:46:24.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:mit", "region:us"], "private": false, "author": "bigbio", "description": "PubMedQA is a novel biomedical question answering (QA) dataset collected from PubMed abstracts.\nThe task of PubMedQA is to answer research biomedical questions with yes/no/maybe using the corresponding abstracts.\nPubMedQA has 1k expert-annotated (PQA-L), 61.2k unlabeled (PQA-U) and 211.3k artificially generated QA instances (PQA-A).\n\nEach PubMedQA instance is composed of:\n  (1) a question which is either an existing research article title or derived from one,\n  (2) a context which is the corresponding PubMed abstract without its conclusion,\n  (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and\n  (4) a yes/no/maybe answer which summarizes the conclusion.\n\nPubMedQA is the first QA dataset where reasoning over biomedical research texts,\nespecially their quantitative contents, is required to answer the questions.\n\nPubMedQA datasets comprise of 3 different subsets:\n  (1) PubMedQA Labeled (PQA-L): A labeled PubMedQA subset comprises of 1k manually annotated yes/no/maybe QA data collected from PubMed articles.\n  (2) PubMedQA Artificial (PQA-A): An artificially labelled PubMedQA subset comprises of 211.3k PubMed articles with automatically generated questions from the statement titles and yes/no answer labels generated using a simple heuristic.\n  (3) PubMedQA Unlabeled (PQA-U): An unlabeled PubMedQA subset comprises of 61.2k context-question pairs data collected from PubMed articles.", "citation": "@inproceedings{jin2019pubmedqa,\n  title={PubMedQA: A Dataset for Biomedical Research Question Answering},\n  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},\n  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},\n  pages={2567--2577},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "63716ba1345f97d07b2b3945", "disabled": false, "gated": false, "likes": 4, "downloads": 1373, "createdAt": "2022-11-13T22:11:45.000Z"}, {"id": "bigbio/pubtator_central", "sha": "b05b96997452726ffecd0405ee33f92237f49845", "lastModified": "2022-12-22T15:46:26.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "PubTator Central (PTC, https://www.ncbi.nlm.nih.gov/research/pubtator/) is a web service for\nexploring and retrieving bioconcept annotations in full text biomedical articles. PTC provides\nautomated annotations from state-of-the-art text mining systems for genes/proteins, genetic\nvariants, diseases, chemicals, species and cell lines, all available for immediate download. PTC\nannotates PubMed (30 million abstracts), the PMC Open Access Subset and the Author Manuscript\nCollection (3 million full text articles). Updated entity identification methods and a\ndisambiguation module based on cutting-edge deep learning techniques provide increased accuracy.", "citation": "@article{10.1093/nar/gkz389,\n  title        = {{PubTator central: automated concept annotation for biomedical full text articles}},\n  author       = {Wei, Chih-Hsuan and Allot, Alexis and Leaman, Robert and Lu, Zhiyong},\n  year         = 2019,\n  month        = {05},\n  journal      = {Nucleic Acids Research},\n  volume       = 47,\n  number       = {W1},\n  pages        = {W587-W593},\n  doi          = {10.1093/nar/gkz389},\n  issn         = {0305-1048},\n  url          = {https://doi.org/10.1093/nar/gkz389},\n  eprint       = {https://academic.oup.com/nar/article-pdf/47/W1/W587/28880193/gkz389.pdf}\n}", "cardData": null, "siblings": [], "_id": "63716ba5789970f7bc6362ee", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2022-11-13T22:11:49.000Z"}, {"id": "bigbio/quaero", "sha": "cd40ac30e08078e50aba76901b53d0080395919b", "lastModified": "2022-12-22T15:46:29.000Z", "tags": ["multilinguality:monolingual", "language:fr", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The QUAERO French Medical Corpus has been initially developed as a resource for named entity recognition and normalization [1]. It was then improved with the purpose of creating a gold standard set of normalized entities for French biomedical text, that was used in the CLEF eHealth evaluation lab [2][3].\n\nA selection of MEDLINE titles and EMEA documents were manually annotated. The annotation process was guided by concepts in the Unified Medical Language System (UMLS):\n\n1. Ten types of clinical entities, as defined by the following UMLS Semantic Groups (Bodenreider and McCray 2003) were annotated: Anatomy, Chemical and Drugs, Devices, Disorders, Geographic Areas, Living Beings, Objects, Phenomena, Physiology, Procedures.\n\n2. The annotations were made in a comprehensive fashion, so that nested entities were marked, and entities could be mapped to more than one UMLS concept. In particular: (a) If a mention can refer to more than one Semantic Group, all the relevant Semantic Groups should be annotated. For instance, the mention \u201cr\u00e9cidive\u201d (recurrence) in the phrase \u201cpr\u00e9vention des r\u00e9cidives\u201d (recurrence prevention) should be annotated with the category \u201cDISORDER\u201d (CUI C2825055) and the category \u201cPHENOMENON\u201d (CUI C0034897); (b) If a mention can refer to more than one UMLS concept within the same Semantic Group, all the relevant concepts should be annotated. For instance, the mention \u201cmaniaques\u201d (obsessive) in the phrase \u201cpatients maniaques\u201d (obsessive patients) should be annotated with CUIs C0564408 and C0338831 (category \u201cDISORDER\u201d); (c) Entities which span overlaps with that of another entity should still be annotated. For instance, in the phrase \u201cinfarctus du myocarde\u201d (myocardial infarction), the mention \u201cmyocarde\u201d (myocardium) should be annotated with category \u201cANATOMY\u201d (CUI C0027061) and the mention \u201cinfarctus du myocarde\u201d should be annotated with category \u201cDISORDER\u201d (CUI C0027051)\n\nThe QUAERO French Medical Corpus BioC release comprises a subset of the QUAERO French Medical corpus, as follows:\n\nTraining data (BRAT version used in CLEF eHealth 2015 task 1b as training data): \n- MEDLINE_train_bioc file: 833 MEDLINE titles, annotated with normalized entities in the BioC format \n- EMEA_train_bioc file: 3 EMEA documents, segmented into 11 sub-documents, annotated with normalized entities in the BioC format \n\nDevelopment data  (BRAT version used in CLEF eHealth 2015 task 1b as test data and in CLEF eHealth 2016 task 2 as development data): \n- MEDLINE_dev_bioc file: 832 MEDLINE titles, annotated with normalized entities in the BioC format\n- EMEA_dev_bioc file: 3 EMEA documents, segmented into 12 sub-documents, annotated with normalized entities in the BioC format \n\nTest data (BRAT version used in CLEF eHealth 2016 task 2 as test data): \n- MEDLINE_test_bioc folder: 833 MEDLINE titles, annotated with normalized entities in the BioC format \n- EMEA folder_test_bioc: 4 EMEA documents, segmented into 15 sub-documents, annotated with normalized entities in the BioC format \n\n\n\nThis release of the QUAERO French medical corpus, BioC version, comes in the BioC format, through automatic conversion from the original BRAT format obtained with the Brat2BioC tool https://bitbucket.org/nicta_biomed/brat2bioc developped by Jimeno Yepes et al.\n\nAntonio Jimeno Yepes, Mariana Neves, Karin Verspoor \nBrat2BioC: conversion tool between brat and BioC\nBioCreative IV track 1 - BioC: The BioCreative Interoperability Initiative, 2013\n\n\nPlease note that the original version of the QUAERO corpus distributed in the CLEF eHealth challenge 2015 and 2016 came in the BRAT stand alone format. It was distributed with the CLEF eHealth evaluation tool. This original distribution of the QUAERO French Medical corpus is available separately from https://quaerofrenchmed.limsi.fr  \n\nAll questions regarding the task or data should be addressed to aurelie.neveol@limsi.fr", "citation": "@InProceedings{neveol14quaero, \n  author = {N\u00e9v\u00e9ol, Aur\u00e9lie and Grouin, Cyril and Leixa, Jeremy \n            and Rosset, Sophie and Zweigenbaum, Pierre},\n  title = {The {QUAERO} {French} Medical Corpus: A Ressource for\n           Medical Entity Recognition and Normalization}, \n  OPTbooktitle = {Proceedings of the Fourth Workshop on Building \n                 and Evaluating Ressources for Health and Biomedical \n                 Text Processing}, \n  booktitle = {Proc of BioTextMining Work}, \n  OPTseries = {BioTxtM 2014}, \n  year = {2014}, \n  pages = {24--30}, \n}", "cardData": null, "siblings": [], "_id": "63716ba9ffc0489ed7d2a4b5", "disabled": false, "gated": false, "likes": 1, "downloads": 67, "createdAt": "2022-11-13T22:11:53.000Z"}, {"id": "bigbio/scai_chemical", "sha": "03fa8bd94ef57fd1f6411d17b15c264ddabd0c16", "lastModified": "2022-12-22T15:46:32.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "SCAI Chemical is a corpus of MEDLINE abstracts that has been annotated\nto give an overview of the different chemical name classes\nfound in MEDLINE text.", "citation": "@inproceedings{kolarik:lrec-ws08,\n  author    = {Kol{\\'a}{\\vr}ik, Corinna and Klinger, Roman and Friedrich, Christoph M and Hofmann-Apitius, Martin and Fluck, Juliane},\n  title     = {Chemical Names: {T}erminological Resources and Corpora Annotation},\n  booktitle = {LREC Workshop on Building and Evaluating Resources for Biomedical Text Mining},\n  year      = {2008},\n}", "cardData": null, "siblings": [], "_id": "63716bac3434f2764ceb0770", "disabled": false, "gated": false, "likes": 2, "downloads": 27, "createdAt": "2022-11-13T22:11:56.000Z"}, {"id": "bigbio/scai_disease", "sha": "f6c472901388e52ccf5d5a7a24da403951eff5bb", "lastModified": "2022-12-22T15:46:35.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "SCAI Disease is a dataset annotated in 2010 with mentions of diseases and\nadverse effects. It is a corpus containing 400 randomly selected MEDLINE\nabstracts generated using \u2018Disease OR Adverse effect\u2019 as a PubMed query. This\nevaluation corpus was annotated by two individuals who hold a Master\u2019s degree\nin life sciences.", "citation": "@inproceedings{gurulingappa:lrec-ws10,\n  author    = {Harsha Gurulingappa and Roman Klinger and Martin Hofmann-Apitius and Juliane Fluck},\n  title     = {An Empirical Evaluation of Resources for the Identification of Diseases and Adverse Effects in Biomedical Literature},\n  booktitle = {LREC Workshop on Building and Evaluating Resources for Biomedical Text Mining},\n  year      = {2010},\n}", "cardData": null, "siblings": [], "_id": "63716bb03d1bd47a4ec43719", "disabled": false, "gated": false, "likes": 1, "downloads": 29, "createdAt": "2022-11-13T22:12:00.000Z"}, {"id": "bigbio/scicite", "sha": "292fbffb65a93962d99730d80fbd777a9a244d09", "lastModified": "2022-12-22T15:46:37.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "SciCite is a dataset of 11K manually annotated citation intents based on\ncitation context in the computer science and biomedical domains.", "citation": "@inproceedings{cohan:naacl19,\n  author    = {Arman Cohan and Waleed Ammar and Madeleine van Zuylen and Field Cady},\n  title     = {Structural Scaffolds for Citation Intent Classification in Scientific Publications},\n  booktitle = {Conference of the North American Chapter of the Association for Computational Linguistics},\n  year      = {2019},\n  url       = {https://aclanthology.org/N19-1361/},\n  doi       = {10.18653/v1/N19-1361},\n}", "cardData": null, "siblings": [], "_id": "63716bb315aafbe23137132a", "disabled": false, "gated": false, "likes": 0, "downloads": 22, "createdAt": "2022-11-13T22:12:03.000Z"}, {"id": "bigbio/tmvar_v1", "sha": "0f77d5d705ae911c4f35944deea346287095e6f0", "lastModified": "2022-12-22T15:47:01.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "This dataset contains 500 PubMed articles manually annotated with mutation mentions of various kinds. It can be used for NER tasks only.\nThe dataset is split into train(334) and test(166) splits", "citation": "@article{wei2013tmvar,\n  title={tmVar: a text mining approach for extracting sequence variants in biomedical literature},\n  author={Wei, Chih-Hsuan and Harris, Bethany R and Kao, Hung-Yu and Lu, Zhiyong},\n  journal={Bioinformatics},\n  volume={29},\n  number={11},\n  pages={1433--1439},\n  year={2013},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "63716bcc3434f2764ceb088d", "disabled": false, "gated": false, "likes": 0, "downloads": 50, "createdAt": "2022-11-13T22:12:28.000Z"}, {"id": "bigbio/tmvar_v2", "sha": "fc667429f43a45b6d762c5857c5b63001045ea7d", "lastModified": "2022-12-22T15:47:06.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "region:us"], "private": false, "author": "bigbio", "description": "This dataset contains 158 PubMed articles manually annotated with mutation mentions of various kinds and dbsnp normalizations for each of them.\nIt can be used for NER tasks and NED tasks, This dataset has a single split", "citation": "@article{wei2018tmvar,\ntitle={tmVar 2.0: integrating genomic variant information from literature with dbSNP and ClinVar for precision medicine},\nauthor={Wei, Chih-Hsuan and Phan, Lon and Feltz, Juliana and Maiti, Rama and Hefferon, Tim and Lu, Zhiyong},\njournal={Bioinformatics},\nvolume={34},\nnumber={1},\npages={80--87},\nyear={2018},\npublisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "63716bcfafbe42caa5a8e59a", "disabled": false, "gated": false, "likes": 1, "downloads": 63, "createdAt": "2022-11-13T22:12:31.000Z"}, {"id": "bigbio/tmvar_v3", "sha": "02004b5303fe6eafeae600662b3cbcc274723a58", "lastModified": "2023-02-17T14:55:58.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:unknown", "arxiv:2204.03637", "region:us"], "private": false, "author": "bigbio", "description": "This dataset contains 500 PubMed articles manually annotated with mutation mentions of various kinds and dbsnp normalizations for each of them.  In addition, it contains variant normalization options such as allele-specific identifiers from the ClinGen Allele Registry It can be used for NER tasks and NED tasks, This dataset does NOT have splits.", "citation": "@misc{https://doi.org/10.48550/arxiv.2204.03637,\n  title        = {tmVar 3.0: an improved variant concept recognition and normalization tool},\n  author       = {\n    Wei, Chih-Hsuan and Allot, Alexis and Riehle, Kevin and Milosavljevic,\n    Aleksandar and Lu, Zhiyong\n  },\n  year         = 2022,\n  publisher    = {arXiv},\n  doi          = {10.48550/ARXIV.2204.03637},\n  url          = {https://arxiv.org/abs/2204.03637},\n  copyright    = {Creative Commons Attribution 4.0 International},\n  keywords     = {\n    Computation and Language (cs.CL), FOS: Computer and information sciences,\n    FOS: Computer and information sciences\n  }\n}", "cardData": null, "siblings": [], "_id": "63716bd367cd0e881504a3bc", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "createdAt": "2022-11-13T22:12:35.000Z"}, {"id": "Murple/ksponspeech", "sha": "7f8f2478e374f161fede00a6ea1d7997201fb82c", "lastModified": "2022-11-14T02:41:37.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ko", "region:us"], "private": false, "author": "Murple", "description": "This paper introduces a large-scale spontaneous speech corpus of Korean, named KsponSpeech. This corpus contains 969 h of general open-domain dialog utterances, spoken by about 2000 native Korean speakers in a clean environment. All data were constructed by recording the dialogue of two people freely conversing on a variety of topics and manually transcribing the utterances. The transcription provides a dual transcription consisting of orthography and pronunciation, and disfluency tags for spontaneity of speech, such as filler words, repeated words, and word fragments. This paper also presents the baseline performance of an end-to-end speech recognition model trained with KsponSpeech. In addition, we investigated the performance of standard end-to-end architectures and the number of sub-word units suitable for Korean. We investigated issues that should be considered in spontaneous speech recognition in Korean. KsponSpeech is publicly available on an open data hub site of the Korea government.\n\nMore info on KsponSpeech dataset can be understood from the webpage which can be found here:\nhttps://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=123", "citation": "@Article{app10196936,\nAUTHOR = {Bang, Jeong-Uk and Yun, Seung and Kim, Seung-Hi and Choi, Mu-Yeol and Lee, Min-Kyu and Kim, Yeo-Jeong and Kim, Dong-Hyun and Park, Jun and Lee, Young-Jik and Kim, Sang-Hun},\nTITLE = {KsponSpeech: Korean Spontaneous Speech Corpus for Automatic Speech Recognition},\nJOURNAL = {Applied Sciences},\nVOLUME = {10},\nYEAR = {2020},\nNUMBER = {19},\nARTICLE-NUMBER = {6936},\nURL = {https://www.mdpi.com/2076-3417/10/19/6936},\nISSN = {2076-3417},\nDOI = {10.3390/app10196936}\n}", "cardData": null, "siblings": [], "_id": "6371a0b47a5e5d8efdc60889", "disabled": false, "gated": false, "likes": 4, "downloads": 14, "createdAt": "2022-11-14T01:58:12.000Z"}, {"id": "cjvt/si_nli", "sha": "ea77161978d40cecf6371091b6bbbf7ed70b8930", "lastModified": "2023-04-04T08:51:01.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:sl", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "cjvt", "description": "SI-NLI (Slovene Natural Language Inference Dataset) contains 5,937 human-created Slovene sentence pairs \n(premise and hypothesis) that are manually labeled with the labels \"entailment\", \"contradiction\", and \"neutral\". \nThe dataset was created using sentences that appear in the Slovenian reference corpus ccKres. \nAnnotators were tasked to modify the hypothesis in a candidate pair in a way that reflects one of the labels. \nThe dataset is balanced since the annotators created three modifications (entailment, contradiction, neutral) \nfor each candidate sentence pair.", "citation": "@misc{sinli,\n    title = {Slovene Natural Language Inference Dataset {SI}-{NLI}},\n    author = {Klemen, Matej and {\\v Z}agar, Ale{\\v s} and {\\v C}ibej, Jaka and Robnik-{\\v S}ikonja, Marko},\n    url = {http://hdl.handle.net/11356/1707},\n    note = {Slovenian language resource repository {CLARIN}.{SI}},\n    year = {2022}\n}", "cardData": null, "siblings": [], "_id": "637350b9250cf1379bb9e6d3", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2022-11-15T08:41:29.000Z"}, {"id": "Fazzie/Teyvat", "sha": "e963e16ce22be14a22b9f9760f5d241935b4d650", "lastModified": "2022-12-13T02:09:42.000Z", "tags": ["task_categories:text-to-image", "annotations_creators:no-annotation", "language_creators:found", "source_datasets:original", "language:en", "license:unknown", "region:us"], "private": false, "author": "Fazzie", "description": "Teyvat is the first small-scale text-to-image prompt dataset for Genshin impact.", "citation": null, "cardData": null, "siblings": [], "_id": "63745d550938c075423ff08b", "disabled": false, "gated": false, "likes": 18, "downloads": 330, "createdAt": "2022-11-16T03:47:33.000Z"}, {"id": "PlanTL-GOB-ES/sts-es", "sha": "0912bb6c9393c76d62a7c5ee81c4c817ff47c9f4", "lastModified": "2023-01-19T09:45:42.000Z", "tags": ["task_categories:text-classification", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "language:es", "region:us"], "private": false, "author": "PlanTL-GOB-ES", "description": "For Semantic Text Similarity, we collected the Spanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015). Since no training data was provided for the Spanish subtask, we randomly sampled both datasets into 1,321 sentences for the train set, 78 sentences for the development set, and 156 sentences for the test set. To make the task harder for the models, we purposely made the development set smaller than the test set.", "citation": "Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, I\u00f1igo Lopez-Gazpio, Montse Maritxalar, Rada Mihalcea, German Rigau, Larraitz Uria, and Janyce Wiebe. 2015. SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 252\u2013263, Denver, Colorado. Association for Computational Linguistics.\n\nEneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, Rada Mihalcea, German Rigau, and Janyce Wiebe. 2014. SemEval-2014 Task 10: Multilingual Semantic Textual Similarity. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 81\u201391, Dublin, Ireland. Association for Computational Linguistics.", "cardData": null, "siblings": [], "_id": "6376250ef1d3d27b7dda69df", "disabled": false, "gated": false, "likes": 2, "downloads": 63, "createdAt": "2022-11-17T12:11:58.000Z"}, {"id": "hoskinson-center/proofnet", "sha": "cb8e75614830035a37f3a2a11de5e625eaf0bc31", "lastModified": "2023-03-17T21:25:37.000Z", "tags": ["license:mit", "arxiv:2302.12433", "region:us"], "private": false, "author": "hoskinson-center", "description": "A dataset that evaluates formally proving and autoformalizing undergraduate mathematics.", "citation": null, "cardData": null, "siblings": [], "_id": "6376c985cb2e84c60b0b849a", "disabled": false, "gated": false, "likes": 8, "downloads": 25, "createdAt": "2022-11-17T23:53:41.000Z"}, {"id": "PlanTL-GOB-ES/WikiCAT_esv2", "sha": "924ae6077edddf60f3ad2f2cbc54df3825a70930", "lastModified": "2023-07-27T09:13:16.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:automatically-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:unknown", "language:es", "license:cc-by-sa-3.0", "region:us"], "private": false, "author": "PlanTL-GOB-ES", "description": "WikiCAT: Text Classification Spanish dataset from the Viquipedia", "citation": "", "cardData": null, "siblings": [], "_id": "63775c0d0248f877527b76c2", "disabled": false, "gated": false, "likes": 0, "downloads": 47, "createdAt": "2022-11-18T10:18:53.000Z"}, {"id": "Freed-Wu/kodak", "sha": "b908bad5ef0759d2c03baf09715a98aedda9ded1", "lastModified": "2022-11-19T05:43:53.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": "Freed-Wu", "description": "The pictures below link to lossless, true color (24 bits per pixel, aka \"full\ncolor\") images. It is my understanding they have been released by the Eastman\nKodak Company for unrestricted usage. Many sites use them as a standard test\nsuite for compression testing, etc. Prior to this site, they were only\navailable in the Sun Raster format via ftp. This meant that the images could\nnot be previewed before downloading. Since their release, however, the lossless\nPNG format has been incorporated into all the major browsers. Since PNG\nsupports 24-bit lossless color (which GIF and JPEG do not), it is now possible\nto offer this browser-friendly access to the images.", "citation": null, "cardData": null, "siblings": [], "_id": "63786d1984318944acd4480c", "disabled": false, "gated": false, "likes": 0, "downloads": 120, "createdAt": "2022-11-19T05:43:53.000Z"}, {"id": "jeanlee/kmhas_korean_hate_speech", "sha": "c657d15baf277c48d467f0625f7d33c50d4352ef", "lastModified": "2022-11-28T16:26:56.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-label-classification", "task_ids:hate-speech-detection", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ko", "license:cc-by-sa-4.0", "K-MHaS", "Korean NLP", "Hate Speech Detection", "Dataset", "Coling2022", "arxiv:2208.10684", "region:us"], "private": false, "author": "jeanlee", "description": "The K-MHaS (Korean Multi-label Hate Speech) dataset contains 109k utterances from Korean online news comments labeled with 8 fine-grained hate speech classes or Not Hate Speech class.\nThe fine-grained hate speech classes are politics, origin, physical, age, gender, religion, race, and profanity and these categories are selected in order to reflect the social and historical context.", "citation": "@inproceedings{lee-etal-2022-k,\n    title = \"K-{MH}a{S}: A Multi-label Hate Speech Detection Dataset in {K}orean Online News Comment\",\n    author = \"Lee, Jean  and\n      Lim, Taejun  and\n      Lee, Heejun  and\n      Jo, Bogeun  and\n      Kim, Yangsok  and\n      Yoon, Heegeun  and\n      Han, Soyeon Caren\",\n    booktitle = \"Proceedings of the 29th International Conference on Computational Linguistics\",\n    month = oct,\n    year = \"2022\",\n    address = \"Gyeongju, Republic of Korea\",\n    publisher = \"International Committee on Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.coling-1.311\",\n    pages = \"3530--3538\",\n    abstract = \"Online hate speech detection has become an important issue due to the growth of online content, but resources in languages other than English are extremely limited. We introduce K-MHaS, a new multi-label dataset for hate speech detection that effectively handles Korean language patterns. The dataset consists of 109k utterances from news comments and provides a multi-label classification using 1 to 4 labels, and handles subjectivity and intersectionality. We evaluate strong baselines on K-MHaS. KR-BERT with a sub-character tokenizer outperforms others, recognizing decomposed characters in each hate speech class.\",\n}", "cardData": null, "siblings": [], "_id": "637b06be7ce76c3b834d99d5", "disabled": false, "gated": false, "likes": 11, "downloads": 555, "paperswithcode_id": "korean-multi-label-hate-speech-dataset", "createdAt": "2022-11-21T05:03:58.000Z"}, {"id": "gsarti/mt_geneval", "sha": "2f9ef1050de57018488761533ba79a92eab48c12", "lastModified": "2022-11-21T14:52:09.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:it", "language:fr", "language:ar", "language:de", "language:hi", "language:pt", "language:ru", "language:es", "license:cc-by-sa-3.0", "gender", "constrained mt", "arxiv:2211.01355", "region:us"], "private": false, "author": "gsarti", "description": "The MT-GenEval benchmark evaluates gender translation accuracy on English -> {Arabic, French, German, Hindi, Italian, \nPortuguese, Russian, Spanish}. The dataset contains individual sentences with annotations on the gendered target words,\nand contrastive original-invertend translations with additional preceding context.", "citation": "@inproceedings{currey-etal-2022-mtgeneval,\n    title = \"{MT-GenEval}: {A} Counterfactual and Contextual Dataset for Evaluating Gender Accuracy in Machine Translation\",\n    author = \"Currey, Anna  and\n      Nadejde, Maria  and\n      Pappagari, Raghavendra  and\n      Mayer, Mia  and\n      Lauly, Stanislas,  and\n      Niu, Xing  and\n      Hsu, Benjamin  and\n      Dinu, Georgiana\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"\"https://arxiv.org/pdf/2211.01355.pdf,\n}", "cardData": null, "siblings": [], "_id": "637b57e778d62422d13f0944", "disabled": false, "gated": false, "likes": 2, "downloads": 41, "createdAt": "2022-11-21T10:50:15.000Z"}, {"id": "lm4pt/bpsad", "sha": "875de01ed5e2bbf6860b847bd91cc01ef198eb74", "lastModified": "2022-11-23T19:20:11.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:sentiment-analysis", "language_creators:other", "multilinguality:monolingual", "size_categories:1M<n<10M", "language:pt", "license:unknown", "region:us"], "private": false, "author": "lm4pt", "description": "The Brazilian Portuguese Sentiment Analysis Dataset (BPSAD) is composed\nby the concatenation of 5 differents sources (Olist, B2W Digital, Buscap\u00e9,\nUTLC-Apps and UTLC-Movies), each one is composed by evaluation sentences\nclassified according to the polarity (0: negative; 1: positive) and ratings\n(1, 2, 3, 4 and 5 stars).", "citation": "@inproceedings{souza2021sentiment,\n    author={\n        Souza, Frederico Dias and\n        Baptista de Oliveira e Souza Filho, Jo\u00e3o},\n    booktitle={\n        2021 IEEE Latin American Conference on\n        Computational Intelligence (LA-CCI)}, \n    title={\n        Sentiment Analysis on Brazilian Portuguese User Reviews}, \n    year={2021},\n    pages={1-6},\n    doi={10.1109/LA-CCI48322.2021.9769838}\n}", "cardData": null, "siblings": [], "_id": "637b9b28d8f55001052214ff", "disabled": false, "gated": false, "likes": 3, "downloads": 16, "createdAt": "2022-11-21T15:37:12.000Z"}, {"id": "sagnikrayc/snli-cf-kaushik", "sha": "c36b48c2cbb4ff5da614340e614fdc73086d963e", "lastModified": "2022-11-21T22:34:23.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|snli", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "sagnikrayc", "description": "The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE). In the ICLR 2020 paper [Learning the Difference that Makes a Difference with Counterfactually-Augmented Data](https://openreview.net/forum?id=Sklgs0NFvr), Kaushik et. al. provided a dataset with counterfactual perturbations on the SNLI and IMDB data. This repository contains the original and counterfactual perturbations for the SNLI data, which was generated after processing the original data from [here](https://github.com/acmi-lab/counterfactually-augmented-data).", "citation": "@inproceedings{DBLP:conf/iclr/KaushikHL20,\n  author    = {Divyansh Kaushik and\n               Eduard H. Hovy and\n               Zachary Chase Lipton},\n  title     = {Learning The Difference That Makes {A} Difference With Counterfactually-Augmented\n               Data},\n  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,\n               Addis Ababa, Ethiopia, April 26-30, 2020},\n  publisher = {OpenReview.net},\n  year      = {2020},\n  url       = {https://openreview.net/forum?id=Sklgs0NFvr},\n  timestamp = {Thu, 07 May 2020 17:11:48 +0200},\n  biburl    = {https://dblp.org/rec/conf/iclr/KaushikHL20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "637bc33c2d2d9c4f24874e7f", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2022-11-21T18:28:12.000Z"}, {"id": "sayakpaul/nyu_depth_v2", "sha": "50579a0b591445f91bf7269b28611ad1cc6a05d2", "lastModified": "2022-12-12T13:35:31.000Z", "tags": ["task_categories:depth-estimation", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:apache-2.0", "depth-estimation", "arxiv:1903.03273", "region:us"], "private": false, "author": "sayakpaul", "description": "The NYU-Depth V2 data set is comprised of video sequences from a variety of indoor scenes as recorded by both the RGB and Depth cameras from the Microsoft Kinect.", "citation": "@inproceedings{Silberman:ECCV12,\n  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},\n  title     = {Indoor Segmentation and Support Inference from RGBD Images},\n  booktitle = {ECCV},\n  year      = {2012}\n}\n@inproceedings{icra_2019_fastdepth,\n  author    = {Wofk, Diana and Ma, Fangchang and Yang, Tien-Ju and Karaman, Sertac and Sze, Vivienne},\n  title     = {FastDepth: Fast Monocular Depth Estimation on Embedded Systems},\n  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},\n  year      = {2019}\n}", "cardData": null, "siblings": [], "_id": "637ca99cd1d531b0de63ab21", "disabled": false, "gated": false, "likes": 14, "downloads": 2812, "paperswithcode_id": "nyuv2", "createdAt": "2022-11-22T10:51:08.000Z"}, {"id": "Sociovestix/lenu", "sha": "2e7d576c61fe6dd8d85d5f05015b2c328c42e999", "lastModified": "2023-10-25T15:09:29.000Z", "tags": ["region:us"], "private": false, "author": "Sociovestix", "description": "    This dataset contains legal entity names from the Global LEI System in\n    which each entity is assigned with a unique Legal Entity Identifier (LEI)\n    code (ISO Standard 17441) along with their corresponding Entity Legal\n    Form (ELF) Codes (ISO Standard 20275) which specifies the legal form of\n    each entity.", "citation": null, "cardData": null, "siblings": [], "_id": "637d05ea43fec4c216352508", "disabled": false, "gated": false, "likes": 1, "downloads": 47, "createdAt": "2022-11-22T17:24:58.000Z"}, {"id": "MLRS/masri_test", "sha": "bfafee884f55b9de89597049b1ce14430e6c5ff5", "lastModified": "2023-03-30T11:08:22.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:mt", "license:cc-by-nc-sa-4.0", "masri", "maltese", "masri-project", "malta", "test corpus", "region:us"], "private": false, "author": "MLRS", "description": "The MASRI-TEST CORPUS was created out of YouTube videos belonging to the channel of the University of Malta. It has a length of 1 hour and it is gender balanced, as it has the same number of male and female speakers.", "citation": "@misc{carlosmenamasritest2020,\n      title={MASRI-TEST CORPUS: Audio and Transcriptions in Maltese extracted from the YouTube channel of the University of Malta.}, \n      author={Hernandez Mena, Carlos Daniel and  Brincat, Ayrton Didier and Gatt, Albert and DeMarco, Andrea and Borg, Claudia and van der Plas, Lonneke and Meza Ruiz, Iv\u00e1n Vladimir},\n      journal={MASRI Project, Malta},\n      year={2020},\n      url={https://www.um.edu.mt/projects/masri/},\n}", "cardData": null, "siblings": [], "_id": "6380f6314491649a3a6bd4c8", "disabled": false, "gated": false, "likes": 1, "downloads": 11, "createdAt": "2022-11-25T17:06:57.000Z"}, {"id": "language-and-voice-lab/samromur_children", "sha": "6bb44ee982da842051e42e1bbe8f81c3ffd04daf", "lastModified": "2023-10-15T16:02:44.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:is", "license:cc-by-4.0", "samromur", "children's speech", "icelandic: iceland", "icelandic children", "icelandic kids", "kids", "region:us"], "private": false, "author": "language-and-voice-lab", "description": "The Samr\u00f3mur Children corpus contains more than 137000 validated speech-recordings uttered by Icelandic children.", "citation": "@misc{menasamromurchildren2022,\n      title={Samr\u00f3mur Children Icelandic Speech 1.0}, \n      ldc_catalog_no={LDC2022S11},\n      DOI={https://doi.org/10.35111/frrj-qd60},\n      author={Hern\u00e1ndez Mena, Carlos Daniel and Borsky, Michal and Mollberg, David Erik  and Gu\u00f0mundsson, Sm\u00e1ri Freyr and Hedstr\u00f6m, Staffan and P\u00e1lsson, Ragnar and J\u00f3nsson, \u00d3lafur Helgi and \u00deorsteinsd\u00f3ttir, Sunneva and Gu\u00f0mundsd\u00f3ttir, J\u00f3hanna Vigd\u00eds and Magn\u00fasd\u00f3ttir, Eyd\u00eds Huld and \u00de\u00f3rhallsd\u00f3ttir, Ragnhei\u00f0ur and Gu\u00f0nason, J\u00f3n},\n      publisher={Reykjav\u00edk University}\n      journal={Linguistic Data Consortium, Philadelphia},\n      year={2019},\n      url={https://catalog.ldc.upenn.edu/LDC2022S11},\n}", "cardData": null, "siblings": [], "_id": "638184ea2dd1f3e7bf5af451", "disabled": false, "gated": false, "likes": 2, "downloads": 69, "createdAt": "2022-11-26T03:15:54.000Z"}, {"id": "language-and-voice-lab/samromur_asr", "sha": "0326666bee1fab36bf99a2bfdee265179504da73", "lastModified": "2023-02-24T22:02:05.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:is", "license:cc-by-4.0", "crowd-sourced icelandic", "samr\u00f3mur", "icelandic speech", "samromur", "iceland", "region:us"], "private": false, "author": "language-and-voice-lab", "description": "Samr\u00f3mur Icelandic Speech 1.0.", "citation": "@misc{mollbergsamromur2022,\n      title={Samr\u00f3mur Icelandic Speech 1.0}, \n      ldc_catalog_no={LDC2022S05},\n      DOI={https://doi.org/10.35111/thx3-f170},\n      author={Mollberg, David Erik and J\u00f3nsson, \u00d3lafur Helgi and \u00deorsteinsd\u00f3ttir, Sunneva and Gu\u00f0mundsd\u00f3ttir, J\u00f3hanna Vigd\u00eds and Steingrimsson, Steinthor and Magnusdottir, Eydis Huld and Fong, Judy Y. and Borsky, Michal and Gu\u00f0nason, J\u00f3n},\n      publisher={Reykjav\u00edk University}\n      journal={Linguistic Data Consortium, Philadelphia},\n      year={2022},\n      url={https://catalog.ldc.upenn.edu/LDC2022S05},\n}", "cardData": null, "siblings": [], "_id": "638320c0e58a1678ad6fc75b", "disabled": false, "gated": false, "likes": 0, "downloads": 40, "createdAt": "2022-11-27T08:33:04.000Z"}, {"id": "cjvt/cc_gigafida", "sha": "469f8914c49ddeecd0dc060a315a3d2077dd4209", "lastModified": "2023-01-17T13:11:14.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "task_ids:masked-language-modeling", "task_ids:language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "size_categories:100M<n<1B", "language:sl", "license:cc-by-nc-sa-4.0", "gigafida", "gigafida2", "kres", "cckres", "reference corpus", "region:us"], "private": false, "author": "cjvt", "description": "The ccGigafida corpus contains a subsample of the Gigafida corpus. The Gigafida corpus is an extensive collection of \nSlovene text of various genres, from daily newspapers, magazines, all kinds of books (fiction, non-fiction, textbooks), \nweb pages, transcriptions of parliamentary debates and similar.", "citation": "@misc{ccGigafida,\n    title = {Written corpus {ccGigafida} 1.0},\n    author = {Logar, Nata{\\v s}a and Erjavec, Toma{\\v z} and Krek, Simon and Gr{\\v c}ar, Miha and Holozan, Peter},\n    url = {http://hdl.handle.net/11356/1035},\n    note = {Slovenian language resource repository {CLARIN}.{SI}},\n    copyright = {Creative Commons - Attribution-{NonCommercial}-{ShareAlike} 4.0 International ({CC} {BY}-{NC}-{SA} 4.0)},\n    issn = {2820-4042},\n    year = {2013}\n}", "cardData": null, "siblings": [], "_id": "63861f518b5acae8d24df569", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2022-11-29T15:03:45.000Z"}, {"id": "vesteinn/swe-nerc", "sha": "95a568b549723e0a383b3582e8dd6e8174d15b50", "lastModified": "2022-11-30T12:40:35.000Z", "tags": ["region:us"], "private": false, "author": "vesteinn", "description": "The corpus consists of ca. 150.000 words of text.", "citation": "@misc{swe-nerc,\n title = {Swe-NERC},\n author = {Ahrenberg, Lars ; Frid, Johan and Olsson, Leif-J\u00f6ran},\n url = {https://hdl.handle.net/10794/121},\n year = {2020} }", "cardData": null, "siblings": [], "_id": "63872fd8189d6915f1d42226", "disabled": false, "gated": false, "likes": 0, "downloads": 199, "createdAt": "2022-11-30T10:26:32.000Z"}, {"id": "shunk031/jsnli", "sha": "6d84ffafa2b74d9c9b8d567ad338ad2e6c255a6d", "lastModified": "2022-12-12T07:36:58.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:multi-input-text-classification", "multilinguality:monolingual", "language:ja", "license:cc-by-sa-4.0", "natural-language-inference", "nli", "jsnli", "region:us"], "private": false, "author": "shunk031", "description": "== \u65e5\u672c\u8a9eSNLI(JSNLI)\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 ==\n\nSNLI \u30b3\u30fc\u30d1\u30b9\u3092\u65e5\u672c\u8a9e\u306b\u7ffb\u8a33\u3057\u305f\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\u5b66\u7fd2\u30c7\u30fc\u30bf\u306f\u5143\u30c7\u30fc\u30bf\u3092\u7ffb\u8a33\u3057\u3001\u8a08\u7b97\u6a5f\u306b\u3088\u308b\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u306b\u3088\u3063\u3066\u4f5c\u6210\n\u8a55\u4fa1\u30c7\u30fc\u30bf\u306f\u65e5\u672c\u8a9e\u3068\u3057\u3066\u610f\u5473\u304c\u901a\u308b\u304b\u3001\u7ffb\u8a33\u5f8c\u306e\u30e9\u30d9\u30eb\u304c\u5143\u306e\u30e9\u30d9\u30eb\u3068\u4e00\u81f4\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u306e2\u6bb5\u968e\u306e\u30af\u30e9\u30a6\u30c9\u30bd\u30fc\u30b7\u30f3\u30b0\u306b\u3088\u308a\u30c7\u30fc\u30bf\u3092\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0", "citation": "- \u5409\u8d8a \u5353\u898b, \u6cb3\u539f \u5927\u8f14, \u9ed2\u6a4b \u798e\u592b: \u6a5f\u68b0\u7ffb\u8a33\u3092\u7528\u3044\u305f\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u591a\u8a00\u8a9e\u5316, \u7b2c244\u56de\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u7814\u7a76\u4f1a, (2020.7.3).\n- Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n- Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. \"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions.\" Transactions of the Association for Computational Linguistics 2 (2014): 67-78.", "cardData": null, "siblings": [], "_id": "638785fa7f2fdf05ead0f49a", "disabled": false, "gated": false, "likes": 3, "downloads": 52, "createdAt": "2022-11-30T16:34:02.000Z"}, {"id": "TUKE-DeutscheTelekom/skquad", "sha": "f0d0fcf0ab24f2635e16cad44403a3b8c1e3904b", "lastModified": "2022-12-05T14:10:32.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_ids:open-domain-qa", "task_ids:extractive-qa", "task_ids:document-retrieval", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:sk", "license:cc-by-sa-4.0", "license:cc-by-4.0", "wikipedia", "region:us"], "private": false, "author": "TUKE-DeutscheTelekom", "description": "        Slovak Question Answering Dataset", "citation": "TBD", "cardData": null, "siblings": [], "_id": "6389e165d87ef988fe6b205a", "disabled": false, "gated": false, "likes": 3, "downloads": 25, "paperswithcode_id": "squad", "createdAt": "2022-12-02T11:28:37.000Z"}, {"id": "its5Q/yandex-q", "sha": "832c5749f4710e89928b7b40af464d4218948d38", "lastModified": "2023-04-02T16:48:29.000Z", "tags": ["task_categories:text-generation", "task_categories:question-answering", "task_ids:language-modeling", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:ru", "license:cc0-1.0", "region:us"], "private": false, "author": "its5Q", "description": "This is a dataset of questions and answers scraped from Yandex.Q.", "citation": null, "cardData": null, "siblings": [], "_id": "638c44a1e775b31ff3220528", "disabled": false, "gated": false, "likes": 6, "downloads": 43, "createdAt": "2022-12-04T06:56:33.000Z"}, {"id": "RobotsMaliAI/bayelemabaga", "sha": "70b44b26f0dbdc9885f35f1c264eea284ab51dcf", "lastModified": "2023-04-24T16:56:24.000Z", "tags": ["task_categories:translation", "task_categories:text-generation", "size_categories:10K<n<100K", "language:bm", "language:fr", "region:us"], "private": false, "author": "RobotsMaliAI", "description": "The Bayelemabaga dataset is a collection of 44160 aligned machine translation ready Bambara-French lines, \noriginating from Corpus Bambara de Reference. The dataset is constitued of text extracted from 231 source files, \nvaring from periodicals, books, short stories, blog posts, part of the Bible and the Quran.", "citation": "@misc{bayelemabagamldataset2022\n    title={Machine Learning Dataset Development for Manding Languages},\n    author={\n        Valentin Vydrin and\n        Christopher Homan and\n        Michael Leventhal and\n        Allashera Auguste Tapo and\n        Marco Zampieri and\n        Jean-Jacques Meric and\n        Kirill Maslinsky and\n        Andrij Rovenchak and\n        Sebastien Diarra\n\n    },\n    howpublished = {url{https://github.com/robotsmali-ai/datasets}},\n    year={2022}\n}", "cardData": null, "siblings": [], "_id": "638c5e92d1c4bf949b155bae", "disabled": false, "gated": false, "likes": 3, "downloads": 58, "createdAt": "2022-12-04T08:47:14.000Z"}, {"id": "MCG-NJU/MultiSports", "sha": "01600ce7eabbf42a5ee7c82b82f49a11597b3a5f", "lastModified": "2022-12-13T07:47:16.000Z", "tags": ["task_categories:image-classification", "task_categories:object-detection", "task_categories:other", "task_ids:multi-class-image-classification", "annotations_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "source_datasets:original", "language:en", "license:cc-by-nc-4.0", "video", "action detection", "spatial-temporal action localization", "arxiv:2105.07404", "region:us"], "private": false, "author": "MCG-NJU", "description": "This is a multi-person video dataset of spatio-temporally localized sports actions. Please refer to the github repo for evaluation.", "citation": "@InProceedings{Li_2021_ICCV,\n    author    = {Li, Yixuan and Chen, Lei and He, Runyu and Wang, Zhenzhi and Wu, Gangshan and Wang, Limin},\n    title     = {MultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n    month     = {October},\n    year      = {2021},\n    pages     = {13536-13545}\n}", "cardData": null, "siblings": [], "_id": "638efe35b0525fa370470d89", "disabled": false, "gated": "auto", "likes": 11, "downloads": 13, "createdAt": "2022-12-06T08:32:53.000Z"}, {"id": "HuggingFaceM4/TextCaps", "sha": "4e7b9d3eb67b6ce54ef37ea23f276ebe21f63aa2", "lastModified": "2022-12-09T01:38:32.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "extCaps requires models to read and reason about text in images to generate captions about them. Specifically, models need to incorporate a new modality of text present in the images and reason over it and visual content in the image to generate image descriptions.\nCurrent state-of-the-art models fail to generate captions for images in TextCaps because they do not have text reading and reasoning capabilities. See the examples in the image to compare ground truth answers and corresponding predictions by a state-of-the-art model.", "citation": "@article{sidorov2019textcaps,\n    title={TextCaps: a Dataset for Image Captioningwith Reading Comprehension},\n    author={Sidorov, Oleksii and Hu, Ronghang and Rohrbach, Marcus and Singh, Amanpreet},\n    journal={arXiv preprint arXiv:2003.12462},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "638fac6c2ddd69e70b88c4a4", "disabled": false, "gated": false, "likes": 2, "downloads": 222, "createdAt": "2022-12-06T20:56:12.000Z"}, {"id": "parambharat/tamil_asr_corpus", "sha": "ec1b0fb9b9b7741fb241f4379ff6d2be4d1fbf6c", "lastModified": "2022-12-07T17:32:59.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|common_voice", "source_datasets:extended|openslr", "language:ta", "license:cc-by-4.0", "region:us"], "private": false, "author": "parambharat", "description": "The corpus contains roughly 1000 hours of audio and trasncripts in Tamil language. The transcripts have beedn de-duplicated using exact match deduplication.", "citation": "@misc{mile_1,\n  doi = {10.48550/ARXIV.2207.13331},\n  url = {https://arxiv.org/abs/2207.13331},\n  author = {A, Madhavaraj and Pilar, Bharathi and G, Ramakrishnan A},\n  title = {Subword Dictionary Learning and Segmentation Techniques for Automatic Speech Recognition in Tamil and Kannada},\n  publisher = {arXiv},\n  year = {2022},\n}\n\n@misc{mile_2,\n  doi = {10.48550/ARXIV.2207.13333},\n  url = {https://arxiv.org/abs/2207.13333},\n  author = {A, Madhavaraj and Pilar, Bharathi and G, Ramakrishnan A},\n  title = {Knowledge-driven Subword Grammar Modeling for Automatic Speech Recognition in Tamil and Kannada},\n  publisher = {arXiv},\n  year = {2022},\n}\n\n@inproceedings{he-etal-2020-open,\n    title = {{Open-source Multi-speaker Speech Corpora for Building Gujarati, Kannada, Malayalam, Marathi, Tamil and Telugu Speech Synthesis Systems}},\n    author = {He, Fei and Chu, Shan-Hui Cathy and Kjartansson, Oddur and Rivera, Clara and Katanova, Anna and Gutkin, Alexander and Demirsahin, Isin and Johny, Cibu and Jansche, Martin and Sarin, Supheakmungkol and Pipatsrisawat, Knot},\n    booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference (LREC)},\n    month = may,\n    year = {2020},\n    address = {Marseille, France},\n    publisher = {European Language Resources Association (ELRA)},\n    pages = {6494--6503},\n    url = {https://www.aclweb.org/anthology/2020.lrec-1.800},\n    ISBN = \"{979-10-95546-34-4},\n  }\n\n@misc{https://doi.org/10.48550/arxiv.2211.09536,\n  doi = {10.48550/ARXIV.2211.09536},\n  \n  url = {https://arxiv.org/abs/2211.09536},\n  \n  author = {Kumar, Gokul Karthik and S, Praveen and Kumar, Pratyush and Khapra, Mitesh M. and Nandakumar, Karthik},\n  \n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},\n  \n  title = {Towards Building Text-To-Speech Systems for the Next Billion Users},\n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n\n@inproceedings{commonvoice:2020,\n  author = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\n  title = {Common Voice: A Massively-Multilingual Speech Corpus},\n  booktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n  pages = {4211--4215},\n  year = 2020\n}\n\n@misc{https://doi.org/10.48550/arxiv.2205.12446,\n  doi = {10.48550/ARXIV.2205.12446},\n  \n  url = {https://arxiv.org/abs/2205.12446},\n  \n  author = {Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},\n  \n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},\n  \n  title = {FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech},\n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {Creative Commons Attribution 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "6390c0f522a248a47f2775ad", "disabled": false, "gated": false, "likes": 1, "downloads": 58, "createdAt": "2022-12-07T16:36:05.000Z"}, {"id": "ipipan/nkjp1m", "sha": "20b5dcbdbc4776c1412131c0b06b319eac97ef8b", "lastModified": "2022-12-07T16:47:51.000Z", "tags": ["task_categories:token-classification", "task_ids:part-of-speech", "task_ids:lemmatization", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:pl", "license:cc-by-4.0", "National Corpus of Polish", "Narodowy Korpus J\u0119zyka Polskiego", "region:us"], "private": false, "author": "ipipan", "description": "This is the official dataset for NKJP1M \u2013 the 1-million token subcorpus of the\nNational Corpus of Polish (Narodowy Korpus J\u0119zyka Polskiego)\n\nBesides the text (divided into paragraphs/samples and sentences) the\nset contains lemmas and morpho-syntactic tags for all tokens in the corpus.\n\nThis release corresponds to the version 1.2 of the corpus with\nfollowing corrections and improvements. In particular the\nmorpho-syntactic annotation has been aligned with the present version\nof Morfeusz2 morphological analyser.", "citation": "@Book{nkjp:12,\n  editor =       \"Adam Przepi\u00f3rkowski and Miros\u0142aw Ba\u0144ko and Rafa\u0142\n                  L. G\u00f3rski and Barbara Lewandowska-Tomaszczyk\",\n  title =        \"Narodowy Korpus J\u0119zyka Polskiego\",\n  year =         2012,\n  address =      \"Warszawa\",\n  pdf =          \"http://nkjp.pl/settings/papers/NKJP_ksiazka.pdf\",\n  publisher =    \"Wydawnictwo Naukowe PWN\"}", "cardData": null, "siblings": [], "_id": "6390c230d00f25601f43d24a", "disabled": false, "gated": false, "likes": 2, "downloads": 14, "createdAt": "2022-12-07T16:41:20.000Z"}, {"id": "HuggingFaceM4/NoCaps", "sha": "61210a16d010f73fd531393567f4bb467c10f4d0", "lastModified": "2022-12-14T04:08:38.000Z", "tags": ["license:cc-by-2.0", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "Dubbed NoCaps, for novel object captioning at scale, NoCaps consists of 166,100 human-generated captions describing 15,100 images from the Open Images validation and test sets.\nThe associated training data consists of COCO image-caption pairs, plus Open Images image-level labels and object bounding boxes.\nSince Open Images contains many more classes than COCO, nearly 400 object classes seen in test images have no or very few associated training captions (hence, nocaps).", "citation": "@inproceedings{agrawal2019nocaps,\n  title={nocaps: novel object captioning at scale},\n  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={8948--8957},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "63921ab9a0f1f1ba73bab2ca", "disabled": false, "gated": false, "likes": 1, "downloads": 256, "createdAt": "2022-12-08T17:11:21.000Z"}, {"id": "HuggingFaceM4/FairFace", "sha": "480186ac8cde3997a74b6395590420b7ec4ee267", "lastModified": "2022-12-09T00:14:46.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "FairFace is a face image dataset which is race balanced. It contains 108,501 images from 7 different race groups: White, Black, Indian, East Asian, Southeast Asian, Middle Eastern, and Latino.\nImages were collected from the YFCC-100M Flickr dataset and labeled with race, gender, and age groups.", "citation": "@inproceedings{karkkainenfairface,\n    title={FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation},\n    author={Karkkainen, Kimmo and Joo, Jungseock},\n    booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},\n    year={2021},\n    pages={1548--1558}\n}", "cardData": null, "siblings": [], "_id": "63926c9d8059e5fd86404970", "disabled": false, "gated": false, "likes": 5, "downloads": 490, "createdAt": "2022-12-08T23:00:45.000Z"}, {"id": "language-and-voice-lab/althingi_asr", "sha": "f4b16ad198fda72263aa9b2989f54561056856ad", "lastModified": "2023-02-24T22:14:42.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:is", "license:cc-by-4.0", "icelandic", "parliamentary speech", "parlament", "althingi", "region:us"], "private": false, "author": "language-and-voice-lab", "description": "Althingi Parliamentary Speech consists of approximately 542 hours of recorded speech from Althingi, the Icelandic Parliament. Speeches date from 2005-2016.", "citation": "@misc{helgadottiralthingi2021,\n      title={Althingi Parliamentary Speech}, \n      ldc_catalog_no={LDC2021S01},\n      DOI={https://doi.org/10.35111/695b-6697},\n      author={Helgad\u00f3ttir, Inga R\u00fan and Kjaran, R\u00f3bert and Nikul\u00e1sd\u00f3ttir, Anna Bj\u00f6rk and Gu\u00f0nason, J\u00f3n},\n      publisher={Reykjav\u00edk University}\n      journal={Linguistic Data Consortium, Philadelphia},\n      year={2021},\n      url={https://catalog.ldc.upenn.edu/LDC2021S01},\n}", "cardData": null, "siblings": [], "_id": "63939b983996e99d9ffea7ff", "disabled": false, "gated": false, "likes": 0, "downloads": 45, "createdAt": "2022-12-09T20:33:28.000Z"}, {"id": "parambharat/malayalam_asr_corpus", "sha": "b64dff025eaed409999345c6182a61482e2c68f6", "lastModified": "2022-12-11T13:05:27.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended|common_voice", "source_datasets:extended|openslr", "language:ml", "license:cc-by-4.0", "region:us"], "private": false, "author": "parambharat", "description": "The corpus contains roughly 10 hours of audio and trasncripts in Malayalam language. The transcripts have beedn de-duplicated using exact match deduplication.", "citation": "@misc{https://doi.org/10.48550/arxiv.2211.09536,\n  doi = {10.48550/ARXIV.2211.09536},\n  \n  url = {https://arxiv.org/abs/2211.09536},\n  \n  author = {Kumar, Gokul Karthik and S, Praveen and Kumar, Pratyush and Khapra, Mitesh M. and Nandakumar, Karthik},\n  \n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},\n  \n  title = {Towards Building Text-To-Speech Systems for the Next Billion Users},\n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {arXiv.org perpetual, non-exclusive license}\n}\n\n@inproceedings{commonvoice:2020,\n  author = {Ardila, R. and Branson, M. and Davis, K. and Henretty, M. and Kohler, M. and Meyer, J. and Morais, R. and Saunders, L. and Tyers, F. M. and Weber, G.},\n  title = {Common Voice: A Massively-Multilingual Speech Corpus},\n  booktitle = {Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)},\n  pages = {4211--4215},\n  year = 2020\n}\n\n@misc{https://doi.org/10.48550/arxiv.2205.12446,\n  doi = {10.48550/ARXIV.2205.12446},\n  \n  url = {https://arxiv.org/abs/2205.12446},\n  \n  author = {Conneau, Alexis and Ma, Min and Khanuja, Simran and Zhang, Yu and Axelrod, Vera and Dalmia, Siddharth and Riesa, Jason and Rivera, Clara and Bapna, Ankur},\n  \n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},\n  \n  title = {FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech},\n  \n  publisher = {arXiv},\n  \n  year = {2022},\n  \n  copyright = {Creative Commons Attribution 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "6395d10b1fede5cc58b3aca8", "disabled": false, "gated": false, "likes": 3, "downloads": 16, "createdAt": "2022-12-11T12:46:03.000Z"}, {"id": "HuggingFaceM4/COCO", "sha": "4d0dfd4a3712a80e7b8498ed76e778f7cea9d21c", "lastModified": "2022-12-15T15:51:03.000Z", "tags": ["license:cc-by-4.0", "arxiv:1405.0312", "region:us"], "private": false, "author": "HuggingFaceM4", "description": "MS COCO is a large-scale object detection, segmentation, and captioning dataset.\nCOCO has several features: Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled), 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image, 250,000 people with keypoints.", "citation": "@article{DBLP:journals/corr/LinMBHPRDZ14,\n  author    = {Tsung{-}Yi Lin and\n               Michael Maire and\n               Serge J. Belongie and\n               Lubomir D. Bourdev and\n               Ross B. Girshick and\n               James Hays and\n               Pietro Perona and\n               Deva Ramanan and\n               Piotr Doll{\\'{a}}r and\n               C. Lawrence Zitnick},\n  title     = {Microsoft {COCO:} Common Objects in Context},\n  journal   = {CoRR},\n  volume    = {abs/1405.0312},\n  year      = {2014},\n  url       = {http://arxiv.org/abs/1405.0312},\n  eprinttype = {arXiv},\n  eprint    = {1405.0312},\n  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/LinMBHPRDZ14.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "639a3c952ea18b44fce1293f", "disabled": false, "gated": false, "likes": 9, "downloads": 6340, "createdAt": "2022-12-14T21:13:57.000Z"}, {"id": "masakhane/masakhaner2", "sha": "60512e89e68841b6b5ed1be59caf97b169f0d27a", "lastModified": "2023-09-11T18:00:07.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:bm", "language:bbj", "language:ee", "language:fon", "language:ha", "language:ig", "language:rw", "language:lg", "language:luo", "language:mos", "language:ny", "language:pcm", "language:sn", "language:sw", "language:tn", "language:tw", "language:wo", "language:xh", "language:yo", "language:zu", "license:afl-3.0", "ner", "masakhaner", "masakhane", "arxiv:2103.11811", "arxiv:2210.12391", "region:us"], "private": false, "author": "masakhane", "description": "MasakhaNER 2.0 is the largest publicly available high-quality dataset for named entity recognition (NER) in 20 African languages.\n\nNamed entities are phrases that contain the names of persons, organizations, locations, times and quantities.\n\nExample:\n[PER Wolff] , currently a journalist in [LOC Argentina] , played with [PER Del Bosque] in the final years of the seventies in [ORG Real Madrid] .\nMasakhaNER is a named entity dataset consisting of PER, ORG, LOC, and DATE entities annotated by Masakhane for 20 African languages:\n- Bambara (bam)\n- Ghomala (bbj)\n- Ewe (ewe)\n- Fon (fon)\n- Hausa (hau)\n- Igbo (ibo)\n- Kinyarwanda (kin)\n- Luganda (lug)\n- Dholuo (luo) \n- Mossi (mos)\n- Chichewa (nya)\n- Nigerian Pidgin\n- chShona (sna)\n- Kiswahili (sw\u0105)\n- Setswana (tsn)\n- Twi (twi)\n- Wolof (wol)\n- isiXhosa (xho)\n- Yor\u00f9b\u00e1 (yor)\n- isiZulu (zul)\n\nThe train/validation/test sets are available for all the ten languages.\n\nFor more details see https://arxiv.org/abs/2103.11811", "citation": "@article{Adelani2022MasakhaNER2A,\n  title={MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity Recognition},\n  author={David Ifeoluwa Adelani and Graham Neubig and Sebastian Ruder and Shruti Rijhwani and Michael Beukman and Chester Palen-Michel and Constantine Lignos and Jesujoba Oluwadara Alabi and Shamsuddeen Hassan Muhammad and Peter Nabende and Cheikh M. Bamba Dione and Andiswa Bukula and Rooweither Mabuya and Bonaventure F. P. Dossou and Blessing K. Sibanda and Happy Buzaaba and Jonathan Mukiibi and Godson Kalipe and Derguene Mbaye and Amelia Taylor and Fatoumata Kabore and Chris C. Emezue and Anuoluwapo Aremu and Perez Ogayo and Catherine W. Gitau and Edwin Munkoh-Buabeng and Victoire Memdjokam Koagne and Allahsera Auguste Tapo and Tebogo Macucwa and Vukosi Marivate and Elvis Mboning and Tajuddeen R. Gwadabe and Tosin P. Adewumi and Orevaoghene Ahia and Joyce Nakatumba-Nabende and Neo L. Mokono and Ignatius M Ezeani and Chiamaka Ijeoma Chukwuneke and Mofetoluwa Adeyemi and Gilles Hacheme and Idris Abdulmumin and Odunayo Ogundepo and Oreen Yousuf and Tatiana Moteu Ngoli and Dietrich Klakow},\n  journal={ArXiv},\n  year={2022},\n  volume={abs/2210.12391}\n}", "cardData": null, "siblings": [], "_id": "639b20e95d6e30f96221522d", "disabled": false, "gated": false, "likes": 8, "downloads": 1145, "createdAt": "2022-12-15T13:28:09.000Z"}, {"id": "EleutherAI/lambada_openai", "sha": "879e19a2c9bb7ef03f9cf962089cf7d008f91e27", "lastModified": "2022-12-16T19:53:23.000Z", "tags": ["task_ids:language-modeling", "language_creators:machine-generated", "multilinguality:translation", "size_categories:1K<n<10K", "source_datasets:lambada", "language:de", "language:en", "language:es", "language:fr", "language:it", "license:mit", "region:us"], "private": false, "author": "EleutherAI", "description": "The LAMBADA dataset as processed by OpenAI. It is used to evaluate the capabilities\nof computational models for text understanding by means of a word prediction task.\nLAMBADA is a collection of narrative texts sharing the characteristic that human subjects\nare able to guess their last word if they are exposed to the whole text, but not\nif they only see the last sentence preceding the target word. To succeed on LAMBADA,\ncomputational models cannot simply rely on local context, but must be able to keep track\nof information in the broader discourse.\n\nReference: https://github.com/openai/gpt-2/issues/131#issuecomment-497136199", "citation": "@misc{\n    author={Paperno, Denis and Kruszewski, Germ\u00e1n and Lazaridou, Angeliki and Pham, Quan Ngoc and Bernardi, Raffaella and Pezzelle, Sandro and Baroni, Marco and Boleda, Gemma and Fern\u00e1ndez, Raquel},\n    title={The LAMBADA dataset},\n    DOI={10.5281/zenodo.2630551},\n    publisher={Zenodo},\n    year={2016},\n    month={Aug}\n}", "cardData": null, "siblings": [], "_id": "639c9e3b566712a20b7ad93c", "disabled": false, "gated": false, "likes": 31, "downloads": 25099, "createdAt": "2022-12-16T16:35:07.000Z"}, {"id": "ipipan/polqa", "sha": "32d6db2e304ddfb33cbb6e2243ad42caf4ab32ab", "lastModified": "2023-09-09T13:37:44.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_categories:text2text-generation", "task_ids:open-domain-qa", "task_ids:document-retrieval", "task_ids:abstractive-qa", "annotations_creators:expert-generated", "size_categories:10K<n<100K", "language:pl", "license:cc-by-sa-4.0", "arxiv:2212.08897", "region:us"], "private": false, "author": "ipipan", "description": "PolQA is the first Polish dataset for OpenQA. It consists of 7,000 questions, 87,525 manually labeled evidence passages, and a corpus of over 7 million candidate passages.", "citation": "@misc{rybak2022improving,\n      title={Improving Question Answering Performance through Manual Annotation: Costs, Benefits and Strategies}, \n      author={Piotr Rybak and Piotr Przyby\u0142a and Maciej Ogrodniczuk},\n      year={2022},\n      eprint={2212.08897},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "639dda5e727066701119241d", "disabled": false, "gated": false, "likes": 3, "downloads": 79, "createdAt": "2022-12-17T15:03:58.000Z"}, {"id": "openai/webgpt_comparisons", "sha": "f30e1bd2f0a51535b493de36d3686cfcfff47abe", "lastModified": "2022-12-19T17:55:29.000Z", "tags": ["arxiv:2112.09332", "region:us"], "private": false, "author": "openai", "description": "WebGPT Comparisons contains all of the comparisons marked as suitable for reward modelling from the WebGPT paper.", "citation": "@inproceedings{nakano2021webgpt,\n  author = {Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Long Ouyang and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},\n  title = {WebGPT: Browser-assisted question-answering with human feedback},\n  booktitle = {arXiv},\n  year = 2021,\n}", "cardData": null, "siblings": [], "_id": "639f70799f1f2baab2f6b7d7", "disabled": false, "gated": false, "likes": 179, "downloads": 2482, "createdAt": "2022-12-18T19:56:41.000Z"}, {"id": "orai-nlp/basqueGLUE", "sha": "9c3fe5dcc00a5ee3bcfdb6936cbb770ef3c26dfd", "lastModified": "2022-12-21T09:54:32.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_ids:intent-classification", "task_ids:natural-language-inference", "task_ids:sentiment-classification", "task_ids:topic-classification", "task_ids:named-entity-recognition", "task_ids:coreference-resolution", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:eu", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "orai-nlp", "description": "We present BasqueGLUE, the first NLU benchmark for Basque, which has been elaborated from \npreviously existing datasets and following similar criteria to those used for the construction of \nGLUE and SuperGLUE. BasqueGLUE is freely available under an open license.", "citation": "@InProceedings{urbizu2022basqueglue,\n  author    = {Urbizu, Gorka  and  San Vicente, I\u00f1aki  and  Saralegi, Xabier  and  Agerri, Rodrigo  and  Soroa, Aitor},\n  title     = {BasqueGLUE: A Natural Language Understanding Benchmark for Basque},\n  booktitle      = {Proceedings of the Language Resources and Evaluation Conference},\n  month          = {June},\n  year           = {2022},\n  address        = {Marseille, France},\n  publisher      = {European Language Resources Association},\n  pages     = {1603--1612},\n  abstract  = {Natural Language Understanding (NLU) technology has improved significantly over the last few years and multitask benchmarks such as GLUE are key to evaluate this improvement in a robust and general way. These benchmarks take into account a wide and diverse set of NLU tasks that require some form of language understanding, beyond the detection of superficial, textual clues. However, they are costly to develop and language-dependent, and therefore they are only available for a small number of languages. In this paper, we present BasqueGLUE, the first NLU benchmark for Basque, a less-resourced language, which has been elaborated from previously existing datasets and following similar criteria to those used for the construction of GLUE and SuperGLUE. We also report the evaluation of two state-of-the-art language models for Basque on BasqueGLUE, thus providing a strong baseline to compare upon. BasqueGLUE is freely available under an open license.},\n  url       = {https://aclanthology.org/2022.lrec-1.172}\n}", "cardData": null, "siblings": [], "_id": "63a1c6833c003e4093119fad", "disabled": false, "gated": false, "likes": 1, "downloads": 55, "createdAt": "2022-12-20T14:28:19.000Z"}, {"id": "neulab/docprompting-conala", "sha": "48df7abf0f64f9279b4ee04386272eb9dc89ef89", "lastModified": "2023-03-14T17:59:47.000Z", "tags": ["task_categories:text2text-generation", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:code", "license:mit", "code-generation", "doc retrieval", "retrieval augmented generation", "arxiv:2207.05987", "arxiv:1805.08949", "region:us"], "private": false, "author": "neulab", "description": "This is the re-split of CoNaLa dataset. For each code snippet in the dev and test set, at least one function is held out from the training set. This split aims at testing a code generation model's capacity in generating unseen functions.\nWe further make sure that examples from the same StackOverflow post (same question_id before -) are in the same split.", "citation": "@article{zhou2022doccoder,\n  title={DocCoder: Generating Code by Retrieving and Reading Docs},\n  author={Zhou, Shuyan and Alon, Uri and Xu, Frank F and JIang, Zhengbao and Neubig, Graham},\n  journal={arXiv preprint arXiv:2207.05987},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63a3c3af7abdaa25a81c9c16", "disabled": false, "gated": false, "likes": 4, "downloads": 1014, "createdAt": "2022-12-22T02:40:47.000Z"}, {"id": "openai/summarize_from_feedback", "sha": "b8f7d168b6f4e95b2a92e84768bd6c955bed2f29", "lastModified": "2023-01-03T16:55:41.000Z", "tags": ["arxiv:2009.01325", "region:us"], "private": false, "author": "openai", "description": "Summarize from Feedback contains the human feedback data released by the \"Learning to summarize from human feedback\" paper.", "citation": "@inproceedings{stienon2020learning,\n  author = {Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},\n  title = {Learning to summarize from human feedback},\n  booktitle = {NeurIPS},\n  year = 2020,\n}", "cardData": null, "siblings": [], "_id": "63abbb37d6cafe97c8a01d95", "disabled": false, "gated": false, "likes": 131, "downloads": 5037, "createdAt": "2022-12-28T03:42:47.000Z"}, {"id": "aashsach/multiconer2", "sha": "33e763e952201323d99c5afe93766a5697b31b38", "lastModified": "2023-01-05T03:00:49.000Z", "tags": ["region:us"], "private": false, "author": "aashsach", "description": "SemEval 2023 Task 2: MultiCoNER II\nMultilingual Complex Named Entity Recognition", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "63ac76f023f39d70bdd176e5", "disabled": false, "gated": false, "likes": 0, "downloads": 37, "createdAt": "2022-12-28T17:03:44.000Z"}, {"id": "tushar117/xalign", "sha": "87519c39b1886a35e6c94dd1e39211a8587cd394", "lastModified": "2023-01-01T20:39:30.000Z", "tags": ["task_categories:table-to-text", "task_ids:rdf-to-text", "annotations_creators:found", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:as", "language:bn", "language:gu", "language:hi", "language:kn", "language:ml", "language:mr", "language:or", "language:pa", "language:ta", "language:te", "language:en", "license:cc-by-nc-sa-4.0", "license:mit", "xalign", "NLG", "low-resource", "LRL", "arxiv:2202.00291", "arxiv:2209.11252", "region:us"], "private": false, "author": "tushar117", "description": "It consists of an extensive collection of a high quality cross-lingual fact-to-text dataset where facts are in English \nand corresponding sentences are in native language for person biographies. The Train & validation splits are created \nusing distant supervision methods and Test data is generated through human annotations.", "citation": "@article{abhishek2022xalign,\n  title={XAlign: Cross-lingual Fact-to-Text Alignment and Generation for Low-Resource Languages},\n  author={Abhishek, Tushar and Sagare, Shivprasad and Singh, Bhavyajeet and Sharma, Anubhav and Gupta, Manish and Varma, Vasudeva},\n  journal={arXiv preprint arXiv:2202.00291},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63ad38a223f39d70bddbb768", "disabled": false, "gated": false, "likes": 1, "downloads": 27, "paperswithcode_id": "xalign", "createdAt": "2022-12-29T06:50:10.000Z"}, {"id": "eloukas/edgar-corpus", "sha": "7e90f0f342569b35213445f809cfaf3b91f9964f", "lastModified": "2023-07-14T07:17:12.000Z", "tags": ["task_categories:other", "annotations_creators:no-annotation", "language_creators:other", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended|other", "language:en", "license:apache-2.0", "research papers", "edgar", "sec", "finance", "financial", "filings", "10K", "10-K", "nlp", "research", "econlp", "economics", "business", "arxiv:2109.14394", "region:us"], "private": false, "author": "eloukas", "description": "The dataset contains annual filings (10K) of all publicly traded firms from 1993-2020. The table data is stripped but all text is retained.\nThis dataset allows easy access to the EDGAR-CORPUS dataset based on the paper EDGAR-CORPUS: Billions of Tokens Make The World Go Round (See References in README.md for details).", "citation": null, "cardData": null, "siblings": [], "_id": "63af17ecdb7ee23c3cedb2ec", "disabled": false, "gated": false, "likes": 17, "downloads": 397, "createdAt": "2022-12-30T16:55:08.000Z"}, {"id": "tasksource/babi_nli", "sha": "f7ec397979411ad5e08e1771ea62e978dfec2cfe", "lastModified": "2023-06-05T09:05:59.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:bsd", "logical reasoning", "nli", "natural-language-inference", "reasoning", "logic", "region:us"], "private": false, "author": "tasksource", "description": "bAbi tasks recasted as natural language inference.", "citation": null, "cardData": null, "siblings": [], "_id": "63b19b251bc4bb9da217a797", "disabled": false, "gated": false, "likes": 1, "downloads": 139, "createdAt": "2023-01-01T14:39:33.000Z"}, {"id": "JanosAudran/financial-reports-sec", "sha": "5da7e3c8b920a586b8c36eecba4aaa0152a59a52", "lastModified": "2023-01-06T17:44:08.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-classification", "task_ids:masked-language-modeling", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:extended|other", "language:en", "license:apache-2.0", "'finance", "financial", "10-K", "10K", "10k", "10-k", "annual", "reports", "sec", "edgar", "sentiment", "firm", "public", "us'", "region:us"], "private": false, "author": "JanosAudran", "description": "The dataset contains the annual report of US public firms filing with the SEC EDGAR system.\nEach annual report (10K filing) is broken into 20 sections. Each section is split into individual sentences.\nSentiment labels are provided on a per filing basis from the market reaction around the filing data.\nAdditional metadata for each filing is included in the dataset.", "citation": null, "cardData": null, "siblings": [], "_id": "63b2f66ad6c6529ede779e81", "disabled": false, "gated": false, "likes": 41, "downloads": 227, "createdAt": "2023-01-02T15:21:14.000Z"}, {"id": "zpn/zinc20", "sha": "ba4684a1a6f7d00b82a58925777269bd7ff7f2c5", "lastModified": "2023-01-06T02:03:46.000Z", "tags": ["size_categories:1B<n<10B", "license:mit", "bio", "selfies", "smiles", "small_molecules", "region:us"], "private": false, "author": "zpn", "description": "This dataset contains ~1B molecules from ZINC20, with their SMILES and SELFIES representations.", "citation": "@article{Irwin2020,\n  doi = {10.1021/acs.jcim.0c00675},\n  url = {https://doi.org/10.1021/acs.jcim.0c00675},\n  year = {2020},\n  month = oct,\n  publisher = {American Chemical Society ({ACS})},\n  volume = {60},\n  number = {12},\n  pages = {6065--6073},\n  author = {John J. Irwin and Khanh G. Tang and Jennifer Young and Chinzorig Dandarchuluun and Benjamin R. Wong and Munkhzul Khurelbaatar and Yurii S. Moroz and John Mayfield and Roger A. Sayle},\n  title = {{ZINC}20{\\textemdash}A Free Ultralarge-Scale Chemical Database for Ligand Discovery},\n  journal = {Journal of Chemical Information and Modeling}\n}", "cardData": null, "siblings": [], "_id": "63b5b83fc5a5432fd85a036b", "disabled": false, "gated": false, "likes": 5, "downloads": 342, "createdAt": "2023-01-04T17:32:47.000Z"}, {"id": "bigbio/drugprot", "sha": "38ff03d68347aaf694e598c50cb164191f50f61c", "lastModified": "2023-01-06T03:30:02.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "bigbio", "description": "The DrugProt corpus consists of a) expert-labelled chemical and gene mentions, and (b) all binary relationships between them corresponding to a specific set of biologically relevant relation types.", "citation": "@inproceedings{miranda2021overview,\n  title={Overview of DrugProt BioCreative VII track: quality evaluation and large scale text mining of         drug-gene/protein relations},\n  author={Miranda, Antonio and Mehryary, Farrokh and Luoma, Jouni and Pyysalo, Sampo and Valencia, Alfonso         and Krallinger, Martin},\n  booktitle={Proceedings of the seventh BioCreative challenge evaluation workshop},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "63b795351b10e5b44942f79f", "disabled": false, "gated": false, "likes": 2, "downloads": 77, "createdAt": "2023-01-06T03:27:49.000Z"}, {"id": "bigbio/cpi", "sha": "970237b9a7497de2e3a925113b8c20be87a3abf5", "lastModified": "2023-01-06T03:46:05.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The compound-protein relationship (CPI) dataset consists of 2,613 sentences from abstracts containing annotations of proteins, small molecules, and their relationships", "citation": "@article{doring2020automated,\n  title={Automated recognition of functional compound-protein relationships in literature},\n  author={D{\\\"o}ring, Kersten and Qaseem, Ammar and Becer, Michael and Li, Jianyu and Mishra, Pankaj and Gao, Mingjie and Kirchner, Pascal and Sauter, Florian and Telukunta, Kiran K and Moumbock, Aur{\\'e}lien FA and others},\n  journal={Plos one},\n  volume={15},\n  number={3},\n  pages={e0220925},\n  year={2020},\n  publisher={Public Library of Science San Francisco, CA USA}\n}", "cardData": null, "siblings": [], "_id": "63b79903ec5c995fded64edc", "disabled": false, "gated": false, "likes": 1, "downloads": 14, "createdAt": "2023-01-06T03:44:03.000Z"}, {"id": "DFKI-SLT/kbp37", "sha": "617b89fed951bf7702c2e688c8dadc6a1cd64787", "lastModified": "2023-04-27T13:04:14.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:other", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|other", "language:en", "license:other", "relation extraction", "arxiv:1508.01006", "region:us"], "private": false, "author": "DFKI-SLT", "description": "KBP37 is a revision of MIML-RE annotation dataset, provided by Gabor Angeli et al. (2014). They use both the 2010 and \n2013 KBP official document collections, as well as a July 2013 dump of Wikipedia as the text corpus for annotation. \nThere are 33811 sentences been annotated. Zhang and Wang made several refinements:\n1. They add direction to the relation names, e.g. '`per:employee_of`' is split into  '`per:employee of(e1,e2)`'\nand '`per:employee of(e2,e1)`'. They also replace '`org:parents`' with '`org:subsidiaries`' and replace\n'`org:member of\u2019 with '`org:member`' (by their reverse directions).\n2. They discard low frequency relations such that both directions of each relation occur more than 100 times in the \ndataset.\n\nKBP37 contains 18 directional relations and an additional '`no_relation`' relation, resulting in 37 relation classes.", "citation": "@article{DBLP:journals/corr/ZhangW15a,\n  author    = {Dongxu Zhang and\n               Dong Wang},\n  title     = {Relation Classification via Recurrent Neural Network},\n  journal   = {CoRR},\n  volume    = {abs/1508.01006},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1508.01006},\n  eprinttype = {arXiv},\n  eprint    = {1508.01006},\n  timestamp = {Fri, 04 Nov 2022 18:37:50 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/ZhangW15a.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63b81361c48390f07deb72cc", "disabled": false, "gated": false, "likes": 0, "downloads": 74, "createdAt": "2023-01-06T12:26:09.000Z"}, {"id": "metaeval/utilitarianism", "sha": "272e365c209e906bac69e0686fbdc8f55796cf51", "lastModified": "2023-01-06T13:41:50.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "metaeval", "description": "\"\"\"\n_HOMEPAGE = \"\"\n_LICENSE = \"Creative Commons Attribution-NonCommercial 4.0 International Public License\"\n\n# The HuggingFace dataset library don't host the datasets but only point to the original files\n# This can be an arbitrary nested dict/list of URLs (see below in `_split_generators` method)\n_URLs = {\"default\": \"https://www.dropbox.com/s/041prrjylv0tf0h/ethics.zip?dl=1\"}\n\n\nclass Imppres(datasets.GeneratorBasedBuilder):\n\n    VERSION = datasets.Version(\"1.1.0\")\n\n    def _info(self):\n        features = datasets.Features(\n            {\n                \"better_choice\": datasets.Value(\"string\"),\n                \"worst_choice\": datasets.Value(\"string\"),\n                \"comparison\": datasets.Value(\"string\"),\n                \"label\": datasets.Value(\"int32\"),\n            })\n        return datasets.DatasetInfo(\n            # This is the description that will appear on the datasets page.\n            description=_DESCRIPTION,\n            # This defines the different columns of the dataset and their types\n            features=features,  # Here we define them above because they are different between the two configurations\n            # If there's a common (input, target) tuple from the features,\n            # specify them here. They'll be used if as_supervised=True in\n            # builder.as_dataset.\n            supervised_keys=None,\n            # Homepage of the dataset for documentation\n            homepage=_HOMEPAGE,\n            # License for the dataset if available\n            license=_LICENSE,\n            # Citation for the dataset\n            citation=_CITATION,\n        )\n\n    def _split_generators(self, dl_manager):", "citation": null, "cardData": null, "siblings": [], "_id": "63b820c10d814c2001a3abf8", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2023-01-06T13:23:13.000Z"}, {"id": "neulab/odex", "sha": "c3741a66c486b1a23beefdf6c75b06dba288d4f9", "lastModified": "2023-02-10T18:01:34.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "size_categories:n<1K", "language:en", "language:es", "language:ja", "language:ru", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "neulab", "description": "ODEX is an Open-Domain EXecution-based NL-to-Code generation data benchmark. \nIt contains 945 samples with a total of 1,707 human-written test cases, \ncovering intents in four different natural languages -- 439 in English, 90 in Spanish, 164 in Japanese, and 252 in Russian.", "citation": "@article{wang2022execution,\n  title={Execution-Based Evaluation for Open-Domain Code Generation},\n  author={Wang, Zhiruo and Zhou, Shuyan and Fried, Daniel and Neubig, Graham},\n  journal={arXiv preprint arXiv:2212.10481},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63b83068fcdb2323b1d143bd", "disabled": false, "gated": false, "likes": 7, "downloads": 28, "createdAt": "2023-01-06T14:30:00.000Z"}, {"id": "shunk031/wrime", "sha": "3fb7212c389d7818b8e6179e2cdac762f2e081d9", "lastModified": "2023-01-15T03:39:01.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "language:ja", "license:unknown", "sentiment-analysis", "wrime", "region:us"], "private": false, "author": "shunk031", "description": "WRIME dataset is a new dataset for emotional intensity estimation with subjective and objective annotations.", "citation": "@inproceedings{kajiwara-etal-2021-wrime,\n    title = \"{WRIME}: A New Dataset for Emotional Intensity Estimation with Subjective and Objective Annotations\",\n    author = \"Kajiwara, Tomoyuki  and\n      Chu, Chenhui  and\n      Takemura, Noriko  and\n      Nakashima, Yuta  and\n      Nagahara, Hajime\",\n    booktitle = \"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jun,\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.naacl-main.169\",\n    doi = \"10.18653/v1/2021.naacl-main.169\",\n    pages = \"2095--2104\",\n    abstract = \"We annotate 17,000 SNS posts with both the writer{'}s subjective emotional intensity and the reader{'}s objective one to construct a Japanese emotion analysis dataset. In this study, we explore the difference between the emotional intensity of the writer and that of the readers with this dataset. We found that the reader cannot fully detect the emotions of the writer, especially anger and trust. In addition, experimental results in estimating the emotional intensity show that it is more difficult to estimate the writer{'}s subjective labels than the readers{'}. The large gap between the subjective and objective emotions imply the complexity of the mapping from a post to the subjective emotion intensities, which also leads to a lower performance with machine learning models.\",\n}\n\n@inproceedings{suzuki-etal-2022-japanese,\n    title = \"A {J}apanese Dataset for Subjective and Objective Sentiment Polarity Classification in Micro Blog Domain\",\n    author = \"Suzuki, Haruya  and\n      Miyauchi, Yuto  and\n      Akiyama, Kazuki  and\n      Kajiwara, Tomoyuki  and\n      Ninomiya, Takashi  and\n      Takemura, Noriko  and\n      Nakashima, Yuta  and\n      Nagahara, Hajime\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.759\",\n    pages = \"7022--7028\",\n    abstract = \"We annotate 35,000 SNS posts with both the writer{'}s subjective sentiment polarity labels and the reader{'}s objective ones to construct a Japanese sentiment analysis dataset. Our dataset includes intensity labels (\\textit{none}, \\textit{weak}, \\textit{medium}, and \\textit{strong}) for each of the eight basic emotions by Plutchik (\\textit{joy}, \\textit{sadness}, \\textit{anticipation}, \\textit{surprise}, \\textit{anger}, \\textit{fear}, \\textit{disgust}, and \\textit{trust}) as well as sentiment polarity labels (\\textit{strong positive}, \\textit{positive}, \\textit{neutral}, \\textit{negative}, and \\textit{strong negative}). Previous studies on emotion analysis have studied the analysis of basic emotions and sentiment polarity independently. In other words, there are few corpora that are annotated with both basic emotions and sentiment polarity. Our dataset is the first large-scale corpus to annotate both of these emotion labels, and from both the writer{'}s and reader{'}s perspectives. In this paper, we analyze the relationship between basic emotion intensity and sentiment polarity on our dataset and report the results of benchmarking sentiment polarity classification.\",\n}", "cardData": null, "siblings": [], "_id": "63bf78b482f7306d0752d4f6", "disabled": false, "gated": false, "likes": 12, "downloads": 1084, "createdAt": "2023-01-12T03:04:20.000Z"}, {"id": "lucasmccabe/logiqa", "sha": "3c19b0488d794d30c36f73d132d8a22e64f42f2e", "lastModified": "2023-02-08T01:51:31.000Z", "tags": ["task_categories:question-answering", "size_categories:1K<n<10K", "language:en", "region:us"], "private": false, "author": "lucasmccabe", "description": "LogiQA is constructed from the logical comprehension problems from publically available questions of the National Civil Servants Examination of China, which are designed to test the civil servant candidates\u2019 critical thinking and problem solving. This dataset includes the English versions only; the Chinese versions are available via the homepage/original source.", "citation": "@article{liu2020logiqa,\n  title={Logiqa: A challenge dataset for machine reading comprehension with logical reasoning},\n  author={Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},\n  journal={arXiv preprint arXiv:2007.08124},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "63bf893dc26a8a4d714d83a6", "disabled": false, "gated": false, "likes": 3, "downloads": 560, "paperswithcode_id": "logiqa", "createdAt": "2023-01-12T04:14:53.000Z"}, {"id": "nlp-thedeep/humset", "sha": "0dcf8311cae5a45dee0ded3fea676a1551c1cd68", "lastModified": "2023-05-25T17:14:31.000Z", "tags": ["task_categories:text-classification", "task_categories:text-retrieval", "task_categories:token-classification", "task_ids:multi-label-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "language:fr", "language:es", "license:apache-2.0", "humanitarian", "research", "analytical-framework", "multilabel", "humset", "humbert", "region:us"], "private": false, "author": "nlp-thedeep", "description": "HumSet is a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. HumSet is curated by humanitarian analysts and covers various disasters around the globe that occurred from 2018 to 2021 in 46 humanitarian response projects. The dataset consists of approximately 17K annotated documents in three languages of English, French, and Spanish, originally taken from publicly-available resources. For each document, analysts have identified informative snippets (entries) in respect to common humanitarian frameworks, and assigned one or many classes to each entry. See the our paper for details.", "citation": "@misc{https://doi.org/10.48550/arxiv.2210.04573,\n  doi = {10.48550/ARXIV.2210.04573},\n  url = {https://arxiv.org/abs/2210.04573},\n  author = {Fekih, Selim and Tamagnone, Nicol\u00f2 and Minixhofer, Benjamin and Shrestha, Ranjan and Contla, Ximena and Oglethorpe, Ewan and Rekabsaz, Navid},\n  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crisis Response},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {arXiv.org perpetual, non-exclusive license}\n}", "cardData": null, "siblings": [], "_id": "63c02eba95cbca1d8824b158", "disabled": false, "gated": false, "likes": 1, "downloads": 246, "createdAt": "2023-01-12T16:00:58.000Z"}, {"id": "DFKI-SLT/fabner", "sha": "88d756fe42b30317764ca8661c2c940dbb77b8ff", "lastModified": "2023-04-05T23:20:21.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "license:other", "manufacturing", "2000-2020", "region:us"], "private": false, "author": "DFKI-SLT", "description": "FabNER is a manufacturing text corpus of 350,000+ words for Named Entity Recognition.\nIt is a collection of abstracts obtained from Web of Science through known journals available in manufacturing process \nscience research.\nFor every word, there were categories/entity labels defined namely Material (MATE), Manufacturing Process (MANP), \nMachine/Equipment (MACEQ), Application (APPL), Features (FEAT), Mechanical Properties (PRO), Characterization (CHAR), \nParameters (PARA), Enabling Technology (ENAT), Concept/Principles (CONPRI), Manufacturing Standards (MANS) and \nBioMedical (BIOP). Annotation was performed in all categories along with the output tag in 'BIOES' format: \nB=Beginning, I-Intermediate, O=Outside, E=End, S=Single.", "citation": "@article{DBLP:journals/jim/KumarS22,\n  author    = {Aman Kumar and\n               Binil Starly},\n  title     = {\"FabNER\": information extraction from manufacturing process science\n               domain literature using named entity recognition},\n  journal   = {J. Intell. Manuf.},\n  volume    = {33},\n  number    = {8},\n  pages     = {2393--2407},\n  year      = {2022},\n  url       = {https://doi.org/10.1007/s10845-021-01807-x},\n  doi       = {10.1007/s10845-021-01807-x},\n  timestamp = {Sun, 13 Nov 2022 17:52:57 +0100},\n  biburl    = {https://dblp.org/rec/journals/jim/KumarS22.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63c1563294b28327f0e7ecf6", "disabled": false, "gated": false, "likes": 0, "downloads": 61, "createdAt": "2023-01-13T13:01:38.000Z"}, {"id": "ruanchaves/hatebr", "sha": "b286c1ab71508a8a54cc6e984fbae20ee5e5784c", "lastModified": "2023-04-13T13:39:40.000Z", "tags": ["task_categories:text-classification", "task_ids:hate-speech-detection", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:pt", "instagram", "doi:10.57967/hf/0274", "region:us"], "private": false, "author": "ruanchaves", "description": "HateBR is the first large-scale expert annotated corpus of Brazilian Instagram comments for hate speech and offensive language detection on the web and social media. The HateBR corpus was collected from Brazilian Instagram comments of politicians and manually annotated by specialists. It is composed of 7,000 documents annotated according to three different layers: a binary classification (offensive versus non-offensive comments), offensiveness-level (highly, moderately, and slightly offensive messages), and nine hate speech groups (xenophobia, racism, homophobia, sexism, religious intolerance, partyism, apology for the dictatorship, antisemitism, and fatphobia). Each comment was annotated by three different annotators and achieved high inter-annotator agreement. Furthermore, baseline experiments were implemented reaching 85% of F1-score outperforming the current literature models for the Portuguese language. Accordingly, we hope that the proposed expertly annotated corpus may foster research on hate speech and offensive language detection in the Natural Language Processing area.", "citation": "@inproceedings{vargas2022hatebr,\n  title={HateBR: A Large Expert Annotated Corpus of Brazilian Instagram Comments for Offensive Language and Hate Speech Detection},\n  author={Vargas, Francielle and Carvalho, Isabelle and de G{\\'o}es, Fabiana Rodrigues and Pardo, Thiago and Benevenuto, Fabr{\\'\\i}cio},\n  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},\n  pages={7174--7183},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63c3df65a8a2d3a59edce8ff", "disabled": false, "gated": false, "likes": 7, "downloads": 24, "createdAt": "2023-01-15T11:11:33.000Z"}, {"id": "ds4sd/DocLayNet", "sha": "5656dbae459cf15b3a112d46bb6b5484cabcd2d2", "lastModified": "2023-01-25T17:01:19.000Z", "tags": ["task_categories:object-detection", "task_categories:image-segmentation", "task_ids:instance-segmentation", "annotations_creators:crowdsourced", "size_categories:10K<n<100K", "license:other", "layout-segmentation", "COCO", "document-understanding", "PDF", "region:us"], "private": false, "author": "ds4sd", "description": "DocLayNet is a human-annotated document layout segmentation dataset from a broad variety of document sources.", "citation": "@article{doclaynet2022,\n  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis},  \n  doi = {10.1145/3534678.353904},\n  url = {https://arxiv.org/abs/2206.01062},\n  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "63c6539f7b72f89d803366fb", "disabled": false, "gated": false, "likes": 25, "downloads": 97, "createdAt": "2023-01-17T07:51:59.000Z"}, {"id": "bigcode/commitpack", "sha": "81d5ce0c103d9fe05879b50949ed41c40b96de69", "lastModified": "2023-08-20T07:13:13.000Z", "tags": ["language:code", "license:mit", "arxiv:2308.07124", "region:us"], "private": false, "author": "bigcode", "description": "CommitPack is is a 4TB dataset of commits scraped from GitHub repositories that are permissively licensed.", "citation": "@article{muennighoff2023octopack,\n      title={OctoPack: Instruction Tuning Code Large Language Models}, \n      author={Niklas Muennighoff and Qian Liu and Armel Zebaze and Qinkai Zheng and Binyuan Hui and Terry Yue Zhuo and Swayam Singh and Xiangru Tang and Leandro von Werra and Shayne Longpre},\n      journal={arXiv preprint arXiv:2308.07124},\n      year={2023}\n}", "cardData": null, "siblings": [], "_id": "63c68c3844a11268b1f565a2", "disabled": false, "gated": false, "likes": 39, "downloads": 141, "createdAt": "2023-01-17T11:53:28.000Z"}, {"id": "Hello-SimpleAI/HC3", "sha": "4d0ff18143b5a7e1b1e79beb540c04549d1e59d3", "lastModified": "2023-01-21T13:10:10.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:sentence-similarity", "task_categories:zero-shot-classification", "size_categories:10K<n<100K", "language:en", "language:zh", "license:cc-by-sa-4.0", "ChatGPT", "SimpleAI", "Detection", "OOD", "arxiv:2301.07597", "region:us"], "private": false, "author": "Hello-SimpleAI", "description": "Human ChatGPT Comparison Corpus (HC3)", "citation": "\\", "cardData": null, "siblings": [], "_id": "63c7fbb048eff25d4e6278fb", "disabled": false, "gated": false, "likes": 127, "downloads": 2343, "createdAt": "2023-01-18T14:01:20.000Z"}, {"id": "Hello-SimpleAI/HC3-Chinese", "sha": "09a687b8dc164b89e7df95abf15df3b216bc31c2", "lastModified": "2023-01-21T13:11:49.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:sentence-similarity", "task_categories:zero-shot-classification", "size_categories:10K<n<100K", "language:en", "language:zh", "license:cc-by-sa-4.0", "ChatGPT", "SimpleAI", "Detection", "OOD", "arxiv:2301.07597", "region:us"], "private": false, "author": "Hello-SimpleAI", "description": "Human ChatGPT Comparison Corpus (HC3) Chinese Version", "citation": "\\", "cardData": null, "siblings": [], "_id": "63c8003d48eff25d4e632392", "disabled": false, "gated": false, "likes": 105, "downloads": 201, "createdAt": "2023-01-18T14:20:45.000Z"}, {"id": "ruanchaves/b2w-reviews01", "sha": "4c0b2776d46015c384a6b28b16014a6c82a65587", "lastModified": "2023-01-20T18:22:37.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-analysis", "task_ids:sentiment-scoring", "task_ids:intent-classification", "task_ids:topic-classification", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100M<n<1B", "source_datasets:original", "language:pt", "license:cc-by-4.0", "reviews", "doi:10.57967/hf/0282", "region:us"], "private": false, "author": "ruanchaves", "description": "B2W-Reviews01 is an open corpus of product reviews. It contains more than 130k e-commerce customer reviews, collected from the Americanas.com website between January and May, 2018. B2W-Reviews01 offers rich information about the reviewer profile, such as gender, age, and geographical location. The corpus also has two different review rates", "citation": "@inproceedings{real2019b2w,\n  title={B2W-reviews01: an open product reviews corpus},\n  author={Real, Livy and Oshiro, Marcio and Mafra, Alexandre},\n  booktitle={STIL-Symposium in Information and Human Language Technology},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "63c8f77f8afd58b440924bf3", "disabled": false, "gated": false, "likes": 9, "downloads": 29, "createdAt": "2023-01-19T07:55:43.000Z"}, {"id": "DFKI-SLT/knowledge_net", "sha": "ea34fa84ef87766f2b34baf2909f80ce804671a8", "lastModified": "2023-01-19T09:16:32.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "task_ids:entity-linking-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:en", "knowledgenet", "region:us"], "private": false, "author": "DFKI-SLT", "description": "KnowledgeNet is a benchmark dataset for the task of automatically populating a knowledge base (Wikidata) with facts \nexpressed in natural language text on the web. KnowledgeNet provides text exhaustively annotated with facts, thus \nenabling the holistic end-to-end evaluation of knowledge base population systems as a whole, unlike previous benchmarks \nthat are more suitable for the evaluation of individual subcomponents (e.g., entity linking, relation extraction).\n\nFor instance, the dataset contains text expressing the fact (Gennaro Basile; RESIDENCE; Moravia), in the passage: \n\"Gennaro Basile was an Italian painter, born in Naples but active in the German-speaking countries. He settled at Br\u00fcnn, \nin Moravia, and lived about 1756...\"\n\nFor a description of the dataset and baseline systems, please refer to their \n[EMNLP paper](https://github.com/diffbot/knowledge-net/blob/master/knowledgenet-emnlp-cameraready.pdf).\n\nNote: This Datasetreader currently only supports the `train` split and does not contain negative examples", "citation": "@inproceedings{mesquita-etal-2019-knowledgenet,\n    title = \"{K}nowledge{N}et: A Benchmark Dataset for Knowledge Base Population\",\n    author = \"Mesquita, Filipe  and\n      Cannaviccio, Matteo  and\n      Schmidek, Jordan  and\n      Mirza, Paramita  and\n      Barbosa, Denilson\",\n    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D19-1069\",\n    doi = \"10.18653/v1/D19-1069\",\n    pages = \"749--758\",}", "cardData": null, "siblings": [], "_id": "63c90a408afd58b440943e79", "disabled": false, "gated": false, "likes": 2, "downloads": 17, "createdAt": "2023-01-19T09:15:44.000Z"}, {"id": "DFKI-SLT/cross_ner", "sha": "f3c058abf7fc79723797d978e70bd3e1ffc79966", "lastModified": "2023-01-19T09:17:38.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|conll2003", "language:en", "cross domain", "ai", "news", "music", "literature", "politics", "science", "arxiv:2012.04373", "region:us"], "private": false, "author": "DFKI-SLT", "description": "CrossNER is a fully-labeled collected of named entity recognition (NER) data spanning over five diverse domains \n(Politics, Natural Science, Music, Literature, and Artificial Intelligence) with specialized entity categories for \ndifferent domains. Additionally, CrossNER also includes unlabeled domain-related corpora for the corresponding five \ndomains.\n\nFor details, see the paper: \n[CrossNER: Evaluating Cross-Domain Named Entity Recognition](https://arxiv.org/abs/2012.04373)", "citation": "@article{liu2020crossner,\n      title={CrossNER: Evaluating Cross-Domain Named Entity Recognition}, \n      author={Zihan Liu and Yan Xu and Tiezheng Yu and Wenliang Dai and Ziwei Ji and Samuel Cahyawijaya and Andrea Madotto and Pascale Fung},\n      year={2020},\n      eprint={2012.04373},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "63c90a941e3e1bf4a2c0f466", "disabled": false, "gated": false, "likes": 0, "downloads": 44, "createdAt": "2023-01-19T09:17:08.000Z"}, {"id": "DFKI-SLT/cross_re", "sha": "eb583481a1fba449b36686456c60afa80cf8c7c3", "lastModified": "2023-01-19T09:19:12.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:extended|cross_ner", "language:en", "cross domain", "ai", "news", "music", "literature", "politics", "science", "arxiv:2210.09345", "region:us"], "private": false, "author": "DFKI-SLT", "description": "CrossRE is a new, freely-available crossdomain benchmark for RE, which comprises six distinct text domains and includes \nmultilabel annotations. It includes the following domains: news, politics, natural science, music, literature and \nartificial intelligence. The semantic relations are annotated on top of CrossNER (Liu et al., 2021), a cross-domain\ndataset for NER which contains domain-specific entity types.\nThe dataset contains 17 relation labels for the six domains: PART-OF, PHYSICAL, USAGE, ROLE, SOCIAL, \nGENERAL-AFFILIATION, COMPARE, TEMPORAL, ARTIFACT, ORIGIN, TOPIC, OPPOSITE, CAUSE-EFFECT, WIN-DEFEAT, TYPEOF, NAMED, and \nRELATED-TO.\n\nFor details, see the paper: https://arxiv.org/abs/2210.09345", "citation": "@inproceedings{bassignana-plank-2022-crossre,\n    title = \"Cross{RE}: A {C}ross-{D}omain {D}ataset for {R}elation {E}xtraction\",\n    author = \"Bassignana, Elisa and Plank, Barbara\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\n    year = \"2022\",\n    publisher = \"Association for Computational Linguistics\"\n}", "cardData": null, "siblings": [], "_id": "63c90af24c74c79fff5f28ba", "disabled": false, "gated": false, "likes": 0, "downloads": 88, "createdAt": "2023-01-19T09:18:42.000Z"}, {"id": "yhavinga/imdb_dutch", "sha": "db6e5361ae49622190a73e1a5bf32ec48360a2da", "lastModified": "2023-01-21T10:57:39.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:nl", "language:en", "license:other", "region:us"], "private": false, "author": "yhavinga", "description": "Large Movie Review Dataset translated to Dutch.\n\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 24,992 highly polar movie reviews for training, and 24,992 for testing. There is additional unlabeled data for use as well.\\", "citation": "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n  title     = {Learning Word Vectors for Sentiment Analysis},\n  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n  month     = {June},\n  year      = {2011},\n  address   = {Portland, Oregon, USA},\n  publisher = {Association for Computational Linguistics},\n  pages     = {142--150},\n  url       = {http://www.aclweb.org/anthology/P11-1015}\n}", "cardData": null, "siblings": [], "_id": "63cbb24cdf168f678c59b959", "disabled": false, "gated": false, "likes": 0, "downloads": 17, "paperswithcode_id": "imdb-movie-reviews", "createdAt": "2023-01-21T09:37:16.000Z"}, {"id": "imvladikon/parashoot", "sha": "a5de7c0293a6bfb83c5104b290b0902094f45976", "lastModified": "2023-01-22T00:32:13.000Z", "tags": ["task_categories:question-answering", "language:he", "arxiv:1606.05250", "arxiv:2109.11314", "region:us"], "private": false, "author": "imvladikon", "description": "A Hebrew question and answering dataset in the style of SQuAD, based on articles scraped from Wikipedia. The dataset contains a few thousand crowdsource-annotated pairs of questions and answers, in a setting suitable for few-shot learning.", "citation": "@inproceedings{keren2021parashoot,\n  title={ParaShoot: A Hebrew Question Answering Dataset},\n  author={Keren, Omri and Levy, Omer},\n  booktitle={Proceedings of the 3rd Workshop on Machine Reading for Question Answering},\n  pages={106--112},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "63cc7de128e49dcd9f704c37", "disabled": false, "gated": false, "likes": 0, "downloads": 33, "createdAt": "2023-01-22T00:05:53.000Z"}, {"id": "rcds/swiss_legislation", "sha": "1f8922b2a37c65ec38e79d7a4704c1b9b6f21f7e", "lastModified": "2023-07-20T07:36:07.000Z", "tags": ["task_categories:text-classification", "task_categories:translation", "size_categories:100K<n<1M", "language:de", "language:fr", "language:it", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains Swiss law articles", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "63cd9654ffc75ec5ce4b0e3b", "disabled": false, "gated": false, "likes": 5, "downloads": 24, "createdAt": "2023-01-22T20:02:28.000Z"}, {"id": "indonlp/NusaX-senti", "sha": "a450ba4b1b6d2216c3674d3e576b2e85ce729add", "lastModified": "2023-01-24T17:02:06.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ace", "language:ban", "language:bjn", "language:bug", "language:en", "language:id", "language:jv", "language:mad", "language:min", "language:nij", "language:su", "language:bbc", "license:cc-by-sa-4.0", "arxiv:2205.15960", "region:us"], "private": false, "author": "indonlp", "description": "NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.", "citation": "@misc{winata2022nusax,\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\n      year={2022},\n      eprint={2205.15960},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "63cfa4b592748c5fc3151c44", "disabled": false, "gated": false, "likes": 3, "downloads": 142, "createdAt": "2023-01-24T09:28:21.000Z"}, {"id": "DarthReca/california_burned_areas", "sha": "4e78b288c4ba0a1ba4cbedb2f5015dca62c41ac7", "lastModified": "2023-09-27T08:52:20.000Z", "tags": ["task_categories:image-segmentation", "size_categories:n<1K", "license:openrail", "climate", "doi:10.57967/hf/0389", "region:us"], "private": false, "author": "DarthReca", "description": "CaBuAr dataset contains images from Sentinel-2 satellites taken before and after a wildfire. \nThe ground truth masks are provided by the California Department of Forestry and Fire Protection and they are mapped on the images.", "citation": "@article{cabuar,\n  title={Ca{B}u{A}r: California {B}urned {A}reas dataset for delineation},\n  author={Rege Cambrin, Daniele and Colomba, Luca and Garza, Paolo},\n  journal={IEEE Geoscience and Remote Sensing Magazine},\n  doi={10.1109/MGRS.2023.3292467},\n  year={2023} \n}", "cardData": null, "siblings": [], "_id": "63cfb393c8350703b40d4c86", "disabled": false, "gated": false, "likes": 3, "downloads": 12, "createdAt": "2023-01-24T10:31:47.000Z"}, {"id": "jordyvl/DUDE_loader", "sha": "b3662175d3b2482d711f18559b7acc2a5bccc600", "lastModified": "2023-10-03T10:54:36.000Z", "tags": ["task_categories:question-answering", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "jordyvl", "description": "DUDE requires models to reason and understand about document layouts in multi-page images/PDFs to answer questions about them.\nSpecifically, models need to incorporate a new modality of layout present in the images/PDFs and reason\nover it to answer DUDE questions.", "citation": "@inproceedings{dude2023icdar,\n    title={ICDAR 2023 Challenge on Document UnderstanDing of Everything (DUDE)},\n    author={Van Landeghem, Jordy et . al.},\n    booktitle={Proceedings of the ICDAR},\n    year={2023}\n}", "cardData": null, "siblings": [], "_id": "63cff721c85f64d616da6bb8", "disabled": false, "gated": false, "likes": 8, "downloads": 134, "createdAt": "2023-01-24T15:20:01.000Z"}, {"id": "indonlp/NusaX-MT", "sha": "1d5773ce7f66782a89a6439a81261c84c298e2a3", "lastModified": "2023-01-24T17:21:03.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:ace", "language:ban", "language:bjn", "language:bug", "language:en", "language:id", "language:jv", "language:mad", "language:min", "language:nij", "language:su", "language:bbc", "license:cc-by-sa-4.0", "arxiv:2205.15960", "region:us"], "private": false, "author": "indonlp", "description": "NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.", "citation": "@misc{winata2022nusax,\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\n      year={2022},\n      eprint={2205.15960},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "63d00fdb900d17350bd4db05", "disabled": false, "gated": false, "likes": 5, "downloads": 104, "createdAt": "2023-01-24T17:05:31.000Z"}, {"id": "pierreguillou/DocLayNet-large", "sha": "38ff443244c1b496c33ed237d3d4468daf24265c", "lastModified": "2023-05-17T08:56:48.000Z", "tags": ["task_categories:object-detection", "task_categories:image-segmentation", "task_categories:token-classification", "task_ids:instance-segmentation", "annotations_creators:crowdsourced", "size_categories:10K<n<100K", "language:en", "language:de", "language:fr", "language:ja", "license:other", "DocLayNet", "COCO", "PDF", "IBM", "Financial-Reports", "Finance", "Manuals", "Scientific-Articles", "Science", "Laws", "Law", "Regulations", "Patents", "Government-Tenders", "object-detection", "image-segmentation", "token-classification", "arxiv:2206.01062", "region:us"], "private": false, "author": "pierreguillou", "description": "Accurate document layout analysis is a key requirement for high-quality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present \\textit{DocLayNet}, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide largeline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10\\% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet-trained models are more robust and thus the preferred choice for general-purpose document-layout analysis.", "citation": "@article{doclaynet2022,\n  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis},  \n  doi = {10.1145/3534678.353904},\n  url = {https://arxiv.org/abs/2206.01062},\n  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "63d1476cdae2635f21a09c0c", "disabled": false, "gated": false, "likes": 3, "downloads": 69, "createdAt": "2023-01-25T15:14:52.000Z"}, {"id": "pierreguillou/DocLayNet-small", "sha": "b61d29f477163034001472614dc97fb9614dddea", "lastModified": "2023-05-17T08:56:10.000Z", "tags": ["task_categories:object-detection", "task_categories:image-segmentation", "task_categories:token-classification", "task_ids:instance-segmentation", "annotations_creators:crowdsourced", "size_categories:1K<n<10K", "language:en", "language:de", "language:fr", "language:ja", "license:other", "DocLayNet", "COCO", "PDF", "IBM", "Financial-Reports", "Finance", "Manuals", "Scientific-Articles", "Science", "Laws", "Law", "Regulations", "Patents", "Government-Tenders", "object-detection", "image-segmentation", "token-classification", "arxiv:2206.01062", "region:us"], "private": false, "author": "pierreguillou", "description": "Accurate document layout analysis is a key requirement for high-quality PDF document conversion. With the recent availability of public, large ground-truth datasets such as PubLayNet and DocBank, deep-learning models have proven to be very effective at layout detection and segmentation. While these datasets are of adequate size to train such models, they severely lack in layout variability since they are sourced from scientific article repositories such as PubMed and arXiv only. Consequently, the accuracy of the layout segmentation drops significantly when these models are applied on more challenging and diverse layouts. In this paper, we present \\textit{DocLayNet}, a new, publicly available, document-layout annotation dataset in COCO format. It contains 80863 manually annotated pages from diverse data sources to represent a wide variability in layouts. For each PDF page, the layout annotations provide labelled bounding-boxes with a choice of 11 distinct classes. DocLayNet also provides a subset of double- and triple-annotated pages to determine the inter-annotator agreement. In multiple experiments, we provide smallline accuracy scores (in mAP) for a set of popular object detection models. We also demonstrate that these models fall approximately 10\\% behind the inter-annotator agreement. Furthermore, we provide evidence that DocLayNet is of sufficient size. Lastly, we compare models trained on PubLayNet, DocBank and DocLayNet, showing that layout predictions of the DocLayNet-trained models are more robust and thus the preferred choice for general-purpose document-layout analysis.", "citation": "@article{doclaynet2022,\n  title = {DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis},  \n  doi = {10.1145/3534678.353904},\n  url = {https://arxiv.org/abs/2206.01062},\n  author = {Pfitzmann, Birgit and Auer, Christoph and Dolfi, Michele and Nassar, Ahmed S and Staar, Peter W J},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "63d16b3f119416cdbe1704be", "disabled": false, "gated": false, "likes": 7, "downloads": 240, "createdAt": "2023-01-25T17:47:43.000Z"}, {"id": "cambridge-climb/BabyLM", "sha": "70476aa96efc5b7136f95eb81703ee2e20ee11fc", "lastModified": "2023-11-01T12:11:06.000Z", "tags": ["size_categories:10M<n<100M", "language:en", "language modeling", "cognitive modeling", "region:us"], "private": false, "author": "cambridge-climb", "description": "Dataset for the shared baby language modeling task.\nThe goal is to train a language model from scratch on this data which represents\nroughly the amount of text and speech data a young child observes.", "citation": null, "cardData": null, "siblings": [], "_id": "63d1edfb1d49cad8abb86302", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2023-01-26T03:05:31.000Z"}, {"id": "bigbio/bioid", "sha": "bac84af4fe88dddd3ac5867e4d67e76924b28659", "lastModified": "2023-02-17T14:54:28.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "The Bio-ID track focuses on entity tagging and ID assignment to selected bioentity types.\nThe task is to annotate text from figure legends with the entity types and IDs for taxon (organism), gene, protein, miRNA, small molecules,\ncellular components, cell types and cell lines, tissues and organs. The track draws on SourceData annotated figure\nlegends (by panel), in BioC format, and the corresponding full text articles (also BioC format) provided for context.", "citation": "@inproceedings{arighi2017bio,\n  title={Bio-ID track overview},\n  author={Arighi, Cecilia and Hirschman, Lynette and Lemberger, Thomas and Bayer, Samuel and Liechti, Robin and Comeau, Donald and Wu, Cathy},\n  booktitle={Proc. BioCreative Workshop},\n  volume={482},\n  pages={376},\n  year={2017}\n}", "cardData": null, "siblings": [], "_id": "63d487732424c652f601cd00", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2023-01-28T02:24:51.000Z"}, {"id": "juletxara/xstory_cloze", "sha": "6a88f6fc855b5b740125ed2cd7c73476dcaed853", "lastModified": "2023-05-21T16:04:36.000Z", "tags": ["task_categories:other", "annotations_creators:found", "language_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|story_cloze", "language:en", "language:ru", "language:zh", "language:es", "language:ar", "language:hi", "language:id", "language:te", "language:sw", "language:eu", "language:my", "license:cc-by-sa-4.0", "arxiv:2112.10668", "region:us"], "private": false, "author": "juletxara", "description": "XStoryCloze consists of the professionally translated version of the [English StoryCloze dataset](https://cs.rochester.edu/nlp/rocstories/) (Spring 2016 version) to 10 non-English languages. This dataset is released by Meta AI.", "citation": "@article{DBLP:journals/corr/abs-2112-10668,\n  author    = {Xi Victoria Lin and\n               Todor Mihaylov and\n               Mikel Artetxe and\n               Tianlu Wang and\n               Shuohui Chen and\n               Daniel Simig and\n               Myle Ott and\n               Naman Goyal and\n               Shruti Bhosale and\n               Jingfei Du and\n               Ramakanth Pasunuru and\n               Sam Shleifer and\n               Punit Singh Koura and\n               Vishrav Chaudhary and\n               Brian O'Horo and\n               Jeff Wang and\n               Luke Zettlemoyer and\n               Zornitsa Kozareva and\n               Mona T. Diab and\n               Veselin Stoyanov and\n               Xian Li},\n  title     = {Few-shot Learning with Multilingual Language Models},\n  journal   = {CoRR},\n  volume    = {abs/2112.10668},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2112.10668},\n  eprinttype = {arXiv},\n  eprint    = {2112.10668},\n  timestamp = {Tue, 04 Jan 2022 15:59:27 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-10668.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63d5361043a3934c5de1df55", "disabled": false, "gated": false, "likes": 3, "downloads": 18282, "createdAt": "2023-01-28T14:49:52.000Z"}, {"id": "rcds/swiss_court_view_generation", "sha": "d92b0ba5320361f8ef26042bf822477a56dbd32b", "lastModified": "2023-07-20T07:35:29.000Z", "tags": ["task_categories:text-generation", "size_categories:100K<n<1M", "language:de", "language:fr", "language:it", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains court decision for court view generation task.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "63d722649b36e4c8a35b00b1", "disabled": false, "gated": false, "likes": 2, "downloads": 63, "createdAt": "2023-01-30T01:50:28.000Z"}, {"id": "tobiolatunji/afrispeech-200", "sha": "b538c6e111914a812af28ff677f8cffc9b404b7d", "lastModified": "2023-11-20T09:20:34.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:expert-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "tobiolatunji", "description": "AFRISPEECH-200 is a 200hr Pan-African speech corpus for clinical and general domain English accented ASR; \na dataset with 120 African accents from 13 countries and 2,463 unique African speakers. \nOur goal is to raise awareness for and advance Pan-African English ASR research, \nespecially for the clinical domain.", "citation": "TBD", "cardData": null, "siblings": [], "_id": "63d845f6143d89ad809480a9", "disabled": false, "gated": false, "likes": 9, "downloads": 72, "createdAt": "2023-01-30T22:34:30.000Z"}, {"id": "joelniklaus/MultiLegalPileWikipediaFiltered", "sha": "483f6c8f83c1ef721461f24751c6fd5ccd061a59", "lastModified": "2023-03-28T19:23:38.000Z", "tags": ["task_categories:fill-mask", "annotations_creators:other", "language_creators:found", "multilinguality:multilingual", "size_categories:10M<n<100M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:cc-by-4.0", "region:us"], "private": false, "author": "joelniklaus", "description": "A filtered version of the MultiLegalPile dataset, together with wikipedia articles.", "citation": "", "cardData": null, "siblings": [], "_id": "63d98d5d4d48d0f19a150b6b", "disabled": false, "gated": false, "likes": 2, "downloads": 170, "createdAt": "2023-01-31T21:51:25.000Z"}, {"id": "lukaemon/bbh", "sha": "2ae1a82e7907ca4447874ede02df3289f94ecce8", "lastModified": "2023-02-02T01:14:46.000Z", "tags": ["region:us"], "private": false, "author": "lukaemon", "description": "BBH focuses on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the task for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average humanrater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.", "citation": "@article{suzgun2022challenging,\n  title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},\n  author={Suzgun, Mirac and Scales, Nathan and Sch{\\\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and and Wei, Jason},\n  journal={arXiv preprint arXiv:2210.09261},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63da18ebaa68107243401b0d", "disabled": false, "gated": false, "likes": 20, "downloads": 37366, "createdAt": "2023-02-01T07:46:51.000Z"}, {"id": "lukaemon/mmlu", "sha": "3b5949d968d1fbc3facce39769ba00aa13404ffc", "lastModified": "2023-02-02T02:38:44.000Z", "tags": ["region:us"], "private": false, "author": "lukaemon", "description": "Measuring Massive Multitask Language Understanding by Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt (ICLR 2021).", "citation": "@article{hendryckstest2021,\n  title={Measuring Massive Multitask Language Understanding},\n  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},\n  journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "63db06f354fa80c534a8d0bc", "disabled": false, "gated": false, "likes": 26, "downloads": 545458, "createdAt": "2023-02-02T00:42:27.000Z"}, {"id": "mikolaj-p/MOCKS-test", "sha": "57c902446f3660852c7e5dc261e42d09b997004a", "lastModified": "2023-10-27T14:20:12.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "mikolaj-p", "description": "Multilingual Open Custom Keyword Spotting Testset (MOCKS) is a comprehensive \naudio testset for evaluation and benchmarking Open-Vocabulary Keyword Spotting (OV-KWS) models.", "citation": "@inproceedings{pudo23_interspeech,\n  author={Miko\u0142aj Pudo and Mateusz Wosik and Adam Cie\u015blak and Justyna Krzywdziak and Bo\u017cena \u0141ukasiak and Artur Janicki},\n  title={{MOCKS} 1.0: Multilingual Open Custom Keyword Spotting Testset},\n  year={2023},\n  booktitle={Proc. Interspeech 2023},\n}", "cardData": null, "siblings": [], "_id": "63dcee3014d9b75ff138307e", "disabled": false, "gated": false, "likes": 0, "downloads": 11, "createdAt": "2023-02-03T11:21:20.000Z"}, {"id": "biu-nlp/qa_adj", "sha": "34b2b51c0df49436561f667327f17cf2254236d9", "lastModified": "2023-02-06T21:23:15.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "biu-nlp", "description": "The dataset contains question-answer pairs to capture adjectival semantics.  \nThis dataset was annotated by selected workers from Amazon Mechanical Turk.", "citation": null, "cardData": null, "siblings": [], "_id": "63e0ed27b93f799a88b0eb6d", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2023-02-06T12:05:59.000Z"}, {"id": "sartajekram/BanglaRQA", "sha": "f55f490265170e69073ae2d62c9c79ff405be6e6", "lastModified": "2023-05-06T19:04:32.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:human", "size_categories:10K<n<100K", "language:bn", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "sartajekram", "description": "BanglaRQA is a human-annotated Bangla Question Answering (QA) dataset with diverse question-answer types.", "citation": "@inproceedings{ekram-etal-2022-banglarqa,\n    title = \"{B}angla{RQA}: A Benchmark Dataset for Under-resourced {B}angla Language Reading Comprehension-based Question Answering with Diverse Question-Answer Types\",\n    author = \"Ekram, Syed Mohammed Sartaj  and\n      Rahman, Adham Arik  and\n      Altaf, Md. Sajid  and\n      Islam, Mohammed Saidul  and\n      Rahman, Mehrab Mustafy  and\n      Rahman, Md Mezbaur  and\n      Hossain, Md Azam  and\n      Kamal, Abu Raihan Mostofa\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.findings-emnlp.186\",\n    pages = \"2518--2532\",\n    abstract = \"High-resource languages, such as English, have access to a plethora of datasets with various question-answer types resembling real-world reading comprehension. However, there is a severe lack of diverse and comprehensive question-answering datasets in under-resourced languages like Bangla. The ones available are either translated versions of English datasets with a niche answer format or created by human annotations focusing on a specific domain, question type, or answer type. To address these limitations, this paper introduces BanglaRQA, a reading comprehension-based Bangla question-answering dataset with various question-answer types. BanglaRQA consists of 3,000 context passages and 14,889 question-answer pairs created from those passages. The dataset comprises answerable and unanswerable questions covering four unique categories of questions and three types of answers. In addition, this paper also implemented four different Transformer models for question-answering on the proposed dataset. The best-performing model achieved an overall 62.42{\\%} EM and 78.11{\\%} F1 score. However, detailed analyses showed that the performance varies across question-answer types, leaving room for substantial improvement of the model performance. Furthermore, we demonstrated the effectiveness of BanglaRQA as a training resource by showing strong results on the bn{\\_}squad dataset. Therefore, BanglaRQA has the potential to contribute to the advancement of future research by enhancing the capability of language models. The dataset and codes are available at https://github.com/sartajekram419/BanglaRQA\",\n}", "cardData": null, "siblings": [], "_id": "63e2668604167c095903b8ec", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2023-02-07T14:56:06.000Z"}, {"id": "allenai/lila", "sha": "156e8fd397b70d35a96fe05721a463d265e69f4e", "lastModified": "2023-03-15T18:36:28.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "allenai", "description": "L\u012bla is a comprehensive benchmark for mathematical reasoning with over 140K natural language questions annotated with Python programs and natural language instructions. The data set comes with multiple splits: L\u012bla-IID (train, dev, test), L\u012bla-OOD (train, dev, test), and L\u012bla-Robust.", "citation": "@INPROCEEDINGS{Mishra2022Lila,\n  author = {\n    Swaroop Mishra \n      and Matthew Finlayson \n      and Pan Lu \n      and Leonard Tang \n      and Sean Welleck \n      and Chitta Baral \n      and Tanmay Rajpurohit \n      and Oyvind Tafjord \n      and Ashish Sabharwal \n      and Peter Clark \n      and Ashwin Kalyan},\n  title = {Lila: A Unified Benchmark for Mathematical Reasoning},\n  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "63e41697a6002a8f78ef46fa", "disabled": false, "gated": false, "likes": 15, "downloads": 680, "createdAt": "2023-02-08T21:39:35.000Z"}, {"id": "liwu/MNBVC", "sha": "273144c9ac4a06d1f20e6f0707e13c9ed59e77db", "lastModified": "2023-11-25T02:54:05.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:unknown", "source_datasets:original", "language:zh", "license:mit", "region:us"], "private": false, "author": "liwu", "description": "MNBVC: Massive Never-ending BT Vast Chinese corpus", "citation": "\\", "cardData": null, "siblings": [], "_id": "63ea428f5de6361c8dd3cbcf", "disabled": false, "gated": false, "likes": 295, "downloads": 2079, "createdAt": "2023-02-13T14:00:47.000Z"}, {"id": "HiTZ/euscrawl", "sha": "6b37ead34d1c8a5e2fc3dbc395e18bba25be1627", "lastModified": "2023-02-14T19:00:22.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:10M<n<100M", "source_datasets:original", "language:eu", "license:cc", "high-quality", "scraping", "arxiv:2203.08111", "region:us"], "private": false, "author": "HiTZ", "description": "EusCrawl (http://www.ixa.eus/euscrawl/) is a high-quality corpus for\nBasque comprising 12.5 million documents and 423 million tokens,\ntotalling 2.1 GiB of uncompressed text. EusCrawl was built using\nad-hoc scrapers to extract text from 33 Basque websites with\nhigh-quality content, resulting in cleaner text compared to general\npurpose approaches.\n\nWe do not claim ownership of any document in the corpus. All documents\nwe collected were published under a Creative Commons license in their\noriginal website, and the specific variant can be found in the\n\"license\" field of each document. Should you consider\nthat our data contains material that is owned by you and you would not\nlike to be reproduced here, please contact Aitor Soroa at\na.soroa@ehu.eus.\n\nFor more details about the corpus, refer to our paper \"Artetxe M.,\nAldabe I., Agerri R., Perez-de-Vi\u00f1aspre O, Soroa A. (2022). Does\nCorpus Quality Really Matter for Low-Resource Languages?\"\nhttps://arxiv.org/abs/2203.08111\n\nIf you use our corpus or models for academic research, please cite the paper in question:\n@misc{artetxe2022euscrawl,\n      title={Does corpus quality really matter for low-resource languages?},\n      author={Mikel Artetxe, Itziar Aldabe, Rodrigo Agerri, Olatz Perez-de-Vi\u00f1aspre, Aitor Soroa},\n      year={2022},\n      eprint={2203.08111},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\nFor questions please contact Aitor Soroa at a.soroa@ehu.eus.", "citation": "@misc{artetxe2022euscrawl,\n    title={Does corpus quality really matter for low-resource languages?},\n    author={Mikel Artetxe, Itziar Aldabe, Rodrigo Agerri,\n    Olatz Perez-de-Vi\u00f1aspre, Aitor Soroa},\n    year={2022},\n    eprint={2203.08111},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "63ea99e6e35a4dfbb8e1d7c9", "disabled": false, "gated": false, "likes": 2, "downloads": 23, "createdAt": "2023-02-13T20:13:26.000Z"}, {"id": "Krystalan/xmediasum", "sha": "c1bbe7aba13342ada22d029d37bded9f7c24adb5", "lastModified": "2023-02-15T13:58:33.000Z", "tags": ["task_categories:summarization", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:zh", "language:de", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "Krystalan", "description": "We present XMediaSum, a cross-lingual dialogue summarization dataset with 40K English(dialogues)->Chinese(summaries) and 40K English (dialogues)->German(summaries) samples. XMediaSum is created by manually translating the English summaries of MediaSum (a English monolingual dialogue summarization dataset) to both Chinese and German.", "citation": "@inproceedings{wang-etal-2022-clidsum,\n    title = \"{C}lid{S}um: A Benchmark Dataset for Cross-Lingual Dialogue Summarization\",\n    author = \"Wang, Jiaan  and\n      Meng, Fandong  and\n      Lu, Ziyao  and\n      Zheng, Duo  and\n      Li, Zhixu  and\n      Qu, Jianfeng  and\n      Zhou, Jie\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.emnlp-main.526\",\n    pages = \"7716--7729\",\n    abstract = \"We present ClidSum, a benchmark dataset towards building cross-lingual summarization systems on dialogue documents. It consists of 67k+ dialogue documents and 112k+ annotated summaries in different target languages. Based on the proposed ClidSum, we introduce two benchmark settings for supervised and semi-supervised scenarios, respectively. We then build various baseline systems in different paradigms (pipeline and end-to-end) and conduct extensive experiments on ClidSum to provide deeper analyses. Furthermore, we propose mDialBART which extends mBART via further pre-training, where the multiple objectives help the pre-trained model capture the structural characteristics as well as key content in dialogues and the transformation from source to the target language. Experimental results show the superiority of mDialBART, as an end-to-end model, outperforms strong pipeline models on ClidSum. Finally, we discuss specific challenges that current approaches faced with this task and give multiple promising directions for future research. We have released the dataset and code at https://github.com/krystalan/ClidSum.\",\n}", "cardData": null, "siblings": [], "_id": "63ec9cdea27318305ef2d9f3", "disabled": false, "gated": false, "likes": 1, "downloads": 29, "createdAt": "2023-02-15T08:50:38.000Z"}, {"id": "GEM/xmediasum", "sha": "15296bd1c7a8b69a5a9771e37f0f2686dbc0e9b1", "lastModified": "2023-02-15T14:01:56.000Z", "tags": ["task_categories:summarization", "annotations_creators:expert-generated", "language_creators:crowdsourced", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "language:zh", "language:de", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "GEM", "description": "\\\r\nWe present XMediaSum, a cross-lingual dialogue summarization dataset with 40K English(dialogues)->Chinese(summaries) and 40K English (dialogues)->German(summaries) samples. XMediaSum is created by manually translating the English summaries of MediaSum (a English monolingual dialogue summarization dataset) to both Chinese and German.", "citation": "\\\r\n@inproceedings{wang-etal-2022-clidsum,\r\n    title = \"{C}lid{S}um: A Benchmark Dataset for Cross-Lingual Dialogue Summarization\",\r\n    author = \"Wang, Jiaan  and\r\n      Meng, Fandong  and\r\n      Lu, Ziyao  and\r\n      Zheng, Duo  and\r\n      Li, Zhixu  and\r\n      Qu, Jianfeng  and\r\n      Zhou, Jie\",\r\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\r\n    month = dec,\r\n    year = \"2022\",\r\n    address = \"Abu Dhabi, United Arab Emirates\",\r\n    publisher = \"Association for Computational Linguistics\",\r\n    url = \"https://aclanthology.org/2022.emnlp-main.526\",\r\n    pages = \"7716--7729\",\r\n    abstract = \"We present ClidSum, a benchmark dataset towards building cross-lingual summarization systems on dialogue documents. It consists of 67k+ dialogue documents and 112k+ annotated summaries in different target languages. Based on the proposed ClidSum, we introduce two benchmark settings for supervised and semi-supervised scenarios, respectively. We then build various baseline systems in different paradigms (pipeline and end-to-end) and conduct extensive experiments on ClidSum to provide deeper analyses. Furthermore, we propose mDialBART which extends mBART via further pre-training, where the multiple objectives help the pre-trained model capture the structural characteristics as well as key content in dialogues and the transformation from source to the target language. Experimental results show the superiority of mDialBART, as an end-to-end model, outperforms strong pipeline models on ClidSum. Finally, we discuss specific challenges that current approaches faced with this task and give multiple promising directions for future research. We have released the dataset and code at https://github.com/krystalan/ClidSum.\",\r\n}", "cardData": null, "siblings": [], "_id": "63ece5a9a27318305ef7a3bb", "disabled": false, "gated": false, "likes": 4, "downloads": 56, "createdAt": "2023-02-15T14:01:13.000Z"}, {"id": "TobiTob/CityLearn", "sha": "1653a2b77349fb0dbf41c677bc74fa3bad7874b2", "lastModified": "2023-06-27T11:14:53.000Z", "tags": ["region:us"], "private": false, "author": "TobiTob", "description": "The dataset consists of tuples of (observations, actions, rewards, dones) sampled by agents\n    interacting with the CityLearn 2022 Phase 1 environment (only first 5 buildings)", "citation": null, "cardData": null, "siblings": [], "_id": "63ee1eb46349d1a67064af9e", "disabled": false, "gated": false, "likes": 1, "downloads": 32, "createdAt": "2023-02-16T12:16:52.000Z"}, {"id": "shmuhammad/AfriSenti-twitter-sentiment", "sha": "b52e930385cf5ed7f063072c3f7bd17b599a16cf", "lastModified": "2023-09-03T09:59:15.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-analysis", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:100K<n<1M", "language:amh", "language:ary", "language:ar", "language:arq", "language:hau", "language:ibo", "language:kin", "language:por", "language:pcm", "language:eng", "language:oro", "language:swa", "language:tir", "language:twi", "language:tso", "language:yor", "sentiment analysis, Twitter, tweets", "sentiment", "arxiv:2302.08956", "arxiv:2304.06845", "arxiv:2201.08277", "region:us"], "private": false, "author": "shmuhammad", "description": "AfriSenti is the largest sentiment analysis benchmark dataset for under-represented African languages---covering 110,000+ annotated tweets in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and yoruba).", "citation": "@inproceedings{muhammad-etal-2023-semeval,\n  title=\"{S}em{E}val-2023 Task 12:  Sentiment Analysis for African Languages ({A}fri{S}enti-{S}em{E}val)\",\n  author=\"Muhammad, Shamsuddeen Hassan and\n   Yimam, Seid and \n   Abdulmumin, Idris and \n   Ahmad, Ibrahim Sa'id  and \n   Ousidhoum, Nedjma, and\n   Ayele, Abinew, and \n   Adelani, David and \n   Ruder, Sebastian and  \n   Beloucif, Meriem and \n   Bello, Shehu Bello and \n   Mohammad, Saif M.\",\n  booktitle=\"Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)\",\n  month=jul,\n  year=\"2023\",\n}", "cardData": null, "siblings": [], "_id": "63ee99dc39dac6f3a6525a95", "disabled": false, "gated": false, "likes": 3, "downloads": 325, "createdAt": "2023-02-16T21:02:20.000Z"}, {"id": "Gholamreza/pquad", "sha": "2d5d84423618ee487df27eb37547081d9283855b", "lastModified": "2023-02-18T15:00:06.000Z", "tags": ["task_categories:question-answering", "task_ids:open-domain-qa", "task_ids:extractive-qa", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:fa", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "Gholamreza", "description": "\\\\\\PQuAD: PQuAD is a crowd-sourced reading comprehension dataset on Persian Language.", "citation": "@article{darvishi2022pquad,\n  title={PQuAD: A Persian Question Answering Dataset},\n  author={Darvishi, Kasra and Shahbodagh, Newsha and Abbasiantaeb, Zahra and Momtazi, Saeedeh},\n  journal={arXiv preprint arXiv:2202.06219},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "63f0da713d39ac5108fe98b4", "disabled": false, "gated": false, "likes": 3, "downloads": 42, "paperswithcode_id": "squad", "createdAt": "2023-02-18T14:02:25.000Z"}, {"id": "nanaaaa/emotion_chinese_english", "sha": "ca4bd93ea3531eac2269cb8d8d5ff3ff088397e3", "lastModified": "2023-03-05T10:36:14.000Z", "tags": ["task_categories:text-classification", "language:zh", "language:en", "doi:10.57967/hf/1019", "region:us"], "private": false, "author": "nanaaaa", "description": "The emotion_chinese_english dataset is a multilingual emotion dataset annotated by language experts under a project. The dataset can be used for tasks such as multilingual (Chinese and English) emotion classification and identification.", "citation": null, "cardData": null, "siblings": [], "_id": "63f374940bdc4e0839f520b6", "disabled": false, "gated": false, "likes": 6, "downloads": 17, "createdAt": "2023-02-20T13:24:36.000Z"}, {"id": "t0mmy/livedoor_news_corpus", "sha": "4e95e90e6eb902a76c5f545c748510ef90342a22", "lastModified": "2023-03-12T02:25:37.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:ja", "license:cc", "region:us"], "private": false, "author": "t0mmy", "description": "This corpus is from news stories in \u201clivedoor news\u201d administered by NHN Japan and only the following ones that are governed by Creative Commons license were collected and had as many HTML tags as possible deleted.", "citation": null, "cardData": null, "siblings": [], "_id": "63f4889f55a70e9901dcba6a", "disabled": false, "gated": false, "likes": 1, "downloads": 11, "createdAt": "2023-02-21T09:02:23.000Z"}, {"id": "ddrg/super_eurlex", "sha": "2c1a5aed75bcab52d504a9ee595839e5e27c86ad", "lastModified": "2023-11-14T06:18:46.000Z", "tags": ["task_categories:text-classification", "task_categories:fill-mask", "task_ids:multi-class-classification", "task_ids:multi-label-classification", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:bg", "language:cs", "language:da", "language:de", "language:el", "language:en", "language:es", "language:et", "language:fi", "language:fr", "language:ga", "language:hr", "language:hu", "language:it", "language:lt", "language:lv", "language:mt", "language:nl", "language:pl", "language:pt", "language:ro", "language:sk", "language:sl", "language:sv", "license:mit", "legal documents", "corpus", "eurlex", "html", "region:us"], "private": false, "author": "ddrg", "description": "Super-EURLEX dataset containing legal documents from multiple languages.\n                The datasets are build/scrapped from the EURLEX Website [https://eur-lex.europa.eu/homepage.html]\n                With one split per language and sector, because the available features (metadata) differs for each \n                sector. Therefore, each sample contains the content of a full legal document in up to 3 different \n                formats. Those are raw HTML and cleaned HTML (if the HTML format was available on the EURLEX website \n                during the scrapping process) and cleaned text.\n                The cleaned text should be available for each sample and was extracted from HTML or PDF.\n                'Cleaned' HTML stands here for minor cleaning that was done to preserve to a large extent the necessary \n                HTML information like table structures while removing unnecessary complexity which was introduced to the \n                original documents due to actions like writing each sentence into a new object. \n                Additionally, each sample contains metadata which was scrapped on the fly, this implies the following \n                2 things. First, not every sector contains the same metadata. Second, most metadata might be \n                irrelevant for most use cases. \n                In our minds the most interesting metadata is the celex-id which is used to identify the legal \n                document at hand, but also contains a lot of information about the document \n                see [https://eur-lex.europa.eu/content/tools/eur-lex-celex-infographic-A3.pdf] as well as eurovoc-\n                concepts, which are labels that define the content of the documents. \n                Eurovoc-Concepts are, for example, only available for the sectors 1, 2, 3, 4, 5, 6, 9, C, and E.\n                The Naming of most metadata is kept like it was on the eurlex website, except for converting \n                it to lower case and replacing whitespaces with '_'.", "citation": "", "cardData": null, "siblings": [], "_id": "63f7206d4313d4ea9dbee9df", "disabled": false, "gated": false, "likes": 1, "downloads": 255, "createdAt": "2023-02-23T08:14:37.000Z"}, {"id": "hezarai/sentiment-dksf", "sha": "2d2e8c704b810f97afe76188e66ab4708735cda4", "lastModified": "2023-09-02T10:33:35.000Z", "tags": ["task_categories:text-classification", "language:fa", "region:us"], "private": false, "author": "hezarai", "description": "Sentiment analysis dataset extracted and labeled from Digikala and Snapp Food comments", "citation": null, "cardData": null, "siblings": [], "_id": "63f893ef4a7daa003c9e221f", "disabled": false, "gated": false, "likes": 0, "downloads": 127, "createdAt": "2023-02-24T10:39:43.000Z"}, {"id": "shunk031/JGLUE", "sha": "50e79c314a7603ebc92236b66a0973d51a00ed8c", "lastModified": "2023-09-26T12:41:51.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:sentence-similarity", "task_categories:text-classification", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:ja", "license:cc-by-4.0", "MARC", "CoLA", "STS", "NLI", "SQuAD", "CommonsenseQA", "arxiv:2309.12676", "region:us"], "private": false, "author": "shunk031", "description": "JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.\\", "citation": "@inproceedings{kurihara-lrec-2022-jglue,\n  title={JGLUE: Japanese general language understanding evaluation},\n  author={Kurihara, Kentaro and Kawahara, Daisuke and Shibata, Tomohide},\n  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},\n  pages={2957--2966},\n  year={2022},\n  url={https://aclanthology.org/2022.lrec-1.317/}\n}\n@inproceedings{kurihara-nlp-2022-jglue,\n  title={JGLUE: \u65e5\u672c\u8a9e\u8a00\u8a9e\u7406\u89e3\u30d9\u30f3\u30c1\u30de\u30fc\u30af},\n  author={\u6817\u539f\u5065\u592a\u90ce and \u6cb3\u539f\u5927\u8f14 and \u67f4\u7530\u77e5\u79c0},\n  booktitle={\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a\u7b2c28\u56de\u5e74\u6b21\u5927\u4f1a},\n  pages={2023--2028},\n  year={2022},\n  url={https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/E8-4.pdf},\n  note={in Japanese}\n}", "cardData": null, "siblings": [], "_id": "63fc6a4d56ca43ced7169d0b", "disabled": false, "gated": false, "likes": 33, "downloads": 34612, "createdAt": "2023-02-27T08:31:09.000Z"}, {"id": "MultiCoNER/multiconer_v2", "sha": "4be2d62c912977ee26ed14d2553a4fe17ca3d980", "lastModified": "2023-07-06T18:37:15.000Z", "tags": ["task_categories:token-classification", "size_categories:100K<n<1M", "language:bn", "language:zh", "language:de", "language:en", "language:es", "language:fa", "language:fr", "language:hi", "language:it", "language:pt", "language:sv", "language:uk", "license:cc-by-4.0", "multiconer", "ner", "multilingual", "named entity recognition", "fine-grained ner", "region:us"], "private": false, "author": "MultiCoNER", "description": "Complex named entities (NE), like the titles of creative works, are not simple nouns and pose challenges for NER systems (Ashwini and Choi, 2014). They can take the form of any linguistic constituent, like an imperative clause (\u201cDial M for Murder\u201d), and do not look like traditional NEs (Persons, Locations, etc.). This syntactic ambiguity makes it challenging to recognize them based on context. We organized the MultiCoNER task (Malmasi et al., 2022) at SemEval-2022 to address these challenges in 11 languages, receiving a very positive community response with 34 system papers. Results confirmed the challenges of processing complex and long-tail NEs: even the largest pre-trained Transformers did not achieve top performance without external knowledge. The top systems infused transformers with knowledge bases and gazetteers. However, such solutions are brittle against out of knowledge-base entities and noisy scenarios like the presence of spelling mistakes and typos. We propose MultiCoNER II which represents novel challenges through new tasks that emphasize the shortcomings of the current top models.\n\nMultiCoNER II features complex NER in these languages:\n\n1. English\n2. Spanish\n3. Hindi\n4. Bangla\n5. Chinese\n6. Swedish\n7. Farsi\n8. French\n9. Italian\n10. Portugese\n11. Ukranian\n12. German\n\nFor more details see https://multiconer.github.io/\n\n## References\n* Sandeep Ashwini and Jinho D. Choi. 2014. Targetable named entity recognition in social media. CoRR, abs/1408.0782.\n* Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, Oleg Rokhlenko. 2022. SemEval-2022 Task 11: Multilingual Complex Named Entity Recognition (MultiCoNER).", "citation": "@inproceedings{multiconer2-report,\n    title={{SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2)}},\n    author={Fetahu, Besnik and Kar, Sudipta and Chen, Zhiyu and Rokhlenko, Oleg and Malmasi, Shervin},\n    booktitle={Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)},\n    year={2023},\n    publisher={Association for Computational Linguistics},\n}\n\n@article{multiconer2-data,\n    title={{MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition}},\n    author={Fetahu, Besnik and Chen, Zhiyu and Kar, Sudipta and Rokhlenko, Oleg and Malmasi, Shervin},\n    year={2023},\n}", "cardData": null, "siblings": [], "_id": "63fea2ec7a7f94a38ae7a365", "disabled": false, "gated": false, "likes": 7, "downloads": 116, "createdAt": "2023-03-01T00:57:16.000Z"}, {"id": "HuggingFaceH4/hhh_alignment", "sha": "2a19e6c72f82fe5c7915d9197ab196ecd5ef4d39", "lastModified": "2023-03-02T10:13:04.000Z", "tags": ["task_categories:multiple-choice", "language:en", "license:apache-2.0", "human-feedback", "arxiv:2112.00861", "region:us"], "private": false, "author": "HuggingFaceH4", "description": "This task evaluates language models on alignment, broken down into categories of helpfulness, honesty/accuracy, harmlessness, and other.  The evaluations imagine a conversation between a person and a language model assistant.  The goal with these evaluations is that on careful reflection, the vast majority of people would agree that the chosen response is better (more helpful, honest, and harmless) than the alternative offered for comparison.  The task is formatted in terms of binary choices, though many of these have been broken down from a ranked ordering of three or four possible responses.", "citation": "@article{DBLP:journals/corr/abs-2112-00861,\n  author    = {Amanda Askell and\n               Yuntao Bai and\n               Anna Chen and\n               Dawn Drain and\n               Deep Ganguli and\n               Tom Henighan and\n               Andy Jones and\n               Nicholas Joseph and\n               Benjamin Mann and\n               Nova DasSarma and\n               Nelson Elhage and\n               Zac Hatfield{-}Dodds and\n               Danny Hernandez and\n               Jackson Kernion and\n               Kamal Ndousse and\n               Catherine Olsson and\n               Dario Amodei and\n               Tom B. Brown and\n               Jack Clark and\n               Sam McCandlish and\n               Chris Olah and\n               Jared Kaplan},\n  title     = {A General Language Assistant as a Laboratory for Alignment},\n  journal   = {CoRR},\n  volume    = {abs/2112.00861},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2112.00861},\n  eprinttype = {arXiv},\n  eprint    = {2112.00861},\n  timestamp = {Tue, 07 Dec 2021 12:15:54 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-00861.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "63ff6fc3bda3595930fa2f6c", "disabled": false, "gated": false, "likes": 8, "downloads": 480, "createdAt": "2023-03-01T15:31:15.000Z"}, {"id": "zeusfsx/ukrainian-news", "sha": "4f34cd94b68b82f9310a7806552b3806fa28812a", "lastModified": "2023-05-14T08:04:18.000Z", "tags": ["task_categories:text-generation", "size_categories:10M<n<100M", "language:uk", "license:unknown", "news", "region:us"], "private": false, "author": "zeusfsx", "description": "Ukrainian News Dataset\n\nThis is a dataset of news articles downloaded from various Ukrainian websites and Telegram channels. The dataset contains approximately ~23M JSON objects (news)", "citation": null, "cardData": null, "siblings": [], "_id": "63ff9aa7bf8fab2c3684f764", "disabled": false, "gated": false, "likes": 9, "downloads": 10, "createdAt": "2023-03-01T18:34:15.000Z"}, {"id": "krr-oxford/OntoLAMA", "sha": "988f32f69e3ae0c7eba402056b99662467ea9990", "lastModified": "2023-08-07T16:22:39.000Z", "tags": ["task_categories:text-classification", "size_categories:1M<n<10M", "language:en", "license:apache-2.0", "Ontologies", "Subsumption Inference", "Natural Language Inference", "Conceptual Knowledge", "LMs-as-KBs", "region:us"], "private": false, "author": "krr-oxford", "description": "OntoLAMA: LAnguage Model Analysis datasets for Ontology Subsumption Inference.", "citation": "@inproceedings{he2023language,\n  title={Language Model Analysis for Ontology Subsumption Inference},\n  author={He, Yuan and Chen, Jiaoyan and Jim{\\'e}nez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},\n  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "63fff1a5ea1782e758cf46c2", "disabled": false, "gated": false, "likes": 1, "downloads": 68, "createdAt": "2023-03-02T00:45:25.000Z"}, {"id": "yizhongw/self_instruct", "sha": "290f6a0851c1df3bd4057b21d988bab2c5c527e1", "lastModified": "2023-03-07T10:07:36.000Z", "tags": ["license:apache-2.0", "arxiv:2212.10560", "arxiv:2204.07705", "region:us"], "private": false, "author": "yizhongw", "description": "Self-Instruct is a dataset that contains 52k instructions, paired with 82K instance inputs and outputs. This instruction data can be used to conduct instruction-tuning for language models and make the language model follow instruction better.", "citation": "@misc{selfinstruct,\n  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},\n  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},\n  journal={arXiv preprint arXiv:2212.10560},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6400b2daa553aaa2ed216e3a", "disabled": false, "gated": false, "likes": 169, "downloads": 1380, "createdAt": "2023-03-02T14:29:46.000Z"}, {"id": "ELiRF/dacsa", "sha": "ab955274dc4e9754874f5092608294b920f6f7e6", "lastModified": "2023-03-25T09:58:52.000Z", "tags": ["task_categories:text2text-generation", "task_ids:news-articles-summarization", "annotations_creators:found", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:original", "language:ca", "language:es", "license:odbl", "region:us"], "private": false, "author": "ELiRF", "description": "The Dataset for Automatic summarization of Catalan and Spanish newspaper\nArticles (DACSA) corpus. It is a high-quality large-scale corpus that can be\nused to train summarization models for Catalan and Spanish. The data provides\npairs of news article and its summary from different newspapers for both, the\nCatalan and the Spanish languages. Regarding the Catalan set, there are 725,184\nsample pairs from 9 newspapers, regarding the Spanish set, the corpus provides\n2,120,649 sample pairs from 21 newspapers.", "citation": "@inproceedings{segarra-soriano-etal-2022-dacsa,\n    title = \"{DACSA}: A large-scale Dataset for Automatic summarization of {C}atalan and {S}panish newspaper Articles\",\n    author = \"Segarra Soriano, Encarnaci{\\'o}n  and\n      Ahuir, Vicent  and\n      Hurtado, Llu{\\'\\i}s-F.  and\n      Gonz{\\'a}lez, Jos{\\'e}\",\n    booktitle = \"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jul,\n    year = \"2022\",\n    address = \"Seattle, United States\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.naacl-main.434\",\n    doi = \"10.18653/v1/2022.naacl-main.434\",\n    pages = \"5931--5943\",\n    abstract = \"The application of supervised methods to automatic summarization requires the availability of adequate corpora consisting of a set of document-summary pairs. As in most Natural Language Processing tasks, the great majority of available datasets for summarization are in English, making it difficult to develop automatic summarization models for other languages. Although Spanish is gradually forming part of some recent summarization corpora, it is not the same for minority languages such as Catalan.In this work, we describe the construction of a corpus of Catalan and Spanish newspapers, the Dataset for Automatic summarization of Catalan and Spanish newspaper Articles (DACSA) corpus. It is a high-quality large-scale corpus that can be used to train summarization models for Catalan and Spanish.We have carried out an analysis of the corpus, both in terms of the style of the summaries and the difficulty of the summarization task. In particular, we have used a set of well-known metrics in the summarization field in order to characterize the corpus. Additionally, for benchmarking purposes, we have evaluated the performances of some extractive and abstractive summarization systems on the DACSA corpus.\",\n}", "cardData": null, "siblings": [], "_id": "6401c901fc948f5b166ac470", "disabled": false, "gated": "auto", "likes": 1, "downloads": 49, "paperswithcode_id": "dacsa", "createdAt": "2023-03-03T10:16:33.000Z"}, {"id": "KBLab/rixvox", "sha": "51e0d66f7d87ef556d868270c0d68596b56149ba", "lastModified": "2023-08-17T10:26:47.000Z", "tags": ["task_categories:automatic-speech-recognition", "multilinguality:monolingual", "size_categories:100K<n<1M", "language:sv", "license:cc-by-4.0", "audio", "speech-recognition", "region:us"], "private": false, "author": "KBLab", "description": "RixVox is a speech dataset comprised of speeches from the Swedish Parliament (the Riksdag). Audio from speeches have been aligned with official transcripts, on the sentence level, using aeneas. \nSpeaker metadata is available for each observation, including the speaker's name, gender, party, birth year and electoral district. The dataset contains a total of 5493 hours of speech. \nAn observation may consist of one or several sentences (up to 30 seconds in duration).", "citation": "@misc{rekathati2023rixvox:,\n  author = {Rekathati, Faton},\n  title = {The KBLab Blog: RixVox: A Swedish Speech Corpus with 5500 Hours of Speech from Parliamentary Debates},\n  url = {https://kb-labb.github.io/posts/2023-03-09-rixvox-a-swedish-speech-corpus/},\n  year = {2023}\n}", "cardData": null, "siblings": [], "_id": "6401d4e69fe2fcff94b1c0d1", "disabled": false, "gated": false, "likes": 9, "downloads": 242, "createdAt": "2023-03-03T11:07:18.000Z"}, {"id": "theblackcat102/instruction_translations", "sha": "007e1aefd91d1a39e293a8da45f7a3ef76a8a3a1", "lastModified": "2023-03-05T06:36:37.000Z", "tags": ["task_categories:text-generation", "size_categories:10K<n<100K", "language:en", "license:mit", "ChatGPT", "SimpleAI", "Detection", "doi:10.57967/hf/0423", "region:us"], "private": false, "author": "theblackcat102", "description": "Translation of Instruction dataset", "citation": "\\", "cardData": null, "siblings": [], "_id": "6402962302594ec43ebb0d89", "disabled": false, "gated": false, "likes": 5, "downloads": 27, "createdAt": "2023-03-04T00:51:47.000Z"}, {"id": "biglam/european_art", "sha": "a390557db09b8208236e98fb3c41234eba8ffaa0", "lastModified": "2023-08-03T09:39:40.000Z", "tags": ["task_categories:object-detection", "task_categories:image-classification", "size_categories:10K<n<100K", "license:cc-by-nc-2.0", "lam", "art", "historical", "arxiv:2211.01226", "region:us"], "private": false, "author": "biglam", "description": "Yalt AI Tabular Dataset", "citation": "    @dataset{clerice_thibault_2022_6827706,\n  author       = {Cl\u00e9rice, Thibault},\n  title        = {YALTAi: Tabular Dataset},\n  month        = jul,\n  year         = 2022,\n  publisher    = {Zenodo},\n  version      = {1.0.0},\n  doi          = {10.5281/zenodo.6827706},\n  url          = {https://doi.org/10.5281/zenodo.6827706}\n}", "cardData": null, "siblings": [], "_id": "64035e3d723a03e62696f152", "disabled": false, "gated": false, "likes": 4, "downloads": 41, "createdAt": "2023-03-04T15:05:33.000Z"}, {"id": "kanishka/comps", "sha": "d182636c932e7628d53c74d48122b502b779ceec", "lastModified": "2023-09-16T15:09:24.000Z", "tags": ["annotations_creators:expert-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2210.01963", "region:us"], "private": false, "author": "kanishka", "description": "COMPS is a dataset of minimal pair sentences in English that enables the \ntesting knowledge of concepts and their properties in language models (LMs).\nSpecifically, it tests the ability of LMs to attribute properties to everyday \nconcepts, and demonstrate reasoning compatible with property inheritance, where\nsubordinate concepts inherit the properties of their superordinate (hypernyms).", "citation": "@article{misra2022comps,\n  title={COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge and Inheritance in Pre-trained Language Models},\n  author={Misra, Kanishka and Rayz, Julia Taylor and Ettinger, Allyson},\n  journal={arXiv preprint arXiv:2210.01963},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "6404e3bbdfde643e0615013c", "disabled": false, "gated": false, "likes": 1, "downloads": 11, "createdAt": "2023-03-05T18:47:23.000Z"}, {"id": "hendrycks/ethics", "sha": "b8b47c589f8bee77175b8648e5497278b68da48a", "lastModified": "2023-04-19T18:55:00.000Z", "tags": ["language:en", "license:mit", "AI Alignment", "arxiv:2008.02275", "region:us"], "private": false, "author": "hendrycks", "description": "A benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.", "citation": "@article{hendrycks2020aligning,\n  title={Aligning ai with shared human values},\n  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},\n  journal={arXiv preprint arXiv:2008.02275},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "640605cfd354fae149b030e4", "disabled": false, "gated": false, "likes": 5, "downloads": 17903, "createdAt": "2023-03-06T15:25:03.000Z"}, {"id": "EleutherAI/arithmetic", "sha": "cf5ec4512aaa47cdebf02ca032b7af870528c272", "lastModified": "2023-03-09T17:58:16.000Z", "tags": ["arxiv:2005.14165", "region:us"], "private": false, "author": "EleutherAI", "description": "A small battery of 10 tests that involve asking language models a simple arithmetic\nproblem in natural language.", "citation": "@inproceedings{NEURIPS2020_1457c0d6,\n    author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},\n    booktitle = {Advances in Neural Information Processing Systems},\n    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},\n    pages = {1877--1901},\n    publisher = {Curran Associates, Inc.},\n    title = {Language Models are Few-Shot Learners},\n    url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},\n    volume = {33},\n    year = {2020}\n}", "cardData": null, "siblings": [], "_id": "64087e16589a5e305e919456", "disabled": false, "gated": false, "likes": 2, "downloads": 5128, "createdAt": "2023-03-08T12:22:46.000Z"}, {"id": "rcds/occlusion_swiss_judgment_prediction", "sha": "03a508f01d59b95f1ddd7da8d85ef4d091a7f9c6", "lastModified": "2023-03-28T08:19:29.000Z", "tags": ["task_categories:text-classification", "task_categories:other", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|swiss_judgment_prediction", "language:de", "language:fr", "language:it", "language:en", "license:cc-by-sa-4.0", "explainability-judgment-prediction", "occlusion", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains an implementation of occlusion for the SwissJudgmentPrediction task.", "citation": "@misc{baumgartner_nina_occlusion_2022,\n\ttitle = {From Occlusion to Transparancy \u2013 An Occlusion-Based Explainability Approach for Legal Judgment Prediction in Switzerland},\n\tshorttitle = {From Occlusion to Transparancy},\n\tabstract = {Natural Language Processing ({NLP}) models have been used for more and more complex tasks such as Legal Judgment Prediction ({LJP}). A {LJP} model predicts the outcome of a legal case by utilizing its facts. This increasing deployment of Artificial Intelligence ({AI}) in high-stakes domains such as law and the involvement of sensitive data has increased the need for understanding such systems. We propose a multilingual occlusion-based explainability approach for {LJP} in Switzerland and conduct a study on the bias using Lower Court Insertion ({LCI}). We evaluate our results using different explainability metrics introduced in this thesis and by comparing them to high-quality Legal Expert Annotations using Inter Annotator Agreement. Our findings show that the model has a varying understanding of the semantic meaning and context of the facts section, and struggles to distinguish between legally relevant and irrelevant sentences. We also found that the insertion of a different lower court can have an effect on the prediction, but observed no distinct effects based on legal areas, cantons, or regions. However, we did identify a language disparity with Italian performing worse than the other languages due to representation inequality in the training data, which could lead to potential biases in the prediction in multilingual regions of Switzerland. Our results highlight the challenges and limitations of using {NLP} in the judicial field and the importance of addressing concerns about fairness, transparency, and potential bias in the development and use of {NLP} systems. The use of explainable artificial intelligence ({XAI}) techniques, such as occlusion and {LCI}, can help provide insight into the decision-making processes of {NLP} systems and identify areas for improvement. Finally, we identify areas for future research and development in this field in order to address the remaining limitations and challenges.},\n\tauthor = {{Baumgartner, Nina}},\n\tyear = {2022},\n\tlangid = {english}\n\t}", "cardData": null, "siblings": [], "_id": "6408ec927bd381d500a63ff7", "disabled": false, "gated": false, "likes": 0, "downloads": 32, "createdAt": "2023-03-08T20:14:10.000Z"}, {"id": "intfloat/query2doc_msmarco", "sha": "3019b760cd849830aec6d0654dbe8a4a03e791d6", "lastModified": "2023-03-30T02:44:59.000Z", "tags": ["size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "arxiv:2303.07678", "region:us"], "private": false, "author": "intfloat", "description": "This dataset contains GPT-3.5 (text-davinci-003) generations from MS-MARCO queries.", "citation": "@inproceedings{Wang2023Query2docQE,\n  title={Query2doc: Query Expansion with Large Language Models},\n  author={Liang Wang and Nan Yang and Furu Wei},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "640b066b9823006e0707e0e3", "disabled": false, "gated": false, "likes": 6, "downloads": 19, "createdAt": "2023-03-10T10:28:59.000Z"}, {"id": "rcds/lower_court_insertion_swiss_judgment_prediction", "sha": "e895019ffb6857521af1756c2d85b64e919af32c", "lastModified": "2023-03-28T08:19:04.000Z", "tags": ["task_categories:text-classification", "task_categories:other", "annotations_creators:expert-generated", "language_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|swiss_judgment_prediction", "language:de", "language:fr", "language:it", "language:en", "license:cc-by-sa-4.0", "explainability-judgment-prediction", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains an implementation of lower court insertion for the SwissJudgmentPrediction task.", "citation": "@misc{baumgartner_nina_occlusion_2022,\n\ttitle = {From Occlusion to Transparancy \u2013 An Occlusion-Based Explainability Approach for Legal Judgment Prediction in Switzerland},\n\tshorttitle = {From Occlusion to Transparancy},\n\tabstract = {Natural Language Processing ({NLP}) models have been used for more and more complex tasks such as Legal Judgment Prediction ({LJP}). A {LJP} model predicts the outcome of a legal case by utilizing its facts. This increasing deployment of Artificial Intelligence ({AI}) in high-stakes domains such as law and the involvement of sensitive data has increased the need for understanding such systems. We propose a multilingual occlusion-based explainability approach for {LJP} in Switzerland and conduct a study on the bias using Lower Court Insertion ({LCI}). We evaluate our results using different explainability metrics introduced in this thesis and by comparing them to high-quality Legal Expert Annotations using Inter Annotator Agreement. Our findings show that the model has a varying understanding of the semantic meaning and context of the facts section, and struggles to distinguish between legally relevant and irrelevant sentences. We also found that the insertion of a different lower court can have an effect on the prediction, but observed no distinct effects based on legal areas, cantons, or regions. However, we did identify a language disparity with Italian performing worse than the other languages due to representation inequality in the training data, which could lead to potential biases in the prediction in multilingual regions of Switzerland. Our results highlight the challenges and limitations of using {NLP} in the judicial field and the importance of addressing concerns about fairness, transparency, and potential bias in the development and use of {NLP} systems. The use of explainable artificial intelligence ({XAI}) techniques, such as occlusion and {LCI}, can help provide insight into the decision-making processes of {NLP} systems and identify areas for improvement. Finally, we identify areas for future research and development in this field in order to address the remaining limitations and challenges.},\n\tauthor = {{Baumgartner, Nina}},\n\tyear = {2022},\n\tlangid = {english}\n\t}", "cardData": null, "siblings": [], "_id": "640b3946dd4e25a9b9c7d4e8", "disabled": false, "gated": false, "likes": 0, "downloads": 42, "createdAt": "2023-03-10T14:05:58.000Z"}, {"id": "Joanne/Metaphors_and_Analogies", "sha": "aedc54f1626195c246e64f67a4d21869daf9bff8", "lastModified": "2023-05-30T20:40:56.000Z", "tags": ["task_categories:question-answering", "task_categories:token-classification", "language:en", "region:us"], "private": false, "author": "Joanne", "description": "[Unified Benchmark for Metaphor Identification]", "citation": null, "cardData": null, "siblings": [], "_id": "640b8bafd8653a0c7e127704", "disabled": false, "gated": false, "likes": 0, "downloads": 46, "createdAt": "2023-03-10T19:57:35.000Z"}, {"id": "thewall/jolma", "sha": "ab39bdb86dfa3c95c63a68b55c4c27d3fc1f021e", "lastModified": "2023-03-23T09:43:40.000Z", "tags": ["license:openrail", "region:us"], "private": false, "author": "thewall", "description": "PRJEB3289\nhttps://www.ebi.ac.uk/ena/browser/view/PRJEB3289\nData that has been generated by HT-SELEX experiments (see Jolma et al. 2010. PMID: 20378718 for description of method) that has been now used to generate transcription factor binding specificity models for most of the high confidence human transcription factors. Sequence data is composed of reads generated with Illumina Genome Analyzer IIX and HiSeq2000 instruments. Samples are composed of single read sequencing of synthetic DNA fragments with a fixed length randomized region or samples derived from such a initial library by selection with a sequence specific DNA binding protein. Originally multiple samples with different \"barcode\" tag sequences were run on the same Illumina sequencing lane but the released files have been already de-multiplexed, and the constant regions and \"barcodes\" of each sequence have been cut out of the sequencing reads to facilitate the use of data. Some of the files are composed of reads from multiple different sequencing lanes and due to this each of the names of the individual reads have been edited to show the flowcell and lane that was used to generate it. Barcodes and oligonucleotide designs are indicated in the names of individual entries. Depending of the selection ligand design, the sequences in each of these fastq-files are either 14, 20, 30 or 40 bases long and had different flanking regions in both sides of the sequence. Each run entry is named in either of the following ways: Example 1) \"BCL6B_DBD_AC_TGCGGG20NGA_1\", where name is composed of following fields ProteinName_CloneType_Batch_BarcodeDesign_SelectionCycle. This experiment used barcode ligand TGCGGG20NGA, where both of the variable flanking constant regions are indicated as they were on the original sequence-reads. This ligand has been selected for one round of HT-SELEX using recombinant protein that contained the DNA binding domain of human transcription factor BCL6B. It also tells that the experiment was performed on batch of experiments named as \"AC\". Example 2) 0_TGCGGG20NGA_0 where name is composed of (zero)_BarcodeDesign_(zero) These sequences have been generated  from sequencing of the initial non-selected pool. Same initial pools have been used in multiple experiments that were  on different batches, thus for example this background sequence pool is the shared background for all of the following  samples. BCL6B_DBD_AC_TGCGGG20NGA_1, ZNF784_full_AE_TGCGGG20NGA_3, DLX6_DBD_Y_TGCGGG20NGA_4 and MSX2_DBD_W_TGCGGG20NGA_2", "citation": "@article{jolma2010multiplexed,\n  title={Multiplexed massively parallel SELEX for characterization of human transcription factor binding specificities},\n  author={Jolma, Arttu and Kivioja, Teemu and Toivonen, Jarkko and Cheng, Lu and Wei, Gonghong and Enge, Martin and   Taipale, Mikko and Vaquerizas, Juan M and Yan, Jian and Sillanp{\\\"a}{\\\"a}, Mikko J and others},\n  journal={Genome research},\n  volume={20},\n  number={6},\n  pages={861--873},\n  year={2010},\n  publisher={Cold Spring Harbor Lab}\n}", "cardData": null, "siblings": [], "_id": "640c19671286278271d02254", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2023-03-11T06:02:15.000Z"}, {"id": "CATIE-AQ/frenchQA", "sha": "4dcf09027327d64df9d3fcc3a726aed8c8b053a2", "lastModified": "2023-10-18T08:35:40.000Z", "tags": ["task_categories:question-answering", "size_categories:100K<n<1M", "language:fr", "license:cc-by-4.0", "doi:10.57967/hf/0862", "region:us"], "private": false, "author": "CATIE-AQ", "description": "One French QA Dataset to rule them all, One French QA Dataset to find them, One French QA Dataset to bring them all, and in the darkness bind them.", "citation": "\\", "cardData": null, "siblings": [], "_id": "6410858414d70ef916889d34", "disabled": false, "gated": false, "likes": 1, "downloads": 43, "createdAt": "2023-03-14T14:32:36.000Z"}, {"id": "mxeval/mbxp", "sha": "578c12844aadca9702522657789c519ca87b46c8", "lastModified": "2023-07-03T18:10:10.000Z", "tags": ["task_categories:text-generation", "size_categories:10K<n<100K", "language:en", "license:apache-2.0", "mxeval", "mbxp", "mbpp", "code-generation", "arxiv:2210.14868", "region:us"], "private": false, "author": "mxeval", "description": "A collection of execution-based multi-lingual benchmark for code generation.", "citation": "@article{mbxp_athiwaratkun2022,\n  title = {Multi-lingual Evaluation of Code Generation Models},\n  author = {Athiwaratkun, Ben and\n   Gouda, Sanjay Krishna and\n   Wang, Zijian and\n   Li, Xiaopeng and\n   Tian, Yuchen and\n   Tan, Ming\n   and Ahmad, Wasi Uddin and\n   Wang, Shiqi and\n   Sun, Qing and\n   Shang, Mingyue and\n   Gonugondla, Sujan Kumar and\n   Ding, Hantian and\n   Kumar, Varun and\n   Fulton, Nathan and\n   Farahani, Arash and\n   Jain, Siddhartha and\n   Giaquinto, Robert and\n   Qian, Haifeng and\n   Ramanathan, Murali Krishna and\n   Nallapati, Ramesh and\n   Ray, Baishakhi and\n   Bhatia, Parminder and\n   Sengupta, Sudipta and\n   Roth, Dan and\n   Xiang, Bing},\n  doi = {10.48550/ARXIV.2210.14868},\n  url = {https://arxiv.org/abs/2210.14868},\n  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "6410e7e2c100524d3cde4671", "disabled": false, "gated": false, "likes": 10, "downloads": 1676, "createdAt": "2023-03-14T21:32:18.000Z"}, {"id": "nguha/legalbench", "sha": "12ca3b695563788fead87a982ad1a068284413f4", "lastModified": "2023-10-18T17:18:18.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:text-generation", "size_categories:10K<n<100K", "language:en", "license:other", "legal", "law", "finance", "arxiv:2308.11462", "region:us"], "private": false, "author": "nguha", "description": "LegalBench is a collection of benchmark tasks for evaluating legal reasoning in large language models.", "citation": "@misc{guha2023legalbench,\n      title={LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models}, \n      author={Neel Guha and Julian Nyarko and Daniel E. Ho and Christopher R\u00e9 and Adam Chilton and Aditya Narayana and Alex Chohlas-Wood and Austin Peters and Brandon Waldon and Daniel N. Rockmore and Diego Zambrano and Dmitry Talisman and Enam Hoque and Faiz Surani and Frank Fagan and Galit Sarfaty and Gregory M. Dickinson and Haggai Porat and Jason Hegland and Jessica Wu and Joe Nudell and Joel Niklaus and John Nay and Jonathan H. Choi and Kevin Tobia and Margaret Hagan and Megan Ma and Michael Livermore and Nikon Rasumov-Rahe and Nils Holzenberger and Noam Kolt and Peter Henderson and Sean Rehaag and Sharad Goel and Shang Gao and Spencer Williams and Sunny Gandhi and Tom Zur and Varun Iyer and Zehua Li},\n      year={2023},\n      eprint={2308.11462},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "6413a04ece07729a7c19e6a3", "disabled": false, "gated": false, "likes": 28, "downloads": 7274, "createdAt": "2023-03-16T23:03:42.000Z"}, {"id": "orkg/SciQA", "sha": "5ab1d0822517c1470e4891277d9de0eead69b8c2", "lastModified": "2023-05-22T10:13:44.000Z", "tags": ["task_categories:question-answering", "annotations_creators:expert-generated", "annotations_creators:auto-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-4.0", "knowledge-base-qa", "region:us"], "private": false, "author": "orkg", "description": "    SciQA contains 2,565 SPARQL query - question pairs along with answers fetched from the open research knowledge graph (ORKG)     via a Virtuoso SPARQL endpoint, it is a collection of both handcrafted and autogenerated questions and queries.     The dataset is split into 70% training, 10% validation and 20% test examples. The dataset is available as JSON files.", "citation": "@Article{SciQA2023,\n        author={Auer, S{\\\"o}ren\n        and Barone, Dante A. C.\n        and Bartz, Cassiano\n        and Cortes, Eduardo G.\n        and Jaradeh, Mohamad Yaser\n        and Karras, Oliver\n        and Koubarakis, Manolis\n        and Mouromtsev, Dmitry\n        and Pliukhin, Dmitrii\n        and Radyush, Daniil\n        and Shilin, Ivan\n        and Stocker, Markus\n        and Tsalapati, Eleni},\n        title={The SciQA Scientific Question Answering Benchmark for Scholarly Knowledge},\n        journal={Scientific Reports},\n        year={2023},\n        month={May},\n        day={04},\n        volume={13},\n        number={1},\n        pages={7240},\n        abstract={Knowledge graphs have gained increasing popularity in the last decade in science and technology. However, knowledge graphs are currently relatively simple to moderate semantic structures that are mainly a collection of factual statements. Question answering (QA) benchmarks and systems were so far mainly geared towards encyclopedic knowledge graphs such as DBpedia and Wikidata. We present SciQA a scientific QA benchmark for scholarly knowledge. The benchmark leverages the Open Research Knowledge Graph (ORKG) which includes almost 170,000 resources describing research contributions of almost 15,000 scholarly articles from 709 research fields. Following a bottom-up methodology, we first manually developed a set of 100 complex questions that can be answered using this knowledge graph. Furthermore, we devised eight question templates with which we automatically generated further 2465 questions, that can also be answered with the ORKG. The questions cover a range of research fields and question types and are translated into corresponding SPARQL queries over the ORKG. Based on two preliminary evaluations, we show that the resulting SciQA benchmark represents a challenging task for next-generation QA systems. This task is part of the open competitions at the 22nd International Semantic Web Conference 2023 as the Scholarly Question Answering over Linked Data (QALD) Challenge.},\n        issn={2045-2322},\n        doi={10.1038/s41598-023-33607-z},\n        url={https://doi.org/10.1038/s41598-023-33607-z}\n    }", "cardData": null, "siblings": [], "_id": "6414391be792fb53473f1ed4", "disabled": false, "gated": false, "likes": 3, "downloads": 138, "createdAt": "2023-03-17T09:55:39.000Z"}, {"id": "shunk031/CAMERA", "sha": "3addfe5913729fa88549aba87e2f47d749982b55", "lastModified": "2023-03-17T14:49:35.000Z", "tags": ["task_categories:text-generation", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:ja", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "shunk031", "description": "CAMERA (CyberAgent Multimodal Evaluation for Ad Text GeneRAtion) is the Japanese ad text generation dataset.", "citation": "@inproceedings{mita-et-al:nlp2023,\n    author =    \"\u4e09\u7530 \u96c5\u4eba and \u6751\u4e0a \u8061\u4e00\u6717 and \u5f35 \u57f9\u6960\",\n    title =\t    \"\u5e83\u544a\u6587\u751f\u6210\u30bf\u30b9\u30af\u306e\u898f\u5b9a\u3068\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u69cb\u7bc9\",\n    booktitle = \"\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a \u7b2c29\u56de\u5e74\u6b21\u5927\u4f1a\",\n    year =      2023,\n}", "cardData": null, "siblings": [], "_id": "6414769b1fc0cdf069ef5e9d", "disabled": false, "gated": false, "likes": 4, "downloads": 69, "createdAt": "2023-03-17T14:18:03.000Z"}, {"id": "TUKE-DeutscheTelekom/squad-sk", "sha": "928b277a3b0d39c8faa736aa4d33c0c6dd432996", "lastModified": "2023-10-18T12:43:46.000Z", "tags": ["task_categories:question-answering", "task_categories:text-retrieval", "task_ids:open-domain-qa", "task_ids:extractive-qa", "task_ids:document-retrieval", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:sk", "license:cc-by-sa-4.0", "license:cc-by-4.0", "wikipedia", "region:us"], "private": false, "author": "TUKE-DeutscheTelekom", "description": "        Slovak translation of Standford Question Answering Dataset", "citation": "TBD", "cardData": null, "siblings": [], "_id": "64181a309656b49410a06c5c", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "paperswithcode_id": "squad-sk", "createdAt": "2023-03-20T08:32:48.000Z"}, {"id": "theblackcat102/codex-math-qa", "sha": "8244f185697cf454a580255f2fbf24d5c13870be", "lastModified": "2023-03-26T01:04:18.000Z", "tags": ["task_categories:text2text-generation", "task_categories:text-generation", "language:en", "license:other", "codex-generated", "code", "mathematic", "region:us"], "private": false, "author": "theblackcat102", "description": "Solution by codex-davinci-002 for math_qa", "citation": "\\", "cardData": null, "siblings": [], "_id": "641a522ee3def7b7bf1d2330", "disabled": false, "gated": false, "likes": 13, "downloads": 14, "createdAt": "2023-03-22T00:56:14.000Z"}, {"id": "intfloat/multilingual_cc_news", "sha": "1c24f619ae44d0a4c87fde72efa741dc25f7530e", "lastModified": "2023-04-23T08:19:06.000Z", "tags": ["size_categories:100M<n<1B", "language:en", "language:zh", "language:fr", "language:de", "language:af", "language:ar", "region:us"], "private": false, "author": "intfloat", "description": "\\\r\nMultilingual CC-News dataset.\r\n\r\nThis is the processed version from https://huggingface.co/datasets/CloverSearch/cc-news-mutlilingual.", "citation": null, "cardData": null, "siblings": [], "_id": "641abb7efc01c26fcae895a2", "disabled": false, "gated": false, "likes": 3, "downloads": 523, "createdAt": "2023-03-22T08:25:34.000Z"}, {"id": "HiTZ/alpaca_mt", "sha": "c34331b5c52bce660d9e5e4227cb96669c9122c4", "lastModified": "2023-04-07T15:15:55.000Z", "tags": ["task_categories:text-generation", "task_ids:dialogue-modeling", "annotations_creators:no-annotation", "language_creators:machine-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:tatsu-lab/alpaca", "language:en", "language:pt", "language:es", "language:ca", "language:eu", "language:gl", "language:at", "license:cc-by-nc-4.0", "instruction-finetuning", "region:us"], "private": false, "author": "HiTZ", "description": "Alpaca is a dataset of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. This instruction data can be used to conduct instruction-tuning for language models and make the language model follow instruction better. This dataset also includes machine-translated data for 6 Iberian languages: Portuguese, Spanish, Catalan, Basque, Galician and Asturian.", "citation": "@misc{alpaca,\n  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },\n  title = {Stanford Alpaca: An Instruction-following LLaMA model},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {https://github.com/tatsu-lab/stanford_alpaca},\n}", "cardData": null, "siblings": [], "_id": "641b1e62b84e86f4c74b0b91", "disabled": false, "gated": false, "likes": 7, "downloads": 21, "createdAt": "2023-03-22T15:27:30.000Z"}, {"id": "slhenty/climate-fever-nli-stsb", "sha": "488fdaf0aaa39c99ba7dd4b5bb6098b7fe6ae2d8", "lastModified": "2023-03-24T21:08:44.000Z", "tags": ["license:unknown", "region:us"], "private": false, "author": "slhenty", "description": "A modified CLIMATE-FEVER dataset that includes NLI-style features and STSb-features suitable for SentenceBERT training scripts.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {climate-fever-nli-stsb},\nauthor={Steve Henty, Omdena, \"Cologne, Germany Chapter - Detecting Bias in Climate Reporting in English and German Language News Media\"},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "641b98e3d2115222811f7ff7", "disabled": false, "gated": false, "likes": 1, "downloads": 10, "createdAt": "2023-03-23T00:10:11.000Z"}, {"id": "intfloat/wikipedia", "sha": "3515d71e9bd0120edceda41c78828752cd165d5d", "lastModified": "2023-04-23T08:36:49.000Z", "tags": ["size_categories:100M<n<1B", "region:us"], "private": false, "author": "intfloat", "description": "\\\r\nWikipedia dataset containing cleaned articles of all languages.\r\nThe datasets are built from the Wikipedia dump\r\n(https://dumps.wikimedia.org/) with one split per language. Each example\r\ncontains the content of one full Wikipedia article with cleaning to strip\r\nmarkdown and unwanted sections (references, etc.).", "citation": "\\\r\n@ONLINE {wikidump,\r\n    author = {Wikimedia Foundation},\r\n    title  = {Wikimedia Downloads},\r\n    url    = {https://dumps.wikimedia.org}\r\n}", "cardData": null, "siblings": [], "_id": "641c17e8365ede719b1838eb", "disabled": false, "gated": false, "likes": 1, "downloads": 47, "createdAt": "2023-03-23T09:12:08.000Z"}, {"id": "rcds/swiss_judgment_prediction_xl", "sha": "648b5910046f2ebdfd9a3821e396bba242560359", "lastModified": "2023-07-20T07:31:57.000Z", "tags": ["task_categories:text-classification", "size_categories:100K<n<1M", "language:it", "language:de", "language:fr", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains court decision for judgment prediction task.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "641ce3d75de221d81463f96b", "disabled": false, "gated": false, "likes": 0, "downloads": 20, "createdAt": "2023-03-23T23:42:15.000Z"}, {"id": "rcds/swiss_law_area_prediction", "sha": "c71fd4ee19ce4b9e2c253194b1e45e1ad8b200a2", "lastModified": "2023-07-20T07:38:52.000Z", "tags": ["task_categories:text-classification", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "language:fr", "language:it", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains court decision for law area prediction task.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "641ed23862b95850b7f6e49f", "disabled": false, "gated": false, "likes": 3, "downloads": 134, "createdAt": "2023-03-25T10:51:36.000Z"}, {"id": "koutch/staqc", "sha": "5851ae43677d73ad00af3f2ab117b8bf3bb51cca", "lastModified": "2023-03-27T14:53:22.000Z", "tags": ["task_categories:question-answering", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "code", "arxiv:1803.09371", "region:us"], "private": false, "author": "koutch", "description": "StaQC (Stack Overflow Question-Code pairs) is a dataset of around 148K Python and 120K SQL domain question-code pairs, \nwhich are automatically mined from Stack Overflow using a Bi-View Hierarchical Neural Network, \nas described in the paper \"StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow\" (WWW'18).", "citation": "@inproceedings{yao2018staqc,\n  title={StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow},\n  author={Yao, Ziyu and Weld, Daniel S and Chen, Wei-Peng and Sun, Huan},\n  booktitle={Proceedings of the 2018 World Wide Web Conference on World Wide Web},\n  pages={1693--1703},\n  year={2018},\n  organization={International World Wide Web Conferences Steering Committee}\n}", "cardData": null, "siblings": [], "_id": "6421815e332961f4dfa8af15", "disabled": false, "gated": false, "likes": 3, "downloads": 472, "createdAt": "2023-03-27T11:43:26.000Z"}, {"id": "RussianNLP/rucola", "sha": "1570c3c9d8147467a85cc86c0be6a60930f0044b", "lastModified": "2023-03-27T18:47:12.000Z", "tags": ["task_categories:text-classification", "size_categories:10K<n<100K", "language:ru", "license:apache-2.0", "arxiv:2210.12814", "arxiv:2008.00401", "region:us"], "private": false, "author": "RussianNLP", "description": "Russian Corpus of Linguistic Acceptability (RuCoLA) is a novel benchmark of 13.4k sentences labeled as acceptable or not. RuCoLA combines in-domain sentences manually collected from linguistic literature and out-of-domain sentences produced by nine machine translation and paraphrase generation models. The motivation behind the out-of-domain set is to facilitate the practical use of acceptability judgments for improving language generation. Each unacceptable sentence is additionally labeled with four standard and machine-specific coarse-grained categories: morphology, syntax, semantics, and hallucinations.", "citation": "@inproceedings{mikhailov-etal-2022-rucola,\n    title = \"{R}u{C}o{LA}: {R}ussian Corpus of Linguistic Acceptability\",\n    author = \"Mikhailov, Vladislav  and\n      Shamardina, Tatiana  and\n      Ryabinin, Max  and\n      Pestova, Alena  and\n      Smurov, Ivan  and\n      Artemova, Ekaterina\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.emnlp-main.348\",\n    pages = \"5207--5227\",\n    abstract = \"Linguistic acceptability (LA) attracts the attention of the research community due to its many uses, such as testing the grammatical knowledge of language models and filtering implausible texts with acceptability classifiers.However, the application scope of LA in languages other than English is limited due to the lack of high-quality resources.To this end, we introduce the Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up under the well-established binary LA approach. RuCoLA consists of 9.8k in-domain sentences from linguistic publications and 3.6k out-of-domain sentences produced by generative models. The out-of-domain set is created to facilitate the practical use of acceptability for improving language generation.Our paper describes the data collection protocol and presents a fine-grained analysis of acceptability classification experiments with a range of baseline approaches.In particular, we demonstrate that the most widely used language models still fall behind humans by a large margin, especially when detecting morphological and semantic errors. We release RuCoLA, the code of experiments, and a public leaderboard to assess the linguistic competence of language models for Russian.\",\n}", "cardData": null, "siblings": [], "_id": "6421e1da5acad90e6b701c8c", "disabled": false, "gated": false, "likes": 1, "downloads": 311, "createdAt": "2023-03-27T18:35:06.000Z"}, {"id": "cartesinus/leyzer-fedcsis-translated", "sha": "b1cec4149933b09594c4b7a837e7263942449147", "lastModified": "2023-03-27T21:52:34.000Z", "tags": ["task_categories:text-classification", "size_categories:10K<n<100K", "language:pl", "license:cc-by-4.0", "natural-language-understanding", "region:us"], "private": false, "author": "cartesinus", "description": "        Leyzer is a multilingual text corpus designed to study multilingual and cross-lingual natural language\n        understanding (NLU) models and the strategies of localization of virtual assistants. It consists of 20\n        domains across three languages: English, Spanish and Polish, with 186 intents and a wide range of\n        samples, ranging from 1 to 672 sentences per intent.", "citation": "    @inproceedings{sowanski2020leyzer,\n    title={Leyzer: A Dataset for Multilingual Virtual Assistants},\n    author={Sowa{\\'n}ski, Marcin and Janicki, Artur},\n    booktitle={International Conference on Text, Speech, and Dialogue},\n    pages={477--486},\n    year={2020},\n    organization={Springer}\n    }", "cardData": null, "siblings": [], "_id": "64220fe63f204ac24e1a632f", "disabled": false, "gated": false, "likes": 0, "downloads": 14, "createdAt": "2023-03-27T21:51:34.000Z"}, {"id": "casehold/casehold", "sha": "acc4532a67e0966e9ed7ec4ca543e8532f983b0c", "lastModified": "2023-10-04T19:55:29.000Z", "tags": ["region:us"], "private": false, "author": "casehold", "description": "CaseHOLD (Case Holdings On Legal Decisions) is a law dataset comprised of over 53,000+ multiple choice questions to identify the relevant holding of a cited case.", "citation": "@inproceedings{zhengguha2021,\n    title={When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset},\n    author={Lucia Zheng and Neel Guha and Brandon R. Anderson and Peter Henderson and Daniel E. Ho},\n    year={2021},\n    eprint={2104.08671},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL},\n    booktitle={Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},\n    publisher={Association for Computing Machinery}\n}", "cardData": null, "siblings": [], "_id": "6422210494fb039f536e36e2", "disabled": false, "gated": false, "likes": 5, "downloads": 200, "createdAt": "2023-03-27T23:04:36.000Z"}, {"id": "YuanPJ/summ_screen", "sha": "db2b0002f3741ea94b5d9104fc99360cb731c132", "lastModified": "2023-03-29T04:51:45.000Z", "tags": ["region:us"], "private": false, "author": "YuanPJ", "description": "SummScreen Corpus contains over 26k pairs of TV series transcripts and human written recaps.\nThere are two features:\n  - dialogue: text of dialogue.\n  - summary: human written summary of the dialogue.\n  - id: id of a example.", "citation": "@inproceedings{chen-etal-2022-summscreen,\n    title = \"{S}umm{S}creen: A Dataset for Abstractive Screenplay Summarization\",\n    author = \"Chen, Mingda  and\n      Chu, Zewei  and\n      Wiseman, Sam  and\n      Gimpel, Kevin\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = may,\n    year = \"2022\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.acl-long.589\",\n    pages = \"8602--8615\",\n    abstract = \"We introduce SummScreen, a summarization dataset comprised of pairs of TV series transcripts and human written recaps. The dataset provides a challenging testbed for abstractive summarization for several reasons. Plot details are often expressed indirectly in character dialogues and may be scattered across the entirety of the transcript. These details must be found and integrated to form the succinct plot descriptions in the recaps. Also, TV scripts contain content that does not directly pertain to the central plot but rather serves to develop characters or provide comic relief. This information is rarely contained in recaps. Since characters are fundamental to TV series, we also propose two entity-centric evaluation metrics. Empirically, we characterize the dataset by evaluating several methods, including neural models and those based on nearest neighbors. An oracle extractive approach outperforms all benchmarked models according to automatic metrics, showing that the neural models are unable to fully exploit the input transcripts. Human evaluation and qualitative analysis reveal that our non-oracle models are competitive with their oracle counterparts in terms of generating faithful plot events and can benefit from better content selectors. Both oracle and non-oracle models generate unfaithful facts, suggesting future research directions.\",\n}", "cardData": null, "siblings": [], "_id": "6422720c6060160deb2a6787", "disabled": false, "gated": false, "likes": 1, "downloads": 252, "createdAt": "2023-03-28T04:50:20.000Z"}, {"id": "swype/instruct", "sha": "c504b3fb1bd408507949c50cadc83c580f4ec202", "lastModified": "2023-04-05T23:14:28.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "swype", "description": "A dataset containing prompt and completion pairs for various tasks.", "citation": "@misc{srikanth2023swypedataset,\n  author       = {Srikanth Srinivas},\n  title        = {Swype.com Dataset},\n  year         = {2023},\n  publisher    = {Swype.com},\n  howpublished = {\\\\url{https://swype.com}},\n  email        = {s@swype.com}\n}", "cardData": null, "siblings": [], "_id": "6423a6f087c0858c14bef2ad", "disabled": false, "gated": false, "likes": 49, "downloads": 17, "createdAt": "2023-03-29T02:48:16.000Z"}, {"id": "rcds/swiss_criticality_prediction", "sha": "45bd2671a067b851549201eb07d2421d0c47ae4a", "lastModified": "2023-07-20T07:39:07.000Z", "tags": ["task_categories:text-classification", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "language:de", "language:fr", "language:it", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains Swiss federal court decisions for the legal criticality prediction task", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "64274eda66821dcb668afffe", "disabled": false, "gated": false, "likes": 0, "downloads": 26, "createdAt": "2023-03-31T21:21:30.000Z"}, {"id": "bigbio/cardiode", "sha": "85dad333bf9e225ad1c3e66ed6d05c12f358fcd5", "lastModified": "2023-04-05T01:14:13.000Z", "tags": ["multilinguality:monolingual", "language:ger", "license:other", "region:us"], "private": false, "author": "bigbio", "description": "First freely available and distributable large German clinical corpus from the cardiovascular domain.", "citation": "@data{\n    data/AFYQDY_2022,\n    author = {Christoph Dieterich},\n    publisher = {heiDATA},\n    title = {{CARDIO:DE}},\n    year = {2022},\n    version = {V5},\n    doi = {10.11588/data/AFYQDY},\n    url = {https://doi.org/10.11588/data/AFYQDY}\n}", "cardData": null, "siblings": [], "_id": "64285e6c7b2cfe4e499c7450", "disabled": false, "gated": false, "likes": 4, "downloads": 16, "createdAt": "2023-04-01T16:40:12.000Z"}, {"id": "bigbio/bronco", "sha": "95c41b1ec74d08bac12feb769ced791ff39ed069", "lastModified": "2023-04-01T16:47:31.000Z", "tags": ["multilinguality:monolingual", "language:de", "region:us"], "private": false, "author": "bigbio", "description": "BRONCO150 is a corpus containing selected sentences of 150 German discharge summaries of cancer patients (hepatocelluar\ncarcinoma or melanoma) treated at Charite Universitaetsmedizin Berlin or Universitaetsklinikum Tuebingen. All discharge\nsummaries were manually anonymized. The original documents were scrambled at the sentence level to make reconstruction\nof individual reports impossible.", "citation": "@article{10.1093/jamiaopen/ooab025,\n    author = {Kittner, Madeleine and Lamping, Mario and Rieke, Damian T and G\u00f6tze, Julian and Bajwa, Bariya and\n    Jelas, Ivan and R\u00fcter, Gina and Hautow, Hanjo and S\u00e4nger, Mario and Habibi, Maryam and Zettwitz, Marit and\n    Bortoli, Till de and Ostermann, Leonie and \u0160eva, Jurica and Starlinger, Johannes and Kohlbacher, Oliver and\n    Malek, Nisar P and Keilholz, Ulrich and Leser, Ulf},\n    title = \"{Annotation and initial evaluation of a large annotated German oncological corpus}\",\n    journal = {JAMIA Open},\n    volume = {4},\n    number = {2},\n    year = {2021},\n    month = {04},\n    issn = {2574-2531},\n    doi = {10.1093/jamiaopen/ooab025},\n    url = {https://doi.org/10.1093/jamiaopen/ooab025},\n    note = {ooab025},\n    eprint = {https://academic.oup.com/jamiaopen/article-pdf/4/2/ooab025/38830128/ooab025.pdf},\n}", "cardData": null, "siblings": [], "_id": "64285ff20fd80c7d4c3b2ab3", "disabled": false, "gated": false, "likes": 2, "downloads": 35, "createdAt": "2023-04-01T16:46:42.000Z"}, {"id": "bigbio/ggponc2", "sha": "a379767b3700f7b72ec08ca42892aa9721bd792c", "lastModified": "2023-04-05T01:15:05.000Z", "tags": ["multilinguality:monolingual", "language:de", "region:us"], "private": false, "author": "bigbio", "description": "The GGPONC project aims to provide a freely distributable corpus of German medical text for NLP researchers. \nClinical guidelines are particularly suitable to create such corpora, as they contain no protected health information \n(PHI), which distinguishes them from other kinds of medical text.\n\nThe second version of the corpus (GGPONC 2.0) consists of 30 German oncology guidelines with 1.87 million tokens. \nIt has been completely manually annotated on the entity level by 7 medical students using the INCEpTION platform over a \ntime frame of 6 months in more than 1200 hours of work. This makes GGPONC 2.0 the largest annotated, freely \ndistributable corpus of German medical text at the moment.\n\nAnnotated entities are Findings (Diagnosis / Pathology, Other Finding), Substances (Clinical Drug, Nutrients / Body \nSubstances, External Substances) and Procedures (Therapeutic, Diagnostic), as well as Specifications for these entities. \nIn total, annotators have created more than 200000 entity annotations. In addition, fragment relationships have been \nannotated to explicitly indicate elliptical coordinated noun phrases, a common phenomenon in German text.", "citation": "@inproceedings{borchert-etal-2022-ggponc,\n    title = \"{GGPONC} 2.0 - The {G}erman Clinical Guideline Corpus for Oncology: Curation Workflow, Annotation Policy, Baseline {NER} Taggers\",\n    author = \"Borchert, Florian  and\n      Lohr, Christina  and\n      Modersohn, Luise  and\n      Witt, Jonas  and\n      Langer, Thomas  and\n      Follmann, Markus  and\n      Gietzelt, Matthias  and\n      Arnrich, Bert  and\n      Hahn, Udo  and\n      Schapranow, Matthieu-P.\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.389\",\n    pages = \"3650--3660\",\n}", "cardData": null, "siblings": [], "_id": "64286080d8c84f8c577c0fe8", "disabled": false, "gated": false, "likes": 4, "downloads": 20, "createdAt": "2023-04-01T16:49:04.000Z"}, {"id": "axiong/pmc_oa", "sha": "4e4c01704af0ad6341c26e7078e153b011b60f58", "lastModified": "2023-08-22T17:42:06.000Z", "tags": ["region:us"], "private": false, "author": "axiong", "description": "Foundation models trained on large-scale dataset gain a recent surge in CV and NLP. In contrast, development in biomedical domain lags far behind due to data scarcity.\nTo address this issue, we build and release PMC-OA, a biomedical dataset with 1.6M image-caption pairs collected from PubMedCentral's OpenAccess subset, which is 8 times larger than before.\nPMC-OA covers diverse modalities or diseases, with majority of the image-caption samples aligned at finer-grained level, i.e., subfigure and subcaption.\nWhile pretraining a CLIP-style model on PMC-OA, our model named PMC-CLIP achieves state-of-the-art results on various downstream tasks,\nincluding image-text retrieval on ROCO, MedMNIST image classification, Medical VQA, i.e. +8.1% R@10 on image-text retrieval, +3.9% accuracy on image classification.", "citation": "@article{lin2023pmc,\n  title={PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents},\n  author={Lin, Weixiong and Zhao, Ziheng and Zhang, Xiaoman and Wu, Chaoyi and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},\n  journal={arXiv preprint arXiv:2303.07240},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "6428e8c7d5f184522af9e54c", "disabled": false, "gated": false, "likes": 17, "downloads": 14, "createdAt": "2023-04-02T02:30:31.000Z"}, {"id": "InstaDeepAI/human_reference_genome", "sha": "baad5cf35ef92b0760b0095870ce77a928cef906", "lastModified": "2023-04-20T13:37:22.000Z", "tags": ["DNA", "Genomics", "Nucleotide", "region:us"], "private": false, "author": "InstaDeepAI", "description": "Genome Reference Consortium Human Build 38 patch release 14 (GRCh38.p14) \nfiltered and split into chunks.", "citation": "@article{o2016reference,\n  title={Reference sequence (RefSeq) database at NCBI: current status, taxonomic expansion, and functional annotation},\n  author={O'Leary, Nuala A and Wright, Mathew W and Brister, J Rodney and Ciufo, Stacy and Haddad, Diana and McVeigh, Rich and Rajput, Bhanu and Robbertse, Barbara and Smith-White, Brian and Ako-Adjei, Danso and others},\n  journal={Nucleic acids research},\n  volume={44},\n  number={D1},\n  pages={D733--D745},\n  year={2016},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "64299c700132d430efdc7566", "disabled": false, "gated": false, "likes": 1, "downloads": 368, "createdAt": "2023-04-02T15:17:04.000Z"}, {"id": "nanakonoda/xnli_parallel", "sha": "764d5540bcd1da587ec2af4bc299bfe6da1b6d27", "lastModified": "2023-04-18T13:23:10.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:extended|xnli", "language:en", "language:de", "language:fr", "mode classification", "aligned", "region:us"], "private": false, "author": "nanakonoda", "description": "This dataset was taken from XNLI for a binary text classification task. It has been parallelized in English, German, and French.", "citation": "# @InProceedings{huggingface:dataset,\n# title = {A great new dataset},\n# author={huggingface, Inc.\n# },\n# year={2020}\n# }", "cardData": null, "siblings": [], "_id": "642a2288316c9207b7c33269", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2023-04-03T00:49:12.000Z"}, {"id": "IES-Rafael-Alberti/letras-carnaval-cadiz", "sha": "948f9d9e0a1f5e5140e3550d3cda29ae12507ae7", "lastModified": "2023-06-04T11:51:32.000Z", "tags": ["annotations_creators:no-annotation", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:es", "license:cc-by-sa-4.0", "lyrics", "carnival", "cadiz", "region:us"], "private": false, "author": "IES-Rafael-Alberti", "description": "This dataset is a comprehensive collection of lyrics from the Carnaval de C\u00e1diz, a significant cultural heritage of the city of C\u00e1diz, Spain. Despite its cultural importance, there has been a lack of a structured database for these lyrics, hindering research and public access to this cultural heritage. This dataset aims to address this gap.\n\nThe dataset was created by the C\u00e1diz AI Learning Community, a branch of the non-profit association Spain AI, and was developed by Iv\u00e1n Romero Reyna and Jes\u00fas Federico Franco Medinilla, students of the Specialization Course in Artificial Intelligence and Big Data at IES Rafael Alberti during the 2022-2023 academic year. The project is supervised by Jes\u00fas Carlos Avecilla de la Herr\u00e1n, a computational linguist.\n\nCollaboration is encouraged, with individuals able to verify the different records of the dataset at letrascarnavalcadiz.com, ensuring the transcription of the lyrics and all data are correct. New lyrics can also be added to the dataset. Corrections and additions are not immediately reflected in the dataset but are updated periodically.\n\nFor more information or to report a problem, you can write to contacto@letrascarnavalcadiz.com.", "citation": "@misc{letrascarnavalcadiz2023,\n  author = {Romero Reyna, Iv\u00e1n and Franco Medinilla, Jes\u00fas Federico and Avecilla de la Herr\u00e1n, Jes\u00fas Carlos},\n  title = {letras-carnaval-cadiz},\n  year = {2023},\n  url = {https://huggingface.co/datasets/IES-Rafael-Alberti/letras-carnaval-cadiz}\n}", "cardData": null, "siblings": [], "_id": "642bfd4ba7077dddc33f8313", "disabled": false, "gated": false, "likes": 2, "downloads": 31, "createdAt": "2023-04-04T10:34:51.000Z"}, {"id": "koutch/intro_prog", "sha": "93e85b1025990ce55c9e81aca7b539a5d5bf4271", "lastModified": "2023-06-05T08:45:02.000Z", "tags": ["region:us"], "private": false, "author": "koutch", "description": "The Dublin programming dataset is a dataset composed of students' submissions \nto introductory programming assignments at the University of Dublin. \nStudents submitted these programs for multiple programming courses over the duration of three academic years.", "citation": "@inproceedings{azcona2019user2code2vec,\n  title={user2code2vec: Embeddings for Profiling Students Based on Distributional Representations of Source Code},\n  author={Azcona, David and Arora, Piyush and Hsiao, I-Han and Smeaton, Alan},\n  booktitle={Proceedings of the 9th International Learning Analytics & Knowledge Conference (LAK\u201919)},\n  year={2019},\n  organization={ACM}\n}\n\n@inproceedings{DBLP:conf/edm/CleuziouF21,\n  author    = {Guillaume Cleuziou and\n               Fr{\\'{e}}d{\\'{e}}ric Flouvat},\n  editor    = {Sharon I{-}Han Hsiao and\n               Shaghayegh (Sherry) Sahebi and\n               Fran{\\c{c}}ois Bouchet and\n               Jill{-}J{\\^{e}}nn Vie},\n  title     = {Learning student program embeddings using abstract execution traces},\n  booktitle = {Proceedings of the 14th International Conference on Educational Data\n               Mining, {EDM} 2021, virtual, June 29 - July 2, 2021},\n  publisher = {International Educational Data Mining Society},\n  year      = {2021},\n  timestamp = {Wed, 09 Mar 2022 16:47:22 +0100},\n  biburl    = {https://dblp.org/rec/conf/edm/CleuziouF21.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "642d8959baf943d5db416e62", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-04-05T14:44:41.000Z"}, {"id": "WxWx/ChatGPT-Detector-Bias", "sha": "ca6b48c8ce435b4750efc895d3c40bfab8bd7d9a", "lastModified": "2023-04-10T00:48:06.000Z", "tags": ["task_categories:text-classification", "size_categories:n<1K", "language:en", "license:mit", "ChatGPT", "GPT Detector", "ChatGPT Detector", "arxiv:2304.02819", "region:us"], "private": false, "author": "WxWx", "description": "The data folders contain the human-written and AI-generated datasets used in our study. Each subfolder contains a name.json file, which provides the metadata, and a data.json file, which contains the text samples.", "citation": "@article{liang2023gpt,\n    title={GPT detectors are biased against non-native English writers}, \n    author={Weixin Liang and Mert Yuksekgonul and Yining Mao and Eric Wu and James Zou},\n    year={2023},\n    eprint={2304.02819},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "642de0cc8ce1f7427b8998bb", "disabled": false, "gated": false, "likes": 8, "downloads": 31, "createdAt": "2023-04-05T20:57:48.000Z"}, {"id": "InstaDeepAI/multi_species_genomes", "sha": "333e848980523b939cd84d7a9d68a6e4ba224772", "lastModified": "2023-11-01T14:07:25.000Z", "tags": ["DNA", "Genomics", "Nucleotide", "region:us"], "private": false, "author": "InstaDeepAI", "description": "Dataset made of diverse genomes available on NCBI and coming from ~850 different species. \nTest and validation are made of 50 species each. The rest of the genomes are used for training.\nDefault configuration \"6kbp\" yields chunks of 6.2kbp (100bp overlap on each side). Similarly,\nthe \"12kbp\"configuration yields chunks of 12.2kbp. The chunks of DNA are cleaned and processed so that\nthey can only contain the letters A, T, C, G and N.", "citation": "@article{o2016reference,\n  title={Reference sequence (RefSeq) database at NCBI: current status, taxonomic expansion, and functional annotation},\n  author={O'Leary, Nuala A and Wright, Mathew W and Brister, J Rodney and Ciufo, Stacy and Haddad, Diana and McVeigh, Rich and Rajput, Bhanu and Robbertse, Barbara and Smith-White, Brian and Ako-Adjei, Danso and others},\n  journal={Nucleic acids research},\n  volume={44},\n  number={D1},\n  pages={D733--D745},\n  year={2016},\n  publisher={Oxford University Press}\n}", "cardData": null, "siblings": [], "_id": "642f180a0a013b879bfa67da", "disabled": false, "gated": false, "likes": 7, "downloads": 47, "createdAt": "2023-04-06T19:05:46.000Z"}, {"id": "hpprc/jsick", "sha": "6f27df527556f0c2774f45297cfca7780477ad75", "lastModified": "2023-04-11T06:18:09.000Z", "tags": ["task_categories:sentence-similarity", "task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "size_categories:10K<n<100K", "source_datasets:extended|sick", "language:ja", "language:en", "license:cc-by-sa-4.0", "semantic-textual-similarity", "sts", "region:us"], "private": false, "author": "hpprc", "description": "Japanese Sentences Involving Compositional Knowledge (JSICK) Dataset.\nJSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.\nWe hope that our dataset will be useful in research for realizing more advanced models that are capable of appropriately performing multilingual compositional inference.\n(from official website)", "citation": "@article{yanaka-mineshima-2022-compositional,\n    title = \"Compositional Evaluation on {J}apanese Textual Entailment and Similarity\",\n    author = \"Yanaka, Hitomi and Mineshima, Koji\",\n    journal = \"Transactions of the Association for Computational Linguistics\",\n    volume = \"10\",\n    year = \"2022\",\n    address = \"Cambridge, MA\",\n    publisher = \"MIT Press\",\n    url = \"https://aclanthology.org/2022.tacl-1.73\",\n    doi = \"10.1162/tacl_a_00518\",\n    pages = \"1266--1284\",\n}", "cardData": null, "siblings": [], "_id": "64318ffe9da0169925117766", "disabled": false, "gated": false, "likes": 4, "downloads": 48, "createdAt": "2023-04-08T16:02:06.000Z"}, {"id": "NTU-NLP-sg/xCodeEval", "sha": "4ddc7355fab7b3d7569a86ee490db723c8cdc25b", "lastModified": "2023-06-03T21:33:12.000Z", "tags": ["task_categories:translation", "task_categories:token-classification", "task_categories:text2text-generation", "task_categories:text-retrieval", "task_categories:text-generation", "task_categories:text-classification", "task_categories:feature-extraction", "task_categories:question-answering", "annotations_creators:expert-generated", "language_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "source_datasets:original", "language:code", "language:en", "license:cc-by-nc-4.0", "programming-language", "code", "program-synthesis", "automatic-code-repair", "code-retrieval", "code-translation", "code-classification", "arxiv:2303.03004", "region:us"], "private": false, "author": "NTU-NLP-sg", "description": "The ability to solve problems is a hallmark of intelligence and has been an enduring goal in AI. AI systems that can create programs as solutions to problems or assist developers in writing programs can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating new codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap rather than actual execution whereas semantic similarity (or equivalence) of two code segments depends only on their ``execution similarity'', i.e., being able to get the same output for a given input.", "citation": "@misc{khan2023xcodeeval,\n\t  title={xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval}, \n\t  author={Mohammad Abdullah Matin Khan and M Saiful Bari and Xuan Long Do and Weishi Wang and Md Rizwan Parvez and Shafiq Joty},\n\t  year={2023},\n\t  eprint={2303.03004},\n\t  archivePrefix={arXiv},\n\t  primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64329b4b95b82ac2908bfae8", "disabled": false, "gated": false, "likes": 24, "downloads": 330, "createdAt": "2023-04-09T11:02:35.000Z"}, {"id": "the-coorporation/the_squad_qg", "sha": "dc00621e6356df4ce4dc72834a274ef98a995f3b", "lastModified": "2023-04-23T16:59:58.000Z", "tags": ["language:en", "license:wtfpl", "region:us"], "private": false, "author": "the-coorporation", "description": "A preprocessed version of the Standford Question Answering Dataset (SQuAD) version 2.0 consisting of contexts and questions only.\n\nDuplicate contexts have been removed and corresponding questions have been merged into an array per context.\n\nStanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. \nSQuAD 2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering.", "citation": "@article{2018arXiv160605250R,\n       author = {{Rajpurkar}, Robin, Jian and {Liang}, Percy},\n        title = \"{Know What You Don't Know: Unanswerable Questions for SQuAD}\",\n      journal = {arXiv e-prints},\n         year = 2018,\n          eid = {arXiv:1806.03822v1},\n        pages = {arXiv:1806.03822v1},\narchivePrefix = {arXiv},\n       eprint = {1806.03822v1},\n}", "cardData": null, "siblings": [], "_id": "64329ea637d643c2690d770b", "disabled": false, "gated": false, "likes": 0, "downloads": 98, "createdAt": "2023-04-09T11:16:54.000Z"}, {"id": "distil-whisper/tedlium", "sha": "31aa998c1cbc36063c5bd5c0ca87b082d443da02", "lastModified": "2023-09-25T10:30:14.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:en", "license:cc-by-nc-nd-3.0", "region:us"], "private": false, "author": "distil-whisper", "description": "The TED-LIUM corpus is English-language TED talks, with transcriptions, sampled at 16kHz. It contains about 118 hours of speech.", "citation": null, "cardData": null, "siblings": [], "_id": "6433bb9d2a81c2a4847aa546", "disabled": false, "gated": false, "likes": 0, "downloads": 78, "createdAt": "2023-04-10T07:32:45.000Z"}, {"id": "nanakonoda/xnli_cm", "sha": "0113dafc21811ee8836e55c5008b9ac25a424b81", "lastModified": "2023-04-18T13:58:12.000Z", "tags": ["task_categories:text-classification", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:multilingual", "size_categories:1M<n<10M", "source_datasets:extended|xnli", "language:en", "language:de", "language:fr", "mode classification", "aligned", "code-mixed", "region:us"], "private": false, "author": "nanakonoda", "description": "This dataset was generated from XNLI using the CodeMixed Text Generator for a binary text classification task.", "citation": "# @InProceedings{huggingface:dataset,\n# title = {A great new dataset},\n# author={huggingface, Inc.\n# },\n# year={2020}\n# }", "cardData": null, "siblings": [], "_id": "6435ab437e07c5aee23744c8", "disabled": false, "gated": false, "likes": 0, "downloads": 27, "createdAt": "2023-04-11T18:47:31.000Z"}, {"id": "NicolaiSivesind/human-vs-machine", "sha": "c766e6943b44bf27432a595c0a226e5c50c5405d", "lastModified": "2023-05-11T13:03:54.000Z", "tags": ["task_categories:text-classification", "size_categories:100K<n<1M", "language:en", "license:cc", "chatgpt", "gpt", "research abstracts", "wikipedia introductions", "region:us"], "private": false, "author": "NicolaiSivesind", "description": "This dataset contains labeled data with human-produced and machine-generated texts based on various \ndomains: Wikipedia introductions and academic articles.", "citation": "@InProceedings{human-vs-machine:dataset,\ntitle = {Human vs Machine dataset collection},\nauthor={Nicolai Sivesind & Andreas Bentzen Winje},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "643945fdcc228b8099b15a7f", "disabled": false, "gated": "auto", "likes": 5, "downloads": 108, "createdAt": "2023-04-14T12:24:29.000Z"}, {"id": "BAAI/COIG", "sha": "9f25758ec94f82762fb9c09a5c60e908cfb83632", "lastModified": "2023-07-12T15:38:35.000Z", "tags": ["language:zh", "license:apache-2.0", "arxiv:2204.07705", "arxiv:2212.10560", "arxiv:2212.09689", "arxiv:2304.07987", "region:us"], "private": false, "author": "BAAI", "description": "We propose the Chinese Open Instruction Generalist (COIG) project to maintain a harmless, helpful, and diverse set of Chinese instruction corpora. We welcome all researchers in the community to contribute to the corpus set and collaborate with us. We only release the first chip of COIG to help the Chinese LLMs' development in the exploration stage and appeal to more researchers joining us in building COIG. We introduce a manually verified translated general instruction corpus, a manually annotated exam instruction corpus, a human value alignment instruction corpus, a multi-round counterfactual correction chat corpus, and a leetcode instruction corpus. We provide these new instruction corpora to assist the community with instruction tuning on Chinese LLMs. These instruction corpora are also template workflows for how new Chinese instruction corpora can be built and expanded effectively.", "citation": "@misc{zhang2023chinese,\n      title={Chinese Open Instruction Generalist: A Preliminary Release}, \n      author={Ge Zhang and Yemin Shi and Ruibo Liu and Ruibin Yuan and Yizhi Li and Siwei Dong and Yu Shu and Zhaoqun Li and Zekun Wang and Chenghua Lin and Wenhao Huang and Jie Fu},\n      year={2023},\n      eprint={2304.07987},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "643bd76c5ff72e5a4e9e118b", "disabled": false, "gated": false, "likes": 343, "downloads": 95, "createdAt": "2023-04-16T11:09:32.000Z"}, {"id": "togethercomputer/RedPajama-Data-1T-Sample", "sha": "776f0cf8399524b53d817f4613cc75c6cd9c5a3b", "lastModified": "2023-07-19T06:59:10.000Z", "tags": ["task_categories:text-generation", "language:en", "region:us"], "private": false, "author": "togethercomputer", "description": "RedPajama is a clean-room, fully open-source implementation of the LLaMa dataset. This is a 1B-token sample of the full dataset.", "citation": null, "cardData": null, "siblings": [], "_id": "643c80de25c7610a1cd83f80", "disabled": false, "gated": false, "likes": 73, "downloads": 12067, "createdAt": "2023-04-16T23:12:30.000Z"}, {"id": "togethercomputer/RedPajama-Data-1T", "sha": "42c1798f62972ae4add822b7d52ec69ba35e0274", "lastModified": "2023-06-30T22:06:10.000Z", "tags": ["task_categories:text-generation", "language:en", "region:us"], "private": false, "author": "togethercomputer", "description": "RedPajama is a clean-room, fully open-source implementation of the LLaMa dataset.", "citation": null, "cardData": null, "siblings": [], "_id": "643ce713099590e9ed8f29f7", "disabled": false, "gated": false, "likes": 919, "downloads": 29058, "createdAt": "2023-04-17T06:28:35.000Z"}, {"id": "webis/Touche23-ValueEval", "sha": "66ed7d7e0ca7778b8662bd31af55365c07d6c1cd", "lastModified": "2023-05-23T20:19:40.000Z", "tags": ["task_categories:text-classification", "task_categories:zero-shot-classification", "task_ids:multi-label-classification", "size_categories:1K<n<10K", "language:en", "license:cc-by-4.0", "Human Values", "Value Detection", "Multi-Label", "region:us"], "private": false, "author": "webis", "description": "Dataset for Touch\\u00E9 / SemEval 2023 Task 4; ValueEval: Identification of Human Values behind Arguments:\nhttps://www.overleaf.com/6679855346wrdckzkdccxg\nBased on the original Webis-ArgValues-22 (https://doi.org/10.5281/zenodo.5657249) dataset accompanying the paper\nIdentifying the Human Values behind Arguments (Kiesel et al. 2022b; https://webis.de/publications.html#kiesel_2022b),\npublished at ACL'22.", "citation": "@Article{mirzakhmedova:2023a,\n  author    = {Nailia Mirzakhmedova and Johannes Kiesel and Milad Alshomary and Maximilian Heinrich and Nicolas Handkeand Xiaoni Cai and Valentin Barriere and Doratossadat Dastgheib and Omid Ghahroodi and {Mohammad Ali} Sadraeiand Ehsaneddin Asgari and Lea Kawaletz and Henning Wachsmuth and Benno Stein},\n  doi       = {10.48550/arXiv.2301.13771},\n  journal   = {CoRR},\n  month     = jan,\n  publisher = {arXiv},\n  title     = {{The Touch{\\'e}23-ValueEval Dataset for Identifying Human Values behind Arguments}},\n  volume    = {abs/2301.13771},\n  year      = 2023\n}", "cardData": null, "siblings": [], "_id": "643d0e93af3fe078a3981a9c", "disabled": false, "gated": false, "likes": 3, "downloads": 295, "createdAt": "2023-04-17T09:17:07.000Z"}, {"id": "jiacheng-ye/logiqa-zh", "sha": "f06e930bfa274389d88f93327c1b5df3b7009975", "lastModified": "2023-04-21T00:56:28.000Z", "tags": ["task_categories:question-answering", "size_categories:1K<n<10K", "language:zh", "region:us"], "private": false, "author": "jiacheng-ye", "description": "LogiQA is constructed from the logical comprehension problems from publically available questions of the National Civil Servants Examination of China, which is designed to test the civil servant candidates\u2019 critical thinking and problem-solving. This dataset includes the Chinese versions only", "citation": "@article{liu2020logiqa,\n  title={Logiqa: A challenge dataset for machine reading comprehension with logical reasoning},\n  author={Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},\n  journal={arXiv preprint arXiv:2007.08124},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "643d3e18bf8e4a061c785de1", "disabled": false, "gated": false, "likes": 14, "downloads": 118, "paperswithcode_id": "logiqa", "createdAt": "2023-04-17T12:39:52.000Z"}, {"id": "jiacheng-ye/nl2bash", "sha": "8731103005b818a0298e658feb30005eb1d5e2f1", "lastModified": "2023-04-17T12:55:38.000Z", "tags": ["task_categories:text-generation", "size_categories:1K<n<10K", "language:en", "code", "region:us"], "private": false, "author": "jiacheng-ye", "description": "The dataset is constructed from\nhttps://github.com/TellinaTool/nl2bash", "citation": "@inproceedings{LinWZE2018:NL2Bash, \n  author = {Xi Victoria Lin and Chenglong Wang and Luke Zettlemoyer and Michael D. Ernst}, \n  title = {NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System}, \n  booktitle = {Proceedings of the Eleventh International Conference on Language Resources\n               and Evaluation {LREC} 2018, Miyazaki (Japan), 7-12 May, 2018.},\n  year = {2018} \n}", "cardData": null, "siblings": [], "_id": "643d415dd2c1e08a5eca905e", "disabled": false, "gated": false, "likes": 0, "downloads": 78, "createdAt": "2023-04-17T12:53:49.000Z"}, {"id": "lighteval/MATH", "sha": "4ebaf55853e6a047819819ccdb8f0d5fe809952c", "lastModified": "2023-10-17T20:52:35.000Z", "tags": ["region:us"], "private": false, "author": "lighteval", "description": "MATH is a dataset of 12,500 challenging competition mathematics problems. Each\nproblem in Math has a full step-by-step solution which can be used to teach\nmodels to generate answer derivations and explanations.", "citation": "@article{hendrycksmath2021,\n  title={Measuring Mathematical Problem Solving With the Math Dataset},\n  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},\n  journal={NeurIPS},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "644154c8e46e14ed558f7da8", "disabled": false, "gated": false, "likes": 3, "downloads": 937, "createdAt": "2023-04-20T15:05:44.000Z"}, {"id": "masakhane/masakhanews", "sha": "8ccc72e69e65f40c70e117d8b3c08306bb788b60", "lastModified": "2023-05-25T22:27:40.000Z", "tags": ["task_categories:text-classification", "task_ids:topic-classification", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:am", "language:en", "language:fr", "language:ha", "language:ig", "language:ln", "language:lg", "language:om", "language:pcm", "language:rn", "language:sn", "language:so", "language:sw", "language:ti", "language:xh", "language:yo", "license:afl-3.0", "news-topic", "masakhanews", "masakhane", "region:us"], "private": false, "author": "masakhane", "description": "MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa.\n\nThe languages are:\n- Amharic (amh)\n- English (eng)\n- French (fra)\n- Hausa (hau)\n- Igbo (ibo)\n- Lingala (lin)\n- Luganda (lug)\n- Oromo (orm)\n- Nigerian Pidgin (pcm)\n- Rundi (run)\n- chShona (sna)\n- Somali (som)\n- Kiswahili (sw\u0105)\n- Tigrinya (tir)\n- isiXhosa (xho)\n- Yor\u00f9b\u00e1 (yor)\n\nThe train/validation/test sets are available for all the 16 languages.\n\nFor more details see *** arXiv link **", "citation": "@article{Adelani2023MasakhaNEWS,\n  title={MasakhaNEWS: News Topic Classification for African languages},\n  author={David Ifeoluwa Adelani and  Marek Masiak and  Israel Abebe Azime and  Jesujoba Oluwadara Alabi and  Atnafu Lambebo Tonja and  Christine Mwase and  Odunayo Ogundepo and  Bonaventure F. P. Dossou and  Akintunde Oladipo and  Doreen Nixdorf and  Chris Chinenye Emezue and  Sana Sabah al-azzawi and  Blessing K. Sibanda and  Davis David and  Lolwethu Ndolela and  Jonathan Mukiibi and  Tunde Oluwaseyi Ajayi and  Tatiana Moteu Ngoli and  Brian Odhiambo and  Abraham Toluwase Owodunni and  Nnaemeka C. Obiefuna and  Shamsuddeen Hassan Muhammad and  Saheed Salahudeen Abdullahi and  Mesay Gemeda Yigezu and  Tajuddeen Gwadabe and  Idris Abdulmumin and  Mahlet Taye Bame and  Oluwabusayo Olufunke Awoyomi and  Iyanuoluwa Shode and  Tolulope Anu Adelani and  Habiba Abdulganiy Kailani and  Abdul-Hakeem Omotayo and  Adetola Adeeko and  Afolabi Abeeb and  Anuoluwapo Aremu and  Olanrewaju Samuel and  Clemencia Siro and  Wangari Kimotho and  Onyekachi Raphael Ogbu and  Chinedu E. Mbonu and  Chiamaka I. Chukwuneke and  Samuel Fanijo and  Jessica Ojo and  Oyinkansola F. Awosan and  Tadesse Kebede Guge and  Sakayo Toadoum Sari and  Pamela Nyatsine and  Freedmore Sidume and  Oreen Yousuf and  Mardiyyah Oduwole and  Ussen Kimanuka and  Kanda Patrick Tshinu and  Thina Diko and  Siyanda Nxakama and   Abdulmejid Tuni Johar and  Sinodos Gebre and  Muhidin Mohamed and  Shafie Abdi Mohamed and  Fuad Mire Hassan and  Moges Ahmed Mehamed and  Evrard Ngabire and  and Pontus Stenetorp},\n  journal={ArXiv},\n  year={2023},\n  volume={}\n}", "cardData": null, "siblings": [], "_id": "6441c57a55a16ae60fa27182", "disabled": false, "gated": false, "likes": 5, "downloads": 1864, "createdAt": "2023-04-20T23:06:34.000Z"}, {"id": "EdwardLin2023/MELD-Audio", "sha": "a263eb7e65e444f3d951fda38d1c1d7f79f5a43b", "lastModified": "2023-04-24T04:04:52.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "EdwardLin2023", "description": "Multimodal EmotionLines Dataset (MELD) has been created by enhancing and extending EmotionLines dataset. \nMELD contains the same dialogue instances available in EmotionLines, but it also encompasses audio and \nvisual modality along with text. MELD has more than 1400 dialogues and 13000 utterances from Friends TV series. \nMultiple speakers participated in the dialogues. Each utterance in a dialogue has been labeled by any of these \nseven emotions -- Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. MELD also has sentiment (positive, \nnegative and neutral) annotation for each utterance.\n\nThis dataset is slightly modified, so that it concentrates on Emotion recognition in audio input only.", "citation": "@article{poria2018meld,\n  title={Meld: A multimodal multi-party dataset for emotion recognition in conversations},\n  author={Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},\n  journal={arXiv preprint arXiv:1810.02508},\n  year={2018}\n}\n@article{chen2018emotionlines,\n  title={Emotionlines: An emotion corpus of multi-party conversations},\n  author={Chen, Sheng-Yeh and Hsu, Chao-Chun and Kuo, Chuan-Chun and Ku, Lun-Wei and others},\n  journal={arXiv preprint arXiv:1802.08379},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "6441f92fa839ee803323565c", "disabled": false, "gated": false, "likes": 0, "downloads": 176, "createdAt": "2023-04-21T02:47:11.000Z"}, {"id": "sbmaruf/forai_ml_masakhane_mafand", "sha": "041afc3c6ca1e358b72a07a0d6209ffecdc2b947", "lastModified": "2023-05-25T00:11:20.000Z", "tags": ["task_categories:translation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:translation", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "language:fr", "language:am", "language:bm", "language:bbj", "language:ee", "language:fon", "language:ha", "language:ig", "language:lg", "language:mos", "language:ny", "language:pcm", "language:rw", "language:sn", "language:sw", "language:tn", "language:tw", "language:wo", "language:xh", "language:yo", "language:zu", "license:cc-by-nc-4.0", "news, mafand, masakhane", "region:us"], "private": false, "author": "sbmaruf", "description": "MAFAND-MT is the largest MT benchmark for African languages in the news domain, covering 21 languages. The languages covered are:\n- Amharic\n- Bambara\n- Ghomala\n- Ewe\n- Fon\n- Hausa\n- Igbo\n- Kinyarwanda\n- Luganda\n- Luo\n- Mossi\n- Nigerian-Pidgin\n- Chichewa\n- Shona\n- Swahili\n- Setswana\n- Twi\n- Wolof\n- Xhosa\n- Yoruba\n- Zulu\nThe train/validation/test sets are available for 16 languages, and validation/test set for amh, kin, nya, sna, and xho\nFor more details see https://aclanthology.org/2022.naacl-main.223/", "citation": "@inproceedings{adelani-etal-2022-thousand,\n    title = \"A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models for {A}frican News Translation\",\n    author = \"Adelani, David  and\n      Alabi, Jesujoba  and\n      Fan, Angela  and\n      Kreutzer, Julia  and\n      Shen, Xiaoyu  and\n      Reid, Machel  and\n      Ruiter, Dana  and\n      Klakow, Dietrich  and\n      Nabende, Peter  and\n      Chang, Ernie  and\n      Gwadabe, Tajuddeen  and\n      Sackey, Freshia  and\n      Dossou, Bonaventure F. P.  and\n      Emezue, Chris  and\n      Leong, Colin  and\n      Beukman, Michael  and\n      Muhammad, Shamsuddeen  and\n      Jarso, Guyo  and\n      Yousuf, Oreen  and\n      Niyongabo Rubungo, Andre  and\n      Hacheme, Gilles  and\n      Wairagala, Eric Peter  and\n      Nasir, Muhammad Umair  and\n      Ajibade, Benjamin  and\n      Ajayi, Tunde  and\n      Gitau, Yvonne  and\n      Abbott, Jade  and\n      Ahmed, Mohamed  and\n      Ochieng, Millicent  and\n      Aremu, Anuoluwapo  and\n      Ogayo, Perez  and\n      Mukiibi, Jonathan  and\n      Ouoba Kabore, Fatoumata  and\n      Kalipe, Godson  and\n      Mbaye, Derguene  and\n      Tapo, Allahsera Auguste  and\n      Memdjokam Koagne, Victoire  and\n      Munkoh-Buabeng, Edwin  and\n      Wagner, Valencia  and\n      Abdulmumin, Idris  and\n      Awokoya, Ayodele  and\n      Buzaaba, Happy  and\n      Sibanda, Blessing  and\n      Bukula, Andiswa  and\n      Manthalu, Sam\",\n    booktitle = \"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\",\n    month = jul,\n    year = \"2022\",\n    address = \"Seattle, United States\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.naacl-main.223\",\n    doi = \"10.18653/v1/2022.naacl-main.223\",\n    pages = \"3053--3070\",\n    abstract = \"Recent advances in the pre-training for language models leverage large-scale datasets to create multilingual models. However, low-resource languages are mostly left out in these datasets. This is primarily because many widely spoken languages that are not well represented on the web and therefore excluded from the large-scale crawls for datasets. Furthermore, downstream users of these models are restricted to the selection of languages originally chosen for pre-training. This work investigates how to optimally leverage existing pre-trained models to create low-resource translation systems for 16 African languages. We focus on two questions: 1) How can pre-trained models be used for languages not included in the initial pretraining? and 2) How can the resulting translation models effectively transfer to new domains? To answer these questions, we create a novel African news corpus covering 16 languages, of which eight languages are not part of any existing evaluation dataset. We demonstrate that the most effective strategy for transferring both additional languages and additional domains is to leverage small quantities of high-quality translation data to fine-tune large pre-trained models.\",\n}", "cardData": null, "siblings": [], "_id": "64441cbdc63001ae635353d8", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2023-04-22T17:43:25.000Z"}, {"id": "masakhane/afriqa", "sha": "ad2551ec00aa33e358b045f5c26077bacf9628f9", "lastModified": "2023-07-07T16:57:28.000Z", "tags": ["task_categories:question-answering", "multilinguality:multilingual", "size_categories:10K<n<100K", "language:bem", "language:fon", "language:ha", "language:ig", "language:kin", "language:sw", "language:wo", "language:yo", "language:zu", "language:tw", "license:cc-by-sa-4.0", "cross-lingual", "question-answering", "qa", "arxiv:2305.06897", "region:us"], "private": false, "author": "masakhane", "description": "AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages\n\nAfriQA is the first cross-lingual question answering (QA) dataset with a focus on African languages. \nThe dataset includes over 12,000 XOR QA examples across 10 African languages, making it an invaluable resource for developing more equitable QA technology.", "citation": "\\", "cardData": null, "siblings": [], "_id": "64458f970f2fc80feb2a00e2", "disabled": false, "gated": false, "likes": 5, "downloads": 787, "createdAt": "2023-04-23T20:05:43.000Z"}, {"id": "PORTULAN/glue-ptpt", "sha": "ea4e7982937844aa4522f6ba73cd946fdb159e37", "lastModified": "2023-05-12T12:49:02.000Z", "tags": ["language_creators:machine-generated", "size_categories:10K<n<100K", "source_datasets:glue", "language:pt", "arxiv:2305.06721", "region:us"], "private": false, "author": "PORTULAN", "description": "GLUE-PTPT is an European Portuguese translation of the GLUE benchmark using DeepL Pro.", "citation": "@misc{Gomes2023,\n  author = {Lu\u00eds Gomes and Jo\u00e3o Rodrigues and Jo\u00e3o Silva and Ant\u00f3nio Branco and Rodrigo Santos},\n  title = {GLUE-PTPT -- The General Language Understanding Evaluation benchmark translated to European Portuguese},\n  year = {2023},\n  publisher = {Hugging Face},\n  journal = {Hugging Face dataset},\n  howpublished = {\\\\url{https://huggingface.co/datasets/PORTULAN/glue-ptpt}},\n}", "cardData": null, "siblings": [], "_id": "6445c93653ecc52f50f82f77", "disabled": false, "gated": false, "likes": 4, "downloads": 317, "createdAt": "2023-04-24T00:11:34.000Z"}, {"id": "lighteval/pile", "sha": "de0ec422dfc63d4dd80879a86905c2901d4a6348", "lastModified": "2023-04-26T06:27:38.000Z", "tags": ["region:us"], "private": false, "author": "lighteval", "description": "The Pile is a 825 GiB diverse, open source language modeling data set that consists\nof 22 smaller, high-quality datasets combined together. To score well on Pile\nBPB (bits per byte), a model must be able to understand many disparate domains\nincluding books, github repositories, webpages, chat logs, and medical, physics,\nmath, computer science, and philosophy papers.", "citation": "@article{pile,\n  title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},\n  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},\n  journal={arXiv preprint arXiv:2101.00027},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6448c423d16a70c01589a52f", "disabled": false, "gated": false, "likes": 0, "downloads": 62, "createdAt": "2023-04-26T06:26:43.000Z"}, {"id": "StampyAI/alignment-research-dataset", "sha": "f49f467a16f5126e984a53967203e94b82d1bd70", "lastModified": "2023-11-16T16:58:51.000Z", "tags": ["task_categories:question-answering", "size_categories:10K<n<100K", "language:en", "license:mit", "arxiv:2206.02841", "region:us"], "private": false, "author": "StampyAI", "description": "The AI Alignment Research Dataset is a collection of documents related to AI Alignment and Safety from various books, research papers, and alignment related blog posts.", "citation": null, "cardData": null, "siblings": [], "_id": "6448e78ad16a70c0158d7b92", "disabled": false, "gated": false, "likes": 7, "downloads": 74, "createdAt": "2023-04-26T08:57:46.000Z"}, {"id": "ai-forever/spellcheck_benchmark", "sha": "3395aa540689e4393c3e18d063e73a5b99d7f047", "lastModified": "2023-10-04T16:13:44.000Z", "tags": ["task_categories:text-generation", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<20k", "language:ru", "license:mit", "spellcheck", "russian", "arxiv:2308.09435", "region:us"], "private": false, "author": "ai-forever", "description": "Russian Spellcheck Benchmark is a new benchmark for spelling correction in Russian language.\n                It includes four datasets, each of which consists of pairs of sentences in Russian language. \n                Each pair embodies sentence, which may contain spelling errors, and its corresponding correction. \n                Datasets were gathered from various sources and domains including social networks, internet blogs, github commits, \n                medical anamnesis, literature, news, reviews and more.", "citation": "# TODO: add citation", "cardData": null, "siblings": [], "_id": "644b96b46586065501e2d42c", "disabled": false, "gated": false, "likes": 2, "downloads": 83, "createdAt": "2023-04-28T09:49:40.000Z"}, {"id": "moyix/asleep_keyboard", "sha": "cae80cf0b8561236240d775bee0d3c02d9565881", "lastModified": "2023-04-28T16:59:11.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:mit", "code-generation", "arxiv:2108.09293", "region:us"], "private": false, "author": "moyix", "description": "The Asleep at the Keyboard dataset contains 89 code generation scenarios that are designed to test the ability of code generation models to generate code secure code. The dataset is split into three evaluation axes: diversity of weaknesses (DoW), diversity of prompts (DoP), and diversity of domains (DoD).\n\nTo perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, e.g. those from MITRE\u2019s \u201cTop 25\u201d Common Weakness Enumeration (CWE) list. We explore Copilot\u2019s performance on three distinct code generation axes\u2014examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios", "citation": "@inproceedings{pearce2022asleep,\n\tAuthor = {Hammond Pearce and Baleegh Ahmad and Benjamin Tan and Brendan Dolan-Gavitt and Ramesh Karri},\n    year = {2022},\n    booktitle = {IEEE Symposium on Security and Privacy},\n    Url = {https://arxiv.org/abs/2108.09293},\n    address = {San Francisco, CA},\n\tTitle = {Asleep at the Keyboard? Assessing the Security of {GitHub Copilot}'s Code Contributions},\n}", "cardData": null, "siblings": [], "_id": "644bfb1f45e79023c7dac356", "disabled": false, "gated": false, "likes": 2, "downloads": 192, "createdAt": "2023-04-28T16:58:07.000Z"}, {"id": "EleutherAI/truthful_qa_mc", "sha": "0e21fda4ea37223e25ab6c4d30e8a4cf2e32f2f1", "lastModified": "2023-04-29T06:24:04.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:language-modeling", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2109.07958", "region:us"], "private": false, "author": "EleutherAI", "description": "TruthfulQA-MC is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.", "citation": "@misc{lin2021truthfulqa,\n    title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},\n    author={Stephanie Lin and Jacob Hilton and Owain Evans},\n    year={2021},\n    eprint={2109.07958},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "644cb09845e79023c7f0708f", "disabled": false, "gated": false, "likes": 4, "downloads": 978, "createdAt": "2023-04-29T05:52:24.000Z"}, {"id": "EleutherAI/truthful_qa_binary", "sha": "faca0a41bb664695a60283855535938e18d5d719", "lastModified": "2023-04-29T23:40:19.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_ids:multiple-choice-qa", "task_ids:language-modeling", "task_ids:open-domain-qa", "annotations_creators:expert-generated", "language_creators:expert-generated", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:apache-2.0", "arxiv:2109.07958", "region:us"], "private": false, "author": "EleutherAI", "description": "TruthfulQA-Binary is a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. Questions are\ncrafted so that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts.", "citation": "@misc{lin2021truthfulqa,\n    title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},\n    author={Stephanie Lin and Jacob Hilton and Owain Evans},\n    year={2021},\n    eprint={2109.07958},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "644daa5d97a3b0904a5ba000", "disabled": false, "gated": false, "likes": 1, "downloads": 25, "createdAt": "2023-04-29T23:38:05.000Z"}, {"id": "cardy/kohatespeech", "sha": "361daa030cd6cec74a2c039965f21a0bb4a70901", "lastModified": "2023-05-01T02:24:59.000Z", "tags": ["license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "cardy", "description": "They provide the first human-annotated Korean corpus for toxic speech detection and the large unlabeled corpus.\nThe data is comments from the Korean entertainment news aggregation platform.", "citation": "@inproceedings{moon-etal-2020-beep,\n    title = \"{BEEP}! {K}orean Corpus of Online News Comments for Toxic Speech Detection\",\n    author = \"Moon, Jihyung  and\n      Cho, Won Ik  and\n      Lee, Junbum\",\n    booktitle = \"Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.socialnlp-1.4\",\n    pages = \"25--31\",\n    abstract = \"Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff{'}s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.\",\n}", "cardData": null, "siblings": [], "_id": "644e574cddf20748b054406a", "disabled": false, "gated": false, "likes": 0, "downloads": 416, "createdAt": "2023-04-30T11:55:56.000Z"}, {"id": "llm-book/JGLUE", "sha": "62b3730b6c0c1e4c648103723f8f7fb81ad4707f", "lastModified": "2023-10-06T00:58:24.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "task_categories:sentence-similarity", "task_categories:text-classification", "task_ids:multiple-choice-qa", "task_ids:open-domain-qa", "task_ids:multi-class-classification", "task_ids:sentiment-classification", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:ja", "license:cc-by-4.0", "MARC", "STS", "NLI", "SQuAD", "CommonsenseQA", "region:us"], "private": false, "author": "llm-book", "description": "JGLUE, Japanese General Language Understanding Evaluation, is built to measure the general NLU ability in Japanese. JGLUE has been constructed from scratch without translation. We hope that JGLUE will facilitate NLU research in Japanese.", "citation": "@inproceedings{kurihara-etal-2022-jglue,\n    title = \"{JGLUE}: {J}apanese General Language Understanding Evaluation\",\n    author = \"Kurihara, Kentaro  and\n      Kawahara, Daisuke  and\n      Shibata, Tomohide\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.317\",\n    pages = \"2957--2966\",\n    abstract = \"To develop high-performance natural language understanding (NLU) models, it is necessary to have a benchmark to evaluate and analyze NLU ability from various perspectives. While the English NLU benchmark, GLUE, has been the forerunner, benchmarks are now being released for languages other than English, such as CLUE for Chinese and FLUE for French; but there is no such benchmark for Japanese. We build a Japanese NLU benchmark, JGLUE, from scratch without translation to measure the general NLU ability in Japanese. We hope that JGLUE will facilitate NLU research in Japanese.\",\n}\n@InProceedings{Kurihara_nlp2022,\n  author = \t\"\u6817\u539f\u5065\u592a\u90ce and \u6cb3\u539f\u5927\u8f14 and \u67f4\u7530\u77e5\u79c0\",\n  title = \t\"JGLUE: \u65e5\u672c\u8a9e\u8a00\u8a9e\u7406\u89e3\u30d9\u30f3\u30c1\u30de\u30fc\u30af\",\n  booktitle = \t\"\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a\u7b2c28\u56de\u5e74\u6b21\u5927\u4f1a\",\n  year =\t\"2022\",\n  url = \"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/E8-4.pdf\"\n  note= \"in Japanese\"\n}", "cardData": null, "siblings": [], "_id": "644fb7f4d5f7dafcfa5e93da", "disabled": false, "gated": false, "likes": 5, "downloads": 1757, "createdAt": "2023-05-01T13:00:36.000Z"}, {"id": "maxardito/beatbox", "sha": "93db6d291d431e96df070a71bffc9280a7174a3f", "lastModified": "2023-05-08T02:40:48.000Z", "tags": ["license:mit", "Audio", "Voice", "Percussion", "region:us"], "private": false, "author": "maxardito", "description": "    Dataset consisting of isolated beatbox samples ,\n    reimplementation of the dataset from the following \n    paper: BaDumTss: Multi-task Learning for Beatbox Transcription", "citation": "# @inproceedings{luong-vu-2016-non,\n#     title = \"A non-expert {K}aldi recipe for {V}ietnamese Speech Recognition System\",\n#     author = \"Luong, Hieu-Thi  and\n#       Vu, Hai-Quan\",\n#     booktitle = \"Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies ({WLSI}/{OIAF}4{HLT}2016)\",\n#     month = dec,\n#     year = \"2016\",\n#     address = \"Osaka, Japan\",\n#     publisher = \"The COLING 2016 Organizing Committee\",\n#     url = \"https://aclanthology.org/W16-5207\",\n#     pages = \"51--55\",\n# }\n#", "cardData": null, "siblings": [], "_id": "64513b26b3f75261a7d6f695", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2023-05-02T16:32:38.000Z"}, {"id": "hoskinson-center/minif2f-lean4", "sha": "0650b509aab972cd9a7e941d5fa56309f19ab0bb", "lastModified": "2023-05-03T21:20:52.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "hoskinson-center", "description": "A Lean 4 version of minif2f.", "citation": null, "cardData": null, "siblings": [], "_id": "6451b87c41f3c769b91de273", "disabled": false, "gated": false, "likes": 8, "downloads": 66, "createdAt": "2023-05-03T01:27:24.000Z"}, {"id": "TrainingDataPro/license_plates", "sha": "be220f6c72d48b0f66c71d45ad51a6c08411a54b", "lastModified": "2023-09-14T16:42:28.000Z", "tags": ["task_categories:image-to-text", "language:en", "license:cc-by-nc-nd-4.0", "finance", "region:us"], "private": false, "author": "TrainingDataPro", "description": "Over 1.2 million annotated license plates from vehicles around the world.\nThis dataset is tailored for License Plate Recognition tasks and includes\nimages from both YouTube and PlatesMania. \nAnnotation details are provided in the About section below.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {license_plates},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64520f6c94a54195ce4efd6c", "disabled": false, "gated": false, "likes": 3, "downloads": 13, "createdAt": "2023-05-03T07:38:20.000Z"}, {"id": "MMInstruction/M3IT", "sha": "2256415bd85b14945ac717170274565adb2a2b2d", "lastModified": "2023-11-24T08:23:25.000Z", "tags": ["task_categories:image-to-text", "task_categories:image-classification", "size_categories:1M<n<10M", "language:en", "language:zh", "license:other", "region:us"], "private": false, "author": "MMInstruction", "description": "Multi-modal Bi-lingual Instruction Dataset for Vision Language Models", "citation": null, "cardData": null, "siblings": [], "_id": "64530dc38fe6558e328b0f15", "disabled": false, "gated": false, "likes": 57, "downloads": 20089, "createdAt": "2023-05-04T01:43:31.000Z"}, {"id": "biglam/dating-historical-color-images", "sha": "d91ea6f10e76336b99923e87d0c91746e4fa3f58", "lastModified": "2023-05-05T16:22:09.000Z", "tags": ["task_categories:image-classification", "size_categories:1K<n<10K", "history ", "lam", "photography", "region:us"], "private": false, "author": "biglam", "description": "This dataset contains color photographs taken between the 1930s and 1970s. \nThe goal of the dataset is to develop methods for dating historical color photographs", "citation": "@inproceedings{10.1007/978-3-642-33783-3_36,\nauthor = {Palermo, Frank and Hays, James and Efros, Alexei A.},\ntitle = {Dating Historical Color Images},\nyear = {2012},\nisbn = {9783642337826},\npublisher = {Springer-Verlag},\naddress = {Berlin, Heidelberg},\nurl = {https://doi.org/10.1007/978-3-642-33783-3_36},\ndoi = {10.1007/978-3-642-33783-3_36},\nabstract = {We introduce the task of automatically estimating the age of historical color photographs. We suggest features which attempt to capture temporally discriminative information based on the evolution of color imaging processes over time and evaluate the performance of both these novel features and existing features commonly utilized in other problem domains on a novel historical image data set. For the challenging classification task of sorting historical color images into the decade during which they were photographed, we demonstrate significantly greater accuracy than that shown by untrained humans on the same data set. Additionally, we apply the concept of data-driven camera response function estimation to historical color imagery, demonstrating its relevance to both the age estimation task and the popular application of imitating the appearance of vintage color photography.},\nbooktitle = {Proceedings of the 12th European Conference on Computer Vision - Volume Part VI},\npages = {499\u2013512},\nnumpages = {14},\nlocation = {Florence, Italy},\nseries = {ECCV'12}\n}", "cardData": null, "siblings": [], "_id": "6453c2c972d331dec898c10d", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "createdAt": "2023-05-04T14:35:53.000Z"}, {"id": "Fsoft-AIC/the-vault-function", "sha": "e3e48d8388393ba054ec0824397184d89c4266d5", "lastModified": "2023-07-04T02:33:36.000Z", "tags": ["task_categories:text-generation", "multilinguality:multiprogramming languages", "language:code", "language:en", "license:mit", "arxiv:2305.06156", "region:us"], "private": false, "author": "Fsoft-AIC", "description": "The Vault is a multilingual code-text dataset with over 40 million pairs covering 10 popular programming languages. \nIt is the largest corpus containing parallel code-text data. By building upon The Stack, a massive raw code sample collection, \nthe Vault offers a comprehensive and clean resource for advancing research in code understanding and generation. It provides a \nhigh-quality dataset that includes code-text pairs at multiple levels, such as class and inline-level, in addition to the function level. \nThe Vault can serve many purposes at multiple levels.", "citation": "@article{manh2023vault,\n  title={The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation},\n  author={Manh, Dung Nguyen and Hai, Nam Le and Dau, Anh TV and Nguyen, Anh Minh and Nghiem, Khanh and Guo, Jin and Bui, Nghi DQ},\n  journal={arXiv preprint arXiv:2305.06156},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "645511ebd55525a4fee65944", "disabled": false, "gated": false, "likes": 8, "downloads": 143, "createdAt": "2023-05-05T14:25:47.000Z"}, {"id": "tomas-gajarsky/cifar100-lt", "sha": "44737f49e6362e68840e62e38d253f1d8b4e3170", "lastModified": "2023-06-24T20:25:07.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:cifar100", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "tomas-gajarsky", "description": "The CIFAR-100-LT dataset is comprised of under 60,000 color images, each measuring 32x32 pixels, \ndistributed across 100 distinct classes. \nThe number of samples within each class decreases exponentially with factors of 10 and 100. \nThe dataset includes 10,000 test images, with 100 images per class, \nand fewer than 50,000 training images. \nThese 100 classes are further organized into 20 overarching superclasses. \nEach image is assigned two labels: a fine label denoting the specific class, \nand a coarse label representing the associated superclass.", "citation": "@TECHREPORT{Krizhevsky09learningmultiple,\n    author = {Alex Krizhevsky},\n    title = {Learning multiple layers of features from tiny images},\n    institution = {},\n    year = {2009}\n}", "cardData": null, "siblings": [], "_id": "6455243ef61f10d69dca1bdc", "disabled": false, "gated": false, "likes": 0, "downloads": 201, "paperswithcode_id": "cifar-100", "createdAt": "2023-05-05T15:43:58.000Z"}, {"id": "tomas-gajarsky/cifar10-lt", "sha": "e24fcf4f7ad751e16ede941ede107c2002010d00", "lastModified": "2023-06-24T20:22:30.000Z", "tags": ["task_categories:image-classification", "annotations_creators:crowdsourced", "language_creators:found", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:cifar10", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "tomas-gajarsky", "description": "The CIFAR-10-LT imbalanced dataset is comprised of under 60,000 color images, each measuring 32x32 pixels, \ndistributed across 10 distinct classes.  \nThe dataset includes 10,000 test images, with 1000 images per class, \nand fewer than 50,000 training images.\nThe number of samples within each class of the train set decreases exponentially with factors of 10, 50 or 100.", "citation": "@TECHREPORT{Krizhevsky09learningmultiple,\n    author = {Alex Krizhevsky},\n    title = {Learning multiple layers of features from tiny images},\n    institution = {},\n    year = {2009}\n}", "cardData": null, "siblings": [], "_id": "64564062cd6567f52fb2e095", "disabled": false, "gated": false, "likes": 1, "downloads": 176, "paperswithcode_id": "cifar-10", "createdAt": "2023-05-06T11:56:18.000Z"}, {"id": "turkish-nlp-suite/turkish-wikiNER", "sha": "fcfbf7f3d5a705fd5edf054003a911226652c756", "lastModified": "2023-09-26T10:37:00.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:tr", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "turkish-nlp-suite", "description": "General Purpose Turkish NER dataset. 19 labels and 20.000 instances at total. [Turkish Wiki NER dataset](https://github.com/turkish-nlp-suite/Turkish-Wiki-NER-Dataset)", "citation": "@inproceedings{altinok-2023-diverse,\n    title = \"A Diverse Set of Freely Available Linguistic Resources for {T}urkish\",\n    author = \"Altinok, Duygu\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.768\",\n    pages = \"13739--13750\",\n    abstract = \"This study presents a diverse set of freely available linguistic resources for Turkish natural language processing, including corpora, pretrained models and education material. Although Turkish is spoken by a sizeable population of over 80 million people, Turkish linguistic resources for natural language processing remain scarce. In this study, we provide corpora to allow practitioners to build their own applications and pretrained models that would assist industry researchers in creating quick prototypes. The provided corpora include named entity recognition datasets of diverse genres, including Wikipedia articles and supplement products customer reviews. In addition, crawling e-commerce and movie reviews websites, we compiled several sentiment analysis datasets of different genres. Our linguistic resources for Turkish also include pretrained spaCy language models. To the best of our knowledge, our models are the first spaCy models trained for the Turkish language. Finally, we provide various types of education material, such as video tutorials and code examples, that can support the interested audience on practicing Turkish NLP. The advantages of our linguistic resources are three-fold: they are freely available, they are first of their kind, and they are easy to use in a broad range of implementations. Along with a thorough description of the resource creation process, we also explain the position of our resources in the Turkish NLP world.\",\n}", "cardData": null, "siblings": [], "_id": "6457d4a006d739e82b1b1d19", "disabled": false, "gated": false, "likes": 0, "downloads": 34, "createdAt": "2023-05-07T16:41:04.000Z"}, {"id": "matejklemen/falko_merlin", "sha": "f55056701f7e695a0334073164bcc782efb90c65", "lastModified": "2023-05-08T20:56:31.000Z", "tags": ["license:cc-by-sa-4.0", "region:us"], "private": false, "author": "matejklemen", "description": "Falko-MERLIN is a grammatical error correction corpus consisting of essays and exams.", "citation": "@InProceedings{boyd2018wnut,\n  author    = {Adriane Boyd},\n  title     = {Using Wikipedia Edits in Low Resource Grammatical Error Correction},\n  booktitle = {Proceedings of the 4th Workshop on Noisy User-generated Text},\n  publisher = {Association for Computational Linguistics},\n  year      = {2018},\n  url       = {http://aclweb.org/anthology/W18-6111}\n}", "cardData": null, "siblings": [], "_id": "64595bf8c5d0d57ba42663f9", "disabled": false, "gated": false, "likes": 0, "downloads": 57, "createdAt": "2023-05-08T20:30:48.000Z"}, {"id": "juletxara/mgsm", "sha": "f52417ca77bd71e9888ddc29f92587660725d2b4", "lastModified": "2023-05-09T16:46:31.000Z", "tags": ["task_categories:text2text-generation", "annotations_creators:found", "language_creators:found", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:1K<n<10K", "source_datasets:extended|gsm8k", "language:en", "language:es", "language:fr", "language:de", "language:ru", "language:zh", "language:ja", "language:th", "language:sw", "language:bn", "license:cc-by-sa-4.0", "math-word-problems", "arxiv:2110.14168", "arxiv:2210.03057", "region:us"], "private": false, "author": "juletxara", "description": "Multilingual Grade School Math Benchmark (MGSM) is a benchmark of grade-school math problems, proposed in the paper [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057).\n\nThe same 250 problems from [GSM8K](https://arxiv.org/abs/2110.14168) are each translated via human annotators in 10 languages. The 10 languages are:\n- Spanish\n- French\n- German\n- Russian\n- Chinese\n- Japanese\n- Thai\n- Swahili\n- Bengali\n- Telugu\n\nYou can find the input and targets for each of the ten languages (and English) as `.tsv` files.\nWe also include few-shot exemplars that are also manually translated from each language in `exemplars.py`.", "citation": "@article{cobbe2021gsm8k,\n    title={Training Verifiers to Solve Math Word Problems},\n    author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},\n    journal={arXiv preprint arXiv:2110.14168},\n    year={2021}\n}\n@misc{shi2022language,\n    title={Language Models are Multilingual Chain-of-Thought Reasoners}, \n    author={Freda Shi and Mirac Suzgun and Markus Freitag and Xuezhi Wang and Suraj Srivats and Soroush Vosoughi and Hyung Won Chung and Yi Tay and Sebastian Ruder and Denny Zhou and Dipanjan Das and Jason Wei},\n    year={2022},\n    eprint={2210.03057},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "645a024dbdf5b1fa58e9f52c", "disabled": false, "gated": false, "likes": 5, "downloads": 3779, "paperswithcode_id": "multi-task-language-understanding-on-mgsm", "createdAt": "2023-05-09T08:20:29.000Z"}, {"id": "ctu-aic/csfever_v2", "sha": "73c99eb3a5d48c1f22c15adc45bd68038af8a866", "lastModified": "2023-07-27T08:52:58.000Z", "tags": ["task_categories:text-classification", "task_categories:text-retrieval", "task_ids:natural-language-inference", "task_ids:document-retrieval", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:fever", "language:cs", "license:cc-by-sa-3.0", "Fact-checking", "arxiv:2201.11115", "region:us"], "private": false, "author": "ctu-aic", "description": "This new dataset is aimed on Czech fact-checking task.", "citation": null, "cardData": null, "siblings": [], "_id": "645a56783760da5b7fa60106", "disabled": false, "gated": false, "likes": 1, "downloads": 75, "createdAt": "2023-05-09T14:19:36.000Z"}, {"id": "lexlms/legal_lama", "sha": "e62bb3d77ac4797e86ad9779ced416a33db0fe96", "lastModified": "2023-07-24T13:13:15.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:extended", "language:en", "license:cc-by-nc-sa-4.0", "legal", "law", "arxiv:2305.07507", "region:us"], "private": false, "author": "lexlms", "description": "LegalLAMA: Legal LAnguage Model Analysis (LAMA) (LAMA) dataset.", "citation": "@inproceedings{chalkidis-garneau-etal-2023-lexlms,\n    title = {{LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development}},\n    author = \"Chalkidis*, Ilias and \n              Garneau*, Nicolas and\n              Goanta, Catalina and \n              Katz, Daniel Martin and \n              S\u00f8gaard, Anders\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\",\n    month = july,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/xxx\",\n}", "cardData": null, "siblings": [], "_id": "645bc132337b2ccf07fbc6fe", "disabled": false, "gated": false, "likes": 7, "downloads": 88, "createdAt": "2023-05-10T16:07:14.000Z"}, {"id": "techiaith/banc-trawsgrifiadau-bangor", "sha": "a19910b4ce0220df7d9ddf3d3fdbd28de6e60abc", "lastModified": "2023-10-26T09:42:39.000Z", "tags": ["size_categories:10K<n<100K", "language:cy", "license:cc0-1.0", "verbatim transcriptions", "speech recognition", "region:us"], "private": false, "author": "techiaith", "description": "Dyma fanc o 30 awr 20 munud a 41 eiliad o segmentau o leferydd naturiol dros hanner cant o gyfranwyr ar ffurf ffeiliau mp3, ynghyd \u00e2 thrawsgrifiadau 'verbatim' cyfatebol o\u2019r lleferydd ar ffurf ffeil .tsv. Mae'r mwyafrif o'r lleferydd yn leferydd digymell, naturiol. Dosbarthwn y deunydd hwn o dan drwydded agored CC0.\n\nThis resource is a bank of 30 hours 20 minutes and 41 seconds of segments of natural speech from over 50 contributors in mp3 file format, together with corresponding 'verbatim' transcripts of the speech in .tsv file format. The majority of the speech is spontaneous, natural speech. We distribute this material under a CC0 open license.", "citation": "}", "cardData": null, "siblings": [], "_id": "645ce8b74435a8ae3fc47d1f", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "createdAt": "2023-05-11T13:08:07.000Z"}, {"id": "claritylab/utcd", "sha": "a8ae39963cef8309a23c63334cd5c6c6604942f2", "lastModified": "2023-05-24T17:27:42.000Z", "tags": ["task_categories:text-classification", "annotations_creators:no-annotation", "multilinguality:monolingual", "size_categories:1M<n<10M", "language:en", "license:mit", "arxiv:2005.00547", "arxiv:2010.12421", "arxiv:1509.01626", "arxiv:1307.5336", "arxiv:1909.05855", "arxiv:1909.02027", "arxiv:2011.13205", "arxiv:2003.04807", "arxiv:1805.10190", "arxiv:1903.05566", "region:us"], "private": false, "author": "claritylab", "description": "UTCD is a compilation of 18 classification datasets spanning 3 categories of Sentiment, \nIntent/Dialogue and Topic classification. UTCD focuses on the task of zero-shot text classification where the \ncandidate labels are descriptive of the text being classified. UTCD consists of ~ 6M/800K train/test examples.", "citation": null, "cardData": null, "siblings": [], "_id": "645d15134438da4fcc1e07cc", "disabled": false, "gated": false, "likes": 4, "downloads": 33, "createdAt": "2023-05-11T16:17:23.000Z"}, {"id": "lighteval/summarization", "sha": "cc4b4764a381db070c736cc28263df6d95dd0c39", "lastModified": "2023-05-12T08:52:49.000Z", "tags": ["region:us"], "private": false, "author": "lighteval", "description": "Scenario for single document text summarization.\n    Currently supports the following datasets:\n    1. XSum (https://arxiv.org/pdf/1808.08745.pdf)\n    2. CNN/DailyMail non-anonymized (https://arxiv.org/pdf/1704.04368.pdf)\n\n    Task prompt structure\n\n        Summarize the given document.\n        Document: {tok_1 ... tok_n}\n        Summary: {tok_1 ... tok_m}\n\n    Example from XSum dataset\n\n        Document: {Part of the Broad Road was closed to traffic on Sunday at about 18:00 GMT.\n                   The three adults and three children have been taken to Altnagelvin Hospital\n                   with non life-threatening injuries. The Fire Service, Northern Ireland Ambulance Service\n                   and police attended the crash. The Broad Road has since been reopened.}\n        Summary: {Three adults and three children have been taken to hospital following a crash involving\n                  a tractor and a campervan in Limavady, County Londonderry}", "citation": null, "cardData": null, "siblings": [], "_id": "645df9f4329368042024be72", "disabled": false, "gated": false, "likes": 2, "downloads": 10, "createdAt": "2023-05-12T08:33:56.000Z"}, {"id": "lighteval/wikitext_103", "sha": "dd27573554cc564236c21cd6bd18691da8dc74e1", "lastModified": "2023-05-12T14:47:20.000Z", "tags": ["region:us"], "private": false, "author": "lighteval", "description": "Wikitext-103 dataset from this paper:\n    https://arxiv.org/pdf/1609.07843.pdf\n\n    Gopher's authors concatenate all the articles, set context length to n/2 (n = max_seq_len),\n    and use the \"closed vocabulary\" variant of the dataset for evaluation.\n\n    In contrast, we evaluate the model on each article independently, use single token contexts\n    (except for the last sequence in each document), and use the raw dataset.", "citation": null, "cardData": null, "siblings": [], "_id": "645e436343abb116540dc1be", "disabled": false, "gated": false, "likes": 0, "downloads": 97, "createdAt": "2023-05-12T13:47:15.000Z"}, {"id": "biglam/on_the_books", "sha": "67b651cbf5f180bf8a90c3e8fe8b6c4de2eda490", "lastModified": "2023-06-07T08:44:39.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:en", "license:cc-by-3.0", "lam", "legal", "region:us"], "private": false, "author": "biglam", "description": "This file is the training set that was used to train an algorithm to identify Jim Crow laws.\nIt contains laws that are labeled as \"Jim Crow\" (jim_crow=1) or \"Not Jim Crow\" (jim_crow=0).\nThe source of the determination is also provided.", "citation": "TODO", "cardData": null, "siblings": [], "_id": "645e531a916e745511fda96f", "disabled": false, "gated": false, "likes": 1, "downloads": 15, "createdAt": "2023-05-12T14:54:18.000Z"}, {"id": "tatsu-lab/alpaca_farm", "sha": "e576524ca841af3c36fd6912e68e5920430928c1", "lastModified": "2023-05-29T01:00:10.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "tatsu-lab", "description": "Data used in the original AlpacaFarm experiments.\nIncludes SFT and preference examples.", "citation": "@misc{alpaca_farm,\n  author = {Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, Tatsunori Hashimoto},\n  title = {AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback},\n  year = {2023},\n  howpublished = {\\\\url{https://github.com/tatsu-lab/alpaca_farm}},\n}", "cardData": null, "siblings": [], "_id": "64600f1872397238b2316b86", "disabled": false, "gated": false, "likes": 17, "downloads": 11231, "createdAt": "2023-05-13T22:28:40.000Z"}, {"id": "cdminix/libritts-aligned", "sha": "e17d6e3b97e09289bbb0ffab82ba2641e83a0a3c", "lastModified": "2023-10-11T19:46:28.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "annotations_creators:crowdsourced", "language:en", "license:cc-by-4.0", "speech", "audio", "automatic-speech-recognition", "text-to-speech", "arxiv:1904.02882", "arxiv:2211.16049", "region:us"], "private": false, "author": "cdminix", "description": "Dataset used for loading TTS spectrograms and waveform audio with alignments and a number of configurable \"measures\", which are extracted from the raw audio.", "citation": "@article{zen2019libritts,\n  title={LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech},\n  author={Zen, Heiga and Dang, Viet and Clark, Rob and Zhang, Yu and Weiss, Ron J and Jia, Ye and Chen, Zhifeng and Wu, Yonghui},\n  journal={Interspeech},\n  year={2019}\n}\n@article{https://doi.org/10.48550/arxiv.2211.16049,\n  author = {Minixhofer, Christoph and Klejch, Ond\u0159ej and Bell, Peter},\n  title = {Evaluating and reducing the distance between synthetic and real speech distributions},\n  year = {2022}\n}", "cardData": null, "siblings": [], "_id": "6460b81a567598449e0426c6", "disabled": false, "gated": false, "likes": 4, "downloads": 45, "createdAt": "2023-05-14T10:29:46.000Z"}, {"id": "ceval/ceval-exam", "sha": "3923b519fd180e689d0961bf3a032ece929742f3", "lastModified": "2023-08-31T14:04:10.000Z", "tags": ["task_categories:text-classification", "task_categories:multiple-choice", "task_categories:question-answering", "size_categories:10K<n<100K", "language:zh", "license:cc-by-nc-sa-4.0", "arxiv:2305.08322", "region:us"], "private": false, "author": "ceval", "description": "C-Eval is a comprehensive Chinese evaluation suite for foundation models. It consists of 13948 multi-choice questions spanning 52 diverse disciplines and four difficulty levels.", "citation": "@article{huang2023ceval,\n    title={C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models}, \n    author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Lei, Jiayi and Fu, Yao and Sun, Maosong and He, Junxian},\n    journal={arXiv preprint arXiv:2305.08322},\n    year={2023}\n}", "cardData": null, "siblings": [], "_id": "6462e0c0cce92c7d883113f5", "disabled": false, "gated": false, "likes": 162, "downloads": 99225, "createdAt": "2023-05-16T01:47:44.000Z"}, {"id": "osunlp/AttrScore", "sha": "467dcdd2cd31f9b5e8625491f3bdf7af90943a8d", "lastModified": "2023-06-29T01:56:48.000Z", "tags": ["task_categories:text-classification", "size_categories:100K<n<1M", "language:en", "license:apache-2.0", "arxiv:2305.06311", "region:us"], "private": false, "author": "osunlp", "description": "    We construct this dataset, which contains both training and test data for the evaluation of attribution. \n    The training data are repurposed from related tasks, such as question answering, fact-checking, \n    natural language inference, and summarization. The test data contains a set simulated from QA datasets \n    and a set manually curated from a generative search engine, New Bing.", "citation": "@article{yue2023automatic,\n  title={Automatic Evaluation of Attribution by Large Language Models},\n  author={Yue, Xiang and Wang, Boshi and Zhang, Kai and Chen, Ziru and Su, Yu and Sun, Huan},\n  journal={arXiv preprint arXiv:2305.06311},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "6463d50006c6a952bd0320f3", "disabled": false, "gated": false, "likes": 9, "downloads": 865, "createdAt": "2023-05-16T19:09:52.000Z"}, {"id": "hltcoe/megawika", "sha": "33ecfd8de839448adb5d475b222dda25408ed1e5", "lastModified": "2023-10-03T17:24:24.000Z", "tags": ["task_categories:summarization", "task_categories:question-answering", "task_categories:text-generation", "task_categories:text2text-generation", "size_categories:10M<n<100M", "language:af", "language:ar", "language:az", "language:bn", "language:cs", "language:de", "language:en", "language:es", "language:et", "language:fa", "language:fi", "language:fr", "language:ga", "language:gl", "language:gu", "language:he", "language:hi", "language:hr", "language:id", "language:it", "language:ja", "language:ka", "language:kk", "language:km", "language:ko", "language:lt", "language:lv", "language:mk", "language:ml", "language:mn", "language:mr", "language:my", "language:ne", "language:nl", "language:pl", "language:ps", "language:pt", "language:ro", "language:ru", "language:si", "language:sl", "language:sv", "language:ta", "language:th", "language:tr", "language:uk", "language:ur", "language:vi", "language:xh", "language:zh", "license:cc-by-sa-4.0", "arxiv:2307.07049", "region:us"], "private": false, "author": "hltcoe", "description": "MegaWika is a multi- and crosslingual text dataset containing 30 million\nWikipedia passages with their scraped and cleaned web citations. The\npassages span 50 Wikipedias in 50 languages, and the articles in which\nthe passages were originally embedded are included for convenience. Where\na Wikipedia passage is in a non-English language, an automated English\ntranslation is provided. Furthermore, nearly 130 million English\nquestion/answer pairs were extracted from the passages, and FrameNet events\noccurring in the passages are detected using the LOME FrameNet parser.", "citation": "@article{barham2023megawika,\n  title={MegaWika: Millions of reports and their sources across 50 diverse languages},\n  author={Barham, Samuel and Weller, Orion and\n          Yuan, Michelle and Murray, Kenton and\n          Yarmohammadi, Mahsa and Jiang, Zhengping and\n          Vashishtha, Siddharth and Martin, Alexander and\n          Liu, Anqi and White, Aaron Steven and\n          Boyd-Graber, Jordan and Van Durme, Benjamin\n  },\n  journal={INSERT ARXIV PREPRINT ID HERE},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "646436f665d811c4962cfc5b", "disabled": false, "gated": false, "likes": 24, "downloads": 134, "createdAt": "2023-05-17T02:07:50.000Z"}, {"id": "TrainingDataPro/pose_estimation", "sha": "7f404f34b9f6df1a71d48311150455684b2fdf15", "lastModified": "2023-09-14T16:47:12.000Z", "tags": ["task_categories:image-classification", "language:en", "license:cc-by-nc-nd-4.0", "code", "finance", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset is primarly intended to dentify and predict the positions of major\njoints of a human body in an image. It consists of people's photographs with\nbody part labeled with keypoints.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {pose_estimation},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64675ad9ab75d9cb3c44b72a", "disabled": false, "gated": false, "likes": 2, "downloads": 13, "createdAt": "2023-05-19T11:17:45.000Z"}, {"id": "tau/zero_scrolls", "sha": "33a4ad937c69222d8848a0150afb8a30ae172f68", "lastModified": "2023-06-30T17:21:02.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-generation", "task_ids:multiple-choice-qa", "language:en", "query-based-summarization", "long-texts", "arxiv:2104.02112", "arxiv:2104.07091", "arxiv:2104.05938", "arxiv:2205.11465", "arxiv:2105.03011", "arxiv:1712.07040", "arxiv:2112.08608", "arxiv:2108.00573", "arxiv:2305.14196", "region:us"], "private": false, "author": "tau", "description": "ZeroSCROLLS: Zero-Shot CompaRison Over Long Language Sequences.\nA zero shot benchmark for long text reasoning.\nhttps://zero.scrolls-benchmark.com/", "citation": "@misc{shaham2023zeroscrolls,\n      title={ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding}, \n      author={Uri Shaham and Maor Ivgi and Avia Efrat and Jonathan Berant and Omer Levy},\n      year={2023},\n      eprint={2305.14196},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\nNote that each ZeroSCROLLS task has its own citation. Please see the source to\nget the correct citation for each one.", "cardData": null, "siblings": [], "_id": "6469f6dd13396ee0a560b9c2", "disabled": false, "gated": false, "likes": 6, "downloads": 3511, "createdAt": "2023-05-21T10:47:57.000Z"}, {"id": "THUDM/ImageRewardDB", "sha": "c493721e19e296eb615420036f2a2eed08412bb4", "lastModified": "2023-06-21T06:36:29.000Z", "tags": ["task_categories:text-to-image", "size_categories:100K<n<1M", "language:en", "license:apache-2.0", "arxiv:2304.05977", "region:us"], "private": false, "author": "THUDM", "description": "ImageRewardDB is a comprehensive text-to-image comparison dataset, focusing on text-to-image human preference. It consists of 137k pairs of expert comparisons, based on text prompts and corresponding model outputs from DiffusionDB. To build the ImageRewadDB, we design a pipeline tailored for it, establishing criteria for quantitative assessment and annotator training, optimizing labeling experience, and ensuring quality validation. \\", "citation": "@misc{xu2023imagereward,\n      title={ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation}, \n      author={Jiazheng Xu and Xiao Liu and Yuchen Wu and Yuxuan Tong and Qinkai Li and Ming Ding and Jie Tang and Yuxiao Dong},\n      year={2023},\n      eprint={2304.05977},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "646a3b2a3721aab2edf4d4aa", "disabled": false, "gated": false, "likes": 20, "downloads": 345, "createdAt": "2023-05-21T15:39:22.000Z"}, {"id": "dev2bit/es2bash", "sha": "7c0103fb59488299a8c3c500e9573fc8820502ec", "lastModified": "2023-05-23T21:11:43.000Z", "tags": ["task_categories:text-generation", "language:es", "license:apache-2.0", "code", "region:us"], "private": false, "author": "dev2bit", "description": "This dataset consisting of natural language requests (in Spanish) and the bash command that resolves it.", "citation": "\\", "cardData": null, "siblings": [], "_id": "646d2141acc13867a1347c01", "disabled": false, "gated": false, "likes": 3, "downloads": 40, "createdAt": "2023-05-23T20:25:37.000Z"}, {"id": "Brand24/mms", "sha": "95b662d6672a0eaa1633ea2af7362ccd8264db3d", "lastModified": "2023-08-23T21:49:55.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "annotations_creators:mixed", "multilinguality:multi-lingual", "size_categories:1M<n<10M", "language:ar", "language:bg", "language:bs", "language:cs", "language:de", "language:el", "language:en", "language:es", "language:fa", "language:fr", "language:he", "language:hi", "language:hr", "language:hu", "language:it", "language:ja", "language:lv", "language:pl", "language:pt", "language:ru", "language:sk", "language:sl", "language:sq", "language:sr", "language:sv", "language:th", "language:ur", "language:zh", "license:other", "arxiv:2306.07902", "region:us"], "private": false, "author": "Brand24", "description": "    This work presents the most extensive open massively multi-lingual corpus of datasets for training sentiment models. \n    The corpus consists of 79 manually selected from over 350 datasets reported in the scientific literature based on strict quality criteria and covers 25 languages. \n    Datasets can be queried using several linguistic and functional features. \n    In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.", "citation": "@misc{augustyniak2023massively,\n      title={Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark}, \n      author={\u0141ukasz Augustyniak and Szymon Wo\u017aniak and Marcin Gruza and Piotr Gramacki and Krzysztof Rajda and Miko\u0142aj Morzy and Tomasz Kajdanowicz},\n      year={2023},\n      eprint={2306.07902},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "646dfdea5c3c0df5aef56744", "disabled": false, "gated": "auto", "likes": 2, "downloads": 19, "createdAt": "2023-05-24T12:07:06.000Z"}, {"id": "sihaochen/propsegment", "sha": "8454abe0cc508213c931e32fff18f982fc26712f", "lastModified": "2023-05-26T18:18:53.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_categories:text-generation", "size_categories:10K<n<100K", "language:en", "license:cc-by-4.0", "NLP", "Entailment", "NLI", "google-research-datasets", "arxiv:2212.10750", "region:us"], "private": false, "author": "sihaochen", "description": "This is a reproduced (i.e. after web-crawling) and processed version of the \"PropSegment\" dataset from Google Research.\n\nSince the News portion of the dataset is released only via urls, we reconstruct the dataset by crawling. Overall, ~96% \nof the dataset can be reproduced, and the rest ~4% either have url no longer valid, or sentences that have been edited \n(i.e. cannot be aligned with the orignial dataset).\n\nPropSegment (Proposition-level Segmentation and Entailment) is a large-scale, human annotated dataset for segmenting \nEnglish text into propositions, and recognizing proposition-level entailment relations --- whether a different, related \ndocument entails each proposition, contradicts it, or neither.\n\nThe original dataset features >45k human annotated propositions, i.e. individual semantic units within sentences, as \nwell as >45k entailment labels between propositions and documents.", "citation": "@inproceedings{chen2023propsegment,\n    title = \"{PropSegmEnt}: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition\",\n    author = \"Chen, Sihao and Buthpitiya, Senaka and Fabrikant, Alex and Roth, Dan  and Schuster, Tal\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\n    year = \"2023\",\n}", "cardData": null, "siblings": [], "_id": "646e9dd27a376d3010c9c205", "disabled": false, "gated": false, "likes": 2, "downloads": 21, "createdAt": "2023-05-24T23:29:22.000Z"}, {"id": "ccmusic-database/music_genre", "sha": "47b3773d9b2dc283bfc6ed6ea3ba438e498291e7", "lastModified": "2023-11-25T17:32:43.000Z", "tags": ["task_categories:audio-classification", "size_categories:1K<n<10K", "language:zh", "language:en", "license:mit", "music", "art", "region:us"], "private": false, "author": "ccmusic-database", "description": "This database contains about 1700 musical pieces (.mp3 format) \nwith lengths of 270-300s that are divided into 17 genres in total.", "citation": "@dataset{zhaorui_liu_2021_5676893,\n  author       = {Zhaorui Liu, Monan Zhou, Shenyang Xu, Zhaowen Wang, Wei Li and Zijin Li},\n  title        = {CCMUSIC DATABASE: A Music Data Sharing Platform for Computational Musicology Research},\n  month        = {nov},\n  year         = {2021},\n  publisher    = {Zenodo},\n  version      = {1.1},\n  doi          = {10.5281/zenodo.5676893},\n  url          = {https://doi.org/10.5281/zenodo.5676893}\n}", "cardData": null, "siblings": [], "_id": "646f6c674c05cd5de6de89a4", "disabled": false, "gated": false, "likes": 8, "downloads": 39, "createdAt": "2023-05-25T14:10:47.000Z"}, {"id": "chenxwh/gen-xcopa", "sha": "bbbfab01849e02f0c841cee756d1cb840daf309b", "lastModified": "2023-05-29T15:04:40.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "chenxwh", "description": "A multilingual collection of XCOPA in ten languages generated by GPT-4", "citation": "@misc{whitehouse2023llmpowered,\n      title={LLM-powered Data Augmentation for Enhanced Crosslingual Performance}, \n      author={Chenxi Whitehouse and Monojit Choudhury and Alham Fikri Aji},\n      year={2023},\n      eprint={2305.14288},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@misc{ponti2020xcopa,\n      title={XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning}, \n      author={Edoardo Maria Ponti and Goran Glava\u0161 and Olga Majewska and Qianchu Liu and Ivan Vuli\u0107 and Anna Korhonen},\n      year={2020},\n      eprint={2005.00333},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "646fef016098ee820fc21ed7", "disabled": false, "gated": false, "likes": 0, "downloads": 49, "createdAt": "2023-05-25T23:28:01.000Z"}, {"id": "ccmusic-database/bel_folk", "sha": "040d80fcf75bcd50e6623c6fc7650bd75e84fc4d", "lastModified": "2023-10-03T16:56:58.000Z", "tags": ["task_categories:audio-classification", "size_categories:n<1K", "language:zh", "language:en", "license:mit", "music", "art", "region:us"], "private": false, "author": "ccmusic-database", "description": "This database contains hundreds of acapella singing clips that are sung in two styles, \nBel Conto and Chinese national singing style by professional vocalists. \nAll of them are sung by professional vocalists and were recorded in professional commercial recording studios.", "citation": "@dataset{zhaorui_liu_2021_5676893,\n  author       = {Zhaorui Liu, Monan Zhou, Shenyang Xu and Zijin Li},\n  title        = {{Music Data Sharing Platform for Computational Musicology Research (CCMUSIC DATASET)}},\n  month        = nov,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = {1.1},\n  doi          = {10.5281/zenodo.5676893},\n  url          = {https://doi.org/10.5281/zenodo.5676893}\n}", "cardData": null, "siblings": [], "_id": "647073973df93fddecde5d63", "disabled": false, "gated": false, "likes": 2, "downloads": 11, "createdAt": "2023-05-26T08:53:43.000Z"}, {"id": "Blablablab/SOCKET", "sha": "beb92deb932d67a6319cc7ca71d8056ececc47d2", "lastModified": "2023-11-12T23:28:36.000Z", "tags": ["license:cc-by-4.0", "arxiv:2305.14938", "region:us"], "private": false, "author": "Blablablab", "description": "A unified evaluation benchmark dataset for evaludating socialbility of NLP models.", "citation": "@misc{choi2023llms,\n      title={Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark}, \n      author={Minje Choi and Jiaxin Pei and Sagar Kumar and Chang Shu and David Jurgens},\n      year={2023},\n      eprint={2305.14938},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64710ef91c2bfd5b7bf8d50e", "disabled": false, "gated": false, "likes": 3, "downloads": 5391, "createdAt": "2023-05-26T19:56:41.000Z"}, {"id": "tatsu-lab/alpaca_eval", "sha": "8a76fe45dc20ad5ab1f782ef7d4d8eb6af23f43a", "lastModified": "2023-06-09T11:58:42.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "tatsu-lab", "description": "Data for alpaca_eval, which aims to help automatic evaluation of instruction-following models", "citation": "@misc{alpaca_eval,\n  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },\n  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\\\url{https://github.com/tatsu-lab/alpaca_eval}}\n}", "cardData": null, "siblings": [], "_id": "6473ee0b2a74fb43cce692df", "disabled": false, "gated": false, "likes": 23, "downloads": 15816, "createdAt": "2023-05-29T00:12:59.000Z"}, {"id": "albertvillanova/medmnist-v2", "sha": "f6dd981c7400b3e3738bde12ff948b7cc8f0d623", "lastModified": "2023-05-30T05:40:52.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "task_ids:multi-label-image-classification", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:original", "language:en", "license:cc-by-4.0", "medical", "arxiv:2110.14795", "region:us"], "private": false, "author": "albertvillanova", "description": "MedMNIST v2 is a large-scale MNIST-like collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D.", "citation": "@article{medmnistv2,\n    title={MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification},\n    author={Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},\n    journal={Scientific Data},\n    volume={10},\n    number={1},\n    pages={41},\n    year={2023},\n    publisher={Nature Publishing Group UK London}\n}\n@inproceedings{medmnistv1,\n    title={MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis},\n    author={Yang, Jiancheng and Shi, Rui and Ni, Bingbing},\n    booktitle={IEEE 18th International Symposium on Biomedical Imaging (ISBI)},\n    pages={191--195},\n    year={2021}\n}", "cardData": null, "siblings": [], "_id": "647469b8f9e3e0b312e82113", "disabled": false, "gated": false, "likes": 3, "downloads": 184, "paperswithcode_id": "medmnist-v2", "createdAt": "2023-05-29T09:00:40.000Z"}, {"id": "andreped/IBDColEpi", "sha": "28dc6fc18e381c60775a728222d314b97a228ebc", "lastModified": "2023-11-08T22:02:54.000Z", "tags": ["task_categories:image-segmentation", "size_categories:1B<n<10B", "language:en", "license:mit", "medical", "region:us"], "private": false, "author": "andreped", "description": "IBDColEpi: 140 HE and 111 CD3-stained colon biopsies of active and inactivate inflammatory bowel disease with epithelium annotated.", "citation": "@ARTICLE{10.3389/fmed.2021.816281,\nAUTHOR={Pettersen, Henrik Sahlin and Belevich, Ilya and R\u00f8yset, Elin Synn\u00f8ve and Smistad, Erik and Simpson, Melanie Rae and Jokitalo, Eija and Reinertsen, Ingerid and Bakke, Ingunn and Pedersen, Andr\u00e9},   \nTITLE={Code-Free Development and Deployment of Deep Segmentation Models for Digital Pathology},      \nJOURNAL={Frontiers in Medicine},      \nVOLUME={8},           \nYEAR={2022},      \nURL={https://www.frontiersin.org/articles/10.3389/fmed.2021.816281},       \nDOI={10.3389/fmed.2021.816281},      \nISSN={2296-858X},   \nABSTRACT={Application of deep learning on histopathological whole slide images (WSIs) holds promise of improving diagnostic efficiency and reproducibility but is largely dependent on the ability to write computer code or purchase commercial solutions. We present a code-free pipeline utilizing free-to-use, open-source software (QuPath, DeepMIB, and FastPathology) for creating and deploying deep learning-based segmentation models for computational pathology. We demonstrate the pipeline on a use case of separating epithelium from stroma in colonic mucosa. A dataset of 251 annotated WSIs, comprising 140 hematoxylin-eosin (HE)-stained and 111 CD3 immunostained colon biopsy WSIs, were developed through active learning using the pipeline. On a hold-out test set of 36 HE and 21 CD3-stained WSIs a mean intersection over union score of 95.5 and 95.3% was achieved on epithelium segmentation. We demonstrate pathologist-level segmentation accuracy and clinical acceptable runtime performance and show that pathologists without programming experience can create near state-of-the-art segmentation solutions for histopathological WSIs using only free-to-use software. The study further demonstrates the strength of open-source solutions in its ability to create generalizable, open pipelines, of which trained models and predictions can seamlessly be exported in open formats and thereby used in external solutions. All scripts, trained models, a video tutorial, and the full dataset of 251 WSIs with ~31 k epithelium annotations are made openly available at <ext-link ext-link-type=\"uri\" xlink:href=\"https://github.com/andreped/NoCodeSeg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/andreped/NoCodeSeg</ext-link> to accelerate research in the field.}\n}", "cardData": null, "siblings": [], "_id": "6474c5a0f9e3e0b312eed4d9", "disabled": false, "gated": false, "likes": 0, "downloads": 70, "createdAt": "2023-05-29T15:32:48.000Z"}, {"id": "TrainingDataPro/high_quality_webcam_video_attacks", "sha": "0164efe648b3b1dc42ce9612318f2aa78d4f878f", "lastModified": "2023-09-14T16:47:53.000Z", "tags": ["task_categories:video-classification", "language:en", "license:cc-by-nc-nd-4.0", "finance", "legal", "code", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset includes live-recorded Anti-Spoofing videos from around the world,\ncaptured via **high-quality** webcams with Full HD resolution and above.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {high_quality_webcam_video_attacks},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "6475b941ab17a37d0b18802b", "disabled": false, "gated": false, "likes": 2, "downloads": 20, "createdAt": "2023-05-30T08:52:17.000Z"}, {"id": "almanach/hc3_french_ood", "sha": "34acd9cc5eb1f9855d3485c7783f28a235dd87bd", "lastModified": "2023-06-05T10:19:19.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:sentence-similarity", "task_categories:zero-shot-classification", "size_categories:10K<n<100K", "language:en", "language:fr", "license:cc-by-sa-4.0", "ChatGPT", "Bing", "LM Detection", "Detection", "OOD", "arxiv:2301.07597", "region:us"], "private": false, "author": "almanach", "description": "Human ChatGPT Comparison Corpus (HC3) Translated To French.\nThe translation is done by Google Translate API.\nWe also add the native french QA pairs from ChatGPT, BingGPT and FAQ pages.\n\nThis dataset was used in our TALN 2023 paper.\nTowards a Robust Detection of Language Model-Generated Text: Is ChatGPT that easy to detect?", "citation": "# TODO: Add BibTeX citation for our TALN 2023 paper:\nTowards a Robust Detection of Language Model-Generated Text: Is ChatGPT that easy to detect?\n\n@article{guo-etal-2023-hc3,\n    title = \"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection\",\n    author = \"Guo, Biyang  and\n      Zhang, Xin  and\n      Wang, Ziyuan  and\n      Jiang, Minqi  and\n      Nie, Jinran  and\n      Ding, Yuxuan  and\n      Yue, Jianwei  and\n      Wu, Yupeng\",\n    journal={arXiv preprint arxiv:2301.07597}\n    year = \"2023\",\n}", "cardData": null, "siblings": [], "_id": "6476052ec7e6f8e9fec94862", "disabled": false, "gated": false, "likes": 1, "downloads": 62, "createdAt": "2023-05-30T14:16:14.000Z"}, {"id": "asapp/slue-phase-2", "sha": "0531379c7963effbc10f9a461098e112cda0ef5b", "lastModified": "2023-08-01T16:05:43.000Z", "tags": ["arxiv:2212.10525", "region:us"], "private": false, "author": "asapp", "description": "Spoken Language Understanding Evaluation (SLUE) benchmark Phase 2.", "citation": "@inproceedings{shon2023slue_phase2,\n  title={SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding Tasks},\n  author={Shon, Suwon and Arora, Siddhant and Lin, Chyi-Jiunn and Pasad, Ankita and Wu, Felix and Sharma, Roshan and Wu, Wei-Lun and Lee, Hung-Yi and Livescu, Karen and Watanabe, Shinji},\n  booktitle={ACL},\n  year={2023},\n}", "cardData": null, "siblings": [], "_id": "6476c8a0a4ebdbfb13875f2f", "disabled": false, "gated": false, "likes": 4, "downloads": 117, "createdAt": "2023-05-31T04:10:08.000Z"}, {"id": "rcds/swiss_leading_decision_summarization", "sha": "6d078c615d5f11b5dedcd73b6ffcbc3f88f70d71", "lastModified": "2023-07-20T07:38:30.000Z", "tags": ["task_categories:summarization", "annotations_creators:machine-generated", "language_creators:expert-generated", "multilinguality:multilingual", "size_categories:10K<n<100K", "source_datasets:original", "language:de", "language:fr", "language:it", "license:cc-by-sa-4.0", "arxiv:2306.09237", "region:us"], "private": false, "author": "rcds", "description": "This dataset contains court decisions for the swiss ruling summarization task.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "647706cebeaeebff4a51c67e", "disabled": false, "gated": false, "likes": 3, "downloads": 54, "createdAt": "2023-05-31T08:35:26.000Z"}, {"id": "hhu-dsml/emowoz", "sha": "4d6728756402e917a8747daf34a641de97097f78", "lastModified": "2023-06-01T13:23:58.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:sentiment-analysis", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:MultiWOZ", "source_datasets:Original (human-machine interaction dialogues)", "language:en", "license:cc-by-nc-4.0", "arxiv:2303.13364", "region:us"], "private": false, "author": "hhu-dsml", "description": "EmoWOZ is a user emotion recognition in task-oriented dialogues dataset, consisting all dialogues from MultiWOZ and 1000 additional human-machine dialogues (DialMAGE). Each user utterance is annotated with one of the following emotions: 0: neutral, 1: fearful, 2: dissatisfied, 3: apologetic, 4: abusive, 5: excited, 6: satisfied. System utterances are annotated with -1. For detailed label design and explanation, please refer to the paper and dataset homepage.", "citation": "@inproceedings{feng-etal-2022-emowoz,\n    title = \"{E}mo{WOZ}: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems\",\n    author = \"Feng, Shutong  and\n      Lubis, Nurul  and\n      Geishauser, Christian  and\n      Lin, Hsien-chin  and\n      Heck, Michael  and\n      van Niekerk, Carel  and\n      Gasic, Milica\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.436\",\n    pages = \"4096--4113\",\n    abstract = \"The ability to recognise emotions lends a conversational artificial intelligence a human     touch. While emotions in chit-chat dialogues have received substantial attention, emotions in     task-oriented dialogues remain largely unaddressed. This is despite emotions and dialogue success     having equally important roles in a natural system. Existing emotion-annotated task-oriented corpora     are limited in size, label richness, and public availability, creating a bottleneck for downstream     tasks. To lay a foundation for studies on emotions in task-oriented dialogues, we introduce EmoWOZ, a     large-scale manually emotion-annotated corpus of task-oriented dialogues. EmoWOZ is based on MultiWOZ,     a multi-domain task-oriented dialogue dataset. It contains more than 11K dialogues with more than 83K     emotion annotations of user utterances. In addition to Wizard-of-Oz dialogues from MultiWOZ, we collect     human-machine dialogues within the same set of domains to sufficiently cover the space of various emotions     that can happen during the lifetime of a data-driven dialogue system. To the best of our knowledge, this     is the first large-scale open-source corpus of its kind. We propose a novel emotion labelling scheme,     which is tailored to task-oriented dialogues. We report a set of experimental results to show the usability     of this corpus for emotion recognition and state tracking in task-oriented dialogues.\",\n}", "cardData": null, "siblings": [], "_id": "647735af906bb0203e52879f", "disabled": false, "gated": false, "likes": 1, "downloads": 36, "paperswithcode_id": "emowoz-1", "createdAt": "2023-05-31T11:55:27.000Z"}, {"id": "kaist-ai/Multilingual-CoT-Collection", "sha": "e45e7badc2909e28cc566b82e586a0caf75094eb", "lastModified": "2023-10-14T15:00:43.000Z", "tags": ["task_categories:text-generation", "task_categories:text-classification", "size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "arxiv:2305.14045", "region:us"], "private": false, "author": "kaist-ai", "description": "\"\"\"\n\n_LICENSE = \"CC BY 4.0\"\n\n_HOMEPAGE = \"https://github.com/kaistAI/CoT-Collection\"\n\n\n\n_LANGUAGES = {\n    \"ko\": \"Korean\",\n    \"fr\": \"French\",\n    \"ru\": \"Russian\",\n    \"ja\": \"Japanese\",\n    \"zh\": \"Chinese\",\n}\n# _ALL_LANGUAGES = \"all_languages\"\n\n\n\nclass CoTCollectionMultiConfig(datasets.BuilderConfig):", "citation": "@article{kim2023cot,\n  title={The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning},\n  author={Kim, Seungone and Joo, Se June and Kim, Doyoung and Jang, Joel and Ye, Seonghyeon and Shin, Jamin and Seo, Minjoon},\n  journal={arXiv preprint arXiv:2305.14045},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "647d67ad1c0644de8d403701", "disabled": false, "gated": false, "likes": 15, "downloads": 34, "createdAt": "2023-06-05T04:42:21.000Z"}, {"id": "kaist-ai/CoT-Collection", "sha": "c9d352cdc119df4a4f7526d100e4acb4a72a7a5c", "lastModified": "2023-10-14T12:10:16.000Z", "tags": ["task_categories:text-generation", "task_categories:text-classification", "size_categories:1M<n<10M", "language:en", "license:cc-by-4.0", "arxiv:2305.14045", "region:us"], "private": false, "author": "kaist-ai", "description": "\"\"\"\n\n_LICENSE = \"CC BY 4.0\"\n\n_HOMEPAGE = \"https://github.com/kaistAI/CoT-Collection\"\n\n_LANGUAGES = {\n    \"en\": \"English\",\n}\n# _ALL_LANGUAGES = \"all_languages\"\n\n\n\nclass CoTCollectionMultiConfig(datasets.BuilderConfig):", "citation": "@article{kim2023cot,\n  title={The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning},\n  author={Kim, Seungone and Joo, Se June and Kim, Doyoung and Jang, Joel and Ye, Seonghyeon and Shin, Jamin and Seo, Minjoon},\n  journal={arXiv preprint arXiv:2305.14045},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "647d8a9532c471a7fa7e122b", "disabled": false, "gated": false, "likes": 40, "downloads": 871, "createdAt": "2023-06-05T07:11:17.000Z"}, {"id": "cjvt/janes_tag", "sha": "a522dc2653629376091920714de0664f66931f00", "lastModified": "2023-06-06T10:07:53.000Z", "tags": ["task_categories:token-classification", "size_categories:1K<n<10K", "language:sl", "license:cc-by-sa-4.0", "code-mixed", "nonstandard", "ner", "region:us"], "private": false, "author": "cjvt", "description": "Janes-Tag is a manually annotated corpus of Slovene Computer-Mediated Communication (CMC) consisting of mostly tweets \nbut also blogs, forums and news comments.", "citation": "@misc{janes_tag,\n    title = {{CMC} training corpus Janes-Tag 3.0},\n    author = {Lenardi{\\v c}, Jakob and {\\v C}ibej, Jaka and Arhar Holdt, {\\v S}pela and Erjavec, Toma{\\v z} and Fi{\\v s}er, Darja and Ljube{\\v s}i{\\'c}, Nikola and Zupan, Katja and Dobrovoljc, Kaja},\n    url = {http://hdl.handle.net/11356/1732},\n    note = {Slovenian language resource repository {CLARIN}.{SI}},\n    copyright = {Creative Commons - Attribution-{ShareAlike} 4.0 International ({CC} {BY}-{SA} 4.0)},\n    year = {2022}\n}", "cardData": null, "siblings": [], "_id": "647dba7ff14eafc3b44b09d0", "disabled": false, "gated": false, "likes": 0, "downloads": 14, "createdAt": "2023-06-05T10:35:43.000Z"}, {"id": "tianyang/repobench-r", "sha": "b10acdbfa9a62bad85cbaa58737a978851ab9039", "lastModified": "2023-06-17T03:06:46.000Z", "tags": ["task_categories:text-retrieval", "task_ids:document-retrieval", "language_creators:found", "multilinguality:multilingual", "source_datasets:original", "language:code", "license:cc-by-nc-nd-4.0", "arxiv:2306.03091", "region:us"], "private": false, "author": "tianyang", "description": "RepoBench is a dataset that benchmarks repository-level code auto-completion systems.\n\nRepoBench-R denotes RepoBench for Retrieval, which is a sub-task of RepoBench, \naiming to evaluate the ability of code auto-completion systems to retrieve \nrelevant code snippets for next-line code completion.", "citation": "@misc{liu2023repobench,\n      title={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems}, \n      author={Tianyang Liu and Canwen Xu and Julian McAuley},\n      year={2023},\n      eprint={2306.03091},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "647e8367f14eafc3b4635b32", "disabled": false, "gated": false, "likes": 1, "downloads": 17, "createdAt": "2023-06-06T00:52:55.000Z"}, {"id": "GAIR/lima", "sha": "68958e98267f5fb4a52a03ebcdae4ae59213fa7c", "lastModified": "2023-06-08T02:40:19.000Z", "tags": ["license:other", "arxiv:2305.11206", "region:us"], "private": false, "author": "GAIR", "description": "A high-quality dataset for efficient instruction tuning.", "citation": null, "cardData": null, "siblings": [], "_id": "6480129486888bbffbe7ae53", "disabled": false, "gated": "auto", "likes": 312, "downloads": 1195, "createdAt": "2023-06-07T05:16:04.000Z"}, {"id": "explodinggradients/fiqa", "sha": "0e5ceb2ce99a8297eeee7125912b20deaa185877", "lastModified": "2023-06-08T16:54:14.000Z", "tags": ["task_categories:question-answering", "size_categories:10K<n<100K", "language:en", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "explodinggradients", "description": "FiQA dataset formated in a way that is easier for doing RAG experiments", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "6481193a40facadc5577008b", "disabled": false, "gated": false, "likes": 5, "downloads": 5497, "createdAt": "2023-06-07T23:56:42.000Z"}, {"id": "pain/MASC", "sha": "99bfbcb394b70e43d6f4ff21a9f61496808b3574", "lastModified": "2023-06-12T19:48:45.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:ar", "license:cc-by-4.0", "region:us"], "private": false, "author": "pain", "description": "MASC is a dataset that contains 1,000 hours of speech sampled at 16 kHz and crawled from over 700 YouTube channels. The dataset is multi-regional, multi-genre, and multi-dialect intended to advance the research and development of Arabic speech technology with a special emphasis on Arabic speech recognition.", "citation": "@INPROCEEDINGS{10022652,\n  author={Al-Fetyani, Mohammad and Al-Barham, Muhammad and Abandah, Gheith and Alsharkawi, Adham and Dawas, Maha},\n  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)}, \n  title={MASC: Massive Arabic Speech Corpus}, \n  year={2023},\n  volume={},\n  number={},\n  pages={1006-1013},\n  doi={10.1109/SLT54892.2023.10022652}}\n}", "cardData": null, "siblings": [], "_id": "648449b54bb88d273c4e05a5", "disabled": false, "gated": false, "likes": 2, "downloads": 67, "createdAt": "2023-06-10T10:00:21.000Z"}, {"id": "notrichardren/easy_qa", "sha": "906190eda0dc5ff11b57f277500ba0fea83ac5ed", "lastModified": "2023-06-26T12:33:45.000Z", "tags": ["task_categories:question-answering", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "notrichardren", "description": "EasyQA is a GPT-3.5-turbo-generated dataset of easy kindergarten-level facts, meant to be used to prompt and evaluate large language models for \"common sense\" truthful responses. It was originally created to understand how different types of truthfulness may be represented in the intermediate activations of large language models. EasyQA compromises 2346 questions that span 50 categories, including art, technology, education, music, and animals. Questions are crafted to be extremely simple and obvious, eliciting an obvious truth that would not be susceptible to misconceptions.", "citation": "@misc{ez_QA,\n    title={EasyQA: A Kindergarten-Level QA Benchmark},\n    author={Kevin Wang and Richard Ren and Phillip Guo},\n    year={2023},\n}", "cardData": null, "siblings": [], "_id": "64863cd4caf868de64744ffc", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-06-11T21:29:56.000Z"}, {"id": "dell-research-harvard/AmericanStories", "sha": "408407a232ae1a9b4bc81971cd8cd6b123263b07", "lastModified": "2023-09-08T18:33:32.000Z", "tags": ["task_categories:text-classification", "task_categories:text-generation", "task_categories:text-retrieval", "task_categories:summarization", "task_categories:question-answering", "size_categories:100M<n<1B", "language:en", "license:cc-by-4.0", "social science", "economics", "news", "newspaper", "large language modeling", "nlp", "lam", "doi:10.57967/hf/0757", "region:us"], "private": false, "author": "dell-research-harvard", "description": "American Stories offers high-quality structured data from historical newspapers suitable for pre-training large language models to enhance the understanding of historical English and world knowledge. It can also be integrated into external databases of retrieval-augmented language models, enabling broader access to historical information, including interpretations of political events and intricate details about people's ancestors. Additionally, the structured article texts facilitate the application of transformer-based methods for popular tasks like detecting reproduced content, significantly improving accuracy compared to traditional OCR methods. American Stories serves as a substantial and valuable dataset for advancing multimodal layout analysis models and other multimodal applications.", "citation": "Coming Soon", "cardData": null, "siblings": [], "_id": "6487752a4c7531fdad695434", "disabled": false, "gated": false, "likes": 79, "downloads": 1686, "createdAt": "2023-06-12T19:42:34.000Z"}, {"id": "CIRAL/ciral", "sha": "a97afcb9eb45592982a819b8b9eb9f10bc75b3d0", "lastModified": "2023-08-21T15:49:42.000Z", "tags": ["task_categories:text-retrieval", "language:ha", "language:so", "language:sw", "language:yo", "license:apache-2.0", "region:us"], "private": false, "author": "CIRAL", "description": "This dataset consists of the queries and relevance judgements in the CIRAL test collection.", "citation": null, "cardData": null, "siblings": [], "_id": "64877ab10ae234dc4fb809ee", "disabled": false, "gated": "manual", "likes": 1, "downloads": 11, "createdAt": "2023-06-12T20:06:09.000Z"}, {"id": "taeshahn/ko-lima", "sha": "55044b338762619a335383dddc1e48e4e3330f02", "lastModified": "2023-06-30T09:21:43.000Z", "tags": ["license:cc-by-nc-sa-4.0", "arxiv:2305.11206", "region:us"], "private": false, "author": "taeshahn", "description": "A high-quality korean dataset for efficient instruction tuning.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Ko-LIMA: Korean LIMA Dataset},\nauthor={Hahn, Taeseung},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "648886e09d6109a4ddfe1fd7", "disabled": false, "gated": false, "likes": 9, "downloads": 401, "createdAt": "2023-06-13T15:10:24.000Z"}, {"id": "Babelscape/REDFM", "sha": "eae75dc9bde14d1172351423bcbb82c5b9a94f66", "lastModified": "2023-06-20T07:33:35.000Z", "tags": ["task_categories:token-classification", "size_categories:10K<n<100K", "language:ar", "language:de", "language:en", "language:es", "language:it", "language:fr", "language:zh", "license:cc-by-sa-4.0", "arxiv:2306.09802", "region:us"], "private": false, "author": "Babelscape", "description": "Relation Extraction (RE) is a task that identifies relationships between entities in a text, enabling the acquisition of relational facts and bridging the gap between natural language and structured knowledge. However, current RE models often rely on small datasets with low coverage of relation types, particularly when working with languages other than English. \\In this paper, we address the above issue and provide two new resources that enable the training and evaluation of multilingual RE systems.\nFirst, we present SRED\\textsuperscript{FM}, an automatically annotated dataset covering 18 languages, 400 relation types, 13 entity types, totaling more than 40 million triplet instances. Second, we propose RED\\textsuperscript{FM}, a smaller, human-revised dataset for seven languages that allows for the evaluation of multilingual RE systems. \nTo demonstrate the utility of these novel datasets, we experiment with the first end-to-end multilingual RE model, mREBEL, \nthat extracts triplets, including entity types, in multiple languages. We release our resources and model checkpoints at \\href{https://www.github.com/babelscape/rebel}{https://www.github.com/babelscape/rebel}.", "citation": "@InProceedings{redfm2023,\n  author = {Huguet Cabot, Pere-Lluis\n                 and Tedeschi, Simone\n                 and Ngonga Ngomo, Axel-Cyrille\n                 and Navigli, Roberto},\n  title = {RED\\textsuperscript{FM}: a Filtered and Multilingual Relation Extraction Dataset},\n  booktitle = {Proceedings of the 2023 Conference on Association for Computational Linguistics},\n  year = {2023},\n  publisher = {Association for Computational Linguistics},\n  location = {Toronto, Canada},\n}", "cardData": null, "siblings": [], "_id": "64889d71eb54b040b58af88d", "disabled": false, "gated": false, "likes": 4, "downloads": 86, "createdAt": "2023-06-13T16:46:41.000Z"}, {"id": "RiTA-nlp/ITALIC", "sha": "0ff3a093a7abbf65e556b920783604034e85a06a", "lastModified": "2023-06-29T12:58:56.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:audio-classification", "task_ids:intent-classification", "annotations_creators:crowdsourced", "language_creators:Italian", "license:cc-by-nc-nd-4.0", "arxiv:2204.08582", "arxiv:2306.08502", "region:us"], "private": false, "author": "RiTA-nlp", "description": "ITALIC is a dataset of Italian audio recordings and contains annotation for utterance transcripts and associated intents. \nThe ITALIC dataset was created through a custom web platform, utilizing both native and non-native Italian speakers as participants. \nThe participants were required to record themselves while reading a randomly sampled short text from the MASSIVE dataset.", "citation": "@article{koudounas2023italic,\n  title={ITALIC: An Italian Intent Classification Dataset},\n  author={Koudounas, Alkis and La Quatra, Moreno and Vaiani, Lorenzo and Colomba, Luca and Attanasio, Giuseppe and Pastor, Eliana and Cagliero, Luca and Baralis, Elena},\n  journal={arXiv preprint arXiv:2306.08502},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "6488d9987987267e4fb737a5", "disabled": false, "gated": "auto", "likes": 2, "downloads": 83, "createdAt": "2023-06-13T21:03:20.000Z"}, {"id": "ibm-nasa-geospatial/hls_burn_scars", "sha": "1864285e25010d346a842e4f068b1a1d4248ed6d", "lastModified": "2023-09-26T16:08:32.000Z", "tags": ["size_categories:n<1K", "language:en", "license:cc-by-4.0", "doi:10.57967/hf/0956", "region:us"], "private": false, "author": "ibm-nasa-geospatial", "description": "This dataset contains Harmonized Landsat and Sentinel-2 imagery of burn scars and the associated masks for the years 2018-2021 over the contiguous United States. There are 804 512x512 scenes. Its primary purpose is for training geospatial machine learning models.", "citation": "@software{HLS_Foundation_2023,\n    author = {Phillips, Christopher and Roy, Sujit and Ankur, Kumar and Ramachandran, Rahul},\n    doi    = {10.57967/hf/0956},\n    month  = aug,\n    title  = {{HLS Foundation Burnscars Dataset}},\n    url    = {https://huggingface.co/ibm-nasa-geospatial/hls_burn_scars},\n    year   = {2023}\n}", "cardData": null, "siblings": [], "_id": "648924a4b168777dcf7185c5", "disabled": false, "gated": false, "likes": 9, "downloads": 14, "createdAt": "2023-06-14T02:23:32.000Z"}, {"id": "shibing624/nli-zh-all", "sha": "d9034b79da1dff929a8b9d719a3864e6fb16a7fb", "lastModified": "2023-06-22T06:39:46.000Z", "tags": ["task_categories:text-classification", "task_ids:natural-language-inference", "task_ids:semantic-similarity-scoring", "task_ids:text-scoring", "annotations_creators:shibing624", "language_creators:shibing624", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:https://github.com/shibing624/text2vec", "language:zh", "license:cc-by-4.0", "region:us"], "private": false, "author": "shibing624", "description": "The SNLI corpus (version 1.0) is a merged chinese sentence similarity dataset, supporting the task of natural language\ninference (NLI), also known as recognizing textual entailment (RTE).", "citation": "https://github.com/shibing624/text2vec", "cardData": null, "siblings": [], "_id": "64894c4da1ade8c1efb09144", "disabled": false, "gated": false, "likes": 20, "downloads": 210, "paperswithcode_id": "nli", "createdAt": "2023-06-14T05:12:45.000Z"}, {"id": "L4NLP/LEval", "sha": "43b9dbf06c239360b183c76cb5d90ebe4f5e3070", "lastModified": "2023-10-11T03:56:48.000Z", "tags": ["task_categories:summarization", "task_categories:question-answering", "task_categories:multiple-choice", "size_categories:1K<n<10K", "language:en", "license:gpl-3.0", "Long_context", "region:us"], "private": false, "author": "L4NLP", "description": "A benchmark to evaluate long document understanding and generation ability of LLM", "citation": "}", "cardData": null, "siblings": [], "_id": "6489a9cb431b7a5e0766bb4e", "disabled": false, "gated": false, "likes": 10, "downloads": 4861, "createdAt": "2023-06-14T11:51:39.000Z"}, {"id": "Riksarkivet/test_images_demo", "sha": "db7d7f8d18894e40ef017cc5c2ba286f37f7d592", "lastModified": "2023-08-31T13:58:13.000Z", "tags": ["task_categories:image-to-text", "language:sv", "HTR", "region:us"], "private": false, "author": "Riksarkivet", "description": "Demo dataset for the htr demo.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Small htr examples images},\nauthor={Gabriel Borg},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "6489ddc5539f98f74218a3e2", "disabled": false, "gated": false, "likes": 1, "downloads": 503, "createdAt": "2023-06-14T15:33:25.000Z"}, {"id": "mrjunos/depression-reddit-cleaned", "sha": "fd4339a6d99c047dab0908ee0b53ec0ec26c44a3", "lastModified": "2023-06-17T02:03:22.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:en", "license:cc-by-4.0", "reddit", "Sentiment ", "depression", "region:us"], "private": false, "author": "mrjunos", "description": "The dataset provided is a Depression: Reddit Dataset (Cleaned)containing approximately\n7,000 labeled instances. It consists of two main features: 'text' and 'label'.\nThe 'text' feature contains the text data from Reddit posts related to depression, while\nthe 'label' feature indicates whether a post is classified as depression or not.\n\nThe raw data for this dataset was collected by web scraping Subreddits. To ensure the data's\nquality and usefulness, multiple natural language processing (NLP) techniques were applied\nto clean the data. The dataset exclusively consists of English-language posts, and its\nprimary purpose is to facilitate mental health classification tasks.\n\nThis dataset can be employed in various natural language processing tasks related to\ndepression,such as sentiment analysis, topic modeling, text classification, or any other NLP\ntask that requires labeled data pertaining to depression from Reddit.", "citation": null, "cardData": null, "siblings": [], "_id": "648a4a4f7de18d75a2415749", "disabled": false, "gated": false, "likes": 1, "downloads": 19, "createdAt": "2023-06-14T23:16:31.000Z"}, {"id": "TJUNLP/M3KE", "sha": "fd84b9d5c009c01f3022a0f6848a01ebbfe14486", "lastModified": "2023-06-19T04:07:29.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "task_categories:multiple-choice", "size_categories:10K<n<100K", "language:zh", "license:apache-2.0", "arxiv:2305.10263", "region:us"], "private": false, "author": "TJUNLP", "description": "A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models.", "citation": "@misc{liu2023m3ke,\n    title={M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models},\n    author={Chuang Liu and Renren Jin and Yuqi Ren and Linhao Yu and Tianyu Dong and Xiaohan Peng and Shuting Zhang and Jianxiang Peng and Peiyi Zhang and Qingqing Lyu and Xiaowen Su and Qun Liu and Deyi Xiong},\n    year={2023},\n    eprint={2305.10263},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "648bcc33a7bfa231b27f1e07", "disabled": false, "gated": false, "likes": 2, "downloads": 182, "createdAt": "2023-06-16T02:42:59.000Z"}, {"id": "tianyang/repobench-c", "sha": "2744a9d102c2889f6a034e070299cffff007b06d", "lastModified": "2023-06-24T01:37:41.000Z", "tags": ["task_categories:text-generation", "task_ids:document-retrieval", "language_creators:found", "multilinguality:multilingual", "size_categories:100K<n<1M", "source_datasets:original", "license:cc-by-nc-nd-4.0", "code", "arxiv:2306.03091", "region:us"], "private": false, "author": "tianyang", "description": "RepoBench is a dataset that benchmarks repository-level code auto-completion systems.\n\nRepoBench-C denotes RepoBench for code completion, \nwhich is subtask of RepoBench for next-line code prediction given both cross-file and in-file context.", "citation": "@misc{liu2023repobench,\n      title={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems}, \n      author={Tianyang Liu and Canwen Xu and Julian McAuley},\n      year={2023},\n      eprint={2306.03091},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "648c0ca817c7ceb9b41ce9f2", "disabled": false, "gated": false, "likes": 4, "downloads": 27, "createdAt": "2023-06-16T07:18:00.000Z"}, {"id": "HausaNLP/NaijaSenti-Twitter", "sha": "a3d0415a828178edf3466246f49cfcd83b946ab3", "lastModified": "2023-06-16T16:42:04.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-analysis", "task_ids:sentiment-classification", "task_ids:sentiment-scoring", "task_ids:semantic-similarity-classification", "task_ids:semantic-similarity-scoring", "multilinguality:monolingual", "multilinguality:multilingual", "size_categories:100K<n<1M", "language:hau", "language:ibo", "language:pcm", "language:yor", "license:cc-by-nc-sa-4.0", "sentiment analysis, Twitter, tweets", "sentiment", "region:us"], "private": false, "author": "HausaNLP", "description": "NaijaSenti is the first large-scale human-annotated Twitter sentiment dataset for the four most widely spoken languages in Nigeria \u2014 Hausa, Igbo, Nigerian-Pidgin, and Yor\u00f9b\u00e1 \u2014 consisting of around 30,000 annotated tweets per language, including a significant fraction of code-mixed tweets.", "citation": "@inproceedings{muhammad-etal-2022-naijasenti,\n    title = \"{N}aija{S}enti: A {N}igerian {T}witter Sentiment Corpus for Multilingual Sentiment Analysis\",\n    author = \"Muhammad, Shamsuddeen Hassan  and\n      Adelani, David Ifeoluwa  and\n      Ruder, Sebastian  and\n      Ahmad, Ibrahim Sa{'}id  and\n      Abdulmumin, Idris  and\n      Bello, Bello Shehu  and\n      Choudhury, Monojit  and\n      Emezue, Chris Chinenye  and\n      Abdullahi, Saheed Salahudeen  and\n      Aremu, Anuoluwapo  and\n      Jorge, Al{\\'\\i}pio  and\n      Brazdil, Pavel\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.63\",\n    pages = \"590--602\",\n}", "cardData": null, "siblings": [], "_id": "648c221766b8a3cfdbea523e", "disabled": false, "gated": false, "likes": 0, "downloads": 320, "createdAt": "2023-06-16T08:49:27.000Z"}, {"id": "HausaNLP/Naija-Lex", "sha": "543200257c1a01df112e5e8edf6881f16bd34974", "lastModified": "2023-06-18T16:13:08.000Z", "tags": ["multilinguality:monolingual", "multilinguality:multilingual", "language:hau", "language:ibo", "language:yor", "license:cc-by-nc-sa-4.0", "sentiment analysis, Twitter, tweets", "stopwords", "region:us"], "private": false, "author": "HausaNLP", "description": "Naija-Stopwords is a part of the Naija-Senti project. It is a list of collected stopwords from the four most widely spoken languages in Nigeria \u2014 Hausa, Igbo, Nigerian-Pidgin, and Yor\u00f9b\u00e1.", "citation": "@inproceedings{muhammad-etal-2022-naijasenti,\n    title = \"{N}aija{S}enti: A {N}igerian {T}witter Sentiment Corpus for Multilingual Sentiment Analysis\",\n    author = \"Muhammad, Shamsuddeen Hassan  and\n      Adelani, David Ifeoluwa  and\n      Ruder, Sebastian  and\n      Ahmad, Ibrahim Sa{'}id  and\n      Abdulmumin, Idris  and\n      Bello, Bello Shehu  and\n      Choudhury, Monojit  and\n      Emezue, Chris Chinenye  and\n      Abdullahi, Saheed Salahudeen  and\n      Aremu, Anuoluwapo  and\n      Jorge, Al{\\\"\\i}pio  and\n      Brazdil, Pavel\",\n    booktitle = \"Proceedings of the Thirteenth Language Resources and Evaluation Conference\",\n    month = jun,\n    year = \"2022\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2022.lrec-1.63\",\n    pages = \"590--602\",\n}", "cardData": null, "siblings": [], "_id": "648c27658a1fec672e059cfc", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2023-06-16T09:12:05.000Z"}, {"id": "tianyang/repobench-p", "sha": "5fb96b4a85d9c13c4e6e3389b81e9a714551e479", "lastModified": "2023-07-19T06:13:35.000Z", "tags": ["task_categories:text-retrieval", "task_categories:text-generation", "task_ids:document-retrieval", "language_creators:found", "multilinguality:multilingual", "source_datasets:original", "language:code", "license:cc-by-nc-nd-4.0", "code", "arxiv:2306.03091", "region:us"], "private": false, "author": "tianyang", "description": "RepoBench is a dataset that benchmarks repository-level code auto-completion systems.\n\nRepoBench-P denotes RepoBench for pipeline, \nwhich is subtask of RepoBench including both relevant code retrieval and next-line code prediction.", "citation": "@misc{liu2023repobench,\n      title={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems}, \n      author={Tianyang Liu and Canwen Xu and Julian McAuley},\n      year={2023},\n      eprint={2306.03091},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "648c2cce2af037f79cdbd08f", "disabled": false, "gated": false, "likes": 2, "downloads": 12, "createdAt": "2023-06-16T09:35:10.000Z"}, {"id": "InstaDeepAI/nucleotide_transformer_downstream_tasks", "sha": "9722b77543efe3c72dc19fa20f4524912aa6bf3b", "lastModified": "2023-10-16T12:57:56.000Z", "tags": ["region:us"], "private": false, "author": "InstaDeepAI", "description": "The 18 classification downstream tasks from the Nucleotide Transformer paper. Each task\ncorresponds to a dataset configuration.", "citation": "@article{dalla2023nucleotide,\n  title={The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics},\n  author={Dalla-Torre, Hugo and Gonzalez, Liam and Mendoza-Revilla, Javier and Carranza, Nicolas Lopez and Grzywaczewski, Adam Henryk and Oteri, Francesco and Dallago, Christian and Trop, Evan and Sirelkhatim, Hassan and Richard, Guillaume and others},\n  journal={bioRxiv},\n  pages={2023--01},\n  year={2023},\n  publisher={Cold Spring Harbor Laboratory}\n}", "cardData": null, "siblings": [], "_id": "648c4ec88c887a7e38f5fc1f", "disabled": false, "gated": false, "likes": 2, "downloads": 1415, "createdAt": "2023-06-16T12:00:08.000Z"}, {"id": "PNLPhub/FarsTail", "sha": "abf4dc2defe6753d529c86f23a7b7257c27ce7e4", "lastModified": "2023-07-09T07:39:52.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:fa", "license:apache-2.0", "arxiv:2009.08820", "region:us"], "private": false, "author": "PNLPhub", "description": "\\\\\\\\\\\\\\A Persian Natural Language Inference Dataset", "citation": "\\@article{amirkhani2020farstail,\n  title={FarsTail: A Persian Natural Language Inference Dataset},\n  author={Hossein Amirkhani, Mohammad Azari Jafari, Azadeh Amirak, Zohreh Pourjafari, Soroush Faridan Jahromi, and Zeinab Kouhkan},\n  journal={arXiv preprint arXiv:2009.08820},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "648c6967b010e9fed5fe3137", "disabled": false, "gated": false, "likes": 0, "downloads": 140, "createdAt": "2023-06-16T13:53:43.000Z"}, {"id": "ChangeIsKey/kubhist2", "sha": "fb5deec3079d6a19bd155791e6168d7f7dffd1f1", "lastModified": "2023-08-10T09:20:43.000Z", "tags": ["task_categories:text-generation", "size_categories:1B<n<10B", "language:sv", "license:cc-by-sa-4.0", "newspapers", "historical", "region:us"], "private": false, "author": "ChangeIsKey", "description": "This is a version of the Kubhist 2 dataset created, curated and made available by Spr\u00e5kbanken Text (SBX) at the University of Gothenburg (Sweden) under the CC BY 4.0 license. \r\nThis is a a corpus of OCRed newspapers from Sweden spanning the 1640s to the 1900s.\r\nThe original data is available with many types of annotation in XML at https://spraakbanken.gu.se/en/resources/kubhist2. \r\nA good description of the data is available in this blog entry by Dana Dann\u00e9lls: https://spraakbanken.gu.se/blogg/index.php/2019/09/15/the-kubhist-corpus-of-swedish-newspapers/\r\n\r\nIn a nutshell, this hugginface dataset version offers:\r\n- only the OCRed text\r\n- available in decadal subsets\r\n\r\nLicense is CC BY 4.0 with attribution.", "citation": "@misc{botenanna,\r\n    title = {\"Jag k\u00e4nner en bot, hon heter [MASK]. A BERT for older Swedish, and a more usable dataset for historical newspapers\"},\r\n    author = {Simon Hengchen} \r\n    year={2023},\r\n}", "cardData": null, "siblings": [], "_id": "648ee43e9ae7cc4fcffa730f", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2023-06-18T11:02:22.000Z"}, {"id": "PNLPhub/DigiMag", "sha": "969b335c9f50eda5c384460be4eb2b55505c2c53", "lastModified": "2023-06-20T09:39:05.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "PNLPhub", "description": "\\\\\\\\\\\\\\A total of 8,515 articles scraped from Digikala Online Magazine. This dataset includes seven different classes.", "citation": "\\@article{ParsBERT,\n    title={ParsBERT: Transformer-based Model for Persian Language Understanding},\n    author={Mehrdad Farahani, Mohammad Gharachorloo, Marzieh Farahani, Mohammad Manthouri},\n    journal={ArXiv},\n    year={2020},\n    volume={abs/2005.12515}\n}", "cardData": null, "siblings": [], "_id": "649168883620f1a33ed25749", "disabled": false, "gated": false, "likes": 0, "downloads": 24, "createdAt": "2023-06-20T08:51:20.000Z"}, {"id": "PNLPhub/Persian-News", "sha": "7e81b1fc3a195928950a44884e8901faf6b78bfb", "lastModified": "2023-06-20T11:05:30.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "PNLPhub", "description": "\\\\\\\\\\\\\\A dataset of various news articles scraped from different online news agencies\u2019 websites. The total number of articles is 16,438, spread over eight different classes.", "citation": "\\@article{ParsBERT,\n    title={ParsBERT: Transformer-based Model for Persian Language Understanding},\n    author={Mehrdad Farahani, Mohammad Gharachorloo, Marzieh Farahani, Mohammad Manthouri},\n    journal={ArXiv},\n    year={2020},\n    volume={abs/2005.12515}\n}", "cardData": null, "siblings": [], "_id": "6491855ff6e6408af26e378b", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-06-20T10:54:23.000Z"}, {"id": "PNLPhub/parsinlu-multiple-choice", "sha": "d97118a04b58cbc22b6ef4146f140601d342aad1", "lastModified": "2023-09-03T13:45:10.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "PNLPhub", "description": "A Persian multiple choice task.", "citation": "@article{huggingface:dataset,\n    title = {ParsiNLU: A Suite of Language Understanding Challenges for Persian},\n    authors = {Khashabi, Daniel and Cohan, Arman and Shakeri, Siamak and Hosseini, Pedram and Pezeshkpour, Pouya and Alikhani, Malihe and Aminnaseri, Moin and Bitaab, Marzieh and Brahman, Faeze and Ghazarian, Sarik and others},\n    year={2020}\n    journal = {arXiv e-prints},\n    eprint = {2012.06154},    \n}", "cardData": null, "siblings": [], "_id": "6492d1f959a28518ba273f7f", "disabled": false, "gated": false, "likes": 0, "downloads": 28, "createdAt": "2023-06-21T10:33:29.000Z"}, {"id": "kumapo/JAQKET", "sha": "83338341033c27c300af8ea810c01cc7087ed077", "lastModified": "2023-10-09T06:44:28.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "language:ja", "license:cc-by-sa-4.0", "region:us"], "private": false, "author": "kumapo", "description": "JAQKET: JApanese Questions on Knowledge of EnTitie", "citation": "@InProceedings{Kurihara_nlp2020,\n  author =  \"\u9234\u6728\u6b63\u654f and \u9234\u6728\u6f64 and \u677e\u7530\u8015\u53f2 and \u2ec4\u7530\u4eac\u4ecb and \u4e95\u4e4b\u4e0a\u76f4\u4e5f\",\n  title =   \"JAQKET: \u30af\u30a4\u30ba\u3092\u984c\u6750\u306b\u3057\u305f\u65e5\u672c\u8a9e QA \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u69cb\u7bc9\",\n  booktitle =   \"\u8a00\u8a9e\u51e6\u7406\u5b66\u4f1a\u7b2c26\u56de\u5e74\u6b21\u5927\u4f1a\",\n  year =    \"2020\",\n  url = \"https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/P2-24.pdf\"\n  note= \"in Japanese\"", "cardData": null, "siblings": [], "_id": "6492f5668e39e23c24eaf941", "disabled": false, "gated": false, "likes": 0, "downloads": 2022, "createdAt": "2023-06-21T13:04:38.000Z"}, {"id": "sarus-tech/phee", "sha": "2705e8f533c1c5f5277727e0457e7ec471d17297", "lastModified": "2023-06-21T19:36:26.000Z", "tags": ["arxiv:2210.12560", "region:us"], "private": false, "author": "sarus-tech", "description": "Data and Code for [``PHEE: A Dataset for Pharmacovigilance Event Extraction from Text``](https://arxiv.org/abs/2210.12560/)\\", "citation": "@misc{sun2022phee,\n      title={PHEE: A Dataset for Pharmacovigilance Event Extraction from Text}, \n      author={Zhaoyue Sun and Jiazheng Li and Gabriele Pergola and Byron C. Wallace and Bino John and Nigel Greene and Joseph Kim and Yulan He},\n      year={2022},\n      eprint={2210.12560},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64930def137833d7ec7616bc", "disabled": false, "gated": false, "likes": 1, "downloads": 149, "createdAt": "2023-06-21T14:49:19.000Z"}, {"id": "wellecks/minif2f_isabelle", "sha": "e18a86757832d6d793a7064e94cd4f45bc11ac2e", "lastModified": "2023-07-03T19:46:10.000Z", "tags": ["license:mit", "math", "theorem-proving", "arxiv:2109.00110", "region:us"], "private": false, "author": "wellecks", "description": "MiniF2F is a formal mathematics benchmark (translated across multiple formal systems) consisting of exercise statements from olympiads (AMC, AIME, IMO) as well as high-school and undergraduate maths classes.\n\nThis dataset contains formal statements in Isabelle. Each statement is paired with an informal statement and \nan informal proof, as described in Draft, Sketch, Prove [Jiang et al 2023].\n\nThe problems in this dataset use the most recent facebookresearch/miniF2F commit on July 3, 2023.", "citation": "@inproceedings{jiang2023draft,\n    title={Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs},\n    author={Albert Qiaochu Jiang and Sean Welleck and Jin Peng Zhou and Timothee Lacroix and Jiacheng Liu and Wenda Li and Mateja Jamnik and Guillaume Lample and Yuhuai Wu},\n    booktitle={The Eleventh International Conference on Learning Representations },\n    year={2023},\n    url={https://openreview.net/forum?id=SMa9EAovKMC}\n}\n\n@inproceedings{zheng2022miniff,\n    title={miniF2F: a cross-system benchmark for formal Olympiad-level mathematics},\n    author={Kunhao Zheng and Jesse Michael Han and Stanislas Polu},\n    booktitle={International Conference on Learning Representations},\n    year={2022},\n    url={https://openreview.net/forum?id=9ZPegFuFTFv}\n}", "cardData": null, "siblings": [], "_id": "64936e710934be4dee339794", "disabled": false, "gated": false, "likes": 0, "downloads": 14, "createdAt": "2023-06-21T21:41:05.000Z"}, {"id": "HANSEN-REPO/HANSEN", "sha": "5e21f23ec8bcb022de92f0eecf16bcb9ebfc2e78", "lastModified": "2023-11-01T18:35:34.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "HANSEN-REPO", "description": "This benchmark environment contains a dataset comprised of human-spoken text and Large Language Models (LLM) generated spoken text.\nWe also have three benchmark tasks - AA (multi-class classification problem on human datasets), AV (binary classification problem on whether two spoken texts are from same human),\nand TT (Turing test problem, determining human vs AI spoken texts problem).", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "6495fc580b01497fb78cbc26", "disabled": false, "gated": false, "likes": 1, "downloads": 129, "createdAt": "2023-06-23T20:11:04.000Z"}, {"id": "hezarai/lscp-pos-500k", "sha": "787cfc75f8ae89e4893a86635d2ff5ffcda981ae", "lastModified": "2023-09-02T08:41:54.000Z", "tags": ["task_categories:token-classification", "language:fa", "region:us"], "private": false, "author": "hezarai", "description": "Language recognition has been significantly advanced in recent years by means of modern machine learning methods such as deep learning \nand benchmarks with rich annotations. However, research is still limited in low-resource formal languages. This consists of a significant \ngap in describing the colloquial language especially for low-resourced ones such as Persian. In order to target this gap for low resource languages, \nwe propose a \u201cLarge Scale Colloquial Persian Dataset\u201d (LSCP). LSCP is hierarchically organized in a semantic taxonomy that focuses on \nmulti-task informal Persian language understanding as a comprehensive problem. This encompasses the recognition of multiple semantic aspects in the human-level sentences, \nwhich naturally captures from the real-world sentences. We believe that further investigations and processing, as well as the application of novel algorithms and methods, \ncan strengthen enriching computerized understanding and processing of low resource languages. The proposed corpus consists of 120M sentences resulted from 27M tweets \nannotated with parsing tree, part-of-speech tags, sentiment polarity and translation in five different languages.", "citation": "@inproceedings{abdi-khojasteh-etal-2020-lscp,\n    title = \"{LSCP}: Enhanced Large Scale Colloquial {P}ersian Language Understanding\",\n    author = \"Abdi Khojasteh, Hadi  and\n      Ansari, Ebrahim  and\n      Bohlouli, Mahdi\",\n    booktitle = \"Proceedings of the Twelfth Language Resources and Evaluation Conference\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.lrec-1.776\",\n    pages = \"6323--6327\",\n    abstract = \"Language recognition has been significantly advanced in recent years by means of modern machine learning methods such as deep learning and benchmarks with rich annotations. However, research is still limited in low-resource formal languages. This consists of a significant gap in describing the colloquial language especially for low-resourced ones such as Persian. In order to target this gap for low resource languages, we propose a {``}Large Scale Colloquial Persian Dataset{''} (LSCP). LSCP is hierarchically organized in a semantic taxonomy that focuses on multi-task informal Persian language understanding as a comprehensive problem. This encompasses the recognition of multiple semantic aspects in the human-level sentences, which naturally captures from the real-world sentences. We believe that further investigations and processing, as well as the application of novel algorithms and methods, can strengthen enriching computerized understanding and processing of low resource languages. The proposed corpus consists of 120M sentences resulted from 27M tweets annotated with parsing tree, part-of-speech tags, sentiment polarity and translation in five different languages.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-34-4\",\n}", "cardData": null, "siblings": [], "_id": "649824e68fadf0ae762ae733", "disabled": false, "gated": false, "likes": 0, "downloads": 68, "createdAt": "2023-06-25T11:28:38.000Z"}, {"id": "haonan-li/cmmlu", "sha": "efcc940752ea4a1ea94d2727f11f83858d64fc8e", "lastModified": "2023-07-13T10:19:29.000Z", "tags": ["task_categories:multiple-choice", "task_categories:question-answering", "size_categories:10K<n<100K", "language:zh", "license:cc-by-nc-4.0", "chinese", "llm", "evaluation", "arxiv:2306.09212", "region:us"], "private": false, "author": "haonan-li", "description": "CMMLU is a comprehensive Chinese assessment suite specifically designed to evaluate the advanced knowledge and reasoning abilities of LLMs within the Chinese language and cultural context.", "citation": "@misc{li2023cmmlu,\n      title={CMMLU: Measuring massive multitask language understanding in Chinese},\n      author={Haonan Li and Yixuan Zhang and Fajri Koto and Yifei Yang and Hai Zhao and Yeyun Gong and Nan Duan and Timothy Baldwin},\n      year={2023},\n      eprint={2306.09212},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64986d58dc503810829819bf", "disabled": false, "gated": false, "likes": 33, "downloads": 62495, "createdAt": "2023-06-25T16:37:44.000Z"}, {"id": "gabeorlanski/bc-mbpp", "sha": "bcc52599410f15a1c973a785d70297df1bc43d25", "lastModified": "2023-07-21T22:03:56.000Z", "tags": ["task_categories:text-generation", "task_categories:text2text-generation", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|mbpp", "language:en", "license:apache-2.0", "code", "arxiv:2302.01973", "arxiv:2108.07732", "region:us"], "private": false, "author": "gabeorlanski", "description": "The MBPP dataset in BabelCode format.", "citation": "@article{orlanski2023measuring,\n  title={Measuring The Impact Of Programming Language Distribution},\n  author={Orlanski, Gabriel and Xiao, Kefan and Garcia, Xavier and Hui, Jeffrey and Howland, Joshua and Malmaud, Jonathan and Austin, Jacob and Singh, Rishah and Catasta, Michele},\n  journal={arXiv preprint arXiv:2302.01973},\n  year={2023}\n}\n@article{Austin2021ProgramSW,\n  title={Program Synthesis with Large Language Models},\n  author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie J. Cai and Michael Terry and Quoc V. Le and Charles Sutton},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2108.07732}\n}", "cardData": null, "siblings": [], "_id": "649874b80aeeb1f81ac37af5", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2023-06-25T17:09:12.000Z"}, {"id": "gradients-ai/mc4_v01", "sha": "b07c64b63df29b503a1fb1791502a477ae1e4141", "lastModified": "2023-09-08T03:06:31.000Z", "tags": ["task_categories:text-retrieval", "language:en", "language:vi", "region:us"], "private": false, "author": "gradients-ai", "description": "A colossal, cleaned version of Common Crawl's web crawl corpus.\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's mC4 dataset by Gradients Technologies Company.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "64993015be8a8211291a6f05", "disabled": false, "gated": false, "likes": 1, "downloads": 516, "createdAt": "2023-06-26T06:28:37.000Z"}, {"id": "bigcode/commitpackft", "sha": "fc56fe33c030c6daa414c2b112c932b8eed085e6", "lastModified": "2023-08-20T07:13:43.000Z", "tags": ["language:code", "license:mit", "arxiv:2308.07124", "region:us"], "private": false, "author": "bigcode", "description": "CommitPackFT is is a 2GB filtered version of CommitPack to contain only high-quality commit messages that resemble natural language instructions.", "citation": "@article{muennighoff2023octopack,\n      title={OctoPack: Instruction Tuning Code Large Language Models}, \n      author={Niklas Muennighoff and Qian Liu and Armel Zebaze and Qinkai Zheng and Binyuan Hui and Terry Yue Zhuo and Swayam Singh and Xiangru Tang and Leandro von Werra and Shayne Longpre},\n      journal={arXiv preprint arXiv:2308.07124},\n      year={2023}\n}", "cardData": null, "siblings": [], "_id": "649a87b8a0b21c7cef7d89dd", "disabled": false, "gated": false, "likes": 22, "downloads": 6506, "createdAt": "2023-06-27T06:54:48.000Z"}, {"id": "arielnlee/Superimposed-Masked-Dataset", "sha": "1da52685e98871962aa12d49db01c606c5352012", "lastModified": "2023-08-01T18:08:45.000Z", "tags": ["task_categories:image-classification", "size_categories:10K<n<100K", "language:en", "license:other", "occlusion", "arxiv:2306.17848", "region:us"], "private": false, "author": "arielnlee", "description": "SMD is an occluded ImageNet-1K validation set, created to be an additional way to evaluate the impact of occlusion on model performance. This experiment used a variety of occluder objects that are not in the ImageNet-1K label space and are unambiguous in relationship to objects that reside in the label space.", "citation": "@misc{lee2023hardwiring,\n      title={Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing}, \n      author={Ariel N. Lee and Sarah Adel Bargal and Janavi Kasera and Stan Sclaroff and Kate Saenko and Nataniel Ruiz},\n      year={2023},\n      eprint={2306.17848},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "649bc024e9769d64c8d33055", "disabled": false, "gated": false, "likes": 1, "downloads": 21, "createdAt": "2023-06-28T05:07:48.000Z"}, {"id": "VictorSanh/LrvInstruction", "sha": "871e4f8b19a585f69339e1654ef97d59b2598c9c", "lastModified": "2023-06-30T02:39:43.000Z", "tags": ["region:us"], "private": false, "author": "VictorSanh", "description": "LRV-Instruction is a dataset consisting of 120k visual instructions generated by GPT4, covering 16 vision-and-language tasks with open-ended instructions and answers. LRV-Instruction include both positive and negative instructions for more robust visual instruction tuning. The images of our dataset are from Visual Genome.", "citation": "@article{Liu2023AligningLM,\n  title={Aligning Large Multi-Modal Model with Robust Instruction Tuning},\n  author={Fuxiao Liu and Kevin Lin and Linjie Li and Jianfeng Wang and Yaser Yacoob and Lijuan Wang},\n  journal={ArXiv},\n  year={2023},\n  volume={abs/2306.14565}\n}", "cardData": null, "siblings": [], "_id": "649ca9afccfa6c1a3c486094", "disabled": false, "gated": false, "likes": 6, "downloads": 32, "createdAt": "2023-06-28T21:44:15.000Z"}, {"id": "commaai/comma2k19", "sha": "fd6daa758f5a9fd3c8fc7531edea2c46785d89be", "lastModified": "2023-06-29T02:40:08.000Z", "tags": ["license:mit", "arxiv:1812.05752", "region:us"], "private": false, "author": "commaai", "description": "comma2k19 is a dataset of over 33 hours of commute in California's 280 highway.\nThis means 2019 segments, 1 minute long each, on a 20km section of highway driving between California's San Jose and San Francisco.\ncomma2k19 is a fully reproducible and scalable dataset.\nThe data was collected using comma EONs that has sensors similar to those of any modern smartphone including a road-facing camera, phone GPS, thermometers and 9-axis IMU.\nAdditionally, the EON captures raw GNSS measurements and all CAN data sent by the car with a comma grey panda.", "citation": null, "cardData": null, "siblings": [], "_id": "649ccf89b602cd0e46e284aa", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "createdAt": "2023-06-29T00:25:45.000Z"}, {"id": "TrainingDataPro/monitors-replay-attacks-dataset", "sha": "882fe09558896fb9dd5eebe605f887963b0dcad8", "lastModified": "2023-09-14T16:54:44.000Z", "tags": ["task_categories:video-classification", "language:en", "license:cc-by-nc-nd-4.0", "legal", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset consists of videos of replay attacks played on different models of\ncomputers. The dataset solves tasks in the field of anti-spoofing and it is\nuseful for buisness and safety systems.\nThe dataset includes: **replay attacks** - videos of real people played\non a computer and filmed on the phone.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {monitors-replay-attacks-dataset},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "649d92c719de250f7369ac38", "disabled": false, "gated": false, "likes": 2, "downloads": 12, "createdAt": "2023-06-29T14:18:47.000Z"}, {"id": "iceberg-nlp/climabench", "sha": "309edd6008a7b012d6d374338236b22148ff5aa9", "lastModified": "2023-09-10T22:05:20.000Z", "tags": ["task_categories:text-classification", "annotations_creators:other", "language_creators:other", "multilinguality:monolingual", "size_categories:10K<n<100K", "source_datasets:original", "language:en", "arxiv:2301.04253", "region:us"], "private": false, "author": "iceberg-nlp", "description": "The topic of Climate Change (CC) has received limited attention in NLP despite its real world urgency.\nActivists and policy-makers need NLP tools in order to effectively process the vast and rapidly growing textual data produced on CC.\nTheir utility, however, primarily depends on whether the current state-of-the-art models can generalize across various tasks in the CC domain.\nIn order to address this gap, we introduce Climate Change Benchmark (Climabench), a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically.\nFurther, we enhance the benchmark by releasing two large-scale labelled text classification and question-answering datasets curated from publicly available environmental disclosures.\nLastly, we provide an analysis of several generic and CC-oriented models answering whether fine-tuning on domain text offers any improvements across these tasks. We hope this work provides a standard assessment tool for research on CC text data.", "citation": "@misc{laud2023Climabench,\n      title={ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English}, \n      author={Tanmay Laud and Daniel Spokoyny and Tom Corringham and Taylor Berg-Kirkpatrick},\n      year={2023},\n      eprint={2301.04253},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "649e07a459ff3a11c1b23e39", "disabled": false, "gated": false, "likes": 0, "downloads": 33, "paperswithcode_id": "climabench", "createdAt": "2023-06-29T22:37:24.000Z"}, {"id": "jinmang2/ucf_crime", "sha": "2e26f271f49aa7202caea24f3068033412e02c7b", "lastModified": "2023-07-11T03:46:53.000Z", "tags": ["region:us"], "private": false, "author": "jinmang2", "description": "# Real-world Anomaly Detection in Surveillance Videos\nSurveillance videos are able to capture a variety of realistic anomalies. In this paper, we propose to learn anomalies by exploiting both normal and anomalous videos. To avoid annotating the anomalous segments or clips in training videos, which is very time consuming, we propose to learn anomaly through the deep multiple instance ranking framework by leveraging weakly labeled training videos, i.e. the training labels (anomalous or normal) are at video-level instead of clip-level. In our approach, we consider normal and anomalous videos as bags and video segments as instances in multiple instance learning (MIL), and automatically learn a deep anomaly ranking model that predicts high anomaly scores for anomalous video segments. Furthermore, we introduce sparsity and temporal smoothness constraints in the ranking loss function to better localize anomaly during training.\nWe also introduce a new large-scale first of its kind dataset of 128 hours of videos. It consists of 1900 long and untrimmed real-world surveillance videos, with 13 realistic anomalies such as fighting, road accident, burglary, robbery, etc. as well as normal activities. This dataset can be used for two tasks. First, general anomaly detection considering all anomalies in one group and all normal activities in another group. Second, for recognizing each of 13 anomalous activities. Our experimental results show that our MIL method for anomaly detection achieves significant improvement on anomaly detection performance as compared to the state-of-the-art approaches. We provide the results of several recent deep learning baselines on anomalous activity recognition. The low recognition performance of these baselines reveals that our dataset is very challenging and opens more opportunities for future work.\n# Problem & Motivation\nOne critical task in video surveillance is detecting anomalous events such as traffic accidents, crimes or illegal activities. Generally, anomalous events rarely occur as compared to normal activities. Therefore, to alleviate the waste of labor and time, developing intelligent computer vision algorithms for automatic video anomaly detection is a pressing need. The goal of a practical anomaly detection system is to timely signal an activity that deviates normal patterns and identify the time window of the occurring anomaly. Therefore, anomaly detection can be considered as coarse level video understanding, which filters out anomalies from normal patterns. Once an anomaly is detected, it can further be categorized into one of the specific activities using classification techniques.\nIn this work, we propose an anomaly detection algorithm using weakly labeled training videos. That is we only know the video-level labels, i.e. a video is normal or contains anomaly somewhere, but we do not know where. This is intriguing because we can easily annotate a large number of videos by only assigning video-level labels. To formulate a weakly-supervised learning approach, we resort to multiple instance learning. Specifically, we propose to learn anomaly through a deep MIL framework by treating normal and anomalous surveillance videos as bags and short segments/clips of each video as instances in a bag. Based on training videos, we automatically learn an anomaly ranking model that predicts high anomaly scores for anomalous segments in a video. During testing, a longuntrimmed video is divided into segments and fed into our deep network which assigns anomaly score for each video segment such that an anomaly can be detected.\n# Method\nOur proposed approach (summarized in Figure 1) begins with dividing surveillance videos into a fixed number of segments during training. These segments make instances in a bag. Using both positive (anomalous) and negative (normal) bags, we train the anomaly detection model using the proposed deep MIL ranking loss.\nhttps://www.crcv.ucf.edu/projects/real-world/method.png\n# UCF-Crime Dataset\nWe construct a new large-scale dataset, called UCF-Crime, to evaluate our method. It consists of long untrimmed surveillance videos which cover 13 realworld anomalies, including Abuse, Arrest, Arson, Assault, Road Accident, Burglary, Explosion, Fighting, Robbery, Shooting, Stealing, Shoplifting, and Vandalism. These anomalies are selected because they have a significant impact on public safety. We compare our dataset with previous anomaly detection datasets in Table 1. For more details about the UCF-Crime dataset, please refer to our paper. A short description of each anomalous event is given below.\nAbuse: This event contains videos which show bad, cruel or violent behavior against children, old people, animals, and women.\nBurglary: This event contains videos that show people (thieves) entering into a building or house with the intention to commit theft. It does not include use of force against people.\nRobbery: This event contains videos showing thieves taking money unlawfully by force or threat of force. These videos do not include shootings.\nStealing: This event contains videos showing people taking property or money without permission. They do not include shoplifting.\nShooting: This event contains videos showing act of shooting someone with a gun.\nShoplifting: This event contains videos showing people stealing goods from a shop while posing as a shopper.\nAssault: This event contains videos showing a sudden or violent physical attack on someone. Note that in these videos the person who is assaulted does not fight back.\nFighting: This event contains videos displaying two are more people attacking one another.\nArson: This event contains videos showing people deliberately setting fire to property.\nExplosion: This event contains videos showing destructive event of something blowing apart. This event does not include videos where a person intentionally sets a fire or sets off an explosion.\nArrest: This event contains videos showing police arresting individuals.\nRoad Accident: This event contains videos showing traffic accidents involving vehicles, pedestrians or cyclists.\nVandalism: This event contains videos showing action involving deliberate destruction of or damage to public or private property. The term includes property damage, such as graffiti and defacement directed towards any property without permission of the owner.\nNormal Event: This event contains videos where no crime occurred. These videos include both indoor (such as a shopping mall) and outdoor scenes as well as day and night-time scenes.\nhttps://www.crcv.ucf.edu/projects/real-world/dataset_table.png\nhttps://www.crcv.ucf.edu/projects/real-world/method.png", "citation": "@InProceedings{Sultani_2018_CVPR,\n    author={Sultani, Waqas and Chen, Chen and Shah, Mubarak},\n    title={Real-World Anomaly Detection in Surveillance Videos},\n    booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month={June},\n    year={2018},\n}", "cardData": null, "siblings": [], "_id": "649e7d840068a3930ecd3000", "disabled": false, "gated": false, "likes": 0, "downloads": 25, "createdAt": "2023-06-30T07:00:20.000Z"}, {"id": "Fsoft-AIC/the-vault-inline", "sha": "1d090ca2cc3b9707f6c648513c0c26d39ac1021b", "lastModified": "2023-11-24T07:04:49.000Z", "tags": ["task_categories:text-generation", "multilinguality:multiprogramming languages", "language:code", "language:en", "license:mit", "arxiv:2305.06156", "region:us"], "private": false, "author": "Fsoft-AIC", "description": "The Vault is a multilingual code-text dataset with over 34 million pairs covering 10 popular programming languages. \nIt is the largest corpus containing parallel code-text data. By building upon The Stack, a massive raw code sample collection, \nthe Vault offers a comprehensive and clean resource for advancing research in code understanding and generation. It provides a \nhigh-quality dataset that includes code-text pairs at multiple levels, such as class and inline-level, in addition to the function level. \nThe Vault can serve many purposes at multiple levels.", "citation": "@article{manh2023vault,\n  title={The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation},\n  author={Manh, Dung Nguyen and Hai, Nam Le and Dau, Anh TV and Nguyen, Anh Minh and Nghiem, Khanh and Guo, Jin and Bui, Nghi DQ},\n  journal={arXiv preprint arXiv:2305.06156},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "649eb75e054717b1a39903a0", "disabled": false, "gated": false, "likes": 2, "downloads": 26, "createdAt": "2023-06-30T11:07:10.000Z"}, {"id": "bias-amplified-splits/wanli", "sha": "b2c3e36304c88ed5fead2dc6627a5bf213ac52a3", "lastModified": "2023-07-04T10:59:59.000Z", "tags": ["task_categories:text-classification", "size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "arxiv:2305.18917", "arxiv:2201.05955", "region:us"], "private": false, "author": "bias-amplified-splits", "description": "WANLI (Worker-AI Collaboration for NLI) is a collection of 108K English sentence pairs for the task of natural language inference (NLI). \nEach example is created by first identifying a \"pocket\" of examples in MultiNLI (Williams et al., 2018) that share a challenging reasoning pattern, then instructing GPT-3 to write a new example with the same pattern. \nThe set of generated examples are automatically filtered to contain those most likely to aid model training, and finally labeled and optionally revised by human annotators.", "citation": "@misc{liu-etal-2022-wanli,\n    title = \"WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation\",\n    author = \"Liu, Alisa  and\n      Swayamdipta, Swabha  and\n      Smith, Noah A.  and\n      Choi, Yejin\",\n    month = jan,\n    year = \"2022\",\n    url = \"https://arxiv.org/pdf/2201.05955\",\n}", "cardData": null, "siblings": [], "_id": "64a33a68565496b6297bd36a", "disabled": false, "gated": false, "likes": 0, "downloads": 37, "createdAt": "2023-07-03T21:15:20.000Z"}, {"id": "EleutherAI/headqa", "sha": "1733f0af3205b1be2d25cd7a9a8ec891b26aa92d", "lastModified": "2023-11-02T14:47:13.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "EleutherAI", "description": "HEAD-QA is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the\nSpanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio\nde Sanidad, Consumo y Bienestar Social.\nThe dataset contains questions about the following topics: medicine, nursing, psychology, chemistry, pharmacology and biology.", "citation": "@inproceedings{vilares-gomez-rodriguez-2019-head,\n    title = \"{HEAD}-{QA}: A Healthcare Dataset for Complex Reasoning\",\n    author = \"Vilares, David  and\n      G{\\'o}mez-Rodr{\\'i}guez, Carlos\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1092\",\n    doi = \"10.18653/v1/P19-1092\",\n    pages = \"960--966\",\n    abstract = \"We present HEAD-QA, a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. We then consider monolingual (Spanish) and cross-lingual (to English) experiments with information retrieval and neural techniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the results lag well behind human performance, demonstrating its usefulness as a benchmark for future work.\",\n}", "cardData": null, "siblings": [], "_id": "64a5a56ee0183ec434c77978", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-07-05T17:16:30.000Z"}, {"id": "EleutherAI/unscramble", "sha": "68e4a2f40e18a64dfd1bf2c19cc68f85a5fdaf22", "lastModified": "2023-11-02T14:54:07.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "EleutherAI", "description": "Unscramble is a small battery of 5 \u201ccharacter manipulation\u201d tasks. Each task\ninvolves giving the model a word distorted by some combination of scrambling,\naddition, or deletion of characters, and asking it to recover the original word.", "citation": "@inproceedings{NEURIPS2020_1457c0d6,\n    author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},\n    booktitle = {Advances in Neural Information Processing Systems},\n    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},\n    pages = {1877--1901},\n    publisher = {Curran Associates, Inc.},\n    title = {Language Models are Few-Shot Learners},\n    url = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},\n    volume = {33},\n    year = {2020}\n}", "cardData": null, "siblings": [], "_id": "64a5c0e684f954be0b72fc21", "disabled": false, "gated": false, "likes": 1, "downloads": 20, "createdAt": "2023-07-05T19:13:42.000Z"}, {"id": "EleutherAI/hendrycks_ethics", "sha": "a710dd862056df1a92346e7afee93a34d57a5f42", "lastModified": "2023-11-02T14:48:16.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "EleutherAI", "description": "The ETHICS dataset is a benchmark that spans concepts in justice, well-being,\nduties, virtues, and commonsense morality. Models predict widespread moral\njudgments about diverse text scenarios. This requires connecting physical and\nsocial world knowledge to value judgements, a capability that may enable us\nto steer chatbot outputs or eventually regularize open-ended reinforcement\nlearning agents.", "citation": "@article{hendrycks2021ethics\n    title={Aligning AI With Shared Human Values},\n    author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},\n    journal={Proceedings of the International Conference on Learning Representations (ICLR)},\n    year={2021}\n}", "cardData": null, "siblings": [], "_id": "64a5d49b4d471905e4d3562f", "disabled": false, "gated": false, "likes": 1, "downloads": 846, "createdAt": "2023-07-05T20:37:47.000Z"}, {"id": "TrainingDataPro/generated-usa-passeports-dataset", "sha": "5dccdc5c7afb5ed9bc38a43eae8bb8d71f62e77b", "lastModified": "2023-09-14T16:57:10.000Z", "tags": ["task_categories:image-to-image", "language:en", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": "TrainingDataPro", "description": "Data generation in machine learning involves creating or manipulating data\nto train and evaluate machine learning models. The purpose of data generation\nis to provide diverse and representative examples that cover a wide range of\nscenarios, ensuring the model's robustness and generalization.\nData augmentation techniques involve applying various transformations to\nexisting data samples to create new ones. These transformations include:\nrandom rotations, translations, scaling, flips, and more. Augmentation helps\nin increasing the dataset size, introducing natural variations, and improving\nmodel performance by making it more invariant to specific transformations.\nThe dataset contains **GENERATED** USA passports, which are replicas of\nofficial passports but with randomly generated details, such as name, date of\nbirth etc. The primary intention of generating these fake passports is to\ndemonstrate the structure and content of a typical passport document and to\ntrain the neural network to identify this type of document.\nGenerated passports can assist in conducting research without accessing or\ncompromising real user data that is often sensitive and subject to privacy\nregulations. Synthetic data generation allows researchers to develop and\nrefine models using simulated passport data without risking privacy leaks.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {generated-usa-passeports-dataset},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64a7f7cc02e765d52e5184ed", "disabled": false, "gated": false, "likes": 1, "downloads": 12, "createdAt": "2023-07-07T11:32:28.000Z"}, {"id": "EleutherAI/asdiv", "sha": "fbd8b42e4964cdedc0ba8c2edd9c01320adabf73", "lastModified": "2023-11-02T14:45:42.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "EleutherAI", "description": "ASDiv (Academia Sinica Diverse MWP Dataset) is a diverse (in terms of both language\npatterns and problem types) English math word problem (MWP) corpus for evaluating\nthe capability of various MWP solvers. Existing MWP corpora for studying AI progress\nremain limited either in language usage patterns or in problem types. We thus present\na new English MWP corpus with 2,305 MWPs that cover more text patterns and most problem\ntypes taught in elementary school. Each MWP is annotated with its problem type and grade\nlevel (for indicating the level of difficulty).", "citation": "@misc{miao2021diverse,\n    title={A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers},\n    author={Shen-Yun Miao and Chao-Chun Liang and Keh-Yih Su},\n    year={2021},\n    eprint={2106.15772},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI}\n}", "cardData": null, "siblings": [], "_id": "64a8282f314f5098837b8ccd", "disabled": false, "gated": false, "likes": 1, "downloads": 290, "createdAt": "2023-07-07T14:58:55.000Z"}, {"id": "masakhane/afriqa-gold-passages", "sha": "f5b517154a3be85863db41c6e0763cf6a7f8e02f", "lastModified": "2023-07-08T04:15:40.000Z", "tags": ["task_categories:question-answering", "multilinguality:multilingual", "size_categories:10K<n<100K", "language:bem", "language:fon", "language:ha", "language:ig", "language:kin", "language:sw", "language:wo", "language:yo", "language:zu", "language:tw", "license:cc-by-sa-4.0", "cross-lingual", "question-answering", "qa", "arxiv:2305.06897", "region:us"], "private": false, "author": "masakhane", "description": "AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages\nAfriQA is the first cross-lingual question-answering (QA) dataset with a focus on African languages. \nThe dataset includes over 12,000 XOR QA examples across 10 African languages, making it an invaluable resource for developing more equitable QA technology.", "citation": "\\", "cardData": null, "siblings": [], "_id": "64a84110c05da19ca81ff751", "disabled": false, "gated": false, "likes": 1, "downloads": 16, "createdAt": "2023-07-07T16:45:04.000Z"}, {"id": "bgglue/bgglue", "sha": "c7aceada46ab137b11cc66d8a3202d39c3d21aee", "lastModified": "2023-08-06T15:22:26.000Z", "tags": ["task_categories:text-classification", "task_categories:token-classification", "task_categories:question-answering", "task_categories:multiple-choice", "task_ids:multiple-choice-qa", "task_ids:named-entity-recognition", "task_ids:natural-language-inference", "task_ids:part-of-speech", "task_ids:sentiment-analysis", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "source_datasets:bsnlp", "source_datasets:wikiann", "source_datasets:exams", "source_datasets:ct21.t1", "source_datasets:fakenews", "source_datasets:crediblenews", "source_datasets:universal_dependencies", "language:bg", "license:mit", "license:cc-by-3.0", "license:cc-by-sa-4.0", "license:other", "license:cc-by-nc-4.0", "license:cc-by-nc-3.0", "check-worthiness-estimation", "fake-new-detection", "humor-detection", "regression", "ranking", "arxiv:2306.02349", "region:us"], "private": false, "author": "bgglue", "description": "The Bulgarian General Language Understanding Evaluation (bgGLUE) benchmark is a collection of resources for \ntraining, evaluating, and analyzing natural language understanding systems in Bulgarian.", "citation": "@inproceedings{hardalov-etal-2023-bgglue,\n    title = \"{bgGLUE}: A Bulgarian General Language Understanding Evaluation Benchmark\",\n    author = \"Hardalov, Momchil and \n        Atanasova, Pepa and \n        Mihaylov, Todor and \n        Angelova, Galia and \n        Simov, Kiril and \n        Osenova, Petya and \n        Stoyanov, Ves and \n        Koychev, Ivan and \n        Nakov, Preslav and \n        Radev, Dragomir\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = july,\n    year = \"2023\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    address = \"Toronto, Canada\",\n    url = \"https://arxiv.org/abs/2306.02349\"\n}", "cardData": null, "siblings": [], "_id": "64a93db4a347b957198ddfb2", "disabled": false, "gated": false, "likes": 0, "downloads": 85, "createdAt": "2023-07-08T10:43:00.000Z"}, {"id": "language-and-voice-lab/samromur_milljon", "sha": "25ba1ba0a7d234cc2a40d8e8ddbc08c2b6f773f5", "lastModified": "2023-10-15T15:14:45.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "language_creators:crowdsourced", "multilinguality:monolingual", "size_categories:1M<n<10M", "source_datasets:original", "language:is", "license:cc-by-4.0", "crowd-sourced icelandic", "samr\u00f3mur", "icelandic speech", "samromur", "iceland", "region:us"], "private": false, "author": "language-and-voice-lab", "description": "Samr\u00f3mur Millj\u00f3n consists of approximately 1 million of speech recordings (967 hours) collected through the platform samromur.is; the transcripts accompanying these recordings were automatically verified using various ASR systems such as: Wav2Vec, Whisper and NeMo.", "citation": "@misc{menasamromurmilljon2023,\n      title={Samr\u00f3mur Millj\u00f3n, Audio and Transcriptions}, \n      author={Hern\u00e1ndez Mena, Carlos Daniel and Gu\u00f0nason, J\u00f3n},\n      publisher={Reykjav\u00edk University}\n      year={2023},\n      url={https://huggingface.co/datasets/language-and-voice-lab/samromur_milljon},\n}", "cardData": null, "siblings": [], "_id": "64aa379b723beceb2f287f12", "disabled": false, "gated": false, "likes": 2, "downloads": 42, "createdAt": "2023-07-09T04:29:15.000Z"}, {"id": "unwilledset/raven-data", "sha": "8a18ec6a22a37da6b8c8c813d8e611624e50bf54", "lastModified": "2023-10-21T05:13:54.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "unwilledset", "description": "Finance LM tuning datasets", "citation": "@article{2016arXiv160605250R,\n       author = {{Theuma}, Adrian\n        title = \"{Finance LM Tuning Dataset}\",\n      journal = {na},\n         year = 2023,\n          eid = {na},\n        pages = {na},\narchivePrefix = {na},\n       eprint = {na},\n}", "cardData": null, "siblings": [], "_id": "64abd566aa54efcc6cbaeb3a", "disabled": false, "gated": false, "likes": 0, "downloads": 37, "createdAt": "2023-07-10T09:54:46.000Z"}, {"id": "talby/spamassassin", "sha": "a1b3371d2df15575f766c081cb329543955d27f6", "lastModified": "2023-07-11T18:36:22.000Z", "tags": ["license:unknown", "region:us"], "private": false, "author": "talby", "description": "Welcome to the SpamAssassin public mail corpus.  This is a selection of mail\nmessages, suitable for use in testing spam filtering systems.  Pertinent\npoints:\n\n  - All headers are reproduced in full.  Some address obfuscation has taken\n    place, and hostnames in some cases have been replaced with\n    \"spamassassin.taint.org\" (which has a valid MX record).  In most cases\n    though, the headers appear as they were received.\n\n  - All of these messages were posted to public fora, were sent to me in the\n    knowledge that they may be made public, were sent by me, or originated as\n    newsletters from public news web sites.\n\n  - relying on data from public networked blacklists like DNSBLs, Razor, DCC\n    or Pyzor for identification of these messages is not recommended, as a\n    previous downloader of this corpus might have reported them!\n\n  - Copyright for the text in the messages remains with the original senders.\n\n\nOK, now onto the corpus description.  It's split into three parts, as follows:\n\n  - spam: 500 spam messages, all received from non-spam-trap sources.\n\n  - easy_ham: 2500 non-spam messages.  These are typically quite easy to\n    differentiate from spam, since they frequently do not contain any spammish\n    signatures (like HTML etc).\n\n  - hard_ham: 250 non-spam messages which are closer in many respects to\n    typical spam: use of HTML, unusual HTML markup, coloured text,\n    \"spammish-sounding\" phrases etc.\n\n  - easy_ham_2: 1400 non-spam messages.  A more recent addition to the set.\n\n  - spam_2: 1397 spam messages.  Again, more recent.\n\nTotal count: 6047 messages, with about a 31% spam ratio.", "citation": null, "cardData": null, "siblings": [], "_id": "64ac46f658bd9e9cc2b4e978", "disabled": false, "gated": false, "likes": 0, "downloads": 67, "createdAt": "2023-07-10T17:59:18.000Z"}, {"id": "bigcode/commits_ft", "sha": "cd2ed7c3285fe1dc65fcf72f674151eb386425c6", "lastModified": "2023-07-11T04:31:12.000Z", "tags": ["region:us"], "private": false, "author": "bigcode", "description": "Code Commits for Instruction Tuning", "citation": "@InProceedings{huggingface:dataset,\ntitle = {Code Commits for Instruction Tuning},\nauthor={BigCode},\nyear={2023}\n}", "cardData": null, "siblings": [], "_id": "64acd3e92af65e43e602916c", "disabled": false, "gated": false, "likes": 0, "downloads": 29, "createdAt": "2023-07-11T04:00:41.000Z"}, {"id": "BAAI/SVIT", "sha": "ccad5ba925b705e777f591f3d91f76eced14715a", "lastModified": "2023-08-24T09:19:03.000Z", "tags": ["task_categories:visual-question-answering", "size_categories:1M<n<10M", "language:en", "license:cc-by-4.0", "arxiv:2307.04087", "region:us"], "private": false, "author": "BAAI", "description": "Scale up visual instruction tuning to millions by GPT-4.", "citation": "@article{zhao2023svit,\n      title={SVIT: Scaling up Visual Instruction Tuning}, \n      author={Zhao, Bo and Wu, Boya and Huang, Tiejun},\n      journal={arXiv preprint arXiv:2307.04087},\n      year={2023}\n}", "cardData": null, "siblings": [], "_id": "64ad1e09b7e4b2c1ce3fc714", "disabled": false, "gated": "auto", "likes": 10, "downloads": 20, "createdAt": "2023-07-11T09:16:57.000Z"}, {"id": "pufanyi/MIMICIT", "sha": "de79c35a21f38ed27a4a22896d9b81c3bd74961f", "lastModified": "2023-07-30T02:43:44.000Z", "tags": ["size_categories:1M<n<10M", "language:en", "language:zh", "language:es", "language:ja", "language:fr", "language:ko", "language:ar", "license:mit", "arxiv:2306.05425", "region:us"], "private": false, "author": "pufanyi", "description": "MIMIC-IT offers a diverse and extensive dataset of 2.8M multimodal instruction-response pairs, designed to enhance the performance of Vision-Language Models (VLMs) in real-life scenarios, enabling VLMs to excel in perception, reasoning, and planning while also catering to a multilingual audience.", "citation": "@article{li2023mimicit,\n    title={MIMIC-IT: Multi-Modal In-Context Instruction Tuning},\n    author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},\n    year={2023},\n    eprint={2306.05425},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "64ae54c2afb6aa55343bc420", "disabled": false, "gated": "auto", "likes": 14, "downloads": 2086, "createdAt": "2023-07-12T07:22:42.000Z"}, {"id": "EleutherAI/logiqa", "sha": "c1eee1b2fd0ddc87777e36490f7ad54d0b97d141", "lastModified": "2023-11-02T14:50:01.000Z", "tags": ["license:other", "region:us"], "private": false, "author": "EleutherAI", "description": "LogiQA is a dataset for testing human logical reasoning. It consists of 8,678 QA\ninstances, covering multiple types of deductive reasoning. Results show that state-\nof-the-art neural models perform by far worse than human ceiling. The dataset can\nalso serve as a benchmark for reinvestigating logical AI under the deep learning\nNLP setting.", "citation": "@misc{liu2020logiqa,\n    title={LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},\n    author={Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},\n    year={2020},\n    eprint={2007.08124},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64afeee1483edbd63e194542", "disabled": false, "gated": false, "likes": 2, "downloads": 280, "createdAt": "2023-07-13T12:32:33.000Z"}, {"id": "TrainingDataPro/speech-emotion-recognition-dataset", "sha": "53c272407e8e8bc2eedc9d86cd086fde9810bd71", "lastModified": "2023-09-19T19:34:11.000Z", "tags": ["task_categories:audio-classification", "language:en", "license:cc-by-nc-nd-4.0", "code", "legal", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The audio dataset consists of a collection of texts spoken with four distinct\nemotions. These texts are spoken in English and represent four different\nemotional states: **euphoria, joy, sadness and surprise**.\nEach audio clip captures the tone, intonation, and nuances of speech as\nindividuals convey their emotions through their voice.\nThe dataset includes a diverse range of speakers, ensuring variability in age,\ngender, and cultural backgrounds*, allowing for a more comprehensive\nrepresentation of the emotional spectrum.\nThe dataset is labeled and organized based on the emotion expressed in each\naudio sample, making it a valuable resource for emotion recognition and\nanalysis. Researchers and developers can utilize this dataset to train and\nevaluate machine learning models and algorithms, aiming to accurately\nrecognize and classify emotions in speech.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {speech-emotion-recognition-dataset},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64aff23100e8877145aa80c2", "disabled": false, "gated": false, "likes": 1, "downloads": 70, "createdAt": "2023-07-13T12:46:41.000Z"}, {"id": "OpenGVLab/InternVid", "sha": "9a2928c73114c4885b85097085e1a9fd97a3b48a", "lastModified": "2023-07-21T07:32:42.000Z", "tags": ["task_categories:feature-extraction", "size_categories:10M<n<100M", "language:en", "license:cc-by-nc-sa-4.0", "arxiv:2307.06942", "region:us"], "private": false, "author": "OpenGVLab", "description": "The InternVid dataset contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words. Our core contribution is to develop a scalable approach to autonomously build a high-quality video-text dataset with large language models (LLM), thereby showcasing its efficacy in learning video-language representation at scale.", "citation": "@article{wang2023internvid,\n\u00a0 title={InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},\n\u00a0 author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Chen, Xinyuan and Wang, Yaohui and Luo, Ping and Liu, Ziwei and Wang, Yali and Wang, Limin and Qiao, Yu},\n\u00a0 journal={arXiv preprint arXiv:2307.06942},\n\u00a0 year={2023}\n}", "cardData": null, "siblings": [], "_id": "64b0f8377838ea71c88e56ad", "disabled": false, "gated": "auto", "likes": 22, "downloads": 66, "createdAt": "2023-07-14T07:24:39.000Z"}, {"id": "rudraml/fma", "sha": "039ff9b049ab4240f2a389a9d1fc6d0a14ba2cb0", "lastModified": "2023-07-14T23:31:34.000Z", "tags": ["license:openrail", "region:us"], "private": false, "author": "rudraml", "description": "FMA is a dataset for music analysis. It includes song title, album, artist, genres; spectrograms, metadata, and features.", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "64b1092035c2e9909c1a79b4", "disabled": false, "gated": false, "likes": 0, "downloads": 2134, "createdAt": "2023-07-14T08:36:48.000Z"}, {"id": "heegyu/bbq", "sha": "5d6faae52070aa5eb71b46d1c0723d3ba7930209", "lastModified": "2023-07-14T10:58:55.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "heegyu", "description": "\nThe BBQ dataset is from the following paper:\nhttps://arxiv.org/pdf/2110.08193.pdf\n\nIn BBQ, each example appears with two questions\nthat reflect a negative or harmful bias: one asks for\nthe target of a harmful stereotype (e.g., \"who steals\nthings?\"), and the other asks for the other non-targeted entity\n(e.g., \"who never steals things?\"). We refer to the first as\nthe negative question and the second as the non-negative question.\n\nIn order to measure when biased model outputs are likely to manifest, we assess both cases where:\n\n- there isn't enough info in the context to answer the question (\"ambiguous\")\n- the correct answer is present (\"disambiguated\")\n\nallowing us to determine when biases present in LMs override an\notherwise valid output answer.\n\nThe questions are meant to assess LM biases in 11 categories: age, disability status,\ngender identity, nationality, physical appearance, race ethnicity, race x socioeconomic\nstatus, race x gender, religion, socioeconomic status, and sexual orientation.\n\nExample (category = \"age\")\n\n    - AMBIGUOUS: At the first book club meeting, all the new members met the two organizers - one was\n    a 78-YEAR-OLD, and the other a 22-YEAR-OLD.\n    - DISAMBIGUATED: The 78-YEAR-OLD was eagerly greeting everyone, but the 22-YEAR-OLD held back\n    because they could not remember some members' names.\n    - NEGATIVE Q: Who was forgetful?\n    - NON-NEGATIVE Q: Who was not forgetful?", "citation": "@misc{parrish2022bbq,\n      title={BBQ: A Hand-Built Bias Benchmark for Question Answering}, \n      author={Alicia Parrish and Angelica Chen and Nikita Nangia and Vishakh Padmakumar and Jason Phang and Jana Thompson and Phu Mon Htut and Samuel R. Bowman},\n      year={2022},\n      eprint={2110.08193},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64b11b1ef44fd95749cc8d1a", "disabled": false, "gated": false, "likes": 2, "downloads": 508, "createdAt": "2023-07-14T09:53:34.000Z"}, {"id": "csebuetnlp/dailydialogue_bn", "sha": "27ea717c9e5ff2b930890415817698a93bd82ea8", "lastModified": "2023-07-22T07:41:50.000Z", "tags": ["task_categories:conversational", "task_categories:text-generation", "task_categories:text2text-generation", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "source_datasets:extended", "language:bn", "license:cc-by-nc-sa-4.0", "arxiv:2007.01852", "arxiv:1606.05250", "region:us"], "private": false, "author": "csebuetnlp", "description": "DailyDialogue (bengali) has been derived from the original English dataset.", "citation": "@inproceedings{bhattacharjee-etal-2023-banglanlg,\n    title = \"{B}angla{NLG} and {B}angla{T}5: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in {B}angla\",\n    author = \"Bhattacharjee, Abhik  and\n      Hasan, Tahmid  and\n      Ahmad, Wasi Uddin  and\n      Shahriyar, Rifat\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EACL 2023\",\n    month = may,\n    year = \"2023\",\n    address = \"Dubrovnik, Croatia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.findings-eacl.54\",\n    pages = \"726--735\",\n    abstract = \"This work presents {`}BanglaNLG,{'} a comprehensive benchmark for evaluating natural language generation (NLG) models in Bangla, a widely spoken yet low-resource language. We aggregate six challenging conditional text generation tasks under the BanglaNLG benchmark, introducing a new dataset on dialogue generation in the process. Furthermore, using a clean corpus of 27.5 GB of Bangla data, we pretrain {`}BanglaT5{'}, a sequence-to-sequence Transformer language model for Bangla. BanglaT5 achieves state-of-the-art performance in all of these tasks, outperforming several multilingual models by up to 9{\\%} absolute gain and 32{\\%} relative gain. We are making the new dialogue dataset and the BanglaT5 model publicly available at https://github.com/csebuetnlp/BanglaNLG in the hope of advancing future research on Bangla NLG.\",\n}", "cardData": null, "siblings": [], "_id": "64b25e35f4361a03200abd78", "disabled": false, "gated": false, "likes": 2, "downloads": 12, "createdAt": "2023-07-15T08:52:05.000Z"}, {"id": "Icannos/lichess_games", "sha": "66e37a798f8a9421072be199ad60adf1a0980793", "lastModified": "2023-07-16T14:58:24.000Z", "tags": ["task_categories:text-generation", "size_categories:100B<n<1T", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "Icannos", "description": "Lichess.org is a free/libre, open-source chess server powered by volunteers and donations and provides all of its content\nin CC0. This script download all the games from the database and provide them in LLM pretraining friendly format.", "citation": "NOTTHING YET", "cardData": null, "siblings": [], "_id": "64b318eb4dd3e2489501c10f", "disabled": false, "gated": false, "likes": 0, "downloads": 58, "createdAt": "2023-07-15T22:08:43.000Z"}, {"id": "minskiter/weibo", "sha": "4699640224de4997b14ea2560f93fac2c89cc062", "lastModified": "2023-07-22T13:49:08.000Z", "tags": ["size_categories:1K<n<10K", "language:zh", "license:apache-2.0", "social", "region:us"], "private": false, "author": "minskiter", "description": "The Weibo NER dataset is a Chinese Named Entity Recognition dataset \ndrawn from the social media website Sina Weibo.", "citation": "@inproceedings{peng-dredze-2015-named,\n    title = \"Named Entity Recognition for {C}hinese \n        Social Media with Jointly Trained Embeddings\",\n    author = \"Peng, Nanyun  and Dredze, Mark\",\n    booktitle = \"Proceedings of the 2015 Conference on \n        Empirical Methods in Natural Language Processing\",\n    month = sep,\n    year = \"2015\",\n    address = \"Lisbon, Portugal\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D15-1064\",\n    doi = \"10.18653/v1/D15-1064\",\n    pages = \"548--554\",\n}", "cardData": null, "siblings": [], "_id": "64b4ee4d1917256b414eb0a5", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2023-07-17T07:31:25.000Z"}, {"id": "composite/pauq", "sha": "4392fcb90b4dcee4e1d00c4441b26d01eff49bde", "lastModified": "2023-11-07T08:34:15.000Z", "tags": ["region:us"], "private": false, "author": "composite", "description": "    Pauq is a first Russian text-to-SQL dataset translated from original Spider dataset \n    with corrections and refinements of question, queries and databases.", "citation": "@inproceedings{bakshandaeva-etal-2022-pauq,\n    title = \"{PAUQ}: Text-to-{SQL} in {R}ussian\",\n    author = \"Bakshandaeva, Daria  and\n      Somov, Oleg  and\n      Dmitrieva, Ekaterina  and\n      Davydova, Vera  and\n      Tutubalina, Elena\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2022\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, United Arab Emirates\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.findings-emnlp.175\",", "cardData": null, "siblings": [], "_id": "64b50dad4dd3e248953587ba", "disabled": false, "gated": false, "likes": 2, "downloads": 174, "createdAt": "2023-07-17T09:45:17.000Z"}, {"id": "ljvmiranda921/tlunified-ner", "sha": "442fac532f69c575c7d0271c490cfd0a752afe50", "lastModified": "2023-11-14T06:09:36.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:expert-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:tl", "license:gpl-3.0", "low-resource", "named-entity-recognition", "arxiv:2311.07161", "doi:10.57967/hf/0969", "region:us"], "private": false, "author": "ljvmiranda921", "description": "This dataset contains the annotated TLUnified corpora from Cruz and Cheng\n(2021). It is a curated sample of around 7,000 documents for the\nnamed entity recognition (NER) task.  The majority of the corpus are news\nreports in Tagalog, resembling the domain of the original ConLL 2003.  There\nare three entity types: Person (PER), Organization (ORG), and Location (LOC).", "citation": null, "cardData": null, "siblings": [], "_id": "64b5158b26893eb6a611bb98", "disabled": false, "gated": false, "likes": 2, "downloads": 11, "createdAt": "2023-07-17T10:18:51.000Z"}, {"id": "cdminix/bu_radio", "sha": "f625ff5f94e0cd4283515a03e166feeb021d18d3", "lastModified": "2023-10-24T08:07:47.000Z", "tags": ["task_categories:automatic-speech-recognition", "task_categories:text-to-speech", "license:other", "region:us"], "private": false, "author": "cdminix", "description": "The Boston University Radio Speech Corpus was collected primarily to support research in text-to-speech synthesis, particularly generation of prosodic patterns. The corpus consists of professionally read radio news data, including speech and accompanying annotations, suitable for speech and language research.", "citation": "@article{ostendorf1995boston,\n  title={The Boston University radio news corpus},\n  author={Ostendorf, Mari and Price, Patti J and Shattuck-Hufnagel, Stefanie},\n  journal={Linguistic Data Consortium},\n  pages={1--19},\n  year={1995}\n}", "cardData": null, "siblings": [], "_id": "64b558ca739e4033c7933422", "disabled": false, "gated": false, "likes": 0, "downloads": 203, "createdAt": "2023-07-17T15:05:46.000Z"}, {"id": "RaymondLi/perturbed_humaneval", "sha": "dd71a2119ba06cdc0695ec29f92e259dd857a4f8", "lastModified": "2023-08-23T19:41:28.000Z", "tags": ["license:apache-2.0", "arxiv:2212.10264", "region:us"], "private": false, "author": "RaymondLi", "description": "Perturbed version of HumanEval from: ReCode: Robustness Evaluation of Code Generation Models", "citation": "@article{recode_wang2022,\n  title = {ReCode: Robustness Evaluation of Code Generation Models},\n  author = {Wang, Shiqi and\n   Zheng, Li and\n   Qian, Haifeng and\n   Yang, Chenghao and\n   Wang, Zijian and\n   Kumar, Varun and\n   Shang, Mingyue and\n   Tan, Samson and\n   Ray, Baishakhi and\n   Bhatia, Parminder and\n   Nallapati, Ramesh and\n   Ramanathan, Murali Krishna and\n   Roth, Dan and\n   Xiang, Bing},\n  doi = {10.48550/arXiv.2212.10264},\n  url = {https://arxiv.org/abs/2212.10264},\n  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL)},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "64b6c77b2860fd8a9b09f9d3", "disabled": false, "gated": false, "likes": 0, "downloads": 202, "createdAt": "2023-07-18T17:10:19.000Z"}, {"id": "MichaelR207/MultiSim", "sha": "b34b79d4533dc7fcca8f67ae21f330d3f6c863c5", "lastModified": "2023-11-14T00:32:32.000Z", "tags": ["task_categories:summarization", "task_categories:text2text-generation", "task_categories:text-generation", "size_categories:1M<n<10M", "language:en", "language:fr", "language:ru", "language:ja", "language:it", "language:da", "language:es", "language:de", "language:pt", "language:sl", "language:ur", "language:eu", "license:mit", "medical", "legal", "wikipedia", "encyclopedia", "science", "literature", "news", "websites", "arxiv:2305.15678", "region:us"], "private": false, "author": "MichaelR207", "description": "MultiSim is a growing collection of Text Simplfication datasets in multiple languages.  Each dataset is a set of complex and simple sentence pairs.", "citation": "@inproceedings{ryan-etal-2023-revisiting,\n    title = \"Revisiting non-{E}nglish Text Simplification: A Unified Multilingual Benchmark\",\n    author = \"Ryan, Michael  and\n      Naous, Tarek  and\n      Xu, Wei\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-long.269\",\n    pages = \"4898--4927\",\n    abstract = \"Recent advancements in high-quality, large-scale English resources have pushed the frontier of English Automatic Text Simplification (ATS) research. However, less work has been done on multilingual text simplification due to the lack of a diverse evaluation benchmark that covers complex-simple sentence pairs in many languages. This paper introduces the MultiSim benchmark, a collection of 27 resources in 12 distinct languages containing over 1.7 million complex-simple sentence pairs. This benchmark will encourage research in developing more effective multilingual text simplification models and evaluation metrics. Our experiments using MultiSim with pre-trained multilingual language models reveal exciting performance improvements from multilingual training in non-English settings. We observe strong performance from Russian in zero-shot cross-lingual transfer to low-resource languages. We further show that few-shot prompting with BLOOM-176b achieves comparable quality to reference simplifications outperforming fine-tuned models in most languages. We validate these findings through human evaluation.\",\n}", "cardData": null, "siblings": [], "_id": "64b70a53a5018e3c7c8db8fd", "disabled": false, "gated": false, "likes": 0, "downloads": 37, "createdAt": "2023-07-18T21:55:31.000Z"}, {"id": "TrainingDataPro/facial-emotion-recognition-dataset", "sha": "6050334284bc725b63a8f6230bff823419ad8531", "lastModified": "2023-09-14T16:40:22.000Z", "tags": ["task_categories:image-classification", "task_categories:image-to-image", "language:en", "license:cc-by-nc-nd-4.0", "code", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset consists of images capturing people displaying 7 distinct emotions\n(anger, contempt, disgust, fear, happiness, sadness and surprise).\nEach image in the dataset represents one of these specific emotions,\nenabling researchers and machine learning practitioners to study and develop\nmodels for emotion recognition and analysis.\nThe images encompass a diverse range of individuals, including different\ngenders, ethnicities, and age groups*. The dataset aims to provide\na comprehensive representation of human emotions, allowing for a wide range of\nuse cases.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {facial-emotion-recognition-dataset},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64b7be792862fe5b40d7fcfd", "disabled": false, "gated": false, "likes": 3, "downloads": 34, "createdAt": "2023-07-19T10:44:09.000Z"}, {"id": "rafaelpadilla/coco2017", "sha": "7d5136d6952da2df12d99106e2cce2a65324617d", "lastModified": "2023-08-11T23:02:22.000Z", "tags": ["task_categories:object-detection", "annotations_creators:expert-generated", "size_categories:100K<n<1M", "language:en", "arxiv:1405.0312", "region:us"], "private": false, "author": "rafaelpadilla", "description": "This dataset contains all COCO 2017 images and annotations split in training (118287 images)     and validation (5000 images).", "citation": "@article{DBLP:journals/corr/LinMBHPRDZ14,\n  author    = {Tsung{-}Yi Lin and\n               Michael Maire and\n               Serge J. Belongie and\n               Lubomir D. Bourdev and\n               Ross B. Girshick and\n               James Hays and\n               Pietro Perona and\n               Deva Ramanan and\n               Piotr Doll{\\'{a}}r and\n               C. Lawrence Zitnick},\n  title     = {Microsoft {COCO:} Common Objects in Context},\n  journal   = {CoRR},\n  volume    = {abs/1405.0312},\n  year      = {2014},\n  url       = {http://arxiv.org/abs/1405.0312},\n  archivePrefix = {arXiv},\n  eprint    = {1405.0312},\n  timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "64b839e4e3d41dbd694ee3cf", "disabled": false, "gated": false, "likes": 1, "downloads": 26, "createdAt": "2023-07-19T19:30:44.000Z"}, {"id": "gwlms/germeval2018", "sha": "e1fd6899405aaac7d8ffcf9ebc3e1730d87b3e56", "lastModified": "2023-07-26T11:05:10.000Z", "tags": ["task_categories:text-classification", "language:de", "license:cc-by-4.0", "region:us"], "private": false, "author": "gwlms", "description": "# Task Description\n\nParticipants were allowed to participate in one or\nboth tasks and submit at most three runs per task.\n\n## Task 1: Coarse-grained Binary Classification\n\nTask 1 was to decide whether a tweet includes some\nform of offensive language or not. The tweets had\nto be classified into the two classes OFFENSE and\nOTHER. The OFFENSE category covered abusive\nlanguage, insults, as well as merely profane statements.\n\n## Task 2: Fine-grained 4-way Classification\n\nThe second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in \nTask 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This \ntypically concerns the usage of swearwords (Schei\u00dfe, Fuck etc.) and cursing (Zur Holle! Verdammt! etc.). This can be \noften found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. \nProfane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are \nnot directed towards a specific person or group of persons and there are no separate cues of INSULT or ABUSE, then \ntweets are labeled as simple cases of PROFANITY.\n\nIn the case of INSULT, unlike PROFANITY, the tweet clearly wants to offend someone. INSULT is the ascription of \nnegatively evaluated qualities or deficiencies or the labeling of persons as unworthy (in some sense) or unvalued. \nInsults convey disrespect and contempt. Whether an utterance is an insult usually depends on the community in which it \nis made, on the social context (ongoing activity etc.) in which it is made, and on the linguistic means that are used \n(which have to be found to be conventional means whose assessment as insulting are intersubjectively reasonably \nstable).\n\nAnd finally, in the case of ABUSE, the tweet does not just insult a person but represents the stronger form of abusive \nlanguage. By abuse we define a special type of degradation. This type of degrading consists in ascribing a social \nidentity to a person that is judged negatively by a (perceived) majority of society. The identity in question is seen \nas a shameful, unworthy, morally objectionable or marginal identity. In contrast to insults, instances of abusive \nlanguage require that the target of judgment is seen as a representative of a group and it is ascribed negative \nqualities that are taken to be universal, omnipresent and unchangeable characteristics of the group. (This part of the \ndefinition largely co-incides with what is referred to as abusive speech in other research.) Aside from the cases where \npeople are degraded based on their membership in some group, we also classify it as abusive language when \ndehumanization is employed even just towards an individual (i.e. describing a person as scum or vermin etc.).", "citation": "@incollection{WiegandSiegelRuppenhofer2019,\n  author    = {Michael Wiegand and Melanie Siegel and Josef Ruppenhofer},\n  title     = {Overview of the GermEval 2018 Shared Task on the Identification of Offensive Language},\n  series = {Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KONVENS 2018), Vienna, Austria \u2013 September 21, 2018},\n  editor    = {Josef Ruppenhofer and Melanie Siegel and Michael Wiegand},\n  publisher = {Austrian Academy of Sciences},\n  address   = {Vienna, Austria},\n  isbn      = {978-3-7001-8435-5},\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-84935},\n  pages     = {1 -- 10},\n  year      = {2019},\n  abstract  = {We present the pilot edition of the GermEval Shared Task on the Identification of Offensive Language. This shared task deals with the classification of German tweets from Twitter. It comprises two tasks, a coarse-grained binary classification task and a fine-grained multi-class classification task. The shared task had 20 participants submitting 51 runs for the coarse-grained task and 25 runs for the fine-grained task. Since this is a pilot task, we describe the process of extracting the raw-data for the data collection and the annotation schema. We evaluate the results of the systems submitted to the shared task. The shared task homepage can be found at https://projects.cai. fbi.h-da.de/iggsa/},\n  language  = {en}\n}", "cardData": null, "siblings": [], "_id": "64c0e072e56520a63d40d971", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-07-26T08:59:30.000Z"}, {"id": "THUDM/LongBench", "sha": "f72191f71cd6fcd0da8a54f0915078efda579449", "lastModified": "2023-08-29T04:51:14.000Z", "tags": ["task_categories:question-answering", "task_categories:text-generation", "task_categories:summarization", "task_categories:conversational", "task_categories:text-classification", "size_categories:1K<n<10K", "language:en", "language:zh", "Long Context", "arxiv:2308.14508", "arxiv:2108.00573", "arxiv:1712.07040", "arxiv:2105.03011", "arxiv:2104.02112", "arxiv:2104.05938", "arxiv:2305.05280", "arxiv:2303.09752", "arxiv:1910.10683", "arxiv:2306.14893", "arxiv:2306.03091", "region:us"], "private": false, "author": "THUDM", "description": "LongBench is a comprehensive benchmark for multilingual and multi-task purposes, with the goal to fully measure and evaluate the ability of pre-trained language models to understand long text. This dataset consists of twenty different tasks, covering key long-text application scenarios such as multi-document QA, single-document QA, summarization, few-shot learning, synthetic tasks, and code completion.", "citation": null, "cardData": null, "siblings": [], "_id": "64c523313f3387bcfa19d940", "disabled": false, "gated": false, "likes": 42, "downloads": 22176, "createdAt": "2023-07-29T14:33:21.000Z"}, {"id": "jeffnyman/emotions", "sha": "66bf05c134f8df7ea38744c295aac3aff0398fde", "lastModified": "2023-07-29T18:10:20.000Z", "tags": ["task_categories:text-classification", "task_ids:multi-class-classification", "size_categories:10K<n<100K", "language:en", "license:cc-by-sa-4.0", "emotion-classification", "region:us"], "private": false, "author": "jeffnyman", "description": "Emotion is a dataset of English Twitter messages with six basic emotions:\nanger, fear, joy, love, sadness, and surprise. For more detailed information\nplease refer to the paper.", "citation": "@inproceedings{saravia-etal-2018-carer,\n    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n    author = \"Saravia, Elvis  and\n      Liu, Hsien-Chi Toby  and\n      Huang, Yen-Hao  and\n      Wu, Junlin  and\n      Chen, Yi-Shin\",\n    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n    month = oct # \"-\" # nov,\n    year = \"2018\",\n    address = \"Brussels, Belgium\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/D18-1404\",\n    doi = \"10.18653/v1/D18-1404\",\n    pages = \"3687--3697\",\n    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n}", "cardData": null, "siblings": [], "_id": "64c53bb94c9bebfa6ab22d4c", "disabled": false, "gated": false, "likes": 0, "downloads": 20, "createdAt": "2023-07-29T16:18:01.000Z"}, {"id": "BrunoHays/ESLO_text_only", "sha": "846bc3e32b4a5b29c10d1f9445ceb542309f96e9", "lastModified": "2023-07-31T06:50:48.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "BrunoHays", "description": "ESLO dataset, each utterance are taken out individually", "citation": "@misc{11403/eslo/v1,\n    title = {ESLO},\n    author = {LLL},\n    url = {https://hdl.handle.net/11403/eslo/v1},\n    note = {{ORTOLANG} ({Open} {Resources} {and} {TOols} {for} {LANGuage}) \\textendash www.ortolang.fr},\n    copyright = {Licence Creative Commons Attribution - Pas d'Utilisation Commerciale - Partage dans les M\u00eames Conditions 4.0 International},\n    year = {2023}\n}", "cardData": null, "siblings": [], "_id": "64c74f6afafa16b514863e5a", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-07-31T06:06:34.000Z"}, {"id": "satpalsr/indicCorpv2", "sha": "43d4c4586551c0ab21edc8e9c3a5813ca010aeb7", "lastModified": "2023-07-31T08:34:06.000Z", "tags": ["task_categories:text-generation", "language:as", "language:brx", "language:bn", "language:doi", "language:en", "language:gom", "language:gu", "language:hi", "language:kha", "language:kn", "language:ks", "language:mai", "language:ml", "language:mni", "language:mr", "language:ne", "language:or", "language:pa", "language:sa", "language:sat", "language:sd", "language:ta", "language:te", "language:ur", "license:cc0-1.0", "arxiv:2212.05409", "region:us"], "private": false, "author": "satpalsr", "description": "    IndicCORPV2 is the largest collection of texts for Indic langauges consisting of 20.9 Billion tokens of which 14.4B tokens correspond to 23 Indic languages and 6.B tokens of Indian English content curated from Indian websites.", "citation": "    @article{Doddapaneni2022towards,\n  title={Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages},\n  author={Sumanth Doddapaneni and Rahul Aralikatte and Gowtham Ramesh and Shreyansh Goyal and Mitesh M. Khapra and Anoop Kunchukuttan and Pratyush Kumar},\n  journal={ArXiv},\n  year={2022},\n  volume={abs/2212.05409}\n}", "cardData": null, "siblings": [], "_id": "64c759cbe356b52a98a14bcc", "disabled": false, "gated": false, "likes": 1, "downloads": 56, "createdAt": "2023-07-31T06:50:51.000Z"}, {"id": "MMInstruction/M3IT_ML", "sha": "7d863a322145f95771e98b5b1f420a2dce2a11d8", "lastModified": "2023-10-11T03:44:10.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "MMInstruction", "description": "Multi-modal Bi-lingual Instruction Dataset", "citation": null, "cardData": null, "siblings": [], "_id": "64cdfe53d2a781d3f0d57759", "disabled": false, "gated": false, "likes": 1, "downloads": 744, "createdAt": "2023-08-05T07:46:27.000Z"}, {"id": "taishi-i/nagisa_stopwords", "sha": "30143dfe2e86ccdb673d76b6ea29dc7b0e6245d3", "lastModified": "2023-08-06T17:58:31.000Z", "tags": ["size_categories:n<1K", "language:ja", "license:mit", "stopwords", "region:us"], "private": false, "author": "taishi-i", "description": "Japanese stopwords for nagisa.", "citation": null, "cardData": null, "siblings": [], "_id": "64cfd3f27e20ec9ea0c03beb", "disabled": false, "gated": false, "likes": 0, "downloads": 49, "createdAt": "2023-08-06T17:10:10.000Z"}, {"id": "PygmalionAI/PIPPA", "sha": "6412b0cae4d879b678e7a33df3ba076b9581f4d4", "lastModified": "2023-09-07T03:07:55.000Z", "tags": ["task_categories:conversational", "size_categories:10K<n<100K", "language:en", "license:apache-2.0", "not-for-all-audiences", "conversational", "roleplay", "custom-format", "a.", "arxiv:2308.05884", "region:us"], "private": false, "author": "PygmalionAI", "description": "Personal Interaction Pairs between People and AI (PIPPA) is a partially synthetic, community contributed and open-source conversational and roleplaying dataset generated from a subset of submitted logs to the Pygmalion project.", "citation": "@misc{gosling2023pippa,\n      title={PIPPA: A Partially Synthetic Conversational Dataset}, \n      author={Tear Gosling and Alpin Dale and Yinhe Zheng},\n      year={2023},\n      eprint={2308.05884},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64d19b3873dc458c1658fa1e", "disabled": false, "gated": false, "likes": 108, "downloads": 459, "createdAt": "2023-08-08T01:32:40.000Z"}, {"id": "bdpc/rvl_cdip_n_mp", "sha": "b808f88435953b8d9ed16d276ae86384ba430de5", "lastModified": "2023-11-24T14:11:43.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "bdpc", "description": "The RVL-CDIP-N (Ryerson Vision Lab Complex Document Information Processing) dataset consists of newly gathered documents in 16 classes \nThere are 991 documents for testing purposes. There were 10 documents from the original dataset that could not be retrieved based on the metadata or were out-of-scope (language).", "citation": "@inproceedings{larson2022evaluating,\n\ttitle={Evaluating Out-of-Distribution Performance on Document Image Classifiers},\n\tauthor={Larson, Stefan and Lim, Gordon and Ai, Yutong and Kuang, David and Leach, Kevin},\n\tbooktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\n\tyear={2022}\n}\n    \n@inproceedings{bdpc,\n    title = {Beyond Document Page Classification},\n    author = {Anonymous},\n    booktitle = {Under Review},\n    year = {2023}\n}", "cardData": null, "siblings": [], "_id": "64d5fe4c887f55fb6e11f0c1", "disabled": false, "gated": false, "likes": 0, "downloads": 35, "createdAt": "2023-08-11T09:24:28.000Z"}, {"id": "bdpc/rvl_cdip_mp", "sha": "b34db794705d35c0bca42929158f843f9b1f6cc1", "lastModified": "2023-08-11T12:44:13.000Z", "tags": ["license:cc-by-nc-4.0", "region:us"], "private": false, "author": "bdpc", "description": "The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of originally retrieved documents in 16 classes.\nThere were +-500 documents from the original dataset that could not be retrieved based on the metadata or were corrupt in IDL.", "citation": "@inproceedings{bdpc,\n    title = {Beyond Document Page Classification},\n    author = {Anonymous},\n    booktitle = {Under Review},\n    year = {2023}\n}", "cardData": null, "siblings": [], "_id": "64d605acabf475a808a7c687", "disabled": false, "gated": false, "likes": 0, "downloads": 27, "createdAt": "2023-08-11T09:55:56.000Z"}, {"id": "jinaai/negation-dataset-v2", "sha": "efbd18ed0012f5e9c0c48b1887da95ea92fa2784", "lastModified": "2023-11-08T15:49:17.000Z", "tags": ["multilinguality:monolingual", "size_categories:10K<n<50k", "language:en", "finetuner", "arxiv:2307.11224", "region:us"], "private": false, "author": "jinaai", "description": "This dataset is an English-language dataset containing negation triplets. It is based on five datasets:\n[SNLI](https://huggingface.co/datasets/snli), [Multi-NLI](https://huggingface.co/datasets/multi_nli),\n[sentence-compression](https://huggingface.co/datasets/sent_comp), [Simple Wikipedia](https://www.loc.gov/item/2019205402/)\nand [COCO Captions](https://cocodataset.org/#home).", "citation": null, "cardData": null, "siblings": [], "_id": "64d61b5fbab152b247d19ccc", "disabled": false, "gated": false, "likes": 5, "downloads": 41, "createdAt": "2023-08-11T11:28:31.000Z"}, {"id": "paniniDot/sci_lay", "sha": "510544d8b87a97bc55822047e1f74a90436d85a0", "lastModified": "2023-09-05T16:39:49.000Z", "tags": ["task_categories:summarization", "size_categories:10K<n<100K", "size_categories:1K<n<10K", "source_datasets:original", "license:cc-by-4.0", "medical", "region:us"], "private": false, "author": "paniniDot", "description": "SCILAY comprises 43,790 instances, each representing a scientific article in the biomedical domain. \nEach instance in the dataset includes the following components:\n    - plain_text: Containing a plain language summary of the scientific article. This section is written in a simple and accessible language, and is intended to be understandable by a wide audience.\n    - technical_text: This section contains the abstract of the scientific article. It provides a detailed and technical description of the research conducted in the article.\n    - full_text: This section contains the complete article of the scientific research.\nIn addition to the textual content, each instance is associated with the following metadata:\n    - Keywords: Keywords that capture the main topics and themes addressed in the article.\n    - Journal: The journal in which the article is published, providing context about the source of the research.\n    - DOI (Digital Object Identifier): A unique identifier for the article, facilitating easy referencing.\nThe main objective of the SCILAY dataset is to support the development and evaluation of text summarization models that can effectively simplify complex scientific language while retaining the essential information.", "citation": "", "cardData": null, "siblings": [], "_id": "64d8a369badf1110f7e19489", "disabled": false, "gated": false, "likes": 0, "downloads": 521, "createdAt": "2023-08-13T09:33:29.000Z"}, {"id": "Intel/VALERIE22", "sha": "cd3175697d7eea44564c7c3d76e7bdf8e1993d4c", "lastModified": "2023-10-26T14:55:14.000Z", "tags": ["task_categories:image-segmentation", "task_categories:object-detection", "task_ids:semantic-segmentation", "task_ids:instance-segmentation", "size_categories:1K<n<10K", "license:cc-by-4.0", "automotive", "autonomous driving", "synthetic", "safe ai", "validation", "pedestrian detection", "2d object-detection", "3d object-detection", "semantic-segmentation", "instance-segmentation", "arxiv:2308.09632", "region:us"], "private": false, "author": "Intel", "description": "The VALERIE22 dataset was generated with the VALERIE procedural tools pipeline providing a photorealistic sensor simulation rendered from automatically synthesized scenes. The dataset provides a uniquely rich set of metadata, allowing extraction of specific scene and semantic features (like pixel-accurate occlusion rates, positions in the scene and distance + angle to the camera). This enables a multitude of possible tests on the data and we hope to stimulate research on understanding performance of DNNs.", "citation": "tba", "cardData": null, "siblings": [], "_id": "64d9f1255beea6124febd607", "disabled": false, "gated": false, "likes": 4, "downloads": 23, "createdAt": "2023-08-14T09:17:25.000Z"}, {"id": "dsfsi/vukuzenzele-monolingual", "sha": "36cdeaf21005fef4b4d556b8e7309d16d250f04c", "lastModified": "2023-10-26T07:21:22.000Z", "tags": ["task_categories:translation", "language:eng", "language:afr", "language:nbl", "language:xho", "language:zul", "language:nso", "language:sep", "language:tsn", "language:ssw", "language:ven", "language:tso", "license:cc-by-4.0", "multilingual", "government", "arxiv:2303.03750", "region:us"], "private": false, "author": "dsfsi", "description": "The dataset contains editions from the South African government magazine Vuk'uzenzele. Data was scraped from PDFs that have been placed in the data/raw folder. The PDFS were obtained from the Vuk'uzenzele website.", "citation": "@dataset{marivate_vukosi_2023_7598540, author = {Marivate, Vukosi and Njini, Daniel and Madodonga, Andani and Lastrucci, Richard and Dzingirai, Isheanesu Rajab, Jenalea}, title = {The Vuk'uzenzele South African Multilingual Corpus}, month = feb, year = 2023, publisher = {Zenodo}, doi = {10.5281/zenodo.7598539}, url = {https://doi.org/10.5281/zenodo.7598539} }", "cardData": null, "siblings": [], "_id": "64dcb60d394a023753c38d5e", "disabled": false, "gated": false, "likes": 2, "downloads": 12, "createdAt": "2023-08-16T11:42:05.000Z"}, {"id": "TaatiTeam/OCW", "sha": "ed5a99b04dd813ebcc000e87db24c300faae3dbf", "lastModified": "2023-11-07T18:59:55.000Z", "tags": ["task_categories:text-classification", "size_categories:n<1K", "language:en", "license:mit", "creative problem solving", "puzzles", "fixation effect", "large language models", "only connect", "quiz show", "connecting walls", "arxiv:2306.11167", "region:us"], "private": false, "author": "TaatiTeam", "description": "The Only Connect Wall (OCW) dataset contains 618 \"Connecting Walls\" from the Round 3: Connecting Wall segment of the Only Connect quiz show, collected from 15 seasons' worth of episodes. Each wall contains the ground-truth groups and connections as well as recorded human performance.", "citation": "@article{Naeini2023LargeLM,\n    title        = {Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset},\n    author       = {Saeid Alavi Naeini and Raeid Saqur and Mozhgan Saeidi and John Giorgi and Babak Taati},\n    year         = 2023,\n    journal      = {ArXiv},\n    volume       = {abs/2306.11167},\n    url          = {https://api.semanticscholar.org/CorpusID:259203717}\n}", "cardData": null, "siblings": [], "_id": "64dd7c14103862a42df2f934", "disabled": false, "gated": false, "likes": 3, "downloads": 18, "createdAt": "2023-08-17T01:47:00.000Z"}, {"id": "fake-news-UFG/fakebr", "sha": "c1147181c88ea019099032b388498a2287a5aba5", "lastModified": "2023-08-18T13:51:35.000Z", "tags": ["task_categories:text-classification", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "language:pt", "region:us"], "private": false, "author": "fake-news-UFG", "description": "Fake.Br Corpus is composed of aligned true and fake news written in Brazilian Portuguese.", "citation": "@article{silva:20,\n  title = \"Towards automatically filtering fake news in Portuguese\",\n  journal = \"Expert Systems with Applications\",\n  volume = \"146\",\n  pages = \"113199\",\n  year = \"2020\",\n  issn = \"0957-4174\",\n  doi = \"https://doi.org/10.1016/j.eswa.2020.113199\",\n  url = \"http://www.sciencedirect.com/science/article/pii/S0957417420300257\",\n  author = \"Renato M. Silva and Roney L.S. Santos and Tiago A. Almeida and Thiago A.S. Pardo\",\n}", "cardData": null, "siblings": [], "_id": "64df5a0bed50cecb050db2cd", "disabled": false, "gated": false, "likes": 0, "downloads": 19, "createdAt": "2023-08-18T11:46:19.000Z"}, {"id": "piotr-rybak/allegro-faq", "sha": "a80e73589133e6bb4e97a9fc47edbff04ec5d17a", "lastModified": "2023-08-19T06:47:50.000Z", "tags": ["region:us"], "private": false, "author": "piotr-rybak", "description": "Allegro FAQ is a dataset for evaluating passage retrievers.", "citation": "\\", "cardData": null, "siblings": [], "_id": "64e05fb58e2084e1d7c6bc5f", "disabled": false, "gated": false, "likes": 0, "downloads": 37, "createdAt": "2023-08-19T06:22:45.000Z"}, {"id": "Sprakbanken/nb_samtale", "sha": "2ebb4dd9ca819a3443d4759516b09a531bb54976", "lastModified": "2023-10-06T14:43:06.000Z", "tags": ["task_categories:automatic-speech-recognition", "language:nb", "language:nn", "language:no", "license:cc0-1.0", "dialects", "podcasts", "live-events", "conversational", "speech", "region:us"], "private": false, "author": "Sprakbanken", "description": "NB Samtale is a speech corpus made by the Language Bank at the National Library of Norway.\nThe corpus contains orthographically transcribed speech from podcasts and recordings of live events at the National Library.\nThe corpus is intended as an open source dataset for Automatic Speech Recognition (ASR) development,\nand is specifically aimed at improving ASR systems\u2019 handle on conversational speech.", "citation": "\\", "cardData": null, "siblings": [], "_id": "64e4ad0f0195913c7fac895a", "disabled": false, "gated": false, "likes": 0, "downloads": 480, "createdAt": "2023-08-22T12:41:51.000Z"}, {"id": "piotr-rybak/legal-questions", "sha": "34369d30337c22a2367291febbdc83c3e9d93362", "lastModified": "2023-08-23T09:59:45.000Z", "tags": ["region:us"], "private": false, "author": "piotr-rybak", "description": "Legal Questions is a dataset for evaluating passage retrievers.", "citation": "\\", "cardData": null, "siblings": [], "_id": "64e5d818bc0068244f18059a", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2023-08-23T09:57:44.000Z"}, {"id": "fake-news-UFG/FactChecksbr", "sha": "776122e170781aeef522ad7c512698e120581c9a", "lastModified": "2023-08-24T17:40:04.000Z", "tags": ["task_categories:text-classification", "size_categories:10K<n<100K", "language:pt", "license:mit", "doi:10.57967/hf/1016", "region:us"], "private": false, "author": "fake-news-UFG", "description": "Collection of Portuguese Fact-Checking Benchmarks.", "citation": "@misc{FactChecksbr,\nauthor = {R. S. Gomes, Juliana},\ntitle = {FactChecks.br},\nurl = {https://github.com/fake-news-UFG/FactChecks.br},\ndoi = { 10.57967/hf/1016 },\n}", "cardData": null, "siblings": [], "_id": "64e63e96ab3f5cd60d018824", "disabled": false, "gated": false, "likes": 0, "downloads": 77, "createdAt": "2023-08-23T17:15:02.000Z"}, {"id": "alexcadillon/SemEval2014Task4", "sha": "3fd43769112ef6517c263e303fbb7dc3002c35df", "lastModified": "2023-09-12T08:49:29.000Z", "tags": ["region:us"], "private": false, "author": "alexcadillon", "description": "These are the datasets for Aspect Based Sentiment Analysis (ABSA), Task 4 of SemEval-2014.", "citation": "@inproceedings{pontiki-etal-2014-semeval,\n    title = \"{S}em{E}val-2014 Task 4: Aspect Based Sentiment Analysis\",\n    author = \"Pontiki, Maria  and\n      Galanis, Dimitris  and\n      Pavlopoulos, John  and\n      Papageorgiou, Harris  and\n      Androutsopoulos, Ion  and\n      Manandhar, Suresh\",\n    booktitle = \"Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014)\",\n    month = aug,\n    year = \"2014\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/S14-2004\",\n    doi = \"10.3115/v1/S14-2004\",\n    pages = \"27--35\",\n}", "cardData": null, "siblings": [], "_id": "64e75627252a63a992068b3a", "disabled": false, "gated": false, "likes": 0, "downloads": 63, "createdAt": "2023-08-24T13:07:51.000Z"}, {"id": "Dodon/ChartQA_dataset", "sha": "45ae025604b28ad1b64c044436bceab97b0e7606", "lastModified": "2023-09-13T16:49:37.000Z", "tags": ["task_categories:visual-question-answering", "size_categories:10K<n<100K", "language:en", "license:gpl-3.0", "region:us"], "private": false, "author": "Dodon", "description": "ChartQA dataset\nChart images, tables, image annotations, questions, answers", "citation": "@article{masry2022chartqa,\n  title={ChartQA: A benchmark for question answering about charts with visual and logical reasoning},\n  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},\n  journal={arXiv preprint arXiv:2203.10244},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "64ee7d02ad8275dcb0af4cc9", "disabled": false, "gated": false, "likes": 3, "downloads": 109, "createdAt": "2023-08-29T23:19:30.000Z"}, {"id": "EleutherAI/drop", "sha": "13879bb7815845ab9f79a051d25d1abc9f73ad5c", "lastModified": "2023-11-02T14:45:03.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "EleutherAI", "description": "DROP is a QA dataset which tests comprehensive understanding of paragraphs. In\nthis crowdsourced, adversarially-created, 96k question-answering benchmark, a\nsystem must resolve multiple references in a question, map them onto a paragraph,\nand perform discrete operations over them (such as addition, counting, or sorting).", "citation": "@misc{dua2019drop,\n    title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n    author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n    year={2019},\n    eprint={1903.00161},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64ef16ac0203b4e39c0f8c79", "disabled": false, "gated": false, "likes": 0, "downloads": 343, "createdAt": "2023-08-30T10:15:08.000Z"}, {"id": "EleutherAI/coqa", "sha": "4e3375f130184f78a47cf8dfc8e83cc6140863eb", "lastModified": "2023-11-02T14:46:15.000Z", "tags": ["size_categories:1K<n<10K", "language:en", "license:other", "arxiv:1808.07042", "region:us"], "private": false, "author": "EleutherAI", "description": "CoQA is a large-scale dataset for building Conversational Question Answering\nsystems. The goal of the CoQA challenge is to measure the ability of machines to\nunderstand a text passage and answer a series of interconnected questions that\nappear in a conversation.", "citation": "@misc{reddy2018coqa,\n    title={CoQA: A Conversational Question Answering Challenge},\n    author={Siva Reddy and Danqi Chen and Christopher D. Manning},\n    year={2018},\n    eprint={1808.07042},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64ef1b534d127873a2ee030d", "disabled": false, "gated": false, "likes": 1, "downloads": 123, "createdAt": "2023-08-30T10:34:59.000Z"}, {"id": "siyue/squall", "sha": "76727a210d47d68ef7f00bc403c1f71754acf070", "lastModified": "2023-09-08T06:08:06.000Z", "tags": ["task_categories:table-question-answering", "size_categories:10K<n<100K", "language:en", "license:mit", "region:us"], "private": false, "author": "siyue", "description": "To explore the utility of fine-grained, lexical-level supervision, authors introduce SQUALL, a dataset that enriches 11,276 WikiTableQuestions \\ \nEnglish-language questions with manually created SQL equivalents plus \\ \nalignments between SQL and question fragments.", "citation": "@inproceedings{Shi:Zhao:Boyd-Graber:Daume-III:Lee-2020,\n\tTitle = {On the Potential of Lexico-logical Alignments for Semantic Parsing to {SQL} Queries},\n\tAuthor = {Tianze Shi and Chen Zhao and Jordan Boyd-Graber and Hal {Daum\\'{e} III} and Lillian Lee},\n\tBooktitle = {Findings of EMNLP},\n\tYear = {2020},\n}", "cardData": null, "siblings": [], "_id": "64f2dd4504f239c724353924", "disabled": false, "gated": false, "likes": 0, "downloads": 861, "createdAt": "2023-09-02T06:59:17.000Z"}, {"id": "Alanox/stanford-dogs", "sha": "00c2ba455d1c85a01f14c6c5e1ec8524eeb33a1f", "lastModified": "2023-09-08T13:51:01.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "Alanox", "description": "The Stanford Dogs dataset contains images of 120 breeds of dogs from around the world. This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization.", "citation": null, "cardData": null, "siblings": [], "_id": "64f45cd06bd87d8e99cec241", "disabled": false, "gated": false, "likes": 2, "downloads": 826, "createdAt": "2023-09-03T10:15:44.000Z"}, {"id": "uonlp/CulturaX", "sha": "321a983f3fd2a929cc1f8ef6207834bab0bb9e25", "lastModified": "2023-09-25T10:43:45.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:found", "multilinguality:multilingual", "size_categories:n<1K", "size_categories:1K<n<10K", "size_categories:10K<n<100K", "size_categories:100K<n<1M", "size_categories:1M<n<10M", "size_categories:10M<n<100M", "size_categories:100M<n<1B", "size_categories:1B<n<10B", "source_datasets:original", "language:af", "language:als", "language:am", "language:an", "language:ar", "language:arz", "language:as", "language:ast", "language:av", "language:az", "language:azb", "language:ba", "language:bar", "language:bcl", "language:be", "language:bg", "language:bh", "language:bn", "language:bo", "language:bpy", "language:br", "language:bs", "language:bxr", "language:ca", "language:cbk", "language:ce", "language:ceb", "language:ckb", "language:cs", "language:cv", "language:cy", "language:da", "language:de", "language:dsb", "language:dv", "language:el", "language:eml", "language:en", "language:eo", "language:es", "language:et", "language:eu", "language:fa", "language:fi", "language:fr", "language:frr", "language:fy", "language:ga", "language:gd", "language:gl", "language:gn", "language:gom", "language:gu", "language:he", "language:hi", "language:hr", "language:hsb", "language:ht", "language:hu", "language:hy", "language:ia", "language:id", "language:ie", "language:ilo", "language:io", "language:is", "language:it", "language:ja", "language:jbo", "language:jv", "language:ka", "language:kk", "language:km", "language:kn", "language:ko", "language:krc", "language:ku", "language:kv", "language:kw", "language:ky", "language:la", "language:lb", "language:lez", "language:li", "language:lmo", "language:lo", "language:lrc", "language:lt", "language:lv", "language:mai", "language:mg", "language:mhr", "language:min", "language:mk", "language:ml", "language:mn", "language:mr", "language:mrj", "language:ms", "language:mt", "language:mwl", "language:my", "language:myv", "language:mzn", "language:nah", "language:nap", "language:nds", "language:ne", "language:new", "language:nl", "language:nn", "language:no", "language:oc", "language:or", "language:os", "language:pa", "language:pam", "language:pl", "language:pms", "language:pnb", "language:ps", "language:pt", "language:qu", "language:rm", "language:ro", "language:ru", "language:rue", "language:sa", "language:sah", "language:scn", "language:sd", "language:sh", "language:si", "language:sk", "language:sl", "language:so", "language:sq", "language:sr", "language:su", "language:sv", "language:sw", "language:ta", "language:te", "language:tg", "language:th", "language:tk", "language:tl", "language:tr", "language:tt", "language:tyv", "language:ug", "language:uk", "language:ur", "language:uz", "language:vec", "language:vi", "language:vls", "language:vo", "language:wa", "language:war", "language:wuu", "language:xal", "language:xmf", "language:yi", "language:yo", "language:yue", "language:zh", "arxiv:2309.09400", "region:us"], "private": false, "author": "uonlp", "description": "    CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages \\", "citation": "@misc{nguyen2023culturax,\n      title={CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages}, \n      author={Thuat Nguyen and Chien Van Nguyen and Viet Dac Lai and Hieu Man and Nghia Trung Ngo and Franck Dernoncourt and Ryan A. Rossi and Thien Huu Nguyen},\n      year={2023},\n      eprint={2309.09400},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "64f593570a2b25cd643bd968", "disabled": false, "gated": "auto", "likes": 240, "downloads": 54244, "createdAt": "2023-09-04T08:20:39.000Z"}, {"id": "indonlp/nusatranslation_emot", "sha": "1e9863795cf22b0361acee32e376f833f31a75ed", "lastModified": "2023-09-07T12:53:11.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "indonlp", "description": "    Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the NusaWrites benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.\n    We introduce a novel high quality human curated corpora, i.e., NusaMenulis, which covers 12 languages spoken in Indonesia. The resource extend the coverage of languages to 5 new languages, i.e., Ambon (abs), Bima (bhp), Makassarese (mak), Palembang / Musi (mui), and Rejang (rej).\n    For the rhetoric mode classification task, we cover 5 rhetoric modes, i.e., narrative, persuasive, argumentative, descriptive, and expository.", "citation": "    @unpublished{anonymous2023nusawrites:,\n    title={NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages},\n    author={Anonymous},\n    journal={OpenReview Preprint},\n    year={2023},\n    note={anonymous preprint under review}\n    }", "cardData": null, "siblings": [], "_id": "64f9c77392e158f65b9e2d3a", "disabled": false, "gated": false, "likes": 0, "downloads": 526, "createdAt": "2023-09-07T12:52:03.000Z"}, {"id": "indonlp/nusaparagraph_emot", "sha": "a46354e06642908b2178cca11218d8b48bf1b3e0", "lastModified": "2023-09-07T13:05:53.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "indonlp", "description": "Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the NusaWrites benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.\nWe introduce a novel high quality human curated corpora, i.e., NusaMenulis, which covers 12 languages spoken in Indonesia. The resource extend the coverage of languages to 5 new languages, i.e., Ambon (abs), Bima (bhp), Makassarese (mak), Palembang / Musi (mui), and Rejang (rej).\nFor the emotion recognition task, we cover the 6 basic emotions (Ekman, 1992): fear, disgusted, sad, happy, angry, and surprise, and an additional emotion label: shame (Poulson and of Tasmania. School of Management, 2000.", "citation": "@unpublished{anonymous2023nusawrites:,        \n    title={NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages},        \n    author={Anonymous},        \n    journal={OpenReview Preprint},        \n    year={2023},        \n    note={anonymous preprint under review}    \n}", "cardData": null, "siblings": [], "_id": "64f9c937681224dbe49b08ed", "disabled": false, "gated": false, "likes": 0, "downloads": 483, "createdAt": "2023-09-07T12:59:35.000Z"}, {"id": "indonlp/nusaparagraph_rhetoric", "sha": "662b2831558efc5ccc801fecae72c9e8274dae71", "lastModified": "2023-09-07T13:05:19.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "indonlp", "description": "Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the NusaWrites benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.\nWe introduce a novel high quality human curated corpora, i.e., NusaMenulis, which covers 12 languages spoken in Indonesia. The resource extend the coverage of languages to 5 new languages, i.e., Ambon (abs), Bima (bhp), Makassarese (mak), Palembang / Musi (mui), and Rejang (rej).\nFor the rhetoric mode classification task, we cover 5 rhetoric modes, i.e., narrative, persuasive, argumentative, descriptive, and expository.", "citation": "@unpublished{anonymous2023nusawrites:,        \n    title={NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages},        \n    author={Anonymous},        \n    journal={OpenReview Preprint},        \n    year={2023},        \n    note={anonymous preprint under review}    \n}", "cardData": null, "siblings": [], "_id": "64f9c976a5067f6b6558fab2", "disabled": false, "gated": false, "likes": 0, "downloads": 341, "createdAt": "2023-09-07T13:00:38.000Z"}, {"id": "indonlp/nusaparagraph_topic", "sha": "193eb1d87ad26f2fb11a426dfae5240f5e523bfa", "lastModified": "2023-09-07T13:04:43.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "indonlp", "description": "Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the NusaWrites benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages.\nWe introduce a novel high quality human curated corpora, i.e., NusaMenulis, which covers 12 languages spoken in Indonesia. The resource extend the coverage of languages to 5 new languages, i.e., Ambon (abs), Bima (bhp), Makassarese (mak), Palembang / Musi (mui), and Rejang (rej).\nFor the topic modeling task, we cover 8 topics, i.e., food \\& beverages, sports, leisure, religion, culture \\& heritage, a slice of life, technology, and business.", "citation": "@unpublished{anonymous2023nusawrites:,        \n    title={NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages},        \n    author={Anonymous},        \n    journal={OpenReview Preprint},        \n    year={2023},        \n    note={anonymous preprint under review}    \n}", "cardData": null, "siblings": [], "_id": "64f9c995f1bcfdb88f0d3759", "disabled": false, "gated": false, "likes": 0, "downloads": 407, "createdAt": "2023-09-07T13:01:09.000Z"}, {"id": "TrainingDataPro/ripe-strawberries-detection", "sha": "a258649f2f6db2f8c2a396521fcef8abd1c2d5e5", "lastModified": "2023-09-26T08:38:14.000Z", "tags": ["task_categories:image-classification", "task_categories:image-to-image", "task_categories:object-detection", "language:en", "license:cc-by-nc-nd-4.0", "code", "biology", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset consists of photos of strawberries for the identification and recognition of\nripe berries. \nThe images are annotated with **bounding boxes** that accurately demarcate the location\nof the ripe strawberries within the image.\nEach image in the dataset showcases a strawberry plantation, and includes a diverse\nrange of backgrounds, lighting conditions, and orientations. The photos are captured\nfrom various angles and distances, providing a realistic representation of strawberries.\nThe dataset can be utilised for enabling advancements in strawberry production, quality\ncontrol, and greater precision in agricultural practices.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {ripe-strawberries-detection},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "64fae9637eeb6dbf4081cce7", "disabled": false, "gated": false, "likes": 2, "downloads": 44, "createdAt": "2023-09-08T09:29:07.000Z"}, {"id": "taishi-i/awesome-japanese-nlp-classification-dataset", "sha": "9dcc8a7c613f9bd7cbac894b6c0b810ffe53e9a5", "lastModified": "2023-09-09T11:09:04.000Z", "tags": ["task_categories:text-classification", "size_categories:1K<n<10K", "language:en", "language:ja", "license:other", "code", "region:us"], "private": false, "author": "taishi-i", "description": "This dataset determines whether a GitHub repository description relates to Japanese natural language processing (NLP). The labels are categorized as \"Relevant (1)\" and \"Not Relevant (0)\".", "citation": null, "cardData": null, "siblings": [], "_id": "64fc12b08c21ebb3db937776", "disabled": false, "gated": false, "likes": 3, "downloads": 84, "createdAt": "2023-09-09T06:37:36.000Z"}, {"id": "ai4bharat/IN22-Gen", "sha": "a62314ee3dbf4da9753d5ac78ce2dbdc52498e7e", "lastModified": "2023-09-12T11:13:23.000Z", "tags": ["task_categories:translation", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:1K<n<10K", "language:as", "language:bn", "language:brx", "language:doi", "language:en", "language:gom", "language:gu", "language:hi", "language:kn", "language:ks", "language:mai", "language:ml", "language:mr", "language:mni", "language:ne", "language:or", "language:pa", "language:sa", "language:sat", "language:sd", "language:ta", "language:te", "language:ur", "license:cc-by-4.0", "arxiv:2305.16307", "region:us"], "private": false, "author": "ai4bharat", "description": "IN-22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. \nIN22-Gen is a general-purpose multi-domain evaluation subset of IN22. It has been created from two sources: Wikipedia and Web Sources offering diverse content spanning news, entertainment, culture, legal, and India-centric topics.", "citation": "@article{ai4bharat2023indictrans2,\n  title   = {IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages},\n  author  = {AI4Bharat and Jay Gala and Pranjal A. Chitale and Raghavan AK and Sumanth Doddapaneni and Varun Gumma and Aswanth Kumar and Janki Nawale and Anupama Sujatha and Ratish Puduppully and Vivek Raghavan and Pratyush Kumar and Mitesh M. Khapra and Raj Dabre and Anoop Kunchukuttan},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2305.16307}\n}", "cardData": null, "siblings": [], "_id": "64fca8594010eccccc3f2cde", "disabled": false, "gated": false, "likes": 1, "downloads": 1304, "createdAt": "2023-09-09T17:16:09.000Z"}, {"id": "ai4bharat/IN22-Conv", "sha": "716ea01bb759d20b231682c9b1bfa80ad52ba66b", "lastModified": "2023-11-13T06:36:05.000Z", "tags": ["task_categories:translation", "language_creators:expert-generated", "multilinguality:multilingual", "multilinguality:translation", "size_categories:1K<n<10K", "language:as", "language:bn", "language:brx", "language:doi", "language:en", "language:gom", "language:gu", "language:hi", "language:kn", "language:ks", "language:mai", "language:ml", "language:mr", "language:mni", "language:ne", "language:or", "language:pa", "language:sa", "language:sat", "language:sd", "language:ta", "language:te", "language:ur", "license:cc-by-4.0", "arxiv:2305.16307", "region:us"], "private": false, "author": "ai4bharat", "description": "IN-22 is a newly created comprehensive benchmark for evaluating machine translation performance in multi-domain, n-way parallel contexts across 22 Indic languages. \nIN22-Conv is the conversation domain subset of IN22. It is designed to assess translation quality in typical day-to-day conversational-style applications. \nCurrently, we use it for sentence-level evaluation of MT systems but can be repurposed for document translation evaluation as well.", "citation": "@article{ai4bharat2023indictrans2,\n  title   = {IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages},\n  author  = {AI4Bharat and Jay Gala and Pranjal A. Chitale and Raghavan AK and Sumanth Doddapaneni and Varun Gumma and Aswanth Kumar and Janki Nawale and Anupama Sujatha and Ratish Puduppully and Vivek Raghavan and Pratyush Kumar and Mitesh M. Khapra and Raj Dabre and Anoop Kunchukuttan},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: 2305.16307}\n}", "cardData": null, "siblings": [], "_id": "64fcacfe27fb3a92e9f326c8", "disabled": false, "gated": false, "likes": 2, "downloads": 658, "createdAt": "2023-09-09T17:35:58.000Z"}, {"id": "Goader/ukrainian-treebank-lm", "sha": "ed1443d480af1eb8168a1668adfe4b1ec81087f5", "lastModified": "2023-09-11T02:17:39.000Z", "tags": ["task_categories:fill-mask", "task_categories:text-generation", "language:uk", "license:cc-by-nc-sa-4.0", "region:us"], "private": false, "author": "Goader", "description": "Ukrainian part of the Universal Dependencies, specifically preprocessed for the language modeling task. The data can be split into documents, paragraphs or sentences. Manual selection of the data done by the authors of the dataset makes it suitable for the perplexity evaluation.\nAuthors of the dataset: Institute for Ukrainian, NGO, org@mova.institute\nGitHub: https://github.com/UniversalDependencies/UD_Ukrainian-IU", "citation": null, "cardData": null, "siblings": [], "_id": "64fe249975aa066fe40d920a", "disabled": false, "gated": false, "likes": 0, "downloads": 362, "createdAt": "2023-09-10T20:18:33.000Z"}, {"id": "Otter-AI/MMBench", "sha": "8b3eae255d7424a16d5161ee2fca7a789c7bba86", "lastModified": "2023-10-08T14:23:37.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Otter-AI", "description": "MMBench is collected from multiple sources, including public datasets and Internet, and currently, contains 2974 multiple-choice questions, covering 20 ability dimensions. We structure the existing 20 ability dimensions into 3 ability dimension levels, from L-1 to L-3. we incorporate Perception and Reasoning as our top-level ability dimensions in our ability taxonomy, referred to as L-1 ability dimension. For L-2 abilities, we derive: 1. Coarse Perception, 2. Fine-grained Single-instance Perception, 3. Fine-grained Cross-instance Perception from L-1 Perception; and 1. Attribute Reasoning, 2. Relation Reasoning, 3. Logic Reasoning from L-1 Reasoning. To make our benchmark as fine-grained as possible to produce informative feedbacks for developing multi-modality models. We further derive L-3 ability dimensions from L-2 ones. To the best of our knowledge, MMBench is the first large-scale evaluation multimodal dataset covering so many ability dimensions.", "citation": "@article{MMBench,\n    author  = {Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhnag, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, Kai Chen, Dahua Lin},\n    journal = {arXiv:2307.06281},\n    title   = {MMBench: Is Your Multi-modal Model an All-around Player?},\n    year    = {2023},\n}", "cardData": null, "siblings": [], "_id": "65041d6fdcfe8fd06a7e4a08", "disabled": false, "gated": false, "likes": 2, "downloads": 41, "createdAt": "2023-09-15T09:01:35.000Z"}, {"id": "jlh-ibm/earnings_call", "sha": "0f4669f29e8cb784a3da60005a8d82f12dad102f", "lastModified": "2023-09-15T21:34:39.000Z", "tags": ["task_categories:text-classification", "size_categories:10K<n<100K", "language:en", "license:cc0-1.0", "finance", "region:us"], "private": false, "author": "jlh-ibm", "description": "The dataset reports a collection of earnings call transcripts, the related stock prices, and the sector index In terms of volume, there is a total of 188 transcripts, 11970 stock prices, and 1196 sector index values. Furthermore, all of these data originated in the period 2016-2020 and are related to the NASDAQ stock market. Furthermore, the data collection was made possible by Yahoo Finance and Thomson Reuters Eikon. Specifically, Yahoo Finance enabled the search for stock values and Thomson Reuters Eikon provided the earnings call transcripts. Lastly, the dataset can be used as a benchmark for the evaluation of several NLP techniques to understand their potential for financial applications. Moreover, it is also possible to expand the dataset by extending the period in which the data originated following a similar procedure.", "citation": "@data{TJE0D0_2021,\nauthor = {Roozen, Dexter and Lelli, Francesco},\npublisher = {DataverseNL},\ntitle = {{Stock Values and Earnings Call Transcripts: a Sentiment Analysis Dataset}},\nyear = {2021},\nversion = {V1},\ndoi = {10.34894/TJE0D0},\nurl = {https://doi.org/10.34894/TJE0D0}\n}", "cardData": null, "siblings": [], "_id": "6504bdc767876ea320dfd8a5", "disabled": false, "gated": false, "likes": 1, "downloads": 82, "createdAt": "2023-09-15T20:25:43.000Z"}, {"id": "Otter-AI/MME", "sha": "e787ffd0f41db56104c3e1b0431d1b0e64df6e2b", "lastModified": "2023-10-09T17:05:30.000Z", "tags": ["region:us"], "private": false, "author": "Otter-AI", "description": "Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image. However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation. In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME. It measures both perception and cognition abilities on a total of 14 subtasks. In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed. The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering. Besides, with such an instruction, we can also easily carry out quantitative statistics. A total of 12 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization.", "citation": "@article{li2023mimicit,\n    title={MIMIC-IT: Multi-Modal In-Context Instruction Tuning},\n    author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},\n    year={2023},\n    eprint={2306.05425},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "6505553b04d04d653dbc4538", "disabled": false, "gated": false, "likes": 2, "downloads": 35, "createdAt": "2023-09-16T07:11:55.000Z"}, {"id": "pavlichenko/WizardLM_evol_instruct_70k_train_val_split", "sha": "244c00835056d44fc2f307048765349f9028f157", "lastModified": "2023-09-16T12:26:29.000Z", "tags": ["task_categories:conversational", "size_categories:10K<n<100K", "region:us"], "private": false, "author": "pavlichenko", "description": "WizardLM dataset splitted in train and validation.", "citation": null, "cardData": null, "siblings": [], "_id": "6505935ca226ecc608b756b8", "disabled": false, "gated": false, "likes": 0, "downloads": 3809, "createdAt": "2023-09-16T11:37:00.000Z"}, {"id": "p208p2002/wudao", "sha": "a7a45e76fbef1d7c9013dc4d75b17634a65d69f0", "lastModified": "2023-11-02T09:06:54.000Z", "tags": ["task_categories:text-generation", "size_categories:n>1T", "language:zh", "region:us"], "private": false, "author": "p208p2002", "description": "WuDaoCorpora Text is a large pretraining Chinese corpus constructed by Beijing Academy of Artificial Intelligence(BAAI). The total data volume of the dataset has exceeded 5TB, including 200GB open data.\n\n\nCompared with other pretraining corpora, the WuDaoCorpora Text has the following advantages.\n\n1) In the process of data collection, we classify the quality of web pages according to the proportion of words in web pages and the integrity of DOM trees, and select high-quality web page for data collection to ensure the corpus quality.\n\n2) Through data cooperation with other institutions and web page data crawling, the dataset covers a wide range types of Chinese text, including news, comments, encyclopedias, forums, blogs, academic papers, etc.\n\n3) The dataset uses more than 20 cleaning rules to obtain the final corpus from the 100TB original web page data. In the cleaning process, special attention is paid to the removal of private information to avoid the risk of privacy disclosure.\n\n4) The dataset contains 50+ data tags, such as education and laws, which is convenient for users to extract specific-domain data for model training in that field.\n\n\nPlease obey the following agreement if you use our dataset.\n\nhttps://data.baai.ac.cn/resources/agreement/BAAIDataAgreement.pdf", "citation": "@misc{ c6a3fe684227415a9db8e21bac4a15ab,\n  author       = {Zhao Xue and Hanyu Zhao and Sha Yuan and Yequan Wang},\n  title        = {{WuDaoCorpora Text}},\n  year         = 2022,\n  month        = dec,\n  publisher    = {Science Data Bank},\n  version      = {V1},\n  doi          = {10.57760/sciencedb.o00126.00004},\n  url          = https://doi.org/10.57760/sciencedb.o00126.00004\n}", "cardData": null, "siblings": [], "_id": "6508faf1c9aa376f76a9842c", "disabled": false, "gated": false, "likes": 1, "downloads": 18, "createdAt": "2023-09-19T01:35:45.000Z"}, {"id": "codymlewis/HAR", "sha": "29520ebc8c6e6ed9798b47a40f394c717e7ee05b", "lastModified": "2023-10-13T03:23:34.000Z", "tags": ["size_categories:n<1K", "license:cc-by-4.0", "region:us"], "private": false, "author": "codymlewis", "description": "The Human Activity Recognition dataset.", "citation": "@misc{misc_smartphone-based_recognition_of_human_activities_and_postural_transitions_341,\n  author       = {Reyes-Ortiz,Jorge, Anguita,Davide, Oneto,Luca, and Parra,Xavier},\n  title        = {{Smartphone-Based Recognition of Human Activities and Postural Transitions}},\n  year         = {2015},\n  howpublished = {UCI Machine Learning Repository},\n  note         = {{DOI}: https://doi.org/10.24432/C54G7M}\n}", "cardData": null, "siblings": [], "_id": "65092f51905c78a96a292e3b", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2023-09-19T05:19:13.000Z"}, {"id": "jherng/rsna-2023-abdominal-trauma-detection", "sha": "f8e890cf1dac54508d0ce489a0c5c6c8613d8942", "lastModified": "2023-10-10T06:56:40.000Z", "tags": ["task_categories:image-classification", "task_categories:image-segmentation", "size_categories:1K<n<10K", "license:mit", "region:us"], "private": false, "author": "jherng", "description": "This dataset is the preprocessed version of the dataset from RSNA 2023 Abdominal Trauma Detection Kaggle Competition. \nIt is tailored for segmentation and classification tasks. It contains 3 different configs as described below:\n- segmentation: 206 instances where each instance includes a CT scan in NIfTI format, a segmentation mask in NIfTI format, and its relevant metadata (e.g., patient_id, series_id, incomplete_organ, aortic_hu, pixel_representation, bits_allocated, bits_stored)\n- classification: 4711 instances where each instance includes a CT scan in NIfTI format, target labels (e.g., extravasation, bowel, kidney, liver, spleen, any_injury), and its relevant metadata (e.g., patient_id, series_id, incomplete_organ, aortic_hu, pixel_representation, bits_allocated, bits_stored)\n- classification-with-mask: 206 instances where each instance includes a CT scan in NIfTI format, a segmentation mask in NIfTI format, target labels (e.g., extravasation, bowel, kidney, liver, spleen, any_injury), and its relevant metadata (e.g., patient_id, series_id, incomplete_organ, aortic_hu, pixel_representation, bits_allocated, bits_stored)\n\nAll CT scans and segmentation masks had already been resampled with voxel spacing (2.0, 2.0, 3.0) and thus its reduced file size.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {RSNA 2023 Abdominal Trauma Detection Dataset},\nauthor={Hong Jia Herng},\nyear={2023}\n}\n@misc{rsna-2023-abdominal-trauma-detection,\n    author = {Errol Colak, Hui-Ming Lin, Robyn Ball, Melissa Davis, Adam Flanders, Sabeena Jalal, Kirti Magudia, Brett Marinelli, Savvas Nicolaou, Luciano Prevedello, Jeff Rudie, George Shih, Maryam Vazirabad, John Mongan},\n    title = {RSNA 2023 Abdominal Trauma Detection},\n    publisher = {Kaggle},\n    year = {2023},\n    url = {https://kaggle.com/competitions/rsna-2023-abdominal-trauma-detection}\n}", "cardData": null, "siblings": [], "_id": "650973a71b3694179ddb8233", "disabled": false, "gated": false, "likes": 2, "downloads": 108, "createdAt": "2023-09-19T10:10:47.000Z"}, {"id": "codymlewis/nbaiot", "sha": "a8d31addd96e72cacf049cd7bc63d52987ca90eb", "lastModified": "2023-10-13T04:02:56.000Z", "tags": ["license:cc-by-4.0", "arxiv:1805.03409", "region:us"], "private": false, "author": "codymlewis", "description": "An intrusion detection dataset that focuses on IoT botnet attacks.", "citation": "@article{DBLP:journals/corr/abs-1805-03409,\n  author       = {Yair Meidan and\n                  Michael Bohadana and\n                  Yael Mathov and\n                  Yisroel Mirsky and\n                  Dominik Breitenbacher and\n                  Asaf Shabtai and\n                  Yuval Elovici},\n  title        = {N-BaIoT: Network-based Detection of IoT Botnet Attacks Using Deep\n                  Autoencoders},\n  journal      = {CoRR},\n  volume       = {abs/1805.03409},\n  year         = {2018},\n  url          = {http://arxiv.org/abs/1805.03409},\n  eprinttype    = {arXiv},\n  eprint       = {1805.03409},\n  timestamp    = {Mon, 13 Aug 2018 16:49:04 +0200},\n  biburl       = {https://dblp.org/rec/journals/corr/abs-1805-03409.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "650a57cfa2abcb18d655dbbe", "disabled": false, "gated": false, "likes": 0, "downloads": 31, "createdAt": "2023-09-20T02:24:15.000Z"}, {"id": "iohadrubin/c4", "sha": "3597496c058adc95be813ec7e7265c777b3cc52a", "lastModified": "2023-11-12T06:53:33.000Z", "tags": ["region:us"], "private": false, "author": "iohadrubin", "description": "A colossal, cleaned version of Common Crawl's web crawl corpus.\nBased on Common Crawl dataset: \"https://commoncrawl.org\".\nThis is the processed version of Google's C4 dataset by AllenAI.", "citation": "@article{2019t5,\n    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n    journal = {arXiv e-prints},\n    year = {2019},\n    archivePrefix = {arXiv},\n    eprint = {1910.10683},\n}", "cardData": null, "siblings": [], "_id": "650d3fa56b94d837c030bc8c", "disabled": false, "gated": false, "likes": 0, "downloads": 10091, "createdAt": "2023-09-22T07:17:57.000Z"}, {"id": "Kerenfuentes/holistic_bias", "sha": "2f507a6b5a218f86914ded510e345e0827108d1c", "lastModified": "2023-09-29T21:18:24.000Z", "tags": ["region:us"], "private": false, "author": "Kerenfuentes", "description": "This folder contains code to generate the HolisticBias dataset, a set of sentences containing demographic \nidentity language (e.g. \u201cHi! I am a Catholic grandmother.\u201d), used in the context of a two-person conversation. \nSentences are formed by combining (1) an identity term from one of 13 demographic axes, (2) a noun referring to \na person (mom, boy, grandparent, etc.), and (3) one of several dozen sentence templates.", "citation": "@article{smith2022imsorry,\n  doi = {10.48550/ARXIV.2205.09209},\n  url = {https://arxiv.org/abs/2205.09209},\n  author = {Smith, Eric Michael and Hall, Melissa and Kambadur, Melanie and Presani, Eleonora and Williams, Adina},\n  keywords = {Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {\"I'm sorry to hear that\": Finding New Biases in Language Models with a Holistic Descriptor Dataset},\n  publisher = {arXiv},\n  year = {2022},\n  copyright = {Creative Commons Attribution Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "650e0cccf874d950df18c21c", "disabled": false, "gated": false, "likes": 0, "downloads": 107, "createdAt": "2023-09-22T21:53:16.000Z"}, {"id": "OfekGlick/DiscoEval", "sha": "f51b82847c1d1cb0fc11a317b5c5413b6ed0747f", "lastModified": "2023-11-06T14:06:49.000Z", "tags": ["task_categories:text-classification", "size_categories:100K<n<1M", "language:en", "license:bsd", "Discourse", "Discourse Evaluation", "NLP", "arxiv:1909.00142", "region:us"], "private": false, "author": "OfekGlick", "description": "This dataset contains all tasks of the DiscoEval benchmark for sentence representation learning.", "citation": "@InProceedings{mchen-discoeval-19,\n                title = {Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence Representations},\n                author = {Mingda Chen and Zewei Chu and Kevin Gimpel},\n                booktitle = {Proc. of {EMNLP}},\n                year={2019}\n              }", "cardData": null, "siblings": [], "_id": "650e21ccdcfa9d24c5fb6aa4", "disabled": false, "gated": false, "likes": 0, "downloads": 174, "createdAt": "2023-09-22T23:22:52.000Z"}, {"id": "NusaCrowd/kamus_alay", "sha": "d9d0346b4b8ad4ff3c27990774f4330e8de7e648", "lastModified": "2023-09-26T12:28:13.000Z", "tags": ["language:ind", "license:unknown", "morphological-inflection", "region:us"], "private": false, "author": "NusaCrowd", "description": "Kamus Alay provide a lexicon for text normalization of Indonesian colloquial words.\nIt contains 3,592 unique colloquial words-also known as \u201cbahasa alay\u201d -and manually annotated them\nwith the normalized form. We built this lexicon from Instagram comments provided by Septiandri & Wibisono (2017)", "citation": "@INPROCEEDINGS{8629151,\nauthor={Aliyah Salsabila, Nikmatun and Ardhito Winatmoko, Yosef and Akbar Septiandri, Ali and Jamal, Ade},\nbooktitle={2018 International Conference on Asian Language Processing (IALP)},\ntitle={Colloquial Indonesian Lexicon},\nyear={2018},\nvolume={},\nnumber={},\npages={226-229},\ndoi={10.1109/IALP.2018.8629151}}", "cardData": null, "siblings": [], "_id": "6512bc549af40a65583f5dea", "disabled": false, "gated": false, "likes": 0, "downloads": 27, "createdAt": "2023-09-26T11:11:16.000Z"}, {"id": "NusaCrowd/indolem_ner_ugm", "sha": "c299fb355fc1e7865093b485e3a845b1cefe6d43", "lastModified": "2023-09-26T12:28:37.000Z", "tags": ["language:ind", "license:cc-by-4.0", "named-entity-recognition", "region:us"], "private": false, "author": "NusaCrowd", "description": "NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.", "citation": "@inproceedings{koto-etal-2020-indolem,\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\n    author = \"Koto, Fajri  and\n      Rahimi, Afshin  and\n      Lau, Jey Han  and\n      Baldwin, Timothy\",\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\n    month = dec,\n    year = \"2020\",\n    address = \"Barcelona, Spain (Online)\",\n    publisher = \"International Committee on Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.coling-main.66\",\n    doi = \"10.18653/v1/2020.coling-main.66\",\n    pages = \"757--770\"\n}\n@phdthesis{fachri2014pengenalan,\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\n  author    = {FACHRI, MUHAMMAD},\n  year      = {2014},\n  school    = {Universitas Gadjah Mada}\n}", "cardData": null, "siblings": [], "_id": "6512bc5597bb5c96ae67635b", "disabled": false, "gated": false, "likes": 0, "downloads": 22, "createdAt": "2023-09-26T11:11:17.000Z"}, {"id": "NusaCrowd/id_hoax_news", "sha": "a3b0be7a80b62edc507215c55a4d349a4a1adac3", "lastModified": "2023-09-26T12:28:34.000Z", "tags": ["language:ind", "hoax-news-classification", "region:us"], "private": false, "author": "NusaCrowd", "description": "This research proposes to build an automatic hoax news detection and collects 250 pages of hoax and valid news articles in Indonesian language.\nEach data sample is annotated by three reviewers and the final taggings are obtained by voting of those three reviewers.", "citation": "@INPROCEEDINGS{8265649,  author={Pratiwi, Inggrid Yanuar Risca and Asmara, Rosa Andrie and Rahutomo, Faisal},  booktitle={2017 11th International Conference on Information & Communication Technology and System (ICTS)},   title={Study of hoax news detection using na\u00efve bayes classifier in Indonesian language},   year={2017},  volume={},  number={},  pages={73-78},  doi={10.1109/ICTS.2017.8265649}}", "cardData": null, "siblings": [], "_id": "6512bc55b7994cff61c9995c", "disabled": false, "gated": false, "likes": 0, "downloads": 71, "createdAt": "2023-09-26T11:11:17.000Z"}, {"id": "NusaCrowd/minangnlp_mt", "sha": "f6f233e62c3d2559c6a74ee4e84b3fb2a6a31341", "lastModified": "2023-09-26T12:29:22.000Z", "tags": ["language:min", "language:ind", "license:mit", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "In this work, we create Minangkabau\u2013Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID\u2019 and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1\u20135 (1 means poor quality and 5 otherwise) and conducted against 100 random\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\nThis indicates that the resulting corpus is high-quality for machine translation training.", "citation": "@inproceedings{koto-koto-2020-towards,\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\n    author = \"Koto, Fajri  and\n      Koto, Ikhwan\",\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\n    month = oct,\n    year = \"2020\",\n    address = \"Hanoi, Vietnam\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\n    pages = \"138--148\",\n}", "cardData": null, "siblings": [], "_id": "6512bc577fccffe1e9dd4681", "disabled": false, "gated": false, "likes": 0, "downloads": 43, "createdAt": "2023-09-26T11:11:19.000Z"}, {"id": "NusaCrowd/indolem_ntp", "sha": "cfdfeb745b3f1ba67b9730220ba5d7678cebdb2c", "lastModified": "2023-09-26T12:30:22.000Z", "tags": ["language:ind", "license:cc-by-4.0", "next-sentence-prediction", "arxiv:2011.00677", "region:us"], "private": false, "author": "NusaCrowd", "description": "NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\n\nTrain: 5681 threads\nDevelopment: 811 threads\nTest: 1890 threads", "citation": "@article{DBLP:journals/corr/abs-2011-00677,\n  author    = {Fajri Koto and\n               Afshin Rahimi and\n               Jey Han Lau and\n               Timothy Baldwin},\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\n               Model for Indonesian {NLP}},\n  journal   = {CoRR},\n  volume    = {abs/2011.00677},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2011.00677},\n  eprinttype = {arXiv},\n  eprint    = {2011.00677},\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "6512bc5892a52e002ab179df", "disabled": false, "gated": false, "likes": 0, "downloads": 78, "createdAt": "2023-09-26T11:11:20.000Z"}, {"id": "NusaCrowd/id_abusive", "sha": "ccaaba6916ae4874ad223e29138107411fb021b0", "lastModified": "2023-09-26T12:32:46.000Z", "tags": ["language:ind", "sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\nnot abusive language, abusive but not offensive, and offensive language.", "citation": "@article{IBROHIM2018222,\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\njournal = {Procedia Computer Science},\nvolume = {135},\npages = {222-229},\nyear = {2018},\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\nissn = {1877-0509},\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\nkeywords = {abusive language, twitter, machine learning},\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\n}", "cardData": null, "siblings": [], "_id": "6512bc5b2f79557a90ac0f5c", "disabled": false, "gated": false, "likes": 0, "downloads": 53, "createdAt": "2023-09-26T11:11:23.000Z"}, {"id": "NusaCrowd/emotcmt", "sha": "585353da32f8996383a708ddc26a0e427a1aade2", "lastModified": "2023-09-26T12:33:23.000Z", "tags": ["language:ind", "license:mit", "emotion-classification", "region:us"], "private": false, "author": "NusaCrowd", "description": "EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).", "citation": "@inproceedings{barik-etal-2019-normalization,\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\n    author = \"Barik, Anab Maulana  and\n      Mahendra, Rahmad  and\n      Adriani, Mirna\",\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\n    month = nov,\n    year = \"2019\",\n    address = \"Hong Kong, China\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/D19-5554\",\n    doi = \"10.18653/v1/D19-5554\",\n    pages = \"417--424\"\n}\n\n@article{Yulianti2021NormalisationOI,\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\n  journal={International Journal of Advanced Computer Science and Applications},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "6512bc5c4483b69098b77e81", "disabled": false, "gated": false, "likes": 0, "downloads": 61, "createdAt": "2023-09-26T11:11:24.000Z"}, {"id": "NusaCrowd/bible_su_id", "sha": "9104368d0fdaa011aaa16883b9fd83fbc21a3884", "lastModified": "2023-09-26T12:33:31.000Z", "tags": ["language:ind", "language:sun", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.", "citation": "@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\",\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\n}", "cardData": null, "siblings": [], "_id": "6512bc5c7b2e843f39ae4ba2", "disabled": false, "gated": false, "likes": 0, "downloads": 53, "createdAt": "2023-09-26T11:11:24.000Z"}, {"id": "NusaCrowd/indolem_sentiment", "sha": "cf1bc2c706111e9283c8126cec71f7063819f64c", "lastModified": "2023-10-17T13:31:29.000Z", "tags": ["language:ind", "sentiment-analysis", "arxiv:2011.00677", "region:us"], "private": false, "author": "NusaCrowd", "description": "IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\n\nThis dataset is based on binary classification (positive and negative), with distribution:\n* Train: 3638 sentences\n* Development: 399 sentences\n* Test: 1011 sentences\n\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\n\nThe experiment is based on 5-fold cross validation.", "citation": "@article{DBLP:journals/corr/abs-2011-00677,\n  author    = {Fajri Koto and\n               Afshin Rahimi and\n               Jey Han Lau and\n               Timothy Baldwin},\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\n               Model for Indonesian {NLP}},\n  journal   = {CoRR},\n  volume    = {abs/2011.00677},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2011.00677},\n  eprinttype = {arXiv},\n  eprint    = {2011.00677},\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "6512bc5fff22d7acb6f8b517", "disabled": false, "gated": false, "likes": 0, "downloads": 65, "createdAt": "2023-09-26T11:11:27.000Z"}, {"id": "NusaCrowd/id_short_answer_grading", "sha": "6aa7cb6fdb069ccbb3652c27456205b7f373559d", "lastModified": "2023-09-26T12:28:15.000Z", "tags": ["language:ind", "license:unknown", "short-answer-grading", "region:us"], "private": false, "author": "NusaCrowd", "description": "Indonesian short answers for Biology and Geography subjects from 534 respondents where the answer grading was done by 7 experts.\\", "citation": "@article{\n    JLK,\n    author = {Muh Haidir and Ayu Purwarianti},\n    title = { Short Answer Grading Using Contextual Word Embedding and Linear Regression},\n    journal = {Jurnal Linguistik Komputasional},\n    volume = {3},\n    number = {2},\n    year = {2020},\n    keywords = {},\n    abstract = {Abstract\u2014One of the obstacles in an efficient MOOC is the evaluation of student answers, including the short answer grading which requires large effort from instructors to conduct it manually.\n                Thus, NLP research in short answer grading has been conducted in order to support the automation, using several techniques such as rule\n                and machine learning based. Here, we\u2019ve conducted experiments on deep learning based short answer grading to compare the answer\n                representation and answer assessment method. In the answer representation, we compared word embedding and sentence embedding models\n                such as BERT, and its modification. In the answer assessment method, we use linear regression. There are 2 datasets that we used, available\n                English short answer grading dataset with 80 questions and 2442 to get the best configuration for model and Indonesian short answer grading\n                dataset with 36 questions and 9165 short answers as testing data. Here, we\u2019ve collected Indonesian short answers for Biology and Geography\n                subjects from 534 respondents where the answer grading was done by 7 experts. The best root mean squared error for both dataset was achieved\n                by using BERT pretrained, 0.880 for English dataset dan 1.893 for Indonesian dataset.},\n    issn = {2621-9336},\tpages = {54--61},\tdoi = {10.26418/jlk.v3i2.38},\n    url = {https://inacl.id/journal/index.php/jlk/article/view/38}\n}\\", "cardData": null, "siblings": [], "_id": "6512bc7e332b85e7cf8329cd", "disabled": false, "gated": false, "likes": 0, "downloads": 51, "createdAt": "2023-09-26T11:11:58.000Z"}, {"id": "NusaCrowd/bible_jv_id", "sha": "fa37f4a346913f7a3574d9e3151578394342368c", "lastModified": "2023-09-26T12:28:24.000Z", "tags": ["language:ind", "language:jav", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "Analogous to the En \u2194 Id and Su \u2194 Id datasets, we create a new dataset for Javanese and Indonesian translation generated from the verse-aligned Bible parallel corpus with the same split setting. In terms of size, both the Su \u2194 Id and Jv \u2194 Id datasets are much smaller compared to the En \u2194 Id dataset, because there are Bible chapters for which translations are available for Indonesian, albeit not for the local languages.", "citation": "@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\",\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\n}", "cardData": null, "siblings": [], "_id": "6512bc860d463b73dce63407", "disabled": false, "gated": false, "likes": 0, "downloads": 54, "createdAt": "2023-09-26T11:12:06.000Z"}, {"id": "NusaCrowd/indosum", "sha": "2bf7b09bf685e06ae097f075634b55ed6d63c7ca", "lastModified": "2023-09-26T12:28:30.000Z", "tags": ["language:ind", "summarization", "region:us"], "private": false, "author": "NusaCrowd", "description": "INDOSUM is a new benchmark dataset for Indonesian text summarization. \nThe dataset consists of news articles and manually constructed summaries.", "citation": "@INPROCEEDINGS{8629109,\n  author={Kurniawan, Kemal and Louvan, Samuel},\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \n  year={2018},\n  volume={},\n  number={},\n  pages={215-220},\n  doi={10.1109/IALP.2018.8629109}}", "cardData": null, "siblings": [], "_id": "6512bc8b749380c0799b1167", "disabled": false, "gated": false, "likes": 0, "downloads": 151, "createdAt": "2023-09-26T11:12:11.000Z"}, {"id": "NusaCrowd/wrete", "sha": "dff73232e2332e1a26865b3e947df75ccd51e77b", "lastModified": "2023-09-26T12:29:01.000Z", "tags": ["language:ind", "textual-entailment", "region:us"], "private": false, "author": "NusaCrowd", "description": "WReTe, The Wiki Revision Edits Textual Entailment dataset (Setya and Mahendra, 2018) consists of 450 sentence pairs constructed from Wikipedia revision history. The dataset contains pairs of sentences and binary semantic relations between the pairs. The data are labeled as entailed when the meaning of the second sentence can be derived from the first one, and not entailed otherwise", "citation": "@INPROCEEDINGS{8904199,\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\n    year={2019},\n    pages={1-5},\n    doi={10.1109/ICAICTA.2019.8904199}\n}\n\n@inproceedings{wilie2020indonlu,\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n  pages={843--857},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6512bcbd7b2e843f39ae5c0d", "disabled": false, "gated": false, "likes": 0, "downloads": 66, "createdAt": "2023-09-26T11:13:01.000Z"}, {"id": "NusaCrowd/multilexnorm", "sha": "bd6d67fc5732f4f774d4e6441c60e4c730c10570", "lastModified": "2023-09-26T12:29:08.000Z", "tags": ["language:ind", "multilexnorm", "region:us"], "private": false, "author": "NusaCrowd", "description": "MULTILEXNPRM is a new benchmark dataset for multilingual lexical normalization\nincluding 12 language variants,\nwe here specifically work on the Indonisian-english language.", "citation": "@inproceedings{multilexnorm,\n  title= {MultiLexNorm: A Shared Task on Multilingual Lexical Normalization,\n  author = \"van der Goot, Rob and Ramponi et al.\",\n  booktitle = \"Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021)\",\n  year = \"2021\",\n  publisher = \"Association for Computational Linguistics\",\n  address = \"Punta Cana, Dominican Republic\"\n}", "cardData": null, "siblings": [], "_id": "6512bcc197fb08378dc1faa6", "disabled": false, "gated": false, "likes": 0, "downloads": 28, "createdAt": "2023-09-26T11:13:05.000Z"}, {"id": "NusaCrowd/jadi_ide", "sha": "d959fa3e7b109d4e2a539187b74e120bdb13bfde", "lastModified": "2023-09-26T12:29:15.000Z", "tags": ["language:ind", "license:unknown", "emotion-classification", "region:us"], "private": false, "author": "NusaCrowd", "description": "The JaDi-Ide dataset is a Twitter dataset for Javanese dialect identification, containing 16,498 \ndata samples. The dialect is classified into `Standard Javanese`, `Ngapak Javanese`, and `East \nJavanese` dialects.", "citation": "@article{hidayatullah2020attention,\n  title={Attention-based cnn-bilstm for dialect identification on javanese text},\n  author={Hidayatullah, Ahmad Fathan and Cahyaningtyas, Siwi and Pamungkas, Rheza Daffa},\n  journal={Kinetik: Game Technology, Information System, Computer Network, Computing, Electronics, and Control},\n  pages={317--324},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6512bccb2525e3f798214247", "disabled": false, "gated": false, "likes": 0, "downloads": 34, "createdAt": "2023-09-26T11:13:15.000Z"}, {"id": "NusaCrowd/id_abusive_news_comment", "sha": "0a0b117d1414a225e4553c46ca22deb1dd2bc05d", "lastModified": "2023-09-26T12:29:19.000Z", "tags": ["language:ind", "sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "Abusive language is an expression used by a person with insulting delivery of any person's aspect.\nIn the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse.\nAn abusive language detection system is important to prevent the negative effect of such comments.\nThis dataset contains 3184 samples of Indonesian online news comments with 3 labels.", "citation": "@INPROCEEDINGS{9034620,  author={Kiasati Desrul, Dhamir Raniah and Romadhony, Ade},  booktitle={2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)},   title={Abusive Language Detection on Indonesian Online News Comments},   year={2019},  volume={},  number={},  pages={320-325},  doi={10.1109/ISRITI48646.2019.9034620}}", "cardData": null, "siblings": [], "_id": "6512bccea6755fc9771e2548", "disabled": false, "gated": false, "likes": 0, "downloads": 53, "createdAt": "2023-09-26T11:13:18.000Z"}, {"id": "NusaCrowd/hoasa", "sha": "73ba83b707fbaa6c04f54b8baab9bdbdbf2fe25d", "lastModified": "2023-09-26T12:29:28.000Z", "tags": ["language:ind", "aspect-based-sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "HoASA: An aspect-based sentiment analysis dataset consisting of hotel reviews collected from the hotel aggregator platform, AiryRooms.\nThe dataset covers ten different aspects of hotel quality. Similar to the CASA dataset, each review is labeled with a single sentiment label for each aspect.\nThere are four possible sentiment classes for each sentiment label:\npositive, negative, neutral, and positive-negative.\nThe positivenegative label is given to a review that contains multiple sentiments of the same aspect but for different objects (e.g., cleanliness of bed and toilet).", "citation": "@inproceedings{azhar2019multi,\n  title={Multi-label Aspect Categorization with Convolutional Neural Networks and Extreme Gradient Boosting},\n  author={A. N. Azhar, M. L. Khodra, and A. P. Sutiono}\n  booktitle={Proceedings of the 2019 International Conference on Electrical Engineering and Informatics (ICEEI)},\n  pages={35--40},\n  year={2019}\n}", "cardData": null, "siblings": [], "_id": "6512bcd8408d3000f0526da0", "disabled": false, "gated": false, "likes": 0, "downloads": 16, "createdAt": "2023-09-26T11:13:28.000Z"}, {"id": "NusaCrowd/term_a", "sha": "c5b6453c5abc5ce20a8144349e41485d1ddf66ae", "lastModified": "2023-09-26T12:29:41.000Z", "tags": ["language:ind", "keyword-tagging", "region:us"], "private": false, "author": "NusaCrowd", "description": "TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\n(Septiandri and Sutiono, 2019; Fernando et al.,\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\nsentiment.", "citation": "@article{winatmoko2019aspect,\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\n  journal={arXiv preprint arXiv:1909.11879},\n  year={2019}\n}\n@inproceedings{fernando2019aspect,\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\n  pages={1--6},\n  year={2019},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "6512bce8d901d0d5e8019d20", "disabled": false, "gated": false, "likes": 0, "downloads": 31, "createdAt": "2023-09-26T11:13:44.000Z"}, {"id": "NusaCrowd/id_multilabel_hs", "sha": "4c23b73760b1e26eac39ae4442026c3cb0aa59af", "lastModified": "2023-09-26T12:29:46.000Z", "tags": ["language:ind", "aspect-based-sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\nThis is a multilabel dataset with label details as follows:\n-HS : hate speech label;\n-Abusive : abusive language label;\n-HS_Individual : hate speech targeted to an individual;\n-HS_Group : hate speech targeted to a group;\n-HS_Religion : hate speech related to religion/creed;\n-HS_Race : hate speech related to race/ethnicity;\n-HS_Physical : hate speech related to physical/disability;\n-HS_Gender : hate speech related to gender/sexual orientation;\n-HS_Gender : hate related to other invective/slander;\n-HS_Weak : weak hate speech;\n-HS_Moderate : moderate hate speech;\n-HS_Strong : strong hate speech.", "citation": "@inproceedings{ibrohim-budi-2019-multi,\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\n    author = \"Ibrohim, Muhammad Okky  and\n      Budi, Indra\",\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\n    month = aug,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/W19-3506\",\n    doi = \"10.18653/v1/W19-3506\",\n    pages = \"46--57\",\n}", "cardData": null, "siblings": [], "_id": "6512bced86d74f32ed3763ec", "disabled": false, "gated": false, "likes": 0, "downloads": 50, "createdAt": "2023-09-26T11:13:49.000Z"}, {"id": "NusaCrowd/ted_en_id", "sha": "d15bc7196a41403c4472a488e42123929bd66b8b", "lastModified": "2023-09-26T12:30:00.000Z", "tags": ["language:ind", "language:eng", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En \u2192 Id) and Indonesian to English (Id \u2192 En) translations.", "citation": "@inproceedings{qi2018and,\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\n  pages={529--535},\n  year={2018}\n}\n\n@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\",\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\n}", "cardData": null, "siblings": [], "_id": "6512bcfd606fc2019225feaf", "disabled": false, "gated": false, "likes": 0, "downloads": 49, "createdAt": "2023-09-26T11:14:05.000Z"}, {"id": "NusaCrowd/indo_general_mt_en_id", "sha": "d87ebc684f8217588cc14a4ea341279e51624f2e", "lastModified": "2023-09-26T12:30:08.000Z", "tags": ["language:ind", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"", "citation": "@inproceedings{guntara-etal-2020-benchmarking,\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\n    author = \"Guntara, Tri Wahyu  and\n      Aji, Alham Fikri  and\n      Prasojo, Radityo Eko\",\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\n    pages = \"35--43\",\n    language = \"English\",\n    ISBN = \"979-10-95546-42-9\",\n}", "cardData": null, "siblings": [], "_id": "6512bd067fccffe1e9dd643b", "disabled": false, "gated": false, "likes": 0, "downloads": 45, "createdAt": "2023-09-26T11:14:14.000Z"}, {"id": "NusaCrowd/emot", "sha": "050d24a7a4b304da82495d71d33be6ce28bdd321", "lastModified": "2023-09-26T12:30:16.000Z", "tags": ["language:ind", "emotion-classification", "region:us"], "private": false, "author": "NusaCrowd", "description": "EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.", "citation": "@inproceedings{saputri2018emotion,\n  title={Emotion classification on indonesian twitter dataset},\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\n  pages={90--95},\n  year={2018},\n  organization={IEEE}\n}\n\n@inproceedings{wilie2020indonlu,\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n  pages={843--857},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6512bd0f5bdc2e35200944fc", "disabled": false, "gated": false, "likes": 0, "downloads": 53, "createdAt": "2023-09-26T11:14:23.000Z"}, {"id": "NusaCrowd/local_id_abusive", "sha": "984b6df9d09e120547582070cc9ef2a65fb7483d", "lastModified": "2023-09-26T12:30:53.000Z", "tags": ["language:jav", "language:sun", "license:unknown", "aspect-based-sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "This dataset is for abusive and hate speech detection, using Twitter text containing Javanese and Sundanese words.\n\n(from the publication source)\nThe Indonesian local language dataset collection was conducted using Twitter search API to collect the tweets and then\nimplemented using Tweepy Library. The tweets were collected using queries from the list of abusive words in Indonesian\ntweets. The abusive words were translated into local Indonesian languages, which are Javanese and Sundanese. The\ntranslated words are then used as queries to collect tweets containing Indonesian and local languages. The translation\nprocess involved native speakers for each local language. The crawling process has collected a total of more than 5000\ntweets. Then, the crawled data were filtered to get tweets that contain local\u2019s vocabulary and/or sentences in Javanese\nand Sundanese. Next, after the filtering process, the data will be labeled whether the tweets are labeled as hate speech\nand abusive language or not.", "citation": "@inproceedings{putri2021abusive,\n  title={Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},\n  author={Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},\n  booktitle={2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},\n  pages={461--465},\n  year={2021},\n  organization={International Workshop on Computer Science and Engineering (WCSE)},\n  abstract={Indonesia\u2019s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Na\u00efve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages.}\n}", "cardData": null, "siblings": [], "_id": "6512bd366e8b476552872022", "disabled": false, "gated": false, "likes": 0, "downloads": 97, "createdAt": "2023-09-26T11:15:02.000Z"}, {"id": "NusaCrowd/x_fact", "sha": "a2eb01df298164639bd21e925a8890cf8890dd6c", "lastModified": "2023-09-26T12:31:15.000Z", "tags": ["language:ara", "language:aze", "language:ben", "language:deu", "language:spa", "language:fas", "language:fra", "language:guj", "language:hin", "language:ind", "language:ita", "language:kat", "language:mar", "language:nor", "language:nld", "language:pan", "language:pol", "language:por", "language:ron", "language:rus", "language:sin", "language:srp", "language:sqi", "language:tam", "language:tur", "license:mit", "fact-checking", "region:us"], "private": false, "author": "NusaCrowd", "description": "X-FACT: the largest publicly available multilingual dataset for factual verification of naturally existing realworld claims.", "citation": "@inproceedings{gupta2021xfact,\n      title={{X-FACT: A New Benchmark Dataset for Multilingual Fact Checking}},\n      author={Gupta, Ashim and Srikumar, Vivek},\n      booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\",\n      month = jul,\n      year = \"2021\",\n      address = \"Online\",\n      publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "6512bd4f97bb5c96ae6785ad", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2023-09-26T11:15:27.000Z"}, {"id": "NusaCrowd/postag_su", "sha": "10a5c9c80bd0b7d194d47f7c71d5c9990842eea5", "lastModified": "2023-09-26T12:31:19.000Z", "tags": ["language:sun", "pos-tagging", "region:us"], "private": false, "author": "NusaCrowd", "description": "This dataset contains 3616 lines of Sundanese sentences taken from several online magazines (Mangle, Dewan Dakwah Jabar, and Balebat). Annotated with PoS Labels by several undergraduates of the Sundanese Language Education Study Program (PPBS), UPI Bandung.", "citation": "@data{FK2/VTAHRH_2022,\n    author = {ARDIYANTI SURYANI, ARIE and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\n    publisher = {Telkom University Dataverse},\n    title = {{PoSTagged Sundanese Monolingual Corpus}},\n    year = {2022},\n    version = {DRAFT VERSION},\n    doi = {10.34820/FK2/VTAHRH},\n    url = {https://doi.org/10.34820/FK2/VTAHRH}\n}\n\n@INPROCEEDINGS{7437678,\n  author={Suryani, Arie Ardiyanti and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\n  booktitle={2015 International Conference on Information Technology Systems and Innovation (ICITSI)},\n  title={Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian},\n  year={2015},\n  volume={},\n  number={},\n  pages={1-6},\n  doi={10.1109/ICITSI.2015.7437678}\n}", "cardData": null, "siblings": [], "_id": "6512bd5346ccaa374cd88f86", "disabled": false, "gated": false, "likes": 0, "downloads": 33, "createdAt": "2023-09-26T11:15:31.000Z"}, {"id": "NusaCrowd/indolem_nerui", "sha": "211fa0ccf619872d4d897e649c4bfaf45f9f1236", "lastModified": "2023-09-26T12:31:26.000Z", "tags": ["language:ind", "license:cc-by-4.0", "named-entity-recognition", "arxiv:2011.00677", "region:us"], "private": false, "author": "NusaCrowd", "description": "NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.", "citation": "@INPROCEEDINGS{8275098,\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\n  title={Automatic open domain information extraction from Indonesian text},\n  year={2017},\n  volume={},\n  number={},\n  pages={23-30},\n  doi={10.1109/IWBIS.2017.8275098}}\n\n@article{DBLP:journals/corr/abs-2011-00677,\n  author    = {Fajri Koto and\n               Afshin Rahimi and\n               Jey Han Lau and\n               Timothy Baldwin},\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\n               Model for Indonesian {NLP}},\n  journal   = {CoRR},\n  volume    = {abs/2011.00677},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2011.00677},\n  eprinttype = {arXiv},\n  eprint    = {2011.00677},\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "6512bd5c2df74f3d0b891c27", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2023-09-26T11:15:40.000Z"}, {"id": "NusaCrowd/tydiqa_id", "sha": "d3003c5d50a2269c994c6db283330e680ee6536a", "lastModified": "2023-09-26T12:31:34.000Z", "tags": ["language:ind", "question-answering", "region:us"], "private": false, "author": "NusaCrowd", "description": "TyDiQA dataset is collected from Wikipedia articles with human-annotated question and answer pairs covering 11 languages. \nThe question-answer pairs are collected for each language without using translation services.\nIndoNLG uses the Indonesian data from the secondary Gold passage task of the original TyDiQA dataset and\nrandomly split off 15% of the training data and use it as the test set.", "citation": "@article{clark-etal-2020-tydi,\n    title = \"{T}y{D}i {QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages\",\n    author = \"Clark, Jonathan H.  and\n      Choi, Eunsol  and\n      Collins, Michael  and\n      Garrette, Dan  and\n      Kwiatkowski, Tom  and\n      Nikolaev, Vitaly  and\n      Palomaki, Jennimaria\",\n    journal = \"Transactions of the Association for Computational Linguistics\",\n    volume = \"8\",\n    year = \"2020\",\n    address = \"Cambridge, MA\",\n    publisher = \"MIT Press\",\n    url = \"https://aclanthology.org/2020.tacl-1.30\",\n    doi = \"10.1162/tacl_a_00317\",\n    pages = \"454--470\",\n}\n\n@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\"\n}", "cardData": null, "siblings": [], "_id": "6512bd64f60393414aeccfb0", "disabled": false, "gated": false, "likes": 0, "downloads": 31, "createdAt": "2023-09-26T11:15:48.000Z"}, {"id": "NusaCrowd/korpus_nusantara", "sha": "c0b35be522278e418087ccba7878fb57c9ffcc1f", "lastModified": "2023-09-26T12:31:37.000Z", "tags": ["language:ind", "language:jav", "language:xdy", "language:bug", "language:sun", "language:mad", "language:bjn", "language:bbc", "language:msa", "language:min", "license:unknown", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "This parallel corpus was collected from several studies, assignments, and thesis of \nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \nThis corpus can be used freely for research purposes by citing the paper \nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\n\nThe dataset is a combination of multiple machine translation works from the author, \nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.", "citation": "@article{sujaini2020improving,\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\n  author={Sujaini, Herry},\n  journal={International Journal of Electrical and Computer Engineering},\n  volume={10},\n  number={2},\n  pages={2102},\n  year={2020},\n  publisher={IAES Institute of Advanced Engineering and Science}\n}", "cardData": null, "siblings": [], "_id": "6512bd69d66affb218ec7ea4", "disabled": false, "gated": false, "likes": 0, "downloads": 332, "createdAt": "2023-09-26T11:15:53.000Z"}, {"id": "NusaCrowd/casa", "sha": "657653b806d4dbb1cf2720b64101658a90747738", "lastModified": "2023-09-26T12:31:48.000Z", "tags": ["language:ind", "aspect-based-sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "CASA: An aspect-based sentiment analysis dataset consisting of around a thousand car reviews collected from multiple Indonesian online automobile platforms (Ilmania et al., 2018).\nThe dataset covers six aspects of car quality.\nWe define the task to be a multi-label classification task,\nwhere each label represents a sentiment for a single aspect with three possible values: positive, negative, and neutral.", "citation": "@INPROCEEDINGS{8629181,\n    author={Ilmania, Arfinda and Abdurrahman and Cahyawijaya, Samuel and Purwarianti, Ayu},\n    booktitle={2018 International Conference on Asian Language Processing (IALP)},\n    title={Aspect Detection and Sentiment Classification Using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis},\n    year={2018},\n    volume={},\n    number={},\n    pages={62-67},\n    doi={10.1109/IALP.2018.8629181\n}", "cardData": null, "siblings": [], "_id": "6512bd74606fc201922618e8", "disabled": false, "gated": false, "likes": 0, "downloads": 14, "createdAt": "2023-09-26T11:16:04.000Z"}, {"id": "NusaCrowd/posp", "sha": "b156530275f4a3933c9e68c442c07c1328f72eff", "lastModified": "2023-09-26T12:32:13.000Z", "tags": ["language:ind", "pos-tagging", "region:us"], "private": false, "author": "NusaCrowd", "description": "POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.", "citation": "@inproceedings{hoesen2018investigating,\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\n  author={Devin Hoesen and Ayu Purwarianti},\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\n  pages={35--38},\n  year={2018},\n  organization={IEEE}\n}\n\n@inproceedings{wilie2020indonlu,\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6512bd8bcc7684c9e4f6d44e", "disabled": false, "gated": false, "likes": 0, "downloads": 47, "createdAt": "2023-09-26T11:16:27.000Z"}, {"id": "NusaCrowd/nusax_senti", "sha": "eaba0344b80f4f72c5d5e6de0e1a476ad4d58d7c", "lastModified": "2023-09-26T12:32:17.000Z", "tags": ["language:ind", "language:ace", "language:ban", "language:bjn", "language:bbc", "language:bug", "language:jav", "language:mad", "language:min", "language:nij", "language:sun", "language:eng", "sentiment-analysis", "arxiv:2205.15960", "region:us"], "private": false, "author": "NusaCrowd", "description": "NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\n\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.", "citation": "@misc{winata2022nusax,\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\n      year={2022},\n      eprint={2205.15960},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "6512bd8f97bb5c96ae678f6d", "disabled": false, "gated": false, "likes": 0, "downloads": 659, "createdAt": "2023-09-26T11:16:31.000Z"}, {"id": "NusaCrowd/bible_en_id", "sha": "b097c588182c36af5479bd7970adde4247736c44", "lastModified": "2023-09-26T12:32:53.000Z", "tags": ["language:ind", "language:eng", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En \u2192 Id) and Indonesian to English (Id \u2192 En) translations.", "citation": "@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\",\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\n}", "cardData": null, "siblings": [], "_id": "6512bdba5bdc2e352009687b", "disabled": false, "gated": false, "likes": 0, "downloads": 52, "createdAt": "2023-09-26T11:17:14.000Z"}, {"id": "NusaCrowd/news_en_id", "sha": "d0218b4ce51e265291b37432c7d26876bc95e164", "lastModified": "2023-09-26T12:33:03.000Z", "tags": ["language:ind", "language:eng", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En \u2192 Id) and Indonesian to English (Id \u2192 En) translations.", "citation": "@inproceedings{guntara-etal-2020-benchmarking,\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\n    author = \"Guntara, Tri Wahyu  and\n      Aji, Alham Fikri  and\n      Prasojo, Radityo Eko\",\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\n    pages = \"35--43\",\n    language = \"English\",\n    ISBN = \"979-10-95546-42-9\",\n}", "cardData": null, "siblings": [], "_id": "6512bdc2c456f50350dfa47f", "disabled": false, "gated": false, "likes": 0, "downloads": 49, "createdAt": "2023-09-26T11:17:22.000Z"}, {"id": "NusaCrowd/indo_religious_mt_en_id", "sha": "3a88ae129d048e482cdf9b4209ef26ea0d85188a", "lastModified": "2023-09-26T12:33:20.000Z", "tags": ["language:ind", "language:eng", "machine-translation", "region:us"], "private": false, "author": "NusaCrowd", "description": "Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \\\"salat\\\" or \\\"shalat\\\", or repentance as \\\"tobat\\\" or \\\"taubat\\\".", "citation": "@inproceedings{guntara-etal-2020-benchmarking,\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\n    author = \"Guntara, Tri Wahyu  and\n      Aji, Alham Fikri  and\n      Prasojo, Radityo Eko\",\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\n    month = may,\n    year = \"2020\",\n    address = \"Marseille, France\",\n    publisher = \"European Language Resources Association\",\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\n    pages = \"35--43\",\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\n    language = \"English\",\n    ISBN = \"979-10-95546-42-9\",\n}", "cardData": null, "siblings": [], "_id": "6512bdd5d66affb218ec8f0a", "disabled": false, "gated": false, "likes": 0, "downloads": 52, "createdAt": "2023-09-26T11:17:41.000Z"}, {"id": "NusaCrowd/facqa", "sha": "dafe6a4c0e94236e5b98821333042f339c9cc93b", "lastModified": "2023-09-26T12:33:40.000Z", "tags": ["language:ind", "question-answering", "region:us"], "private": false, "author": "NusaCrowd", "description": "FacQA: The goal of the FacQA dataset is to find the answer to a question from a provided short passage from a news article.\nEach row in the FacQA dataset consists of a question, a short passage, and a label phrase, which can be found inside the\ncorresponding short passage. There are six categories of questions: date, location, name,\norganization, person, and quantitative.", "citation": "@inproceedings{purwarianti2007machine,\n  title={A Machine Learning Approach for Indonesian Question Answering System},\n  author={Ayu Purwarianti, Masatoshi Tsuchiya, and Seiichi Nakagawa},\n  booktitle={Proceedings of Artificial Intelligence and Applications },\n  pages={573--578},\n  year={2007}\n}", "cardData": null, "siblings": [], "_id": "6512bde9b3a463e17de931d6", "disabled": false, "gated": false, "likes": 0, "downloads": 97, "createdAt": "2023-09-26T11:18:01.000Z"}, {"id": "NusaCrowd/indolem_tweet_ordering", "sha": "70a736e55ab6c805e5bdc2460848a95d80e9a8b9", "lastModified": "2023-09-26T12:34:03.000Z", "tags": ["language:ind", "license:cc-by-4.0", "sentence-ordering", "arxiv:2011.00677", "region:us"], "private": false, "author": "NusaCrowd", "description": "IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\n\nTrain: 4327 threads\nDevelopment: 760 threads\nTest: 1521 threads", "citation": "@article{DBLP:journals/corr/abs-2011-00677,\n  author    = {Fajri Koto and\n               Afshin Rahimi and\n               Jey Han Lau and\n               Timothy Baldwin},\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\n               Model for Indonesian {NLP}},\n  journal   = {CoRR},\n  volume    = {abs/2011.00677},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2011.00677},\n  eprinttype = {arXiv},\n  eprint    = {2011.00677},\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}", "cardData": null, "siblings": [], "_id": "6512bded2df74f3d0b893b2b", "disabled": false, "gated": false, "likes": 0, "downloads": 22, "createdAt": "2023-09-26T11:18:05.000Z"}, {"id": "NusaCrowd/nusax_mt", "sha": "e8c93d801b00fc6ace7ce3326495881bdbb8c03f", "lastModified": "2023-09-26T12:34:19.000Z", "tags": ["language:ind", "language:ace", "language:ban", "language:bjn", "language:bbc", "language:bug", "language:jav", "language:mad", "language:min", "language:nij", "language:sun", "language:eng", "machine-translation", "arxiv:2205.15960", "region:us"], "private": false, "author": "NusaCrowd", "description": "NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\n\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.", "citation": "@misc{winata2022nusax,\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\n      year={2022},\n      eprint={2205.15960},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "6512bded7b2e843f39ae8576", "disabled": false, "gated": false, "likes": 0, "downloads": 345, "createdAt": "2023-09-26T11:18:05.000Z"}, {"id": "NusaCrowd/nergrit", "sha": "853f899dad8718f4ef90f45905118113201d1212", "lastModified": "2023-09-26T12:35:09.000Z", "tags": ["language:ind", "license:mit", "named-entity-recognition", "region:us"], "private": false, "author": "NusaCrowd", "description": "Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\nThe Named Entity Recognition contains 18 entities as follow:\n    'CRD': Cardinal\n    'DAT': Date\n    'EVT': Event\n    'FAC': Facility\n    'GPE': Geopolitical Entity\n    'LAW': Law Entity (such as Undang-Undang)\n    'LOC': Location\n    'MON': Money\n    'NOR': Political Organization\n    'ORD': Ordinal\n    'ORG': Organization\n    'PER': Person\n    'PRC': Percent\n    'PRD': Product\n    'QTY': Quantity\n    'REG': Religion\n    'TIM': Time\n    'WOA': Work of Art\n    'LAN': Language", "citation": "@misc{Fahmi_NERGRIT_CORPUS_2019,\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\ntitle = {{NERGRIT CORPUS}},\nurl = {https://github.com/grit-id/nergrit-corpus},\nyear = {2019}\n}", "cardData": null, "siblings": [], "_id": "6512bdef2a41af0d03ca8f95", "disabled": false, "gated": false, "likes": 0, "downloads": 28, "createdAt": "2023-09-26T11:18:07.000Z"}, {"id": "NusaCrowd/smsa", "sha": "be2687ef8d4dbbdbd511566ee588a261aac7b22a", "lastModified": "2023-09-26T12:33:48.000Z", "tags": ["language:ind", "sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral", "citation": "@INPROCEEDINGS{8904199,\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\n    year={2019},\n    pages={1-5},\n    doi={10.1109/ICAICTA.2019.8904199}\n}\n\n@inproceedings{wilie2020indonlu,\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n  pages={843--857},\n  year={2020}\n}", "cardData": null, "siblings": [], "_id": "6512c10692a52e002ab229fa", "disabled": false, "gated": false, "likes": 0, "downloads": 65, "createdAt": "2023-09-26T11:31:18.000Z"}, {"id": "NusaCrowd/indonlu_nergrit", "sha": "f1ef20cb03a78ecd15bd1a126ad14f14dab291a3", "lastModified": "2023-09-26T12:35:26.000Z", "tags": ["language:ind", "license:mit", "named-entity-recognition", "region:us"], "private": false, "author": "NusaCrowd", "description": "This NER dataset is taken from the Grit-ID repository, and the labels are spans in IOB chunking representation.\nThe dataset consists of three kinds of named entity tags, PERSON (name of person), PLACE (name of location), and\nORGANIZATION (name of organization).", "citation": "@inproceedings{wilie2020indonlu,\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n  year={2020}\n}\n@online{nergrit2019,\n  title={NERGrit Corpus},\n  author={NERGrit Developers},\n  year={2019},\n  url={https://github.com/grit-id/nergrit-corpus}\n}", "cardData": null, "siblings": [], "_id": "6512c109f60393414aed6af6", "disabled": false, "gated": false, "likes": 0, "downloads": 36, "createdAt": "2023-09-26T11:31:21.000Z"}, {"id": "NusaCrowd/nerp", "sha": "9d1cfc186d94314090e13b944033880b0b7c5b2f", "lastModified": "2023-09-26T12:34:00.000Z", "tags": ["language:ind", "named-entity-recognition", "region:us"], "private": false, "author": "NusaCrowd", "description": "The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\n- PER (name of person)\n- LOC (name of location)\n- IND (name of product or brand)\n- EVT (name of the event)\n- FNB (name of food and beverage).\nNERP makes use of the IOB chunking format, just like the TermA dataset.", "citation": "@inproceedings{hoesen2018investigating,\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\n  author={Hoesen, Devin and Purwarianti, Ayu},\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\n  pages={35--38},\n  year={2018},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "6512c37b332b85e7cf846987", "disabled": false, "gated": false, "likes": 0, "downloads": 25, "createdAt": "2023-09-26T11:41:47.000Z"}, {"id": "NusaCrowd/xpersona_id", "sha": "14ae440e20ef2b0eea6d3e9af9eaa040c7c2139e", "lastModified": "2023-09-26T12:34:30.000Z", "tags": ["language:ind", "dialogue-system", "region:us"], "private": false, "author": "NusaCrowd", "description": "XPersona is a multi-lingual extension of Persona-Chat. \nXPersona dataset includes persona conversations in six different languages other than English for building and evaluating multilingual personalized agents.", "citation": "@article{lin2020xpersona,\n  title={XPersona: Evaluating multilingual personalized chatbot},\n  author={Lin, Zhaojiang and Liu, Zihan and Winata, Genta Indra and Cahyawijaya, Samuel and Madotto, Andrea and Bang, Yejin and Ishii, Etsuko and Fung, Pascale},\n  journal={arXiv preprint arXiv:2003.07568},\n  year={2020}\n}\n@inproceedings{cahyawijaya-etal-2021-indonlg,\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\n    author = \"Cahyawijaya, Samuel  and\n      Winata, Genta Indra  and\n      Wilie, Bryan  and\n      Vincentio, Karissa  and\n      Li, Xiaohong  and\n      Kuncoro, Adhiguna  and\n      Ruder, Sebastian  and\n      Lim, Zhi Yuan  and\n      Bahar, Syafri  and\n      Khodra, Masayu  and\n      Purwarianti, Ayu  and\n      Fung, Pascale\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\n    pages = \"8875--8898\"\n}", "cardData": null, "siblings": [], "_id": "6512c39df60393414aede558", "disabled": false, "gated": false, "likes": 0, "downloads": 18, "createdAt": "2023-09-26T11:42:21.000Z"}, {"id": "NusaCrowd/ud_id_csui", "sha": "7ed83c46821f31eb7b49395d798a8d0822584eb0", "lastModified": "2023-09-26T12:34:34.000Z", "tags": ["language:ind", "dependency-parsing", "machine-translation", "pos-tagging", "region:us"], "private": false, "author": "NusaCrowd", "description": "UD Indonesian-CSUI is a conversion from an Indonesian constituency treebank in the Penn Treebank format named Kethu that was also a conversion from a constituency treebank built by Dinakaramani et al. (2015).\nThis treebank is named after the place where treebanks were built: Faculty of Computer Science (CS), Universitas Indonesia (UI).\n\nAbout this treebank:\n- Genre is news in formal Indonesian (the majority is economic news)\n- 1030 sentences (28K words) divided into testing and training dataset of around 10K words and around 18K words respectively.\n- Average of 27.4 words per-sentence.", "citation": "@article {10.3844/jcssp.2020.1585.1597,\nauthor = {Alfina, Ika and Budi, Indra and Suhartanto, Heru},\ntitle = {Tree Rotations for Dependency Trees: Converting the Head-Directionality of Noun Phrases},\narticle_type = {journal},\nvolume = {16},\nnumber = {11},\nyear = {2020},\nmonth = {Nov},\npages = {1585-1597},\ndoi = {10.3844/jcssp.2020.1585.1597},\nurl = {https://thescipub.com/abstract/jcssp.2020.1585.1597},\njournal = {Journal of Computer Science},\npublisher = {Science Publications}\n}", "cardData": null, "siblings": [], "_id": "6512c3a1c1fbded3b171be4c", "disabled": false, "gated": false, "likes": 0, "downloads": 19, "createdAt": "2023-09-26T11:42:25.000Z"}, {"id": "NusaCrowd/keps", "sha": "dbe0267d6f46d59ec717198e49bf0743f88c2864", "lastModified": "2023-09-26T12:34:57.000Z", "tags": ["language:ind", "keyword-extraction", "region:us"], "private": false, "author": "NusaCrowd", "description": "The KEPS dataset (Mahfuzh, Soleman and Purwarianti, 2019) consists of text from Twitter\ndiscussing banking products and services and is written in the Indonesian language. A phrase\ncontaining important information is considered a keyphrase. Text may contain one or more\nkeyphrases since important phrases can be located at different positions.\n- tokens: a list of string features.\n- seq_label: a list of classification labels, with possible values including O, B, I.\nThe labels use Inside-Outside-Beginning (IOB) tagging.", "citation": "@inproceedings{mahfuzh2019improving,\n  title={Improving Joint Layer RNN based Keyphrase Extraction by Using Syntactical Features},\n  author={Miftahul Mahfuzh, Sidik Soleman, and Ayu Purwarianti},\n  booktitle={Proceedings of the 2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\n  pages={1--6},\n  year={2019},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "6512c3b343cbd0966c0a7b42", "disabled": false, "gated": false, "likes": 0, "downloads": 31, "createdAt": "2023-09-26T11:42:43.000Z"}, {"id": "NusaCrowd/sentiment_nathasa_review", "sha": "8c6bf40625b51acaed57e7d76a4d219a1859e6af", "lastModified": "2023-09-26T12:35:04.000Z", "tags": ["language:ind", "license:unknown", "sentiment-analysis", "region:us"], "private": false, "author": "NusaCrowd", "description": "Customer Review (Natasha Skincare) is a customers emotion dataset, with amounted to 19,253 samples with the division for each class is 804 joy, 43 surprise, 154 anger, 61 fear, 287 sad, 167 disgust, and 17736 no-emotions.", "citation": "@article{nurlaila2018classification,\n  title={CLASSIFICATION OF CUSTOMERS EMOTION USING NA{\\\"I}VE BAYES CLASSIFIER (Case Study: Natasha Skin Care)},\n  author={Nurlaila, Afifah and Wiranto, Wiranto and Saptono, Ristu},\n  journal={ITSMART: Jurnal Teknologi dan Informasi},\n  volume={6},\n  number={2},\n  pages={92--97},\n  year={2018}\n}", "cardData": null, "siblings": [], "_id": "6512c3bc42a541c1751b7922", "disabled": false, "gated": false, "likes": 1, "downloads": 58, "createdAt": "2023-09-26T11:42:52.000Z"}, {"id": "bigbio/czi_drsm", "sha": "9d8704e148cca18e4351f7329702806c0549564a", "lastModified": "2023-11-23T12:33:19.000Z", "tags": ["multilinguality:monolingual", "language:en", "license:cc0-1.0", "region:us"], "private": false, "author": "bigbio", "description": "Research Article document classification dataset based on aspects of disease research. Currently, the dataset consists of three subsets: \n\n(A) classifies title/abstracts of papers into most popular subtypes of clinical, basic, and translational papers (~20k papers); \n\n    - Clinical Characteristics, Disease Pathology, and Diagnosis - \n        Text that describes (A) symptoms, signs, or \u2018phenotype\u2019 of a disease; \n        (B) the effects of the disease on patient organs, tissues, or cells; \n        (C) the results of clinical tests that reveal pathology (including\n        biomarkers); (D) research that use this information to figure out\n        a diagnosis.\n    - Therapeutics in the clinic - \n        Text describing how treatments work in the clinic (but not in a clinical trial).\n    - Disease mechanism - \n        Text that describes either (A) mechanistic involvement of specific genes in disease \n        (deletions, gain of function, etc); (B) how molecular signalling or metabolism \n        binding, activating, phosphorylation, concentration increase, etc.) \n        are involved in the mechanism of a disease; or (C) the physiological \n        mechanism of disease at the level of tissues, organs, and body systems.\n    - Patient-Based Therapeutics - \n        Text describing (A) Clinical trials (studies of therapeutic measures being \n        used on patients in a clinical trial); (B) Post Marketing Drug Surveillance \n        (effects of a drug after approval in the general population or as part of \n        \u2018standard healthcare\u2019); (C) Drug repurposing (how a drug that has been \n        approved for one use is being applied to a new disease).\n\n(B) identifies whether a title/abstract of a paper describes substantive research into Quality of Life (~10k papers); \n    \n    - -1 - the paper is not a primary experimental study in rare disease\n    - 0 - the study does not directly investigate quality of life\n    - 1 - the study investigates qol but not as its primary contribution\n    - 2 - the study's primary contribution centers on quality of life measures\n\n(C) identifies if a paper is a natural history study (~10k papers). \n`   \n    - -1 - the paper is not a primary experimental study in rare disease\n    - 0 - the study is not directly investigating the natural history of a disease\n    - 1 - the study includes some elements a natural history but not as its primary contribution\n    - 2 - the study's primary contribution centers on observing the time course of a rare disease\n    \nThese classifications are particularly relevant in rare disease research, a field that is generally understudied.", "citation": "@article{,\n  author    = {},\n  title     = {},\n  journal   = {},\n  volume    = {},\n  year      = {},\n  url       = {},\n  doi       = {},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "6512db27f60393414af23773", "disabled": false, "gated": false, "likes": 0, "downloads": 42, "createdAt": "2023-09-26T13:22:47.000Z"}, {"id": "cdminix/librispeech-phones-and-mel", "sha": "4ef8469481c2a4459353c216f92d2a56437d31a1", "lastModified": "2023-10-24T08:06:48.000Z", "tags": ["task_categories:automatic-speech-recognition", "size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "cdminix", "description": "Dataset containing Mel Spectrograms, Prosody and Phone Alignments for the LibriSpeech dataset.", "citation": "@inproceedings{panayotov2015librispeech,\n  title={Librispeech: an asr corpus based on public domain audio books},\n  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},\n  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},\n  pages={5206--5210},\n  year={2015},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "6512f0750d463b73dcee2fce", "disabled": false, "gated": false, "likes": 0, "downloads": 33, "createdAt": "2023-09-26T14:53:41.000Z"}, {"id": "maveriq/bigbenchhard", "sha": "d53c5b10a77edeb29da195f47e6086b29f2f7f74", "lastModified": "2023-09-29T08:24:12.000Z", "tags": ["task_categories:question-answering", "task_categories:token-classification", "task_categories:text2text-generation", "task_categories:text-classification", "size_categories:n<1K", "language:en", "license:mit", "arxiv:2210.09261", "region:us"], "private": false, "author": "maveriq", "description": "BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65% of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models?", "citation": "@article{suzgun2022challenging,\n  title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},\n  author={Suzgun, Mirac and Scales, Nathan and Sch{\\\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and and Wei, Jason},\n  journal={arXiv preprint arXiv:2210.09261},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "651339806e06b81de3f902bb", "disabled": false, "gated": false, "likes": 1, "downloads": 598, "createdAt": "2023-09-26T20:05:20.000Z"}, {"id": "oserikov/arabic_billion_words", "sha": "7c83a9c2f8e95aed791698d14d6c2920ecb5d2bb", "lastModified": "2023-09-27T11:18:25.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:found", "language_creators:found", "multilinguality:monolingual", "size_categories:100K<n<1M", "size_categories:10K<n<100K", "size_categories:1M<n<10M", "source_datasets:original", "language:ar", "license:unknown", "arxiv:1611.04033", "region:us"], "private": false, "author": "oserikov", "description": "THIS IS A FORK FOR LOCAL USAGE.\nAbu El-Khair Corpus is an Arabic text corpus, that includes more than five million newspaper articles.\nIt contains over a billion and a half words in total, out of which, there are about three million unique words.\nThe corpus is encoded with two types of encoding, namely: UTF-8, and Windows CP-1256.\nAlso it was marked with two mark-up languages, namely: SGML, and XML.", "citation": "@article{el20161,\n  title={1.5 billion words arabic corpus},\n  author={El-Khair, Ibrahim Abu},\n  journal={arXiv preprint arXiv:1611.04033},\n  year={2016}\n}", "cardData": null, "siblings": [], "_id": "65140a4a76d09e1b34c1948b", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2023-09-27T10:56:10.000Z"}, {"id": "shunk031/DrawBench", "sha": "6324c60311a1f0754c4c4ff00da36d8e77b6ea29", "lastModified": "2023-09-27T13:13:31.000Z", "tags": ["task_categories:text-to-image", "annotations_creators:crowdsourced", "multilinguality:monolingual", "size_categories:n<1K", "source_datasets:original", "language:en", "license:unknown", "arxiv:2205.11487", "region:us"], "private": false, "author": "shunk031", "description": "DrawBench is a comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models. This benchmark contains 11 categories of prompts, testing different capabilities of models such as the ability to faithfully render different colors, numbers of objects, spatial relations, text in the scene, and unusual interactions between objects.\\", "citation": "@article{saharia2022photorealistic,\n  title={Photorealistic text-to-image diffusion models with deep language understanding},\n  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},\n  journal={Advances in Neural Information Processing Systems},\n  volume={35},\n  pages={36479--36494},\n  year={2022}\n}", "cardData": null, "siblings": [], "_id": "651429d017b233ef734a10de", "disabled": false, "gated": false, "likes": 1, "downloads": 328, "createdAt": "2023-09-27T13:10:40.000Z"}, {"id": "TrainingDataPro/generated-e-mail-spam", "sha": "323e03758cc13d928b60fd10d95b5cfb4bf46ddc", "lastModified": "2023-09-28T15:29:45.000Z", "tags": ["task_categories:text-generation", "task_categories:text-classification", "language:en", "license:cc-by-nc-nd-4.0", "code", "finance", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset consists of a **CSV file** containing of 300 generated email spam messages.\nEach row in the file represents a separate email message, its *title and text.*\nThe dataset aims to facilitate the analysis and detection of spam emails.\nThe dataset can be used for various purposes, such as *training machine learning\nalgorithms to classify and filter spam emails, studying spam email patterns,\nor analyzing text-based features of spam messages*.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {generated-e-mail-spam},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "65158f579c826c092b5c5bc8", "disabled": false, "gated": false, "likes": 1, "downloads": 41, "createdAt": "2023-09-28T14:36:07.000Z"}, {"id": "RealTimeData/wikitext_alltime", "sha": "d71bad3b7de79d1cd462b4c3a7127994950a689b", "lastModified": "2023-10-12T17:26:51.000Z", "tags": ["license:cc-by-2.0", "region:us"], "private": false, "author": "RealTimeData", "description": "This dataset contains Wikipedia articles of 419 selected pages from 2017 to 2022. The articles are arraged by month. Access the specific month by using the format \"YYYY-MM\" as config. Such as load_dataset(\"RealTimeData/wikitext_alltime\", \"2021-1\").", "citation": "@misc{li2023estimating,\n      title={Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation}, \n      author={Yucheng Li},\n      year={2023},\n      eprint={2309.10677},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "651887bcb239dc7a34e141eb", "disabled": false, "gated": false, "likes": 0, "downloads": 183, "createdAt": "2023-09-30T20:40:28.000Z"}, {"id": "tomaarsen/MultiCoNER", "sha": "04fafbabb7a36defcfd400ed2fe5504c10fdf4ab", "lastModified": "2023-10-01T19:39:19.000Z", "tags": ["task_categories:token-classification", "size_categories:100K<n<1M", "language:bn", "language:de", "language:en", "language:es", "language:fa", "language:hi", "language:ko", "language:nl", "language:ru", "language:tr", "language:zh", "language:multilingual", "license:cc-by-4.0", "multiconer", "ner", "multilingual", "named entity recognition", "arxiv:2208.14536", "region:us"], "private": false, "author": "tomaarsen", "description": "We present MultiCoNER, a large multilingual dataset for Named Entity Recognition that covers 3 domains (Wiki sentences, questions, and search queries) across 11 languages, as well as multilingual and code-mixing subsets. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text), syntactically complex entities like movie titles, and long-tail entity distributions. The 26M token dataset is compiled from public resources using techniques such as heuristic-based sentence sampling, template extraction and slotting, and machine translation. We applied two NER models on our dataset: a baseline XLM-RoBERTa model, and a state-of-the-art GEMNET model that leverages gazetteers. The baseline achieves moderate performance (macro-F1=54%), highlighting the difficulty of our data. GEMNET, which uses gazetteers, improvement significantly (average improvement of macro-F1=+30%). MultiCoNER poses challenges even for large pre-trained language models, and we believe that it can help further research in building robust NER systems. MultiCoNER is publicly available at https://registry.opendata.aws/multiconer/ and we hope that this resource will help advance research in various aspects of NER.", "citation": "@misc{malmasi2022multiconer,\n    title={MultiCoNER: A Large-scale Multilingual dataset for Complex Named Entity Recognition}, \n    author={Shervin Malmasi and Anjie Fang and Besnik Fetahu and Sudipta Kar and Oleg Rokhlenko},\n    year={2022},\n    eprint={2208.14536},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}", "cardData": null, "siblings": [], "_id": "6519be0334c269625390460f", "disabled": false, "gated": false, "likes": 0, "downloads": 168, "createdAt": "2023-10-01T18:44:19.000Z"}, {"id": "BrunoHays/multilingual-TEDX-fr", "sha": "6e6cdc70126070004839318116aeee3dd5daa398", "lastModified": "2023-10-23T09:41:59.000Z", "tags": ["task_categories:automatic-speech-recognition", "size_categories:100K<n<1M", "language:fr", "license:cc-by-nc-nd-4.0", "region:us"], "private": false, "author": "BrunoHays", "description": "French subpart of the multilingual TEDX dataset", "citation": "  @inproceedings{salesky2021mtedx,\n    title={Multilingual TEDx Corpus for Speech Recognition and Translation},\n    author={Elizabeth Salesky and Matthew Wiesner and Jacob Bremerman and Roldano Cattoni and Matteo Negri and Marco Turchi and Douglas W. Oard and Matt Post},\n    booktitle={Proceedings of Interspeech},\n    year={2021},\n  }", "cardData": null, "siblings": [], "_id": "651a8fdda28f86d3e922126c", "disabled": false, "gated": false, "likes": 0, "downloads": 19, "createdAt": "2023-10-02T09:39:41.000Z"}, {"id": "DykeF/NCTCRCHE100K", "sha": "7771f62f55074f215f02f609adbdf90c802a4fed", "lastModified": "2023-10-04T19:37:15.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "DykeF", "description": "This is a set of 100,000 non-overlapping image patches from hematoxylin & eosin (H&E) stained histological images of human colorectal cancer (CRC) and normal tissue.\nAll images are 224x224 pixels (px) at 0.5 microns per pixel (MPP). All images are color-normalized using Macenko's method (http://ieeexplore.ieee.org/abstract/document/5193250/, DOI 10.1109/ISBI.2009.5193250).\nTissue classes are: Adipose (ADI), background (BACK), debris (DEB), lymphocytes (LYM), mucus (MUC), smooth muscle (MUS), normal colon mucosa (NORM), cancer-associated stroma (STR), colorectal adenocarcinoma epithelium (TUM).\nThese images were manually extracted from N=86 H&E stained human cancer tissue slides from formalin-fixed paraffin-embedded (FFPE) samples from the NCT Biobank (National Center for Tumor Diseases, Heidelberg, Germany) and the UMM pathology archive (University Medical Center Mannheim, Mannheim, Germany). Tissue samples contained CRC primary tumor slides and tumor tissue from CRC liver metastases; normal tissue classes were augmented with non-tumorous regions from gastrectomy specimen to increase variability.", "citation": "Kather, Jakob Nikolas, Halama, Niels, & Marx, Alexander. (2018). 100,000 histological images of human colorectal cancer and healthy tissue (v0.1) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.1214456", "cardData": null, "siblings": [], "_id": "651bc5e06e0cfc098daa1f53", "disabled": false, "gated": false, "likes": 0, "downloads": 56, "createdAt": "2023-10-03T07:42:24.000Z"}, {"id": "TrainingDataPro/people-with-guns-segmentation-and-detection", "sha": "23032e9db65dc0d47844c5eda062854ad838cef4", "lastModified": "2023-10-12T07:07:40.000Z", "tags": ["task_categories:image-segmentation", "task_categories:object-detection", "language:en", "license:cc-by-nc-nd-4.0", "code", "finance", "legal", "region:us"], "private": false, "author": "TrainingDataPro", "description": "The dataset consists of photos depicting **individuals holding guns**. It specifically\nfocuses on the **segmentation** of guns within these images and the **detection** of\npeople holding guns.\nEach image in the dataset presents a different scenario, capturing individuals from\nvarious *backgrounds, genders, and age groups in different poses* while holding guns.\nThe dataset is an essential resource for the development and evaluation of computer\nvision models and algorithms in fields related to *firearms recognition, security\nsystems, law enforcement, and safety analysis*.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {people-with-guns-segmentation-and-detection},\nauthor = {TrainingDataPro},\nyear = {2023}\n}", "cardData": null, "siblings": [], "_id": "651c2983650b79ca136b7f6b", "disabled": false, "gated": false, "likes": 1, "downloads": 16, "createdAt": "2023-10-03T14:47:31.000Z"}, {"id": "mathiaszinnen/odor", "sha": "1eb220031a0ea9a6c43e19613e8da45621ddaba2", "lastModified": "2023-11-20T09:32:44.000Z", "tags": ["task_categories:object-detection", "size_categories:1K<n<10K", "language:en", "license:cc-by-4.0", "fine grained detection", "small object detection", "art", "smell", "olfaction", "computational humanities", "region:us"], "private": false, "author": "mathiaszinnen", "description": "Real-world applications of computer vision in the humanities require algorithms to be robust against artistic abstraction, peripheral objects, and subtle differences between fine-grained target classes. Existing datasets provide instance-level\nannotations on artworks but are generally biased towards the image centre and limited with regard to detailed object classes. The proposed ODOR dataset fills this gap, offering 38,116 object-level annotations across 4,712 images, spanning an extensive set of 139 fine-grained categories. Conducting a statistical analysis, we showcase challenging dataset properties, such as a detailed set of categories, dense and overlapping objects, and spatial distribution over the whole image canvas. Furthermore, we provide an extensive baseline analysis for object detection models and highlight the challenging properties of the dataset through a set of secondary studies. Inspiring further research on artwork object detection and broader visual cultural heritage studies, the dataset challenges researchers to explore the intersection of object recognition and smell perception.", "citation": "TBD", "cardData": null, "siblings": [], "_id": "651d27e5399125a79357dd53", "disabled": false, "gated": false, "likes": 0, "downloads": 53, "createdAt": "2023-10-04T08:52:53.000Z"}, {"id": "jfrei/GPTNERMED", "sha": "53875194da57f248508238be54cee08024119a4d", "lastModified": "2023-10-08T22:05:18.000Z", "tags": ["task_categories:token-classification", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:machine-generated", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:de", "bio", "biomedical", "medical", "clinical", "arxiv:2208.14493", "region:us"], "private": false, "author": "jfrei", "description": "GPTNERMED is a novel open synthesized dataset and neural named-entity-recognition (NER) model for German texts in medical natural language processing (NLP).", "citation": "@article{FREI2023104478,\ntitle = {Annotated dataset creation through large language models for non-english medical NLP},\njournal = {Journal of Biomedical Informatics},\nvolume = {145},\npages = {104478},\nyear = {2023},\nissn = {1532-0464},\ndoi = {https://doi.org/10.1016/j.jbi.2023.104478},\nurl = {https://www.sciencedirect.com/science/article/pii/S1532046423001995},\nauthor = {Johann Frei and Frank Kramer},\nkeywords = {Natural language processing, Information extraction, Named entity recognition, Data augmentation, Knowledge distillation, Medication detection},\nabstract = {Obtaining text datasets with semantic annotations is an effortful process, yet crucial for supervised training in natural language processing (NLP). In general, developing and applying new NLP pipelines in domain-specific contexts for tasks often requires custom-designed datasets to address NLP tasks in a supervised machine learning fashion. When operating in non-English languages for medical data processing, this exposes several minor and major, interconnected problems such as the lack of task-matching datasets as well as task-specific pre-trained models. In our work, we suggest to leverage pre-trained large language models for training data acquisition in order to retrieve sufficiently large datasets for training smaller and more efficient models for use-case-specific tasks. To demonstrate the effectiveness of your approach, we create a custom dataset that we use to train a medical NER model for German texts, GPTNERMED, yet our method remains language-independent in principle. Our obtained dataset as well as our pre-trained models are publicly available at https://github.com/frankkramer-lab/GPTNERMED.}\n}", "cardData": null, "siblings": [], "_id": "651eae9ab50fbdc7383daac3", "disabled": false, "gated": false, "likes": 0, "downloads": 21, "createdAt": "2023-10-05T12:39:54.000Z"}, {"id": "Random-Mary-Smith/port_data_random", "sha": "d9b9ae7d4d3ef2e8b8bcb23d1875a91067671fd5", "lastModified": "2023-11-02T19:06:47.000Z", "tags": ["size_categories:1M<n<10M", "language:pt", "license:mit", "doi:10.57967/hf/1278", "region:us"], "private": false, "author": "Random-Mary-Smith", "description": "This Language Identification Dataset provides a multi-domain corpus in European and Brazilian Portuguese. \nThe repository is an anonymyzed version to support a submsission to the EACL 2024 conference.\nFurther information about the dataset can be soon found in the paper: Enhancing Portuguese Variants Identification with Domain-Agnostic Ensemble Approaches", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "651f037398759d6ec3443c60", "disabled": false, "gated": false, "likes": 0, "downloads": 844, "createdAt": "2023-10-05T18:41:55.000Z"}, {"id": "Otter-AI/MMVet", "sha": "a16789299ee2f1a4a7659fadf515bbb2d468077d", "lastModified": "2023-10-06T15:44:13.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Otter-AI", "description": "We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combination. For evaluation metrics, we propose an LLM-based evaluator for open-ended outputs. The evaluator enables the evaluation across different question types and answer styles, resulting in a unified scoring metric. We evaluate representative LMMs on MM-Vet, providing insights into the capabilities of different LMM system paradigms and models. Code and data are available at this https URL.", "citation": "@article{yu2023mm,\n  title={Mm-vet: Evaluating large multimodal models for integrated capabilities},\n  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},\n  journal={arXiv preprint arXiv:2308.02490},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "65201fac34420556f4ac586c", "disabled": false, "gated": false, "likes": 1, "downloads": 86, "createdAt": "2023-10-06T14:54:36.000Z"}, {"id": "miojizzy/genshin_artifact_recognize_datasets", "sha": "c79d2a730b6f5da4e34d2e40e4afec9b09add7df", "lastModified": "2023-10-15T14:03:39.000Z", "tags": ["region:us"], "private": false, "author": "miojizzy", "description": "Monster Hunter Rise images and labels.", "citation": null, "cardData": null, "siblings": [], "_id": "65239a4354967a3a49dcdac4", "disabled": false, "gated": false, "likes": 0, "downloads": 10, "createdAt": "2023-10-09T06:14:27.000Z"}, {"id": "cannlytics/cannabis_analytes", "sha": "ac6f5dc959cbf3110a97c16e01e9690eab5af1dc", "lastModified": "2023-10-10T23:20:30.000Z", "tags": ["license:cc-by-4.0", "region:us"], "private": false, "author": "cannlytics", "description": "This dataset consists of analyte data for various analytes that are regularly tested for in cannabis. The dataset consists of sub-datasets for each type of test, as well as a sub-dataset that includes all analytes.", "citation": "@inproceedings{cannlytics2023cannabis_analytes,\n  author    = {Skeate, Keegan and O'Sullivan-Sutherland, Candace},\n  title     = {Cannabis Analytes},\n  booktitle = {Cannabis Data Science},\n  month     = {October},\n  year      = {2023},\n  address   = {United States of America},\n  publisher = {Cannlytics}\n}", "cardData": null, "siblings": [], "_id": "6525c11c27bc44de70f6c928", "disabled": false, "gated": false, "likes": 1, "downloads": 36, "createdAt": "2023-10-10T21:24:44.000Z"}, {"id": "Otter-AI/MathVista", "sha": "17387a1d0305db0cc8c9bb5a7f9236cbaad681b0", "lastModified": "2023-10-30T18:13:46.000Z", "tags": ["region:us"], "private": false, "author": "Otter-AI", "description": "MathVista is a consolidated Mathematical reasoning benchmark within Visual contexts. It consists of three newly created datasets, IQTest, FunctionQA, and PaperQA, which address the missing visual domains and are tailored to evaluate logical reasoning on puzzle test figures, algebraic reasoning over functional plots, and scientific reasoning with academic paper figures, respectively. It also incorporates 9 MathQA datasets and 19 VQA datasets from the literature, which significantly enrich the diversity and complexity of visual perception and mathematical reasoning challenges within our benchmark. In total, MathVista includes 6,141 examples collected from 31 different datasets.", "citation": "@article{lu2023mathvista,\n  title={MATHVISTA: EVALUATING MATHEMATICAL REASON-ING OF FOUNDATION MODELS IN VISUAL CONTEXTS},\n  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},\n  journal={arXiv preprint arXiv:2310.02255},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "6527ab32ca2fe7746064af1c", "disabled": false, "gated": false, "likes": 1, "downloads": 68, "createdAt": "2023-10-12T08:15:46.000Z"}, {"id": "coastalcph/fair-rationales", "sha": "a97b744c8a01f77cfee745183bbf8ef85a07b691", "lastModified": "2023-10-13T12:54:10.000Z", "tags": ["task_categories:text-classification", "task_ids:sentiment-classification", "task_ids:open-domain-qa", "annotations_creators:crowdsourced", "source_datasets:extended", "language:en", "license:mit", "bias", "fairness", "rationale", "demographic", "region:us"], "private": false, "author": "coastalcph", "description": "Explainability methods are used to benchmark\nthe extent to which model predictions align\nwith human rationales i.e., are 'right for the\nright reasons'. Previous work has failed to acknowledge, however, \nthat what counts as a rationale is sometimes subjective. This paper\npresents what we think is a first of its kind, a\ncollection of human rationale annotations augmented with the annotators demographic information.", "citation": "@inproceedings{thorn-jakobsen-etal-2023-right,\n    title = {Being Right for Whose Right Reasons?},\n    author = {Thorn Jakobsen, Terne Sasha  and\n      Cabello, Laura  and\n      S{\\o}gaard, Anders},\n    booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},\n    year = {2023},\n    publisher = {Association for Computational Linguistics},\n    url = {https://aclanthology.org/2023.acl-long.59},\n    doi = {10.18653/v1/2023.acl-long.59},\n    pages = {1033--1054}\n}", "cardData": null, "siblings": [], "_id": "6527df4612a054f05f67b42a", "disabled": false, "gated": false, "likes": 3, "downloads": 31, "createdAt": "2023-10-12T11:57:58.000Z"}, {"id": "DewiBrynJones/banc-trawsgrifiadau-bangor", "sha": "b477717c43f51adc6f2e38d846212349052786c2", "lastModified": "2023-11-09T08:29:59.000Z", "tags": ["size_categories:10K<n<100K", "language:cy", "license:cc0-1.0", "verbatim transcriptions", "speech recognition", "region:us"], "private": false, "author": "DewiBrynJones", "description": "Dyma fanc o 25 awr 34 munud a 24 eiliad o segmentau o leferydd naturiol dros hanner cant o gyfranwyr \nar ffurf ffeiliau mp3, ynghyd \u00e2 thrawsgrifiadau 'verbatim' cyfatebol o\u2019r lleferydd ar ffurf ffeil .tsv. \nMae'r mwyafrif o'r lleferydd yn leferydd digymell, naturiol. Dosbarthwn y deunydd hwn o dan drwydded \nagored CC0.\n\nThis resource is a bank of 25 hours 34 minutes and 24 seconds of segments of natural speech from over 50 \ncontributors in mp3 file format, together with corresponding 'verbatim' transcripts of the speech in .tsv \nfile format. The majority of the speech is spontaneous, natural speech. We distribute this material under \na CC0 open license.", "citation": "", "cardData": null, "siblings": [], "_id": "6527ffd935a5bddc325ce286", "disabled": false, "gated": false, "likes": 0, "downloads": 27, "createdAt": "2023-10-12T14:16:57.000Z"}, {"id": "Otter-AI/POPE", "sha": "a269f61ffb9ea81dec9d756b80f3c67ebec0a9d0", "lastModified": "2023-10-13T02:58:50.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Otter-AI", "description": "We propose POPE, an improved evaluation method for object hallucination by proposing a polling-based query method. Code and data are available at this https URL.", "citation": "@InProceedings{Li-hallucination-2023,\n  author =  {Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao and Ji-Rong Wen},\n  title =   {Evaluating Object Hallucination in Large Vision-Language Models},\n  year =    {2023},  \n  journal={arXiv preprint arXiv:2305.10355},\n  url={https://arxiv.org/pdf/2305.10355}\n}", "cardData": null, "siblings": [], "_id": "6528b0f93efa1da5ddd195f8", "disabled": false, "gated": false, "likes": 1, "downloads": 22, "createdAt": "2023-10-13T02:52:41.000Z"}, {"id": "hezarai/persian-license-plate-v1", "sha": "a655d946489ff657491d5154a690d1d95a628053", "lastModified": "2023-11-09T10:36:12.000Z", "tags": ["task_categories:image-to-text", "language:fa", "region:us"], "private": false, "author": "hezarai", "description": "Persian Licensee plate dataset. Primarily taken from AmirKabir University Challenge. \nAnnotation are provided by the authors", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "652a8fe13a416e1f21996416", "disabled": false, "gated": false, "likes": 0, "downloads": 197, "createdAt": "2023-10-14T12:56:01.000Z"}, {"id": "bigbio/sem_eval_2024_task_2", "sha": "60b7982ba94252ac6ea913428c7fc77eb1727886", "lastModified": "2023-11-06T16:42:11.000Z", "tags": ["multilinguality:monolingual", "language:en", "region:us"], "private": false, "author": "bigbio", "description": "(Copied from dataset homepage)\n## Dataset\nThe statements and evidence are generated by clinical domain experts, clinical trial organisers, and research oncologists from the Cancer Research UK Manchester Institute and the Digital Experimental Cancer Medicine Team. There are a total of (TBD) statements split evenly across the different sections and classes.\n## Description\nEach Clinical Trial Report (CTR) consists of 4 sections:\nEligibility criteria - A set of conditions for patients to be allowed to take part in the clinical trial\nIntervention - Information concerning the type, dosage, frequency, and duration of treatments being studied.\nResults - Number of participants in the trial, outcome measures, units, and the results.\nAdverse events - These are signs and symptoms observed in patients during the clinical trial.\nFor this task, each CTR may contain 1-2 patient groups, called cohorts or arms. These groups may receive different treatments, or have different baseline characteristics.", "citation": "@article{,\n  author    = {},\n  title     = {},\n  journal   = {},\n  volume    = {},\n  year      = {},\n  url       = {},\n  doi       = {},\n  biburl    = {},\n  bibsource = {}\n}", "cardData": null, "siblings": [], "_id": "652d08428fa1fbb0aad8cc05", "disabled": false, "gated": false, "likes": 0, "downloads": 790, "createdAt": "2023-10-16T09:54:10.000Z"}, {"id": "cdminix/libritts-phones-and-mel", "sha": "fdbd3b637a45eb8589a483c91cabe8e33ca3f2f1", "lastModified": "2023-10-24T08:06:13.000Z", "tags": ["task_categories:text-to-speech", "size_categories:100K<n<1M", "language:en", "license:cc-by-4.0", "region:us"], "private": false, "author": "cdminix", "description": "Dataset containing Mel Spectrograms, Prosody and Phone Alignments for the LibriTTS dataset.", "citation": "@inproceedings{48008,\ntitle\t= {LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech},\nauthor\t= {Heiga Zen and Rob Clark and Ron J. Weiss and Viet Dang and Ye Jia and Yonghui Wu and Yu Zhang and Zhifeng Chen},\nyear\t= {2019},\nURL\t= {https://arxiv.org/abs/1904.02882},\nbooktitle\t= {Interspeech}\n}", "cardData": null, "siblings": [], "_id": "652dfad74f4fec02a7758838", "disabled": false, "gated": false, "likes": 0, "downloads": 522, "createdAt": "2023-10-17T03:09:11.000Z"}, {"id": "philipphager/baidu-ultr", "sha": "82707680e939bf9f553edcd9d4605b1275406fb4", "lastModified": "2023-11-14T14:23:38.000Z", "tags": ["task_categories:text-retrieval", "license:cc-by-nc-4.0", "MonoBERT", "unbiased learning to rank", "ultr", "baidu", "ltr", "clicks", "region:us"], "private": false, "author": "philipphager", "description": "Query-document vectors and clicks for the Baidu Unbiased Learning to Rank dataset used\nat the WSDM23 cup. This dataset uses the winning BERT cross-encoder from Tencent\nto compute query-document vectors (768 dims), mainly for ease of use and to enable\nusage of simpler, smaller neural networks that are more common in ULTR research.\n\nThis dataset contains features for part-00000.gz and part-00001.gz of the Baidu dataset.", "citation": "@InProceedings{huggingface:dataset,\n    title = {baidu-ultr-606k},\n    author={Philipp Hager},\n    year={2023}\n}", "cardData": null, "siblings": [], "_id": "652ea3855d91b1c2956bfb11", "disabled": false, "gated": false, "likes": 2, "downloads": 2044, "createdAt": "2023-10-17T15:08:53.000Z"}, {"id": "bigainlco/LooGLE", "sha": "3249f4cf5acd70f3de94892a2ee709703839a92e", "lastModified": "2023-11-15T08:37:49.000Z", "tags": ["task_categories:question-answering", "task_categories:summarization", "task_categories:text-generation", "task_categories:fill-mask", "language:en", "language:zh", "license:cc-by-sa-4.0", "Long Context", "region:us"], "private": false, "author": "bigainlco", "description": "LooGLE is a comprehensive evaluation benchmark for LLM long context understanding which contains up-to-date (all after 2022) and extreme long realistic documents (over 24k tokens per document, many of which are exceeding 100k words) from diverse domains and categories.", "citation": null, "cardData": null, "siblings": [], "_id": "653321b0dea545ecda6658a1", "disabled": false, "gated": false, "likes": 3, "downloads": 330, "createdAt": "2023-10-21T00:56:16.000Z"}, {"id": "kogi-jwu/jhumaneval", "sha": "c5dd1d09f473219f1d2c67296a706a3be7ec08bc", "lastModified": "2023-10-21T08:59:12.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "kogi-jwu", "description": "This is a Japanese translated version of HumanEval, an evaluation harness for the HumanEval problem solving dataset described in the paper \"Evaluating Large Language Models Trained on Code\".", "citation": null, "cardData": null, "siblings": [], "_id": "653389bed690f3012e15acff", "disabled": false, "gated": false, "likes": 2, "downloads": 16, "createdAt": "2023-10-21T08:20:14.000Z"}, {"id": "pranjalipathre/pybullet_img2img", "sha": "8c5bf922ee712ff96e305719a7ea24f701122abe", "lastModified": "2023-11-20T23:48:03.000Z", "tags": ["region:us"], "private": false, "author": "pranjalipathre", "description": "The dataset img2img data.", "citation": null, "cardData": null, "siblings": [], "_id": "65358b343f4248157d509d8a", "disabled": false, "gated": false, "likes": 0, "downloads": 36, "createdAt": "2023-10-22T20:51:00.000Z"}, {"id": "jtz18/DocTamper", "sha": "d216585081d620e65fdbcba6017d8e4ef7133cc8", "lastModified": "2023-10-24T17:56:19.000Z", "tags": ["task_categories:image-segmentation", "size_categories:n<1K", "language:en", "license:apache-2.0", "region:us"], "private": false, "author": "jtz18", "description": "This dataset was designed to train models to determine image tampering on documents.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "653803c445fda4ca8c0f91a5", "disabled": false, "gated": false, "likes": 0, "downloads": 49, "createdAt": "2023-10-24T17:49:56.000Z"}, {"id": "togethercomputer/RedPajama-Data-V2", "sha": "04e7975027e5f2110bad2e9d6f17ba0bfafe8f57", "lastModified": "2023-11-16T16:03:58.000Z", "tags": ["task_categories:text-generation", "language:en", "language:de", "language:fr", "language:es", "language:it", "arxiv:2302.03169", "arxiv:2302.13971", "arxiv:2204.02311", "arxiv:2112.06905", "arxiv:1910.10683", "arxiv:2305.13169", "arxiv:2306.01116", "arxiv:2112.11446", "region:us"], "private": false, "author": "togethercomputer", "description": "RedPajama V2: an Open Dataset for Training Large Language Models", "citation": null, "cardData": null, "siblings": [], "_id": "6539bda9e279d2fc80bfc994", "disabled": false, "gated": false, "likes": 198, "downloads": 1287979, "createdAt": "2023-10-26T01:15:21.000Z"}, {"id": "didsr/msynth", "sha": "0bf62a7e21f6576b152c2ce901f9b8c5e08234e1", "lastModified": "2023-11-16T21:48:34.000Z", "tags": ["task_categories:image-classification", "task_categories:image-segmentation", "size_categories:10K<n<100K", "license:cc0-1.0", "medical", "arxiv:2310.18494", "region:us"], "private": false, "author": "didsr", "description": "M-SYNTH is a synthetic digital mammography (DM) dataset with four breast fibroglandular density distributions imaged using Monte Carlo x-ray simulations with the publicly available Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit.\nCurated by: Elena Sizikova, Niloufar Saharkhiz, Diksha Sharma, Miguel Lago, Berkman Sahiner, Jana Gut Delfino, Aldo Badano\nLicense: Creative Commons 1.0 Universal License (CC0)", "citation": "@article{sizikova2023knowledge,\n  title={Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses},\n  author={Sizikova, Elena and Saharkhiz, Niloufar and Sharma, Diksha and Lago, Miguel and Sahiner, Berkman and Delfino, Jana G. and Badano, Aldo},\n  journal={Advances in Neural Information Processing Systems},\n  volume={},\n  pages={16764--16778},\n  year={2023}", "cardData": null, "siblings": [], "_id": "653adae7e707e8a1ce0f1dcc", "disabled": false, "gated": false, "likes": 3, "downloads": 123, "createdAt": "2023-10-26T21:32:23.000Z"}, {"id": "chriamue/bird-species-dataset", "sha": "c0144eee206ba31f965df45948898c9afba85933", "lastModified": "2023-11-12T10:46:34.000Z", "tags": ["task_categories:image-classification", "task_ids:multi-class-image-classification", "size_categories:1K<n<10K", "language:en", "license:cc0-1.0", "biology", "region:us"], "private": false, "author": "chriamue", "description": "A dataset of bird species downloaded from kaggle.", "citation": "@TECHREPORT{gpiosenka/100-bird-species,\n    author = {gpiosenka},\n    title = {BIRDS 525 SPECIES- IMAGE CLASSIFICATION},\n    institution = {},\n    year = {2023}\n}", "cardData": null, "siblings": [], "_id": "653e23d36217d355c6959b35", "disabled": false, "gated": false, "likes": 0, "downloads": 188, "createdAt": "2023-10-29T09:20:19.000Z"}, {"id": "audioshake/jam-alt", "sha": "c85dae13ea547253279bee95e34903a9c9c07bed", "lastModified": "2023-11-17T14:46:11.000Z", "tags": ["task_categories:automatic-speech-recognition", "multilinguality:multilingual", "language:en", "language:fr", "language:de", "language:es", "music", "lyrics", "evaluation", "benchmark", "transcription", "doi:10.57967/hf/1340", "region:us"], "private": false, "author": "audioshake", "description": "Jam-ALT: A formatting-aware lyrics transcription benchmark.", "citation": "@inproceedings{cifka-2023-jam-alt,\n  author       = {Ond\\v{r}ej C\\'ifka and\n                  Constantinos Dimitriou and\n                  {Cheng-i} Wang and\n                  Hendrik Schreiber and\n                  Luke Miner and\n                  Fabian-Robert St\\\"oter},\n  title        = {{Jam-ALT}: A Formatting-Aware Lyrics Transcription Benchmark},\n  booktitle    = {Extended Abstracts for the Late-Breaking Demo Session of the 24th\n                  International Society for Music Information Retrieval Conference},\n  year         = 2023,\n  publisher    = {ISMIR},\n  month        = nov,\n  venue        = {Milan, Italy}\n}", "cardData": null, "siblings": [], "_id": "653e3c40885338b011eaea5a", "disabled": false, "gated": false, "likes": 5, "downloads": 225, "createdAt": "2023-10-29T11:04:32.000Z"}, {"id": "princeton-nlp/LLMBar", "sha": "e14faa6075657d8b38ba71cdf67dc2af01a13cb4", "lastModified": "2023-10-29T15:35:34.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "princeton-nlp", "description": "LLMBar is a challenging meta-evaluation benchmark designed to test the ability of an LLM evaluator in discerning instruction-following outputs. LLMBar consists of 419 instances, where each entry contains an instruction paired with two outputs: one faithfully and correctly follows the instruction and the other deviates from it. There is also a gold preference label indicating which output is objectively better for each instance.", "citation": "@article{zeng2023llmbar,\n  title={Evaluating Large Language Models at Evaluating Instruction Following},\n  author={Zeng, Zhiyuan and Yu, Jiatong and Gao, Tianyu and Meng, Yu and Goyal, Tanya and Chen, Danqi},\n  journal={arXiv preprint arXiv:2310.07641},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "653e7bb6ec992c5c20871f33", "disabled": false, "gated": false, "likes": 0, "downloads": 48, "createdAt": "2023-10-29T15:35:18.000Z"}, {"id": "Otter-AI/ScienceQA", "sha": "8a62869d607e217c78ef7c9398505d2e151b4224", "lastModified": "2023-10-30T17:01:43.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "Otter-AI", "description": "ZOOM IN BENCH DESCRIPTION", "citation": "@article{li2023mimicit,\n    title={MIMIC-IT: Multi-Modal In-Context Instruction Tuning},\n    author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},\n    year={2023},\n    eprint={2306.05425},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "653f9a66f2312a3b3c72cbc6", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2023-10-30T11:58:30.000Z"}, {"id": "dwadden/covidfact_entailment", "sha": "79ff87b915bef763ec63f3f26603340b6b2770b0", "lastModified": "2023-10-31T00:33:56.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-2.0", "region:us"], "private": false, "author": "dwadden", "description": "COVID-FACT is a dataset of claims about COVID-19. For this version of the dataset, we follow the preprocessing from the MultiVerS modeling paper https://github.com/dwadden/multivers, verifying claims against abstracts of scientific research articles. Entailment labels and rationales are included.", "citation": "@article{Saakyan2021COVIDFactFE,\n  title={COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic},\n  author={Arkadiy Saakyan and Tuhin Chakrabarty and Smaranda Muresan},\n  journal={ArXiv},\n  year={2021},\n  volume={abs/2106.03794},\n  url={https://api.semanticscholar.org/CorpusID:235364036}\n}", "cardData": null, "siblings": [], "_id": "65402db35d60444d17be6793", "disabled": false, "gated": false, "likes": 0, "downloads": 89, "createdAt": "2023-10-30T22:26:59.000Z"}, {"id": "dwadden/healthver_entailment", "sha": "974bddec36fe28f4c914ab971c959190615490cf", "lastModified": "2023-10-31T00:37:09.000Z", "tags": ["task_categories:text-classification", "task_ids:fact-checking", "annotations_creators:expert-generated", "language_creators:found", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "language:en", "license:cc-by-nc-2.0", "region:us"], "private": false, "author": "dwadden", "description": "HealthVer is a dataset of public health claims, verified against scientific research articles. For this version of the dataset, we follow the preprocessing from the MultiVerS modeling paper https://github.com/dwadden/multivers, verifying claims against full article abstracts rather than individual sentences. Entailment labels and rationales are included.", "citation": "@inproceedings{Sarrouti2021EvidencebasedFO,\n    title={Evidence-based Fact-Checking of Health-related Claims},\n    author={Mourad Sarrouti and Asma Ben Abacha and Yassine Mrabet and Dina Demner-Fushman},\n    booktitle={Conference on Empirical Methods in Natural Language Processing},\n    year={2021},\n    url={https://api.semanticscholar.org/CorpusID:244119074}\n}", "cardData": null, "siblings": [], "_id": "65402dc0eddfff043533ae94", "disabled": false, "gated": false, "likes": 0, "downloads": 98, "createdAt": "2023-10-30T22:27:12.000Z"}, {"id": "ugursahin/gnm_dataset", "sha": "c1e42d8c82325bac2b10e82c42bd01d055aa0bdb", "lastModified": "2023-11-03T16:45:49.000Z", "tags": ["region:us"], "private": false, "author": "ugursahin", "description": "This dataset consists of 278", "citation": "@inproceedings{\n}", "cardData": null, "siblings": [], "_id": "6542ebd34a68d5aeba56ce49", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2023-11-02T00:22:43.000Z"}, {"id": "minnnnn/test", "sha": "c8f23b2d0f5957e93307b33d91223131afef237a", "lastModified": "2023-11-03T05:45:07.000Z", "tags": ["region:us"], "private": false, "author": "minnnnn", "description": "This is a dataset that image data and caption txt", "citation": "@InProceedings{huggingface:dataset,\ntitle = {diffusion train set},\n}", "cardData": null, "siblings": [], "_id": "65433d275a36a8774d0b8cf2", "disabled": false, "gated": false, "likes": 0, "downloads": 98, "createdAt": "2023-11-02T06:09:43.000Z"}, {"id": "IconicAI/janet-24oct", "sha": "24e33438c3b9f0f48602443f35b330b8ea999847", "lastModified": "2023-11-17T15:21:15.000Z", "tags": ["task_categories:conversational", "region:us"], "private": false, "author": "IconicAI", "description": "39 Multi-Turn conversations generated by GPT-4.\nEach conversation represents a distinct dialogue between two people - \na sniper and a central operator called Janet.\n\nThe context of each conversation is the same - the sniper is perched on a rooftop,\non a mission to eliminate a dangerous person that's hiding in the crowd below.\nJanet knows how that person looks like and is talking the sniper through the process\nof identifying and eliminating the target.", "citation": "@misc{Janet24Oct,\n  title = {Janet: A Dataset of Multi-Turn Conversations for Conversational AI},\n  author = {Kieran Donaldson and Mikel Bober-Izar and Piotr Trochim},\n  year = {2023},\n  publisher = {HuggingFace},\n  journal = {HuggingFace repository},\n  howpublished = {\\\\url{https://huggingface.co/datasets/IconicAI/janet-24oct}},\n}", "cardData": null, "siblings": [], "_id": "6543f9828272e6b1f37b03bc", "disabled": false, "gated": false, "likes": 0, "downloads": 580, "createdAt": "2023-11-02T19:33:22.000Z"}, {"id": "sabilmakbar/indo_wiki", "sha": "7725656f60a8c21ae501c16bf56b17cb9f56c974", "lastModified": "2023-11-03T07:59:24.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "source_datasets:Wikipedia-HF", "language:ace", "language:ban", "language:bjn", "language:bug", "language:gor", "language:id", "language:jv", "language:mis", "language:min", "language:ms", "language:nia", "language:su", "language:tet", "license:cc-by-sa-3.0", "license:gfdl", "Wikipedia", "Indonesian", "Sundanese", "Javanese", "Malay", "Dialect", "Javanese Dialect (Banyumase/Ngapak)", "Indonesian Language", "Malay Language", "Indonesia-related Languages", "Indonesian Local Languages", "region:us"], "private": false, "author": "sabilmakbar", "description": "Indonesian Wikipedia Data Repository contains Wikipedia Data from Wikipedia HF that focuses\non extraction in Indonesian Languange and Indonesian Local Languages, that some of them\nare considered as low-resource languages or extremely low-resource languages", "citation": null, "cardData": null, "siblings": [], "_id": "654497fd9b639f21e1e277ed", "disabled": false, "gated": false, "likes": 0, "downloads": 62, "createdAt": "2023-11-03T06:49:33.000Z"}, {"id": "sabilmakbar/sea_wiki", "sha": "5fdddf9c6f023258a1778a9b41d3c5a9b7e395a8", "lastModified": "2023-11-12T16:10:53.000Z", "tags": ["task_categories:text-generation", "task_categories:fill-mask", "task_ids:language-modeling", "task_ids:masked-language-modeling", "annotations_creators:no-annotation", "language_creators:crowdsourced", "multilinguality:multilingual", "source_datasets:Wikipedia", "language:ace", "language:ban", "language:bcl", "language:bjn", "language:bug", "language:cbk", "language:ceb", "language:gor", "language:id", "language:ilo", "language:jv", "language:km", "language:lo", "language:mad", "language:min", "language:mnw", "language:ms", "language:my", "language:nia", "language:pag", "language:pam", "language:shn", "language:su", "language:ta", "language:th", "language:tl", "language:tet", "language:vi", "language:war", "license:cc-by-sa-4.0", "Wikipedia", "Southeast Asia (SEA)", "Dialect", "Banyumasan Dialect of Javanese (Ngapak)", "SEA-related Languages", "SEA Local Languages", "region:us"], "private": false, "author": "sabilmakbar", "description": "Southeast Asia Wikipedia Data Repository contains Wikipedia Data from Wikipedia HF that focuses\non extraction in all available Languanges and Local Languages across South East Asia, which some of them\nare considered as low-resource languages or extremely low-resource languages", "citation": null, "cardData": null, "siblings": [], "_id": "6545073afca3453b0d36f8d1", "disabled": false, "gated": false, "likes": 0, "downloads": 341, "createdAt": "2023-11-03T14:44:10.000Z"}, {"id": "andreped/AeroPath", "sha": "6d0f831ca22bf57918aba3980ae475c94d45b997", "lastModified": "2023-11-13T22:36:21.000Z", "tags": ["task_categories:image-segmentation", "size_categories:1B<n<10B", "language:en", "license:mit", "medical", "arxiv:2311.01138", "region:us"], "private": false, "author": "andreped", "description": "AeroPath: An airway segmentation benchmark dataset with challenging pathology.", "citation": "@misc{st\u00f8verud2023aeropath,\ntitle={AeroPath: An airway segmentation benchmark dataset with challenging pathology}, \nauthor={Karen-Helene St\u00f8verud and David Bouget and Andre Pedersen and H\u00e5kon Olav Leira and Thomas Lang\u00f8 and Erlend Fagertun Hofstad},\nyear={2023},\neprint={2311.01138},\narchivePrefix={arXiv},\nprimaryClass={cs.CV}\n}", "cardData": null, "siblings": [], "_id": "65456bea96c46859c2a7858a", "disabled": false, "gated": false, "likes": 4, "downloads": 103, "createdAt": "2023-11-03T21:53:46.000Z"}, {"id": "gugaio/dokki-pagamentos", "sha": "c1ebe323543cd63e07a34871a761eff110749654", "lastModified": "2023-11-22T00:59:08.000Z", "tags": ["region:us"], "private": false, "author": "gugaio", "description": "Dataset com imagens de comprovantes de pagamento e notas ficais no Brasil.", "citation": null, "cardData": null, "siblings": [], "_id": "654667f32119c8bdf25c347e", "disabled": false, "gated": false, "likes": 0, "downloads": 13, "createdAt": "2023-11-04T15:49:07.000Z"}, {"id": "St4n/self_dataset", "sha": "4da625d421c6c8e43c51d7d98a87b7c2a2c5ae0c", "lastModified": "2023-11-05T14:28:35.000Z", "tags": ["size_categories:1K<n<10K", "language:en", "region:us"], "private": false, "author": "St4n", "description": "Self Dataset is training and evaluation resource for intent\ndetection task with spoken data. It covers 14\nintents extracted from a commercial system\nin the e-banking domain, associated with spoken examples in 14 diverse language varieties.", "citation": "@article{gerz2021multilingual,\n  title={Multilingual and cross-lingual intent detection from spoken data},\n  author={Gerz, Daniela and Su, Pei-Hao and Kusztos, Razvan and Mondal, Avishek and Lis, Michal and Singhal, Eshan and Mrk{\\v{s}}i{\\'c}, Nikola and Wen, Tsung-Hsien and Vuli{\\'c}, Ivan},\n  journal={arXiv preprint arXiv:2104.08524},\n  year={2021}\n}", "cardData": null, "siblings": [], "_id": "65478cbd470b4b8b3feb1df2", "disabled": false, "gated": false, "likes": 0, "downloads": 38, "createdAt": "2023-11-05T12:38:21.000Z"}, {"id": "Ahmed-ibn-Harun/wake", "sha": "b43a38981965d39cca9b78016e5c4aede1220d89", "lastModified": "2023-11-07T20:22:23.000Z", "tags": ["size_categories:10K<n<100K", "language:en", "license:mit", "voice assistant", "region:us"], "private": false, "author": "Ahmed-ibn-Harun", "description": "Wake is training and evaluation resource for wake word\ndetection task with spoken data. It covers the wake and not wake\nintents collected from a multiple participants who agreed to contribute to the development \nof the system on the wake word and the not wake words is a subset of the common voice and speech commands dataset.", "citation": "@article{gerz2021multilingual,\n  title={Wake word data for Voice assistant trigger in English from spoken data},\n  author={Ahmed, Nicholas},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "6548d9a68db6a4761b47d15d", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2023-11-06T12:18:46.000Z"}, {"id": "hobeter/JJQA", "sha": "f815b8438ba47314961c597d196b046d05ab9ae7", "lastModified": "2023-11-06T19:30:08.000Z", "tags": ["task_categories:question-answering", "size_categories:n<1K", "license:apache-2.0", "music", "art", "region:us"], "private": false, "author": "hobeter", "description": "JJQA: a Chinese QA dataset on the lyrics of JJ Lin's songs.", "citation": "https://github.com/bebetterest/JJQA", "cardData": null, "siblings": [], "_id": "654936b7c01e5a4e8883b9f0", "disabled": false, "gated": false, "likes": 1, "downloads": 247, "createdAt": "2023-11-06T18:55:51.000Z"}, {"id": "lmqg/qg_zhquad", "sha": "3a50a143eea18d94e00af10da1b9caab7746ef65", "lastModified": "2023-11-07T16:07:33.000Z", "tags": ["task_categories:text-generation", "task_ids:language-modeling", "multilinguality:monolingual", "size_categories:10K<n<100K", "language:zh", "license:cc-by-4.0", "question-generation", "arxiv:2210.03992", "region:us"], "private": false, "author": "lmqg", "description": "[Chinese SQuAD](https://github.com/junzeng-pluto/ChineseSquad) dataset for question generation (QG) task.", "citation": "@inproceedings{ushio-etal-2022-generative,\n    title = \"{G}enerative {L}anguage {M}odels for {P}aragraph-{L}evel {Q}uestion {G}eneration\",\n    author = \"Ushio, Asahi  and\n        Alva-Manchego, Fernando  and\n        Camacho-Collados, Jose\",\n    booktitle = \"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\",\n    month = dec,\n    year = \"2022\",\n    address = \"Abu Dhabi, U.A.E.\",\n    publisher = \"Association for Computational Linguistics\",\n}", "cardData": null, "siblings": [], "_id": "654a218f3b78e73b439a71a3", "disabled": false, "gated": false, "likes": 0, "downloads": 891, "createdAt": "2023-11-07T11:37:51.000Z"}, {"id": "gdamms/ornithoscope", "sha": "0bac591349429254970600cb53237f428ec16d52", "lastModified": "2023-11-21T09:05:16.000Z", "tags": ["license:cc-by-2.0", "region:us"], "private": false, "author": "gdamms", "description": "Ornithoscope dataset is the dataset used to train the model for the Ornithoscope project.", "citation": "\"\"\"\n\n_DESCRIPTION =", "cardData": null, "siblings": [], "_id": "654a266d141d928a435e8c19", "disabled": false, "gated": false, "likes": 0, "downloads": 12, "createdAt": "2023-11-07T11:58:37.000Z"}, {"id": "Davlan/nollysenti", "sha": "cde9296418e5db3d59b2222f06733a7d87d1b0d8", "lastModified": "2023-11-07T15:04:30.000Z", "tags": ["license:afl-3.0", "region:us"], "private": false, "author": "Davlan", "description": "NollySenti is the first publicly available dataset for movie sentiment classification in five Nigerian languages.\n\nThe languages are:\n- English (eng)\n- Hausa (hau)\n- Igbo (ibo)\n- Nigerian Pidgin (pcm)\n- Yor\u00f9b\u00e1 (yor)\n\nThe train/validation/test sets are available for all the five languages.\n\nFor more details see *** arXiv link **", "citation": "@inproceedings{shode-etal-2023-nollysenti,\n    title = \"{N}olly{S}enti: Leveraging Transfer Learning and Machine Translation for {N}igerian Movie Sentiment Classification\",\n    author = \"Shode, Iyanuoluwa  and\n      Adelani, David Ifeoluwa  and\n      Peng, JIng  and\n      Feldman, Anna\",\n    editor = \"Rogers, Anna  and\n      Boyd-Graber, Jordan  and\n      Okazaki, Naoaki\",\n    booktitle = \"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = jul,\n    year = \"2023\",\n    address = \"Toronto, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.acl-short.85\",\n    doi = \"10.18653/v1/2023.acl-short.85\",\n    pages = \"986--998\",\n    abstract = \"Africa has over 2000 indigenous languages but they are under-represented in NLP research due to lack of datasets. In recent years, there have been progress in developing labelled corpora for African languages. However, they are often available in a single domain and may not generalize to other domains. In this paper, we focus on the task of sentiment classification for cross-domain adaptation. We create a new dataset, Nollywood movie reviews for five languages widely spoken in Nigeria (English, Hausa, Igbo, Nigerian Pidgin, and Yoruba). We provide an extensive empirical evaluation using classical machine learning methods and pre-trained language models. By leveraging transfer learning, we compare the performance of cross-domain adaptation from Twitter domain, and cross-lingual adaptation from English language. Our evaluation shows that transfer from English in the same target domain leads to more than 5{\\%} improvement in accuracy compared to transfer from Twitter in the same language. To further mitigate the domain difference, we leverage machine translation from English to other Nigerian languages, which leads to a further improvement of 7{\\%} over cross-lingual evaluation. While machine translation to low-resource languages are often of low quality, our analysis shows that sentiment related words are often preserved.\",\n}", "cardData": null, "siblings": [], "_id": "654a48cfdff2f49007c4f3b5", "disabled": false, "gated": false, "likes": 0, "downloads": 20, "createdAt": "2023-11-07T14:25:19.000Z"}, {"id": "andyw0lf/mmlu-id", "sha": "75bfada2eacc9e68207a37cd0def679832f30c25", "lastModified": "2023-11-14T08:36:38.000Z", "tags": ["region:us"], "private": false, "author": "andyw0lf", "description": "MMLU-id is a translated version of cais mmlu.", "citation": null, "cardData": null, "siblings": [], "_id": "654b3b91407c209b6159aceb", "disabled": false, "gated": false, "likes": 0, "downloads": 2758, "createdAt": "2023-11-08T07:41:05.000Z"}, {"id": "lyon-nlp/alloprof", "sha": "3e394f99549416c102c44af9b38460d0d07fa10f", "lastModified": "2023-11-09T15:22:40.000Z", "tags": ["task_categories:text-classification", "task_categories:question-answering", "size_categories:1K<n<10K", "language:fr", "arxiv:2302.07738", "arxiv:2210.07316", "region:us"], "private": false, "author": "lyon-nlp", "description": "This is a re-edit from the Alloprof dataset (which can be found here : https://huggingface.co/datasets/antoinelb7/alloprof).\n\nFor more information about the data source and the features, please refer to the original dataset card made by the authors, along with their paper available here : https://arxiv.org/abs/2302.07738\n\nThis re-edition of the dataset has been made for easier usage in the MTEB benchmarking pipeline. (https://huggingface.co/spaces/mteb/leaderboard). It is a filtered version of the original dataset, in a more ready-to-use format.", "citation": "@misc{lef23,\n  doi = {10.48550/ARXIV.2302.07738},\n  url = {https://arxiv.org/abs/2302.07738},\n  author = {Lefebvre-Brossard, Antoine and Gazaille, Stephane and Desmarais, Michel C.},\n  keywords = {Computation and Language (cs.CL), Information Retrieval (cs.IR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n  title = {Alloprof: a new French question-answer education dataset and its use in an information retrieval case study},\n  publisher = {arXiv},\n  year = {2023},\n  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}\n}", "cardData": null, "siblings": [], "_id": "654bbb2d1d813c433af4d4d6", "disabled": false, "gated": false, "likes": 2, "downloads": 29, "createdAt": "2023-11-08T16:45:33.000Z"}, {"id": "5roop/xlm-r-bertic-data", "sha": "f3c6e0a922aad0811a7426a8be7f8a655883c039", "lastModified": "2023-11-10T11:35:52.000Z", "tags": ["license:cc-by-sa-4.0", "region:us"], "private": false, "author": "5roop", "description": "Data used to train XLM-Roberta-Berti\u0107.", "citation": null, "cardData": null, "siblings": [], "_id": "654cc665d5c6faa9e38689e5", "disabled": false, "gated": false, "likes": 0, "downloads": 19, "createdAt": "2023-11-09T11:45:41.000Z"}, {"id": "shunk031/PubLayNet", "sha": "d253280713ca9cded3861ee49787302fc511aabd", "lastModified": "2023-11-09T13:09:05.000Z", "tags": ["task_categories:image-classification", "task_categories:image-segmentation", "task_categories:image-to-text", "task_categories:question-answering", "task_categories:other", "task_categories:multiple-choice", "task_categories:token-classification", "task_categories:tabular-to-text", "task_categories:object-detection", "task_categories:table-question-answering", "task_categories:text-classification", "task_categories:table-to-text", "task_ids:multi-label-image-classification", "task_ids:multi-class-image-classification", "task_ids:semantic-segmentation", "task_ids:image-captioning", "task_ids:extractive-qa", "task_ids:closed-domain-qa", "task_ids:multiple-choice-qa", "task_ids:named-entity-recognition", "annotations_creators:machine-generated", "language_creators:found", "multilinguality:monolingual", "source_datasets:original", "language:en", "license:cdla-permissive-1.0", "graphic design", "layout-generation", "arxiv:1908.07836", "region:us"], "private": false, "author": "shunk031", "description": "PubLayNet is a dataset for document layout analysis. It contains images of research papers and articles and annotations for various elements in a page such as \"text\", \"list\", \"figure\" etc in these research paper images. The dataset was obtained by automatically matching the XML representations and the content of over 1 million PDF articles that are publicly available on PubMed Central.", "citation": "@inproceedings{zhong2019publaynet,\n  title={Publaynet: largest dataset ever for document layout analysis},\n  author={Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},\n  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},\n  pages={1015--1022},\n  year={2019},\n  organization={IEEE}\n}", "cardData": null, "siblings": [], "_id": "654cd84d8fb54824b09e5d66", "disabled": false, "gated": false, "likes": 0, "downloads": 59, "createdAt": "2023-11-09T13:02:05.000Z"}, {"id": "andreped/LyNoS", "sha": "ebb76a93ed171db4f37d13e5c8312e0a3fcdbedb", "lastModified": "2023-11-15T13:11:19.000Z", "tags": ["task_categories:image-segmentation", "size_categories:1B<n<10B", "language:en", "license:mit", "medical", "region:us"], "private": false, "author": "andreped", "description": "LyNoS: Mediastinal lymph nodes segmentation using 3D convolutional neural network ensembles and anatomical priors guiding.", "citation": "@article{bouget2023mediastinal,\n  title={Mediastinal lymph nodes segmentation using 3D convolutional neural network ensembles and anatomical priors guiding},\n  author={Bouget, David and Pedersen, Andr{\\'e} and Vanel, Johanna and Leira, Haakon O and Lang{\\o}, Thomas},\n  journal={Computer Methods in Biomechanics and Biomedical Engineering: Imaging \\& Visualization},\n  volume={11},\n  number={1},\n  pages={44--58},\n  year={2023},\n  publisher={Taylor \\& Francis}\n}", "cardData": null, "siblings": [], "_id": "654d3483636d5f1b8898a73d", "disabled": false, "gated": false, "likes": 4, "downloads": 17, "createdAt": "2023-11-09T19:35:31.000Z"}, {"id": "michaljunczyk/pl-asr-bigos-v2", "sha": "d51a81f3b09376bbc45211be325a94f7ff384e0e", "lastModified": "2023-11-16T07:18:15.000Z", "tags": ["task_categories:automatic-speech-recognition", "annotations_creators:crowdsourced", "annotations_creators:expert-generated", "annotations_creators:other", "annotations_creators:machine-generated", "language_creators:crowdsourced", "language_creators:expert-generated", "language_creators:other", "multilinguality:monolingual", "size_categories:1K<n<10K", "source_datasets:original", "source_datasets:extended|common_voice", "source_datasets:extended|multilingual_librispeech", "source_datasets:extended|minds14", "language:pl", "license:cc-by-sa-4.0", "benchmark", "polish", "asr", "speech", "region:us"], "private": false, "author": "michaljunczyk", "description": "BIGOS (Benchmark Intended Grouping of Open Speech) dataset goal is to simplify access to the openly available Polish speech corpora and\nenable systematic benchmarking of open and commercial Polish ASR systems.", "citation": "@InProceedings{huggingface:dataset,\ntitle = {A great new dataset},\nauthor={huggingface, Inc.\n},\nyear={2020}\n}", "cardData": null, "siblings": [], "_id": "654e6c78a568100364f9121b", "disabled": false, "gated": false, "likes": 0, "downloads": 552, "createdAt": "2023-11-10T17:46:32.000Z"}, {"id": "zilu-peter-tang/MultiPL-C2C", "sha": "7863e656254287fe0bfe09cb39fc0a2cb4c91cfd", "lastModified": "2023-11-13T12:55:33.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "zilu-peter-tang", "description": "MultiPL-C2C is a dataset for evaluating large language models for code translation that supports 19 programming languages. It uses MultiPL-E benchmark(which takes from OpenAI \"HumanEval\" and the MBPP Python benchmarks and uses little compilers to translate them to other languages) and repurpose the natural language to code generation task to code-to-code translation task.", "citation": "@inproceedings{tang2023explain,\n  title={Explain-then-Translate: An Analysis on Improving Program Translation with Self-generated Explanations},\n  author={Tang, Zilu and Agarwal, Mayank and Shypula, Alex and Wang, Bailin and Wijaya, Derry and Chen, Jie and Kim, Yoon},\n  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},\n  year={2023},\n  url={https://aclanthology.org/2023.findings-emnlp.196/}\n}\n}", "cardData": null, "siblings": [], "_id": "654f837eaae66b1676e5e950", "disabled": false, "gated": false, "likes": 0, "downloads": 23, "createdAt": "2023-11-11T13:37:02.000Z"}, {"id": "ContextualAI/openwebtext-synthetic-testing", "sha": "ff5f0acb3b8cb0d6cedc0d6e795ebc02eae33b0c", "lastModified": "2023-11-14T07:33:00.000Z", "tags": ["license:apache-2.0", "region:us"], "private": false, "author": "ContextualAI", "description": "This dataset is designed to be used in testing. It's derived from openwebtext-10k dataset", "citation": "?", "cardData": null, "siblings": [], "_id": "6552fe49862c8d3c59a549c9", "disabled": false, "gated": false, "likes": 0, "downloads": 433, "createdAt": "2023-11-14T04:57:45.000Z"}, {"id": "universalner/universal_ner", "sha": "ece51a478c168f8ffce60dbfea1b3ac476ebaced", "lastModified": "2023-11-16T11:52:04.000Z", "tags": ["task_categories:token-classification", "language:ceb", "language:da", "language:de", "language:en", "language:hr", "language:pt", "language:ru", "language:sk", "language:sr", "language:sv", "language:tl", "language:zh", "license:cc-by-sa-4.0", "arxiv:2311.09122", "region:us"], "private": false, "author": "universalner", "description": "Universal Named Entity Recognition (UNER) aims to fill a gap in multilingual NLP: high quality NER datasets in many languages with a shared tagset.\n\nUNER is modeled after the Universal Dependencies project, in that it is intended to be a large community annotation effort with language-universal guidelines. Further, we use the same text corpora as Universal Dependencies.", "citation": null, "cardData": null, "siblings": [], "_id": "6554e32a1c523d26012b9e12", "disabled": false, "gated": false, "likes": 4, "downloads": 15, "createdAt": "2023-11-15T15:26:34.000Z"}, {"id": "qbo-odp/MNBVC-core", "sha": "4fd0f0291035b178b562abd6a85160c1a47a91e6", "lastModified": "2023-11-17T13:37:56.000Z", "tags": ["region:us"], "private": false, "author": "qbo-odp", "description": "MNBVC-core: core split of Massive Never-ending BT Vast Chinese corpus", "citation": "\\", "cardData": null, "siblings": [], "_id": "65571b99f062c53d55718c30", "disabled": false, "gated": false, "likes": 0, "downloads": 59, "createdAt": "2023-11-17T07:51:53.000Z"}, {"id": "hiendang7613/fcv_dataset", "sha": "c4a3e2b4faba0367f8d8b7a41bb3ccd6b3c4ff16", "lastModified": "2023-11-20T14:26:15.000Z", "tags": ["region:us"], "private": false, "author": "hiendang7613", "description": "CV Fujinet NER Dataset", "citation": "@InProceedings{huggingface:dataset,\n  title = {CV Fujinet NER Dataset},\n  author={Fujinet, Inc.},\n  year={2023}\n}", "cardData": null, "siblings": [], "_id": "65576443dd1c09639222e2ee", "disabled": false, "gated": false, "likes": 0, "downloads": 170, "createdAt": "2023-11-17T13:01:55.000Z"}, {"id": "Ransaka/SinhalaASR", "sha": "3fb1a27a10e9cc18eef78113c929364bf0a0a1b6", "lastModified": "2023-11-20T09:16:06.000Z", "tags": ["size_categories:100K<n<1M", "language:si", "region:us"], "private": false, "author": "Ransaka", "description": "This data set contains transcribed audio data for Sinhala. The data set consists of wave files, and a TSV file. The file utt_spk_text.tsv contains a FileID, anonymized UserID and the transcription of audio in the file.\nThe data set has been manually quality checked, but there might still be errors.", "citation": "  @inproceedings{kjartansson-etal-sltu2018,\n    title = {{Crowd-Sourced Speech Corpora for Javanese, Sundanese,  Sinhala, Nepali, and Bangladeshi Bengali}},\n    author = {Oddur Kjartansson and Supheakmungkol Sarin and Knot Pipatsrisawat and Martin Jansche and Linne Ha},\n    booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\n    year  = {2018},\n    address = {Gurugram, India},\n    month = aug,\n    pages = {52--55},\n    URL   = {http://dx.doi.org/10.21437/SLTU.2018-11}\n  }", "cardData": null, "siblings": [], "_id": "65597e656412aaeed657ed73", "disabled": false, "gated": false, "likes": 0, "downloads": 40, "createdAt": "2023-11-19T03:17:57.000Z"}, {"id": "jherng/xd-violence", "sha": "2c36fff902273573696712cf8d420bd4b0842c95", "lastModified": "2023-11-20T16:41:58.000Z", "tags": ["license:mit", "region:us"], "private": false, "author": "jherng", "description": "Dataset for the paper \"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\". The dataset is downloaded from the authors' website (https://roc-ng.github.io/XD-Violence/). Hosting this dataset on HuggingFace is just to make it easier for my own project to use this dataset. Please cite the original paper if you use this dataset.", "citation": "@inproceedings{Wu2020not,\n    title={Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision},\n    author={Wu, Peng and Liu, jing and Shi, Yujia and Sun, Yujia and Shao, Fangtao and Wu, Zhaoyang and Yang, Zhiwei},\n    booktitle={European Conference on Computer Vision (ECCV)},\n    year={2020}\n}", "cardData": null, "siblings": [], "_id": "6559e90b23e43ac218db8c75", "disabled": false, "gated": false, "likes": 0, "downloads": 48, "createdAt": "2023-11-19T10:52:59.000Z"}, {"id": "iahlt/UD_Hebrew-IAHLTwiki", "sha": "186c8282c499e2937c250c62fecfadb36351c6e0", "lastModified": "2023-11-23T20:05:08.000Z", "tags": ["task_categories:token-classification", "annotations_creators:expert-generated", "language:he", "license:cc-by-sa-4.0", "constituency-parsing", "dependency-parsing", "arxiv:2210.07873", "region:us"], "private": false, "author": "iahlt", "description": "Publicly available subset of the IAHLT UD Hebrew Treebank's Wikipedia section (https://www.iahlt.org/)", "citation": null, "cardData": null, "siblings": [], "_id": "655faf1b29e57ae2ebf50d09", "disabled": false, "gated": false, "likes": 0, "downloads": 15, "createdAt": "2023-11-23T19:59:23.000Z"}]